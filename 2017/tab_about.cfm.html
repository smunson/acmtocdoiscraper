
<div style="margin-left:10px; margin-top:10px; margin-right:10px; margin-bottom: 10px;" >

<h5 style="margin-bottom:0px; margin-top:0px" class="medium-text">Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems</h5>


<h5 class="medium-text" style="margin-bottom:10px; margin-top:10px;">Table of Contents</h5>

<div style="clear:both">
    
        <div style="margin-top:5px; margin-bottom: 10px;" class="small-text"><a href="citation.cfm?id=2858036&picked=prox&CFID=758305256&CFTOKEN=14863114" title="previous: CHI '16"><img hspace="5" align="absmiddle" border="0" src="img/prev.gif" width="19" height="11" alt="previous" />previous proceeding</a> <span style="padding-left:5px;padding-right:5px;">|</span><span class="link-text">no next proceeding</span></div>
        
</div>



 
<table class="text12" border="0">

  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Innovative Sensing</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025842&CFID=758305256&CFTOKEN=14863114">Electrick: Low-Cost Touch Sensing Using Electric Field Tomography</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Yang Zhang, Gierad Laput, Chris Harrison 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1-14</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025842" title="DOI">10.1145/3025453.3025842</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025842&ftid=1870033&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow2" style="display:inline;"><br /><div style="display:inline">Current touch input technologies are best suited for small and flat applications, such as smartphones, tablets and kiosks. In general, they are too expensive to scale to large surfaces, such as walls and furniture, and cannot provide input on objects ...</div></span>
          <span id="toHide2" style="display:none;"><br /><div style="display:inline"><p>Current touch input technologies are best suited for small and flat applications, such as smartphones, tablets and kiosks. In general, they are too expensive to scale to large surfaces, such as walls and furniture, and cannot provide input on objects having irregular and complex geometries, such as tools and toys. We introduce Electrick, a low-cost and versatile sensing technique that enables touch input on a wide variety of objects and surfaces, whether small or large, flat or irregular. This is achieved by using electric field tomography in concert with an electrically conductive material, which can be easily and cheaply added to objects and surfaces. We show that our technique is compatible with commonplace manufacturing methods, such as spray/brush coating, vacuum forming, and casting/molding enabling a wide range of possible uses and outputs. Our technique can also bring touch interactivity to rapidly fabricated objects, including those that are laser cut or 3D printed. Through a series of studies and illustrative example uses, we show that Electrick can enable new interactive opportunities on a diverse set of objects and surfaces that were previously static.</p></div></span> <a id="expcoll2" href="JavaScript: expandcollapse('expcoll2',2)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025719&CFID=758305256&CFTOKEN=14863114">GhostID: Enabling Non-Persistent User Differentiation in Frequency-Division Capacitive Multi-Touch Sensors</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Sidharth Sahdev, Clifton Forlines, Ricardo Jota, Bruno De Araujo, Braon Moseley, Jonathan Deber, Steven Sanders, Darren Leigh, Daniel Wigdor 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 15-27</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025719" title="DOI">10.1145/3025453.3025719</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025719&ftid=1870013&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow3" style="display:inline;"><br /><div style="display:inline">Current touch devices are adept at tracking finger touches, but cannot distinguish if multiple touches are caused by different fingers on a single hand, by fingers from both hands of a single user, or by different users. This limitation significantly ...</div></span>
          <span id="toHide3" style="display:none;"><br /><div style="display:inline"><p>Current touch devices are adept at tracking finger touches, but cannot distinguish if multiple touches are caused by different fingers on a single hand, by fingers from both hands of a single user, or by different users. This limitation significantly reduces the possibilities for interaction techniques in touch interfaces. We present <i>GhostID</i>, a capacitive sensor that can differentiate the origins of multiple simultaneous touches. Our approach analyzes the signal ghosting, already present as an artifact in a frequency-division touch controller, to differentiate touches from the same hand or different hands of a single user (77% reliability at 60 fps) or from two different users (95% reliability at 60 fps). In addition to <i>GhostID</i>, we also develop a framework of user-differentiation capabilities for touch input devices, and illustrate a set of interaction techniques enabled by <i>GhostID</i>.</p></div></span> <a id="expcoll3" href="JavaScript: expandcollapse('expcoll3',3)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3026004&CFID=758305256&CFTOKEN=14863114">Essence: Olfactory Interfaces for Unconscious Influence of Mood and Cognitive Performance</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Judith Amores, Pattie Maes 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 28-34</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3026004" title="DOI">10.1145/3025453.3026004</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3026004&ftid=1870014&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow4" style="display:inline;"><br /><div style="display:inline">The sense of smell is perhaps the most pervasive of all senses, but it is also one of the least understood and least exploited in HCI. We present Essence, the first olfactory computational necklace that can be remotely controlled through a smartphone ...</div></span>
          <span id="toHide4" style="display:none;"><br /><div style="display:inline"><p>The sense of smell is perhaps the most pervasive of all senses, but it is also one of the least understood and least exploited in HCI. We present Essence, the first olfactory computational necklace that can be remotely controlled through a smartphone and can vary the intensity and frequency of the released scent based on biometric or contextual data. This paper discusses the role of smell in designing pervasive systems that affect one's mood and cognitive performance while being asleep or awake. We present a set of applications for this type of technology as well as the implementation of the olfactory display and the supporting software. We also discuss the results of an initial test of the prototype that show the robustness and usability of Essence while wearing it for long periods of time in multiple environments.</p></div></span> <a id="expcoll4" href="JavaScript: expandcollapse('expcoll4',4)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025793&CFID=758305256&CFTOKEN=14863114">Group Touch: Distinguishing Tabletop Users in Group Settings via Statistical Modeling of Touch Pairs</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Abigail C. Evans, Katie Davis, James Fogarty, Jacob O. Wobbrock 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 35-47</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025793" title="DOI">10.1145/3025453.3025793</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025793&ftid=1870005&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow5" style="display:inline;"><br /><div style="display:inline">We present Group Touch, a method for distinguishing among multiple users simultaneously interacting with a tabletop computer using only the touch information supplied by the device. Rather than tracking individual users for the duration of an ...</div></span>
          <span id="toHide5" style="display:none;"><br /><div style="display:inline"><p>We present <i>Group Touch</i>, a method for distinguishing among multiple users simultaneously interacting with a tabletop computer using only the touch information supplied by the device. Rather than tracking individual users for the duration of an activity, Group Touch <i>distinguishes</i> users from each other by modeling whether an interaction with the tabletop corresponds to either: (1) a new user, or (2) a change in users currently interacting with the tabletop. This reframing of the challenge as distinguishing users rather than tracking and identifying them allows Group Touch to support multi-user collaboration in real-world settings without custom instrumentation. Specifically, Group Touch examines pairs of touches and uses the difference in orientation, distance, and time between two touches to determine whether the same person performed both touches in the pair. Validated with field data from high-school students in a classroom setting, Group Touch distinguishes among users "in the wild" with a mean accuracy of 92.92% (SD=3.94%). Group Touch can imbue collaborative touch applications in real-world settings with the ability to distinguish among multiple users.</p></div></span> <a id="expcoll5" href="JavaScript: expandcollapse('expcoll5',5)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Interruptions and Email</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025642&CFID=758305256&CFTOKEN=14863114">What Makes Live Events Engaging on Facebook Live, Periscope, and Snapchat</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Oliver L. Haimson, John C. Tang 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 48-60</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025642" title="DOI">10.1145/3025453.3025642</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025642&ftid=1870029&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow7" style="display:inline;"><br /><div style="display:inline">Live streaming platforms bring events from all around the world to people's computing devices. We conducted a mixed methods study including interviews (N = 42) and a survey (N = 223) to understand how people currently experience events using Facebook ...</div></span>
          <span id="toHide7" style="display:none;"><br /><div style="display:inline"><p>Live streaming platforms bring events from all around the world to people's computing devices. We conducted a mixed methods study including interviews (N = 42) and a survey (N = 223) to understand how people currently experience events using Facebook Live, Periscope, and Snapchat Live Stories. We identified four dimensions that make remote event viewing engaging: immersion, immediacy, interaction, and sociality. We find that both live streams and the more curated event content found on Snapchat are immersive and immediate, yet Snapchat Live Stories enable quickly switching among different views of the event. Live streams, on the other hand, offer real time interaction and sociality in a way that Snapchat Live Stories do not. However, the interaction's impact depends on comment volume, comment content, and relationship between viewer and broadcaster. We describe how people experience events remotely using these social media, and identify design opportunities around detecting exciting content, leveraging multiple viewpoints, and enabling interactivity to create engaging user experiences for remotely participating in events.</p></div></span> <a id="expcoll7" href="JavaScript: expandcollapse('expcoll7',7)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025662&CFID=758305256&CFTOKEN=14863114">Reducing Interruptions at Work: A Large-Scale Field Study of FlowLight</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Manuela Z&#252;ger, Christopher Corley, Andr&#233; N. Meyer, Boyang Li, Thomas Fritz, David Shepherd, Vinay Augustine, Patrick Francis, Nicholas Kraft, Will Snipes 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 61-72</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025662" title="DOI">10.1145/3025453.3025662</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025662&ftid=1870006&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow8" style="display:inline;"><br /><div style="display:inline">Due to the high number and cost of interruptions at work, several approaches have been suggested to reduce this cost for knowledge workers. These approaches predominantly focus either on a manual and physical indicator, such as headphones or a closed ...</div></span>
          <span id="toHide8" style="display:none;"><br /><div style="display:inline"><p>Due to the high number and cost of interruptions at work, several approaches have been suggested to reduce this cost for knowledge workers. These approaches predominantly focus either on a manual and physical indicator, such as headphones or a closed office door, or on the automatic measure of a worker's interruptibilty in combination with a computer-based indicator. Little is known about the combination of a physical indicator with an automatic interruptibility measure and its long-term impact in the workplace. In our research, we developed the FlowLight, that combines a physical traffic-light like LED with an automatic interruptibility measure based on computer interaction data. In a large-scale and long-term field study with 449 participants from 12 countries, we found, amongst other results, that the FlowLight reduced the interruptions of participants by 46%, increased their awareness on the potential disruptiveness of interruptions and most participants never stopped using it.</p></div></span> <a id="expcoll8" href="JavaScript: expandcollapse('expcoll8',8)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025954&CFID=758305256&CFTOKEN=14863114">MyriadHub: Efficiently Scaling Personalized Email Conversations with Valet Crowdsourcing</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Nicolas Kokkalis, Chengdiao Fan, Johannes Roith, Michael S. Bernstein, Scott Klemmer 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 73-84</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025954" title="DOI">10.1145/3025453.3025954</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025954&ftid=1870016&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow9" style="display:inline;"><br /><div style="display:inline">Email has scaled our ability to communicate with large groups, but has not equivalently scaled our ability to listen and respond. For example, emailing many people for feedback requires either impersonal surveys or manual effort to hold many similar ...</div></span>
          <span id="toHide9" style="display:none;"><br /><div style="display:inline"><p>Email has scaled our ability to communicate with large groups, but has not equivalently scaled our ability to listen and respond. For example, emailing many people for feedback requires either impersonal surveys or manual effort to hold many similar conversations. To scale personalized conversations, we introduce techniques that exploit similarities across conversations to recycle relevant parts of previous conversations. These techniques reduce the authoring burden, save senders' time, and maintain recipient engagement through personalized responses. We introduce MyriadHub, a mail client where users start conversations and then crowd workers extract underlying conversational patterns and rules to accelerate responses to future similar emails. In a within-subjects experiment comparing MyriadHub to existing mass email techniques, senders spent significantly less time planning events with MyriadHub. In a second experiment comparing MyriadHub to a standard email survey, MyriadHub doubled the recipients' response rate and tripled the number of words in their responses.</p></div></span> <a id="expcoll9" href="JavaScript: expandcollapse('expcoll9',9)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025613&CFID=758305256&CFTOKEN=14863114">"If a person is emailing you, it just doesn't make sense": Exploring Changing Consumer Behaviors in Email</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Frank Bentley, Nediyana Daskalova, Nazanin Andalibi 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 85-95</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025613" title="DOI">10.1145/3025453.3025613</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025613&ftid=1870035&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow10" style="display:inline;"><br /><div style="display:inline">Much of the existing research literature on email use focuses on productivity or work settings. However, personal use of email has rarely been studied in depth. With the growth of messaging platforms being used for an increasing amount of personal communication, ...</div></span>
          <span id="toHide10" style="display:none;"><br /><div style="display:inline"><p>Much of the existing research literature on email use focuses on productivity or work settings. However, personal use of email has rarely been studied in depth. With the growth of messaging platforms being used for an increasing amount of personal communication, yet email use remaining high, we were interested in learning what Americans are using email for in their daily lives in 2016. To explore this topic, we use qualitative data from over 150 interviews with personal email users as well as quantitative data from several larger survey-based studies. We will show that personal email use is very different from what has been previously studied by workplace researchers and that daily use is largely focused on receiving and viewing B2C messages such as coupons, deals, receipts, and event notifications with personal communication over email diminished to a rarer, less-than-daily occurrence. We discuss the implications of this for the design of email and communications clients and present a design and prototype for an application that seeks to support these more frequent uses of consumer email.</p></div></span> <a id="expcoll10" href="JavaScript: expandcollapse('expcoll10',10)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Learning to be Makers</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025849&CFID=758305256&CFTOKEN=14863114">'Maker' within Constraints: Exploratory Study of Young Learners using Arduino at a High School in India</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Sowmya Somanath, Lora Oehlberg, Janette Hughes, Ehud Sharlin, Mario Costa Sousa 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 96-108</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025849" title="DOI">10.1145/3025453.3025849</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025849&ftid=1869998&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow12" style="display:inline;"><br /><div style="display:inline">Do-it-yourself (DIY) inspired activities have gained popularity as a means of creative expression and self-directed learning. However, DIY culture is difficult to implement in places with limited technology infrastructure and traditional learning cultures. ...</div></span>
          <span id="toHide12" style="display:none;"><br /><div style="display:inline"><p>Do-it-yourself (DIY) inspired activities have gained popularity as a means of creative expression and self-directed learning. However, DIY culture is difficult to implement in places with limited technology infrastructure and traditional learning cultures. Our goal is to understand how learners in such a setting react to DIY activities. We present observations from a physical computing workshop with 12 students (13-15 years old) conducted at a high school in India. We observed unique challenges for these students when tackling DIY activities: a high monetary and psychological cost to exploration, limited independent learning resources, difficulties with finding intellectual courage and assumed technical language proficiency. Our participants, however, overcome some of these challenges by adopting their own local strategies: resilience, nonverbal and verbal learning techniques, and creating documentation and fallback circuit versions. Based on our findings, we discuss a set of lessons learned about makerspaces in a context with socio-technical challenges.</p></div></span> <a id="expcoll12" href="JavaScript: expandcollapse('expcoll12',12)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025458&CFID=758305256&CFTOKEN=14863114"><i>'I Make, Therefore I Am'</i>: The Effects of Curriculum-Aligned Making on Children's Self-Identity</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Sharon Lynn Chu, Rebecca Schlegel, Francis Quek, Andrew Christy, Kaiyuan Chen 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 109-120</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025458" title="DOI">10.1145/3025453.3025458</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025458&ftid=1870051&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow13" style="display:inline;"><br /><div style="display:inline">Prior research investigating the effects of incorporating Making into educational contexts has been limited to snapshot studies. These studies however do not allow for the investigation of aspects that require longer-term development and nurture. We ...</div></span>
          <span id="toHide13" style="display:none;"><br /><div style="display:inline"><p>Prior research investigating the effects of incorporating Making into educational contexts has been limited to snapshot studies. These studies however do not allow for the investigation of aspects that require longer-term development and nurture. We present a longitudinal study that investigates the effects of Making on children's degree of science self-efficacy, identity formation as possible scientists and engineers, and academic performance in science. Designed interactions with Making technology were integrated into the science curriculum of elementary school classrooms in a public school with a high proportion of students from minority populations for a year. Results showed significant differences between the "Making classrooms" and the control classrooms, and from pre- to post-test on the students' inclination towards science. The results support the promise and potential of incorporating Making into formal schooling on the growth and long-term attitudes of children towards science and STEM in general.</p></div></span> <a id="expcoll13" href="JavaScript: expandcollapse('expcoll13',13)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025529&CFID=758305256&CFTOKEN=14863114">"It's a Bomb!" -- Material Literacy and Narratives of Making</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Sophie Landwehr Sydow, Jakob Tholander, Martin Jonsson 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 121-132</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025529" title="DOI">10.1145/3025453.3025529</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025529&ftid=1870011&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow14" style="display:inline;"><br /><div style="display:inline">This paper analyses a series of events in which a discarded box found in a garbage room is examined and taken apart in the context of a makerspace. The participants' inquiry provided a rich and multifaceted experience in various settings, including puzzle-solving, ...</div></span>
          <span id="toHide14" style="display:none;"><br /><div style="display:inline"><p>This paper analyses a series of events in which a discarded box found in a garbage room is examined and taken apart in the context of a makerspace. The participants' inquiry provided a rich and multifaceted experience in various settings, including puzzle-solving, exploring physical and digital materials, engaging people with different skills. The social engagements with and around the artifacts brought certain interpretative aspects to the fore. Situated acts of interpretation worked as ways of building a coherent narrative and a meaningful experience. In the paper, we highlight the relationship between on the one hand the subjects' skills and motivations to understand and make sense of the technology at hand which we call <i>material literacy</i>, and on the other hand the specific <i>material qualities</i> that encourage or trigger certain interpretations and experiences. The qualities we discuss are: opacity, risk, authenticity, uniqueness, age, and hybridity. This study allows us to reposition the contemporary understanding of makerspaces beyond that of being places for innovation and learning.</p></div></span> <a id="expcoll14" href="JavaScript: expandcollapse('expcoll14',14)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/bp_award.jpg" alt="Best Paper" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025887&CFID=758305256&CFTOKEN=14863114">MakerWear: A Tangible Approach to Interactive Wearable Creation for Children</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Majeed Kazemitabaar, Jason McPeak, Alexander Jiao, Liang He, Thomas Outing, Jon E. Froehlich 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 133-145</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025887" title="DOI">10.1145/3025453.3025887</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025887&ftid=1870001&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow15" style="display:inline;"><br /><div style="display:inline">Wearable construction toolkits have shown promise in broadening participation in computing and empowering users to create personally meaningful computational designs. However, these kits present a high barrier of entry for some users, particularly young ...</div></span>
          <span id="toHide15" style="display:none;"><br /><div style="display:inline"><p>Wearable construction toolkits have shown promise in broadening participation in computing and empowering users to create personally meaningful computational designs. However, these kits present a high barrier of entry for some users, particularly young children (K-6). In this paper, we introduce MakerWear, a new wearable construction kit for children that uses a tangible, modular approach to wearable creation. We describe our participatory design process, the iterative development of MakerWear, and results from single- and multi-session workshops with 32 children (ages 5-12; M=8.3 years). Our findings reveal how children engage in wearable design, what they make (and want to make), and what challenges they face. As a secondary analysis, we also explore age-related differences.</p></div></span> <a id="expcoll15" href="JavaScript: expandcollapse('expcoll15',15)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Mental Health</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025931&CFID=758305256&CFTOKEN=14863114">Self Harmony: Rethinking Hackathons to Design and Critique Digital Technologies for Those Affected by Self-Harm</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Nataly Birbeck, Shaun Lawson, Kellie Morrissey, Tim Rapley, Patrick Olivier 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 146-157</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025931" title="DOI">10.1145/3025453.3025931</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025931&ftid=1870002&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow17" style="display:inline;"><br /><div style="display:inline">In this paper we explore the opportunities, challenges and best practices around designing technologies for those affected by self-harm. Our work contributes to a growing HCI literature on mental health and wellbeing, as well as understandings of how ...</div></span>
          <span id="toHide17" style="display:none;"><br /><div style="display:inline"><p>In this paper we explore the opportunities, challenges and best practices around designing technologies for those affected by self-harm. Our work contributes to a growing HCI literature on mental health and wellbeing, as well as understandings of how to imbue appropriate value-sensitivity within the digital design process in these contexts. The first phase of our study was centred upon a hackathon during which teams of designers were asked to conceptualise and prototype digital products or services for those affected by self-harm. We discuss how value-sensitive actions and activities, including engagements with those with lived experiences of self-harm, were used to scaffold the conventional hackathon format in such a challenging context. Our approach was then extended through a series of critical engagements with clinicians and charity workers who provided appraisal of the prototypes and designs. Through analysis of these engagements we expose a number of design challenges for future HCI work that considers self-harm; moreover we offer insight into the role of stakeholder critiques in extending and rethinking hackathons as a design method in sensitive contexts.</p></div></span> <a id="expcoll17" href="JavaScript: expandcollapse('expcoll17',17)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025843&CFID=758305256&CFTOKEN=14863114">Changing Moods: How Manual Tracking by Family Caregivers Improves Caring and Family Communication</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Naomi Yamashita, Hideaki Kuzuoka, Keiji Hirata, Takashi Kudo, Eiji Aramaki, Kazuki Hattori 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 158-169</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025843" title="DOI">10.1145/3025453.3025843</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025843&ftid=1870024&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow18" style="display:inline;"><br /><div style="display:inline">Previous research on healthcare technologies has shown how health tracking promotes desired behavior changes and effective health management. However, little is known about how the family caregivers' use of tracking technologies impacts the patient-caregiver ...</div></span>
          <span id="toHide18" style="display:none;"><br /><div style="display:inline"><p>Previous research on healthcare technologies has shown how health tracking promotes desired behavior changes and effective health management. However, little is known about how the family caregivers' use of tracking technologies impacts the patient-caregiver relationship in the home. In this paper, we explore how health-tracking technologies could be designed to support family caregivers cope better with a depressed family member. Based on an interview study, we designed a simple tracking tool called Family Mood and Care Tracker (FMCT) and deployed it for six weeks in the homes of 14 family caregivers who were caring for a depressed family member. FMCT is a tracking tool designed specifically for family caregivers to record their caregiving activities and patient's conditions. Our findings demonstrate how caregivers used it to better understand the illness and cope with depressed family members. We also show how our tool improves family communication, despite the initial concerns about patient-caregiver conflicts.</p></div></span> <a id="expcoll18" href="JavaScript: expandcollapse('expcoll18',18)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025932&CFID=758305256&CFTOKEN=14863114">Modeling and Understanding Visual Attributes of Mental Health Disclosures in Social Media</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Lydia Manikonda, Munmun De Choudhury 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 170-181</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025932" title="DOI">10.1145/3025453.3025932</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025932&ftid=1870034&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow19" style="display:inline;"><br /><div style="display:inline">Content shared on social media platforms has been identified to be valuable in gaining insights into people's mental health experiences. Although there has been widespread adoption of photo-sharing platforms such as Instagram in recent years, the role ...</div></span>
          <span id="toHide19" style="display:none;"><br /><div style="display:inline"><p>Content shared on social media platforms has been identified to be valuable in gaining insights into people's mental health experiences. Although there has been widespread adoption of photo-sharing platforms such as Instagram in recent years, the role of visual imagery as a mechanism of self-disclosure is less understood. We study the nature of visual attributes manifested in images relating to mental health disclosures on Instagram. Employing computer vision techniques on a corpus of thousands of posts, we extract and examine three visual attributes: visual features (e.g., color), themes, and emotions in images. Our findings indicate the use of imagery for unique self-disclosure needs, quantitatively and qualitatively distinct from those shared via the textual modality: expressions of emotional distress, calls for help, and explicit display of vulnerability. We discuss the relationship of our findings to literature in visual sociology, in mental health self disclosure, and implications for the design of health interventions.</p></div></span> <a id="expcoll19" href="JavaScript: expandcollapse('expcoll19',19)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025784&CFID=758305256&CFTOKEN=14863114">The Social Lives of Individuals with Traumatic Brain Injury</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Jessica L. Feuston, Charlotte G. Marshall-Fricker, Anne Marie Piper 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 182-194</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025784" title="DOI">10.1145/3025453.3025784</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025784&ftid=1870007&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow20" style="display:inline;"><br /><div style="display:inline">Traumatic Brain Injury (TBI) can affect all aspects of an individual's life, including physical ability, communication, and mental health, and present chronic health conditions that persist throughout the lifespan. Although prior work documents a decrease ...</div></span>
          <span id="toHide20" style="display:none;"><br /><div style="display:inline"><p>Traumatic Brain Injury (TBI) can affect all aspects of an individual's life, including physical ability, communication, and mental health, and present chronic health conditions that persist throughout the lifespan. Although prior work documents a decrease in social interaction following brain injury, little is known about how individuals with TBI engage in social behavior during their recovery, how others in their lives participate, and how these interactions occur in both online and offline contexts. We examine these issues through an interview study involving individuals with TBI, as well as caregivers and social contacts of individuals with TBI. Our analysis identifies the concept of social re-emergence, a non-linear process of developing a new social identity that involves withdrawing from social life, developing goals for social participation, disclosing health information for social support and acceptance, and attaining social independence.</p></div></span> <a id="expcoll20" href="JavaScript: expandcollapse('expcoll20',20)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Perceptions of Visualizations</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025467&CFID=758305256&CFTOKEN=14863114">User-Guided Synthesis of Interactive Diagrams</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          John Sarracino, Odaris Barrios-Arciga, Jasmine Zhu, Noah Marcus, Sorin Lerner, Ben Wiedermann 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 195-207</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025467" title="DOI">10.1145/3025453.3025467</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025467&ftid=1870030&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow22" style="display:inline;"><br /><div style="display:inline">Interactive diagrams are expensive to build, requiring significant programming experience. The cost of building such diagrams often prevents novice programmers or non-programmers from doing so. In this paper, we present user-guided techniques that transform ...</div></span>
          <span id="toHide22" style="display:none;"><br /><div style="display:inline"><p>Interactive diagrams are expensive to build, requiring significant programming experience. The cost of building such diagrams often prevents novice programmers or non-programmers from doing so. In this paper, we present user-guided techniques that transform a static diagram into an interactive one without requiring the user to write code. We also present a tool called EDDIE that prototypes these techniques. We evaluate EDDIE through: (1) a case study in which we use EDDIE to implement existing real-world diagrams from the literature and (2) a usability session with target users in which subjects build several diagrams in EDDIE and provide feedback on EDDIE's user experience. Our experiments demonstrate that EDDIE is usable and expressive, and that EDDIE enables real-world diagrams to be implemented without requiring programming expertise.</p></div></span> <a id="expcoll22" href="JavaScript: expandcollapse('expcoll22',22)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025984&CFID=758305256&CFTOKEN=14863114">Peripheral Popout: The Influence of Visual Angle and Stimulus Intensity on Popout Effects</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Carl Gutwin, Andy Cockburn, Ashley Coveney 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 208-219</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025984" title="DOI">10.1145/3025453.3025984</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025984&ftid=1870039&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow23" style="display:inline;"><br /><div style="display:inline">By exploiting visual popout effects, interface designers can rapidly draw a user's attention to salient information objects in a display. A variety of different visual stimuli can be used to achieve popout effects, including color, shape, size, motion, ...</div></span>
          <span id="toHide23" style="display:none;"><br /><div style="display:inline"><p>By exploiting visual popout effects, interface designers can rapidly draw a user's attention to salient information objects in a display. A variety of different visual stimuli can be used to achieve popout effects, including color, shape, size, motion, luminance, and flashing. However, there is a lack of understanding about how accurately different intensities of these effects support popout, particularly as targets move further from the center of the visual field. We therefore conducted a study to examine the accuracy of popout target identification using different visual variables, each at five different levels of intensity, and at a wide range of angles from the display center. Results show that motion is a strong popout stimulus, even at low intensities and wide angles. Identification accuracy decreases rapidly across visual angle with other popout stimuli, particularly with shape and color. The findings have relevance to a wide variety of applications, particularly as multi-display desktop environments increase in size and visual extent.</p></div></span> <a id="expcoll23" href="JavaScript: expandcollapse('expcoll23',23)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025834&CFID=758305256&CFTOKEN=14863114">Attention Allocation Aid for Visual Search</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Arturo Deza, Jeffrey R. Peters, Grant S. Taylor, Amit Surana, Miguel P. Eckstein 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 220-231</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025834" title="DOI">10.1145/3025453.3025834</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025834&ftid=1870042&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow24" style="display:inline;"><br /><div style="display:inline">This paper outlines the development and testing of a novel, feedback-enabled attention allocation aid (AAAD), which uses real-time physiological data to improve human performance in a realistic sequential visual search task. Indeed, by optimizing ...</div></span>
          <span id="toHide24" style="display:none;"><br /><div style="display:inline"><p>This paper outlines the development and testing of a novel, feedback-enabled <i>attention allocation aid (AAAD)</i>, which uses real-time physiological data to improve human performance in a realistic sequential visual search task. Indeed, by optimizing over search duration, the aid improves efficiency, while preserving decision accuracy, as the operator identifies and classifies targets within simulated aerial imagery. Specifically, using experimental eye-tracking data and measurements about target detectability across the human visual field, we develop functional models of detection accuracy as a function of search time, number of eye movements, scan path, and image clutter. These models are then used by the AAAD in conjunction with real time eye position data to make probabilistic estimations of attained search accuracy and to recommend that the observer either move on to the next image or continue exploring the present image. An experimental evaluation in a scenario motivated from human supervisory control in surveillance missions confirms the benefits of the AAAD.</p></div></span> <a id="expcoll24" href="JavaScript: expandcollapse('expcoll24',24)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Targets and Paths</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025836&CFID=758305256&CFTOKEN=14863114">Steering Through Sequential Linear Path Segments</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Shota Yamanaka, Wolfgang Stuerzlinger, Homei Miyashita 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 232-243</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025836" title="DOI">10.1145/3025453.3025836</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025836&ftid=1870031&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow26" style="display:inline;"><br /><div style="display:inline">The steering law models human motor performance and has been verified to hold for a single linear and/or circular path. Some extensions investigated steering around corners. Yet, little is known about human performance in navigating joined linear paths, ...</div></span>
          <span id="toHide26" style="display:none;"><br /><div style="display:inline"><p>The steering law models human motor performance and has been verified to hold for a single linear and/or circular path. Some extensions investigated steering around corners. Yet, little is known about human performance in navigating joined linear paths, i.e., successions of path segments with different widths. Such operations appear in graphical user interface tasks, including lasso operations in illustration software. In this work, we conducted several experiments involving joined paths. The results show that users significantly changed their behavior, and that this strategy change can be predicted beforehand. A simple model summing the two indexes of difficulty (<i>ID</i>s) for each path predicts movement time well, but more sophisticated models were also evaluated. The best model in terms of both of <i>R</i><sup>2</sup> and <i>AIC</i> values includes the <i>ID</i> of the crossing operation to enter the second path.</p></div></span> <a id="expcoll26" href="JavaScript: expandcollapse('expcoll26',26)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025951&CFID=758305256&CFTOKEN=14863114">Modeling User Performance on Curved Constrained Paths</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Mathieu Nancel, Edward Lank 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 244-254</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025951" title="DOI">10.1145/3025453.3025951</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025951&ftid=1870026&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow27" style="display:inline;"><br /><div style="display:inline">In 1997, Accot and Zhai presented seminal work analyzing the temporal cost and instantaneous speed profiles associated with movement along constrained paths. Their work posited and validated the emph{steering law}, which described the relationship between ...</div></span>
          <span id="toHide27" style="display:none;"><br /><div style="display:inline"><p>In 1997, Accot and Zhai presented seminal work analyzing the temporal cost and instantaneous speed profiles associated with movement along constrained paths. Their work posited and validated the emph{steering law}, which described the relationship between path constraint, path length and the temporal cost of path traversal using a computer input device (e.g. a mouse). In this paper, we argue that the steering law fails to correctly model constrained paths of varying, arbitrary curvature, propose a new form of the law that accommodates these curved paths, and empirically validate our model.</p></div></span> <a id="expcoll27" href="JavaScript: expandcollapse('expcoll27',27)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025625&CFID=758305256&CFTOKEN=14863114">Free the Hands! Enhanced Target Selection via a Variable-Friction Shoe</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Daniel Horodniczy, Jeremy R. Cooperstock 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 255-259</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025625" title="DOI">10.1145/3025453.3025625</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025625&ftid=1870022&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow28" style="display:inline;"><br /><div style="display:inline">While several foot-controlled pointing devices have been explored as alternatives to conventional interfaces, we are interested in whether such devices can achieve higher performance with the addition of variable friction. Users wore our variable-friction ...</div></span>
          <span id="toHide28" style="display:none;"><br /><div style="display:inline"><p>While several foot-controlled pointing devices have been explored as alternatives to conventional interfaces, we are interested in whether such devices can achieve higher performance with the addition of variable friction. Users wore our variable-friction prototype shoe on their right foot, which they slid on a low-friction surface to control a mouse cursor. Two interface modes were evaluated: constant (CF) and variable friction (VF), under the ISO 9241-9 standard for pointing device evaluation. For the variable-friction modality, target regions were high friction to provide sliding resistance cues. Our findings confirmed that variable-friction foot-controlled pointing can achieve throughput competitive with a range of hand-controlled devices. This suggests the potential for taking advantage of foot input for simple pointing tasks, in particular when the hands are overloaded. With respect to other foot-controlled pointing systems, our implementation offered improved performance and comparable error rates. In addition, the analysis provided further insight into the design of foot-controlled input devices.</p></div></span> <a id="expcoll28" href="JavaScript: expandcollapse('expcoll28',28)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025660&CFID=758305256&CFTOKEN=14863114"><i>To Miss is Human</i>: Information-Theoretic Rationale for Target Misses in Fitts' Law</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Julien Gori, Olivier Rioul, Yves Guiard 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 260-264</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025660" title="DOI">10.1145/3025453.3025660</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025660&ftid=1870036&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow29" style="display:inline;"><br /><div style="display:inline">In usual Fitts' law experiments the outcome of a pointing act can be either measured as an error, i.e., a distance from endpoint to target center, or categorized in an all-or-none way as a hit versus a miss. Information theory offers a useful distinction ...</div></span>
          <span id="toHide29" style="display:none;"><br /><div style="display:inline"><p>In usual Fitts' law experiments the outcome of a pointing act can be either measured as an error, i.e., a distance from endpoint to target center, or categorized in an all-or-none way as a hit versus a miss. Information theory offers a useful distinction between transmission errors (the received symbol is wrong) and erasures (the received symbol is empty). Although Fitts' law research has been very much inspired by the information theoretic rationale, the error/erasure distinction has escaped attention so far: Target misses have always been treated as normally-distributed errors, through the effective index of difficulty <i>ID<sub>e</sub></i>. The paper introduces a new index of difficulty based on the simple observation that a target miss conveys zero bit of information, i.e., it is an erasure. Not only is the new index more consistent with the fundamentals of information theory, it is much simpler to derive than the ISO-recommended <i>ID<sub>e</sub></i>.</p></div></span> <a id="expcoll29" href="JavaScript: expandcollapse('expcoll29',29)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Technology &#38; Adoption</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025742&CFID=758305256&CFTOKEN=14863114">Implications for Adoption</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Joseph Lindley, Paul Coulton, Miriam Sturdee 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 265-277</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025742" title="DOI">10.1145/3025453.3025742</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025742&ftid=1870046&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow31" style="display:inline;"><br /><div style="display:inline">In this paper we explore the motivations for, and practicalities of, incorporating "implications for adoption" into HCI research practice. Implications for adoption are speculations which may be used in research projects to scrutinize and explore the ...</div></span>
          <span id="toHide31" style="display:none;"><br /><div style="display:inline"><p>In this paper we explore the motivations for, and practicalities of, incorporating "implications for adoption" into HCI research practice. Implications for adoption are speculations which may be used in research projects to scrutinize and explore the implications and requirements associated with a technology's potential adoption in the future. There is a rich tradition within the HCI community of implementing, demonstrating, and testing new interactions or technologies by building prototypes. User-centered design methods help us to develop prototypes to and move toward designs that are validated, efficient, and rewarding to use. However, these studies rarely shift their temporal focus to consider, in any significant detail, what it would mean for a technology to exist beyond its prototypical implementation, in other words how these prototypes might ultimately be adopted. Given the CHI community's increasing interest in technology-related human and social effects, the lack of attention paid to adoption represents a significant and relevant gap in current practices. It is this gap that the paper addresses and in doing so offers three contributions: (1) exploring and unpacking different notions of adoption from varying disciplinary perspectives; (2) discussing why considering adoption is relevant and useful, specifically in HCI research; (3) discussing methods for addressing this need, specifically design fiction, and understanding how utilizing these methods may provide researchers with means to better understand the myriad of nuanced, situated, and technologically-mediated relationships that innovative designs facilitate.</p></div></span> <a id="expcoll31" href="JavaScript: expandcollapse('expcoll31',31)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025739&CFID=758305256&CFTOKEN=14863114">UX Design Innovation: Challenges for Working with Machine Learning as a Design Material</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Graham Dove, Kim Halskov, Jodi Forlizzi, John Zimmerman 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 278-288</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025739" title="DOI">10.1145/3025453.3025739</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025739&ftid=1870038&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow32" style="display:inline;"><br /><div style="display:inline">Machine learning (ML) is now a fairly established technology, and user experience (UX) designers appear regularly to integrate ML services in new apps, devices, and systems. Interestingly, this technology has not experienced a wealth of design innovation ...</div></span>
          <span id="toHide32" style="display:none;"><br /><div style="display:inline"><p>Machine learning (ML) is now a fairly established technology, and user experience (UX) designers appear regularly to integrate ML services in new apps, devices, and systems. Interestingly, this technology has not experienced a wealth of design innovation that other technologies have, and this might be because it is a new and difficult design material. To better understand why we have witnessed little design innovation, we conducted a survey of current UX practitioners with regards to how new ML services are envisioned and developed in UX practice. Our survey probed on how ML may or may not have been a part of their UX design education, on how they work to create new things with developers, and on the challenges they have faced working with this material. We use the findings from this survey and our review of related literature to present a series of challenges for UX and interaction design research and education. Finally, we discuss areas where new research and new curriculum might help our community unlock the power of design thinking to re-imagine what ML might be and might do.</p></div></span> <a id="expcoll32" href="JavaScript: expandcollapse('expcoll32',32)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025475&CFID=758305256&CFTOKEN=14863114">Technology Maintenance: A New Frame for Studying Poverty and Marginalization</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Amy Gonzales 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 289-294</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025475" title="DOI">10.1145/3025453.3025475</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025475&ftid=1870019&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow33" style="display:inline;"><br /><div style="display:inline">This paper offers a new theoretical frame for those interested in poverty and design. As digital access rates peak, technology maintenance argues that the digital divide will increasingly manifest in the (in)ability to stay connected. As a novel and ...</div></span>
          <span id="toHide33" style="display:none;"><br /><div style="display:inline"><p>This paper offers a new theoretical frame for those interested in poverty and design. As digital access rates peak, technology maintenance argues that the digital divide will increasingly manifest in the (in)ability to stay connected. As a novel and conservative test, open-ended data from a 748-person university student survey of technology maintenance were analyzed. Use and ownership were ubiquitous, but students demonstrated variability in coping with the inevitable; disconnection was more burdensome for low-resourced students. Findings extend technology maintenance and are leveraged as a starting point for three calls for action in HCI: 1) the CHI community should research the burdens of poverty in poor and wealthy contexts; 2) new HCI projects should accommodate inconsistent access; and, 3) new design choices should minimize disruption and optimize stability. This requires action at the individual and organizational level as designers create products that consider marginalization but also use expertise to influence policy.</p></div></span> <a id="expcoll33" href="JavaScript: expandcollapse('expcoll33',33)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Telepresence and Robots</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025499&CFID=758305256&CFTOKEN=14863114">Someone to Read with: Design of and Experiences with an In-Home Learning Companion Robot for Reading</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Joseph E. Michaelis, Bilge Mutlu 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 301-312</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025499" title="DOI">10.1145/3025453.3025499</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025499&ftid=1870017&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow35" style="display:inline;"><br /><div style="display:inline">The development of literacy and reading proficiency is a building block of lifelong learning that must be supported both in the classroom and at home. While the promise of interactive learning technologies has widely been demonstrated, little is known ...</div></span>
          <span id="toHide35" style="display:none;"><br /><div style="display:inline"><p>The development of literacy and reading proficiency is a building block of lifelong learning that must be supported both in the classroom and at home. While the promise of interactive learning technologies has widely been demonstrated, little is known about how an interactive robot might play a role in this development. We used eight design features based on recommendations from interest-development and human-robot-interaction literatures to design an in-home learning companion robot for children aged 11--12. The robot was used as a technology probe to explore families' (<i>N</i>=8) habits and views about reading, how a reading technology might be used, and how children perceived reading with the robot. Our results indicate reading with the learning companion to be a way to socially engage with reading, which may promote the development of reading interest and ability. We discuss design and research implications based on our findings.</p></div></span> <a id="expcoll35" href="JavaScript: expandcollapse('expcoll35',35)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025855&CFID=758305256&CFTOKEN=14863114">Robotic Telepresence at Scale</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Irene Rae, Carman Neustaedter 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 313-324</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025855" title="DOI">10.1145/3025453.3025855</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025855&ftid=1870028&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow36" style="display:inline;"><br /><div style="display:inline">Telepresence robots offer a relatively new way for people to project their presence remotely. However, these experiences have only been studied in controlled or small scale installations. To broaden our understanding of the successes and limitations ...</div></span>
          <span id="toHide36" style="display:none;"><br /><div style="display:inline"><p>Telepresence robots offer a relatively new way for people to project their presence remotely. However, these experiences have only been studied in controlled or small scale installations. To broaden our understanding of the successes and limitations of telepresence robots in large-scale venues, we conducted a study at CHI 2016 where five factors increased over past research: (1) number of local attendees; (2) ratio of remote users to systems; (3) variety of activities; (4) time zone differences; and, (5) environment size. Our results reveal that unlike small-scale venues and situations, remote users take a more socially isolated and functional approach to remote attendance while combating challenges around scheduling and large navigational spaces. Our results reveal new opportunities for thinking about the design of robot personalization, availability, and navigation for systems targeted at large-scale public contexts.</p></div></span> <a id="expcoll36" href="JavaScript: expandcollapse('expcoll36',36)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025734&CFID=758305256&CFTOKEN=14863114">Movement Matters: Effects of Motion and Mimicry on Perception of Similarity and Closeness in Robot-Mediated Communication</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Mina Choi, Rachel Kornfield, Leila Takayama, Bilge Mutlu 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 325-335</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025734" title="DOI">10.1145/3025453.3025734</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025734&ftid=1870040&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow37" style="display:inline;"><br /><div style="display:inline">In face-to-face interaction, moving with and mimicking the body movements of communication partners has been widely demonstrated to affect interpersonal processes, including feel- ings of affiliation and closeness. In this paper, we examine effects of ...</div></span>
          <span id="toHide37" style="display:none;"><br /><div style="display:inline"><p>In face-to-face interaction, moving with and mimicking the body movements of communication partners has been widely demonstrated to affect interpersonal processes, including feel- ings of affiliation and closeness. In this paper, we examine effects of movement and mimicry in robot-mediated communication. Participants were instructed to get to know their partner, a confederate, who interacted with them via a telepresence robot. The robot either (a) mimicked the participant's body orientation (mimicry condition), (b) mimicked pre-recorded movements of another participant (random movement condition), or (c) did not move during the interaction (static condition). Results showed that mimicry and random movement had similar effects on participants' perceptions of similarity and closeness to their partners and that these effects depend on the participant's gender and level of self-monitoring. The findings suggest that the social movements of a telepresence robot affect interpersonal processes and that these effects are shaped by individual differences.</p></div></span> <a id="expcoll37" href="JavaScript: expandcollapse('expcoll37',37)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025995&CFID=758305256&CFTOKEN=14863114">A Simple Nod of the Head: The Effect of Minimal Robot Movements on Children's Perception of a Low-Anthropomorphic Robot</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Cristina Zaga, Roelof A.J. de Vries, Jamy Li, Khiet P. Truong, Vanessa Evers 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 336-341</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025995" title="DOI">10.1145/3025453.3025995</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025995&ftid=1870004&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow38" style="display:inline;"><br /><div style="display:inline">In this note, we present minimal robot movements for robotic technology for children. Two types of minimal gaze movements were designed: social-gaze movements to communicate social engagement and deictic-gaze movements to communicate task-related referential ...</div></span>
          <span id="toHide38" style="display:none;"><br /><div style="display:inline"><p>In this note, we present minimal robot movements for robotic technology for children. Two types of minimal gaze movements were designed: social-gaze movements to communicate social engagement and deictic-gaze movements to communicate task-related referential information. In a two (social-gaze movements vs. none) by two (deictic-gaze movements vs. none) video-based study (n=72), we found that social-gaze movements significantly increased children's perception of animacy and likeability of the robot. Deictic-gaze and social-gaze movements significantly increased children's perception of helpfulness. Our findings show the compelling communicative power of social-gaze movements, and to a lesser extent deictic-gaze movements, and have implications for designers who want to achieve animacy, likeability and helpfulness with simple and easily implementable minimal robot movements. Our work contributes to human-robot interaction research and design by providing a first indication of the potential of minimal robot movements to communicate social engagement and helpful referential information to children.</p></div></span> <a id="expcoll38" href="JavaScript: expandcollapse('expcoll38',38)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025809&CFID=758305256&CFTOKEN=14863114">My Student is a Robot: How Schools Manage Telepresence Experiences for Students</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Veronica Ahumada Newhart, Judith S. Olson 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 342-347</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025809" title="DOI">10.1145/3025453.3025809</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025809&ftid=1870000&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow39" style="display:inline;"><br /><div style="display:inline">Homebound students, those who can learn but have a serious health issue (e.g. cancer, heart disease, immune deficiency) that prevents physical attendance at school, are now able to go to school using telepresence robots. Telepresence robots are generally ...</div></span>
          <span id="toHide39" style="display:none;"><br /><div style="display:inline"><p>Homebound students, those who can learn but have a serious health issue (e.g. cancer, heart disease, immune deficiency) that prevents physical attendance at school, are now able to go to school using telepresence robots. Telepresence robots are generally video conferencing units on remote-controlled robots. Previous research has shown that using these robots allows homebound students to interact with classmates and teachers as if they are physically present. But, what does this mean for teachers and administrators? We present a qualitative study of 22 teachers and school administrators who worked with telepresent students and 4 who decided against adopting the robot. Our goal was to learn how decisions are made to adopt the robot, what issues arise in its use, and what would make adoption easier. This study contributes new insights on teacher and administrator perspectives on what is needed for effective use of this technology in educational settings.</p></div></span> <a id="expcoll39" href="JavaScript: expandcollapse('expcoll39',39)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Authentication and Access Control</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025999&CFID=758305256&CFTOKEN=14863114">How Do System Administrators Resolve Access-Denied Issues in the Real World?</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Tianyin Xu, Han Min Naing, Le Lu, Yuanyuan Zhou 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 348-361</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025999" title="DOI">10.1145/3025453.3025999</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025999&ftid=1870008&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow41" style="display:inline;"><br /><div style="display:inline">The efficacy of access control largely depends on how system administrators (sysadmins) resolve access-denied issues. A correct resolution should only permit the expected access, while maintaining the protection against illegal access. However, anecdotal ...</div></span>
          <span id="toHide41" style="display:none;"><br /><div style="display:inline"><p>The efficacy of access control largely depends on how system administrators (sysadmins) resolve access-denied issues. A correct resolution should only permit the expected access, while maintaining the protection against illegal access. However, anecdotal evidence suggests that correct resolutions are occasional---sysadmins often grant too much access (known as security misconfigurations) to allow the denied access, posing severe security risks. This paper presents a quantitative study on real-world practices of resolving access-denied issues, with a particular focus on how and why security misconfigurations are introduced during problem solving. We characterize the real-world security misconfigurations introduced in the field, and show that many of these misconfigurations were the results of trial-and-error practices commonly adopted by sysadmins to work around access denials. We argue that the lack of adequate feedback information is one fundamental reason that prevents sysadmins from developing precise understanding and thus induces trial and error. Our study on access-denied messages shows that many of today's software systems miss the opportunities for providing adequate feedback information, imposing unnecessary obstacles to correct resolutions.</p></div></span> <a id="expcoll41" href="JavaScript: expandcollapse('expcoll41',41)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025706&CFID=758305256&CFTOKEN=14863114">User Interactions and Permission Use on Android</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Kristopher Micinski, Daniel Votipka, Rock Stevens, Nikolaos Kofinas, Michelle L. Mazurek, Jeffrey S. Foster 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 362-373</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025706" title="DOI">10.1145/3025453.3025706</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025706&ftid=1870041&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow42" style="display:inline;"><br /><div style="display:inline">Android and other mobile operating systems ask users for authorization before allowing apps to access sensitive resources such as contacts and location. We hypothesize that such authorization systems could be improved by becoming more integrated with ...</div></span>
          <span id="toHide42" style="display:none;"><br /><div style="display:inline"><p>Android and other mobile operating systems ask users for authorization before allowing apps to access sensitive resources such as contacts and location. We hypothesize that such authorization systems could be improved by becoming more integrated with the app's user interface. In this paper, we conduct two studies to test our hypothesis. First, we use apptracer{}, a dynamic analysis tool we developed, to measure to what extent user interactions and sensitive resource use are related in existing apps. Second, we conduct an online survey to examine how different interactions with the UI affect users' expectations about whether an app accesses sensitive resources. Our results suggest that user interactions such as button clicks can be interpreted as authorization, reducing the need for separate requests; but that accesses not directly tied to user interactions should be separately authorized, possibly when apps are first launched.</p></div></span> <a id="expcoll42" href="JavaScript: expandcollapse('expcoll42',42)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025879&CFID=758305256&CFTOKEN=14863114">Where Usability and Security Go Hand-in-Hand: Robust Gesture-Based Authentication for Mobile Systems</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Can Liu, Gradeigh D. Clark, Janne Lindqvist 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 374-386</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025879" title="DOI">10.1145/3025453.3025879</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025879&ftid=1870043&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow43" style="display:inline;"><br /><div style="display:inline">Gestures have recently gained interest as a secure and usable authentication method for mobile devices. Gesture authentication relies on recognition, wherein raw data is collected from user input and preprocessed into a more manageable form before applying ...</div></span>
          <span id="toHide43" style="display:none;"><br /><div style="display:inline"><p>Gestures have recently gained interest as a secure and usable authentication method for mobile devices. Gesture authentication relies on recognition, wherein raw data is collected from user input and preprocessed into a more manageable form before applying recognition algorithms. Preprocessing is done to improve recognition accuracy, but little work has been done in justifying its effects on authentication. We examined the effects of three variables: location, rotation, and scale, on authentication accuracy. We found that an authentication-optimal combination (location invariant, scale variant, and rotation variant) can reduce the error rate by 45.3% on average compared to the recognition-optimal combination (all invariant). We analyzed 13 gesture recognizers and evaluated them with three criteria: authentication accuracy, and resistance against both brute-force and imitation attacks. Our novel multi-expert method (Garda) achieved the lowest error rate (0.015) in authentication accuracy, the lowest error rate (0.040) under imitation attacks, and resisted all brute-force attacks.</p></div></span> <a id="expcoll43" href="JavaScript: expandcollapse('expcoll43',43)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025788&CFID=758305256&CFTOKEN=14863114">I'm too Busy to Reset my LinkedIn Password: On the Effectiveness of Password Reset Emails</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Jun Ho Huh, Hyoungshick Kim, Swathi S.V.P. Rayala, Rakesh B. Bobba, Konstantin Beznosov 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 387-391</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025788" title="DOI">10.1145/3025453.3025788</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025788&ftid=1870012&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow44" style="display:inline;"><br /><div style="display:inline">A common security practice used to deal with a password breach is locking user accounts and sending out an email to tell users that they need to reset their password to unlock their account. This paper evaluates the effectiveness of this security practice ...</div></span>
          <span id="toHide44" style="display:none;"><br /><div style="display:inline"><p>A common security practice used to deal with a password breach is locking user accounts and sending out an email to tell users that they need to reset their password to unlock their account. This paper evaluates the effectiveness of this security practice based on the password reset email that LinkedIn sent out around May 2016, and through an online survey conducted on 249 LinkedIn users who received that email. Our evaluation shows that only about 46% of the participants reset their passwords. The mean time taken to reset password was 26.3 days, revealing that a significant proportion of the participants reset their password a few weeks, or even months after first receiving the email. Our findings suggest that more effective persuasive measures need to be added to convince users to reset their password in a timely manner, and further reduce the risks associated with delaying password resets.</p></div></span> <a id="expcoll44" href="JavaScript: expandcollapse('expcoll44',44)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Cars and Automation</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025507&CFID=758305256&CFTOKEN=14863114">Priming Drivers before Handover in Semi-Autonomous Cars</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Remo M.A. van der Heiden, Shamsi T. Iqbal, Christian P. Janssen 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 392-404</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025507" title="DOI">10.1145/3025453.3025507</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025507&ftid=1870003&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow46" style="display:inline;"><br /><div style="display:inline">Semi-autonomous vehicles occasionally require control to be handed over to the driver in situations where the vehicle is unable to operate safely. Currently, such handover requests require the driver to take control almost instantaneously. We investigate ...</div></span>
          <span id="toHide46" style="display:none;"><br /><div style="display:inline"><p>Semi-autonomous vehicles occasionally require control to be handed over to the driver in situations where the vehicle is unable to operate safely. Currently, such handover requests require the driver to take control almost instantaneously. We investigate how auditory pre-alerts that occur well before the handover request impact the success of the handover in a dual task scenario. In a study with a driving simulator, drivers perform tasks on their phone while the car is in an autonomous mode. They receive a repeated burst audio pre-alert or an increasing pulse audio pre-alert preceding the standard warning for immediate handover. Results show that pre-alerts caused people to look more at the road before the handover occurred, and to disengage from the secondary task earlier, compared to when there was no pre-alert. This resulted in safer handover situations. Increasing pulse pre-alerts show particular promise due to their communication of urgency. Our detailed analysis informs the design and evaluation of alerts in safety-critical systems with automation.</p></div></span> <a id="expcoll46" href="JavaScript: expandcollapse('expcoll46',46)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025822&CFID=758305256&CFTOKEN=14863114">Toward Measurement of Situation Awareness in Autonomous Vehicles</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          David Sirkin, Nikolas Martelaro, Mishel Johns, Wendy Ju 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 405-415</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025822" title="DOI">10.1145/3025453.3025822</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025822&ftid=1870047&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow47" style="display:inline;"><br /><div style="display:inline">Until vehicles are fully autonomous, safety, legal and ethical obligations require that drivers remain aware of the driving situation. Key decisions about whether a driver can take over when the vehicle is confused, or its capabilities are degraded, ...</div></span>
          <span id="toHide47" style="display:none;"><br /><div style="display:inline"><p>Until vehicles are fully autonomous, safety, legal and ethical obligations require that drivers remain aware of the driving situation. Key decisions about whether a driver can take over when the vehicle is confused, or its capabilities are degraded, depend on understanding whether he or she is responsive and aware of external conditions. The leading techniques for measuring situation awareness in simulated environments are ill-suited to autonomous driving scenarios, and particularly to on-road testing. We have developed a technique, named Daze, to measure situation awareness through real-time, in-situ event alerts. The technique is ecologically valid: it resembles applications people use in actual driving. It is also flexible: it can be used in both simulator and on-road research settings. We performed simulator-based and on-road test deployments to (a) check that Daze could characterize drivers' awareness of their immediate environment and (b) understand practical aspects of the technique's use. Our contributions include the Daze technique, examples of collected data, and ways to analyze such data.</p></div></span> <a id="expcoll47" href="JavaScript: expandcollapse('expcoll47',47)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025462&CFID=758305256&CFTOKEN=14863114">The Trouble with Autopilots: Assisted and Autonomous Driving on the Social Road</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Barry Brown, Eric Laurier 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 416-429</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025462" title="DOI">10.1145/3025453.3025462</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025462&ftid=1870044&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow48" style="display:inline;"><br /><div style="display:inline">As self-driving cars have grown in sophistication and ability, they have been deployed on the road in both localised tests and as regular private vehicles. In this paper we draw upon publicly available videos of autonomous and assisted driving (specifically ...</div></span>
          <span id="toHide48" style="display:none;"><br /><div style="display:inline"><p>As self-driving cars have grown in sophistication and ability, they have been deployed on the road in both localised tests and as regular private vehicles. In this paper we draw upon publicly available videos of autonomous and assisted driving (specifically the Tesla autopilot and Google self-driving car) to explore how their drivers and the drivers of other cars interact with, and make sense of, the actions of these cars. Our findings provide an early perspective on human interaction with new forms of driving involving assisted-car drivers, autonomous vehicles and other road users. The focus is on social interaction on the road, and how drivers communicate through, and interpret, the movement of cars. We provide suggestions toward increasing the transparency of autopilots' actions for both their driver and other drivers.</p></div></span> <a id="expcoll48" href="JavaScript: expandcollapse('expcoll48',48)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025686&CFID=758305256&CFTOKEN=14863114">Understanding the Cost of Driving Trips</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Caleb Southern, Yunnuo Cheng, Cheng Zhang, Gregory D. Abowd 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 430-434</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025686" title="DOI">10.1145/3025453.3025686</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025686&ftid=1870027&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow49" style="display:inline;"><br /><div style="display:inline">Driving is the second highest expense for the average American household. Yet few people know the total cost of owning and operating their vehicles, and most cannot estimate accurately how much a common driving trip (like a daily commute) costs. There ...</div></span>
          <span id="toHide49" style="display:none;"><br /><div style="display:inline"><p>Driving is the second highest expense for the average American household. Yet few people know the total cost of owning and operating their vehicles, and most cannot estimate accurately how much a common driving trip (like a daily commute) costs. There are an increasing number of viable alternatives for personal transportation, such as car services (e.g. Uber, Lyft), in addition to ridesharing, transit, biking, and walking. Cost is one factor in transportation mode choice, and awareness of the cost of driving is useful in making better informed decisions. To bridge this awareness gap, we built and deployed a system that makes the total cost of each driving trip (including depreciation, maintenance, insurance, and fuel) visible to the user. After this intervention, participants were able to more accurately and confidently estimate costs of their driving commutes, and transfer this knowledge to other trips for which they had not seen a cost.</p></div></span> <a id="expcoll49" href="JavaScript: expandcollapse('expcoll49',49)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Design Theory</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025630&CFID=758305256&CFTOKEN=14863114">Making Ritual Machines: The Mobile Phone as a Networked Material for Research Products</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          David Chatting, David S. Kirk, Abigail C. Durrant, Chris Elsden, Paulina Yurman, Jo-Anne Bichard 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 435-447</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025630" title="DOI">10.1145/3025453.3025630</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025630&ftid=1870025&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow51" style="display:inline;"><br /><div style="display:inline">Viewing the mobile telephone as a networked material, we demonstrate the ways in which we have used it to make Research Products for the "Family Rituals 2.0" inquiry of families separated by work. Drawing from a diversity of sources we survey and deconstruct ...</div></span>
          <span id="toHide51" style="display:none;"><br /><div style="display:inline"><p>Viewing the mobile telephone as a networked material, we demonstrate the ways in which we have used it to make Research Products for the "Family Rituals 2.0" inquiry of families separated by work. Drawing from a diversity of sources we survey and deconstruct the phone as a material that can be worked to a vast range of technical effects, extended by hardware and configured by software. We demonstrate the transformations of hacking and prototyping practices necessary to construct complex Research Products through the case study of our machines. We offer the Interaction Design community seven specific and actionable techniques for using mobile telephones in Research Products. Finally, we open up a broader discussion for researchers and practitioners using mobile phones as a design material in their work.</p></div></span> <a id="expcoll51" href="JavaScript: expandcollapse('expcoll51',51)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025797&CFID=758305256&CFTOKEN=14863114">Products as Agents: Metaphors for Designing the Products of the IoT Age</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Nazli Cila, Iskander Smit, Elisa Giaccardi, Ben Kr&#246;se 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 448-459</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025797" title="DOI">10.1145/3025453.3025797</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025797&ftid=1870009&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow52" style="display:inline;"><br /><div style="display:inline">Design-based inquiries into the networked products of the Internet of Things (IoT) lack a coherent understanding of the effect of such products on society. This paper proposes a new taxonomy for networked products, which would allow articulation on their ...</div></span>
          <span id="toHide52" style="display:none;"><br /><div style="display:inline"><p>Design-based inquiries into the networked products of the Internet of Things (IoT) lack a coherent understanding of the effect of such products on society. This paper proposes a new taxonomy for networked products, which would allow articulation on their current state and future, and provide insights to designers for creating meaningful and aesthetic products of IoT. Central to this framework is the proposition that our current product-scape should be understood as a distribution of material agencies and best analyzed through the metaphor of "agency". We identify three types of agencies, i.e., the Collector, the Actor, and the Creator, and discuss how this approach could create new design methodologies to create more meaningful networked products that would empower people in their everyday lives.</p></div></span> <a id="expcoll52" href="JavaScript: expandcollapse('expcoll52',52)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3026031&CFID=758305256&CFTOKEN=14863114">Pause: A Multi-lifespan Design Mechanism</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Batya Friedman, Daisy Yoo 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 460-464</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3026031" title="DOI">10.1145/3025453.3026031</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3026031&ftid=1870015&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow53" style="display:inline;"><br /><div style="display:inline">At times, inaction may be a wise course of action. This insight lies at the heart of the design mechanism of pause. In this note, we explore the construct of pause, its rhythms, and nuances of enacting pause. Throughout, we draw on our experience engaging ...</div></span>
          <span id="toHide53" style="display:none;"><br /><div style="display:inline"><p>At times, inaction may be a wise course of action. This insight lies at the heart of the design mechanism of pause. In this note, we explore the construct of pause, its rhythms, and nuances of enacting pause. Throughout, we draw on our experience engaging with pause in the multi-lifespan design of information systems for transitional justice. Five rhythms are identified: periodic hiatus, pending future event, responding to the socio-political climate, (temporary) closure, and laying fallow. In addition, we provide heuristics for managing pause and then restarting the design process. We then explore the scalability of pause from longer (e.g., multi-lifespan design) to shorter timeframes. We conclude with reflections on the potential benefits and open questions about pause as a design mechanism.</p></div></span> <a id="expcoll53" href="JavaScript: expandcollapse('expcoll53',53)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025939&CFID=758305256&CFTOKEN=14863114">Interdependent Wearables (for Play): A Strong Concept for Design</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Katherine Isbister, Kaho Abe, Michael Karlesky 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 465-471</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025939" title="DOI">10.1145/3025453.3025939</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025939&ftid=1870037&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow54" style="display:inline;"><br /><div style="display:inline">Typically wearable devices are conceived of and constructed as stand-alone, individually based technologies. However, in practice wearables become part of the social context and ecology of overall device use. We present a strong concept for design: Interdependent ...</div></span>
          <span id="toHide54" style="display:none;"><br /><div style="display:inline"><p>Typically wearable devices are conceived of and constructed as stand-alone, individually based technologies. However, in practice wearables become part of the social context and ecology of overall device use. We present a strong concept for design: Interdependent Wearables (for play): wearables designed to require shared attention and mutual awareness, with interdependent functionality that encourages and rewards collocated interaction. The concept arose through design, development, and public exhibition of Hotaru, a collocated social game that uses wearables as game controllers. Hotaru has been shown in festivals and also formally playtested with 62 individuals. To more fully articulate the Interdependent Wearables strong concept, we compared this system's design with wearable and embodied systems for play and other purposes, and drew upon relevant HCI theory. The work is of benefit to those in the HCI/UX community focused on the design and development of social wearable technologies, especially those interested in supporting collocated interaction.</p></div></span> <a id="expcoll54" href="JavaScript: expandcollapse('expcoll54',54)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025864&CFID=758305256&CFTOKEN=14863114">How Methods Make Designers</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Seyram Avle, Silvia Lindtner, Kaiton Williams 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 472-483</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025864" title="DOI">10.1145/3025453.3025864</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025864&ftid=1870021&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow55" style="display:inline;"><br /><div style="display:inline">Through their combination of lifestyle and method, Silicon Valley models for tech production such as design thinking, startup incubators, lean management, etc. are spreading across the globe. These paradigms are positioned by product designers, politicians, ...</div></span>
          <span id="toHide55" style="display:none;"><br /><div style="display:inline"><p>Through their combination of lifestyle and method, Silicon Valley models for tech production such as design thinking, startup incubators, lean management, etc. are spreading across the globe. These paradigms are positioned by product designers, politicians, investors and corporations alike as replicable routes to individual and national empowerment. They are portrayed as universal templates, portable across national borders and applicable to local needs. We draw from our ethnographic engagements with tech entrepreneurial efforts in Ghana, China, and Jamaica to unpack the stakes involved in their uptake, showing that while local actors produce situated alternatives, their work nevertheless often results in a continued valorization of these seemingly universal methods. We argue that design methods shape not only use practices, but have consequences for the life worlds of professional designers. This includes how they impact personal and national identities, confer legitimacy in transnational innovation circles, and secure access to social and economic resources. Ultimately, we call for an inclusion of these factors in ongoing conversations about design and design methods.</p></div></span> <a id="expcoll55" href="JavaScript: expandcollapse('expcoll55',55)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Fabrication via 3D Printing</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025666&CFID=758305256&CFTOKEN=14863114">Consumer to Creator: How Households Buy Furniture to Inform Design and Fabrication Interfaces</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Bokyung Lee, Gyeol Han, Jundong Park, Daniel Saakes 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 484-496</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025666" title="DOI">10.1145/3025453.3025666</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025666&ftid=1870018&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow57" style="display:inline;"><br /><div style="display:inline">Emerging technologies for digital design and fabrication let people participate in the making of objects that were previously dominated by professional designers. A growing body of work in HCI provides understanding in the activities of designing and ...</div></span>
          <span id="toHide57" style="display:none;"><br /><div style="display:inline"><p>Emerging technologies for digital design and fabrication let people participate in the making of objects that were previously dominated by professional designers. A growing body of work in HCI provides understanding in the activities of designing and making by novices and in maker communities. However, we know little about how casual users might employ these technologies with the goal of having an object in their home that satisfies a need. We present a long-term qualitative study in which we followed 16 households during a purchasing process of furniture items for their homes. We looked into how families discover what they need, find solutions, realize a solution in their house and put it to use. The results provide insights into their design activities and workflow and we identify two distinct stages: understanding needs and prototyping a solution. Based on the findings, we discuss the social practice of acquiring and appropriating furniture in the home and within families, and identify design opportunities for digital design and fabrication to support people as they create the objects they need, want and desire.</p></div></span> <a id="expcoll57" href="JavaScript: expandcollapse('expcoll57',57)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025460&CFID=758305256&CFTOKEN=14863114">Stretching the Bounds of 3D Printing with Embedded Textiles</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Michael L. Rivera, Melissa Moukperian, Daniel Ashbrook, Jennifer Mankoff, Scott E. Hudson 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 497-508</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025460" title="DOI">10.1145/3025453.3025460</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025460&ftid=1870048&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow58" style="display:inline;"><br /><div style="display:inline">Textiles are an old and well developed technology that have many desirable characteristics. They can be easily folded, twisted, deformed, or cut; some can be stretched; many are soft. Textiles can maintain their shape when placed under tension and can ...</div></span>
          <span id="toHide58" style="display:none;"><br /><div style="display:inline"><p>Textiles are an old and well developed technology that have many desirable characteristics. They can be easily folded, twisted, deformed, or cut; some can be stretched; many are soft. Textiles can maintain their shape when placed under tension and can even be engineered with variable stretching ability. Conversely, 3D printing is a relatively new technology that can precisely produce functional, rigid objects with custom geometry. Combining 3D printing and textiles opens up new opportunities for rapidly creating rigid objects with embedded flexibility as well as soft materials imbued with additional functionality. In this paper, we introduce a suite of techniques for integrating 3D printing with textiles during the printing process, opening up a new design space that takes inspiration from both fields. We demonstrate how the malleability, stretchability and aesthetic qualities of textiles can enhance rigid printed objects, and how textiles can be augmented with functional properties enabled by 3D printing.</p></div></span> <a id="expcoll58" href="JavaScript: expandcollapse('expcoll58',58)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025699&CFID=758305256&CFTOKEN=14863114">WeaveMesh: A Low-Fidelity and Low-Cost Prototyping Approach for 3D Models Created by Flexible Assembly</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Ye Tao, Guanyun Wang, Caowei Zhang, Nannan Lu, Xiaolian Zhang, Cheng Yao, Fangtian Ying 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 509-518</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025699" title="DOI">10.1145/3025453.3025699</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025699&ftid=1870023&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow59" style="display:inline;"><br /><div style="display:inline">To meet the increasing requirements of HCI researchers who are prototyping a variety of forms to create novel interfaces under a ubiquitous situation, we present WeaveMesh, a low-fidelity and low-cost rapid prototyping system that produces 3D objects ...</div></span>
          <span id="toHide59" style="display:none;"><br /><div style="display:inline"><p>To meet the increasing requirements of HCI researchers who are prototyping a variety of forms to create novel interfaces under a ubiquitous situation, we present WeaveMesh, a low-fidelity and low-cost rapid prototyping system that produces 3D objects in a mesh structure. Inspired by hand-weaving craft, WeaveMesh supports a highly customizable software platform, which is applicable for simulating and facilitating freeform surface constructions composed of woven lines arranged in a regular grid, which can serve as a guide for easy assembly. In addition, mobilizable connectors are suggested to support flexible assembly, which can be revised, recycled, and reused to facilitate short iterations. Furthermore, compared to common additive and subtractive techniques, WeaveMesh has a better balance between time and material saving. In this paper, we will introduce the system in detail and demonstrate the feasibility of the technique through various 3D models in the area of interactive media, products and architecture.</p></div></span> <a id="expcoll59" href="JavaScript: expandcollapse('expcoll59',59)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Learning and Reading</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025560&CFID=758305256&CFTOKEN=14863114">A Framework for Speechreading Acquisition Tools</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Benjamin M. Gorman, David R. Flatla 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 519-530</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025560" title="DOI">10.1145/3025453.3025560</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025560&ftid=1870020&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow61" style="display:inline;"><br /><div style="display:inline">At least 360 million people worldwide have disabling hearing loss that frequently causes difficulties in day-to-day conversations. Traditional technology (e.g., hearing aids) often fails to offer enough value, has low adoption rates, and can result in ...</div></span>
          <span id="toHide61" style="display:none;"><br /><div style="display:inline"><p>At least 360 million people worldwide have disabling hearing loss that frequently causes difficulties in day-to-day conversations. Traditional technology (e.g., hearing aids) often fails to offer enough value, has low adoption rates, and can result in social stigma. Speechreading can dramatically improve conversational understanding, but speechreading is a skill that can be challenging to learn. To address this, we developed a novel speechreading acquisition framework that can be used to design Speechreading Acquisition Tools (SATs) - a new type of technology to improve speechreading acquisition. We interviewed seven speechreading tutors and used thematic analysis to identify and organise the key elements of our framework. We then evaluated our framework by using it to: 1) categorise every tutor-identified speechreading teaching technique, 2) critically evaluate existing conversational aids, and 3) design three new SATs. Through the use of SATs designed using our framework, the speechreading abilities of people with hearing loss around the world should be enhanced, thereby improving the conversational foundation of their day-to-day lives.</p></div></span> <a id="expcoll61" href="JavaScript: expandcollapse('expcoll61',61)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025646&CFID=758305256&CFTOKEN=14863114">FLight: A Low-Cost Reading and Writing System for Economically Less-Privileged Visually-Impaired People Exploiting Ink-based Braille System</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Tusher Chakraborty, Taslim Arefin Khan, A. B. M. Alim Al Islam 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 531-540</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025646" title="DOI">10.1145/3025453.3025646</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025646&ftid=1870045&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow62" style="display:inline;"><br /><div style="display:inline">Reading printed documents and writing on a paper pose a great challenge for visually-impaired people. Existing studies that attempt to solve these challenges are expensive and not feasible in low-income context. Moreover, these studies solve reading ...</div></span>
          <span id="toHide62" style="display:none;"><br /><div style="display:inline"><p>Reading printed documents and writing on a paper pose a great challenge for visually-impaired people. Existing studies that attempt to solve these challenges are expensive and not feasible in low-income context. Moreover, these studies solve reading and writing problems separately. On the contrary, in this study, we propose <i>FLight</i>, a low-cost reading and writing system for economically less-privileged people. <i>FLight</i> uses ink-based Braille characters as the medium of textual representation. This helps in keeping a compact spatial representation of texts, yet achieving a low-cost status. Additionally, <i>FLight</i> utilizes a low-cost wearable device to enhance ease of reading by visually-impaired people. We conduct a participatory design and iterative evaluation involving five visually-impaired children in Bangladesh for more than 18 months. Our user evaluation reveals that <i>FLight</i> is easy-to-use, and exhibits a potential low-cost solution for economically less-privileged visually-impaired people.</p></div></span> <a id="expcoll62" href="JavaScript: expandcollapse('expcoll62',62)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025857&CFID=758305256&CFTOKEN=14863114">Teaching Language and Culture with a Virtual Reality Game</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Alan Cheng, Lei Yang, Erik Andersen 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 541-549</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025857" title="DOI">10.1145/3025453.3025857</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025857&ftid=1870049&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow63" style="display:inline;"><br /><div style="display:inline">Many people want to learn a language but find it difficult to stay engaged. Ideally, we would have language learning tools that can make language learning more enjoyable by simulating immersion in a foreign language environment. Therefore, we adapted ...</div></span>
          <span id="toHide63" style="display:none;"><br /><div style="display:inline"><p>Many people want to learn a language but find it difficult to stay engaged. Ideally, we would have language learning tools that can make language learning more enjoyable by simulating immersion in a foreign language environment. Therefore, we adapted <i>Crystallize</i>, a 3D video game for learning Japanese, so that it can be played in virtual reality with the Oculus Rift. Specifically, we explored whether we could leverage virtual reality technology to teach embodied cultural interaction, such as bowing in Japanese greetings. To evaluate the impact of our virtual reality game designs, we conducted a formative user study with 68 participants. We present results showing that the virtual reality design trained players how and when to bow, and that it increased participants' sense of involvement in Japanese culture. Our results suggest that virtual reality technology provides an opportunity to leverage culturally-relevant physical interaction, which can enhance the design of language learning technology and virtual reality games.</p></div></span> <a id="expcoll63" href="JavaScript: expandcollapse('expcoll63',63)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025582&CFID=758305256&CFTOKEN=14863114">Identifying how Visually Impaired People Explore Raised-line Diagrams to Improve the Design of Touch Interfaces</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Sandra Bardot, Marcos Serrano, Bernard Oriola, Christophe Jouffrais 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 550-555</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025582" title="DOI">10.1145/3025453.3025582</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025582&ftid=1869999&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow64" style="display:inline;"><br /><div style="display:inline">Raised-line diagrams are widely used by visually impaired (VI) people to read maps, drawings or graphs. While previous work has identified general exploration strategies for raised-line drawings, we have limited knowledge on how this exploration is performed ...</div></span>
          <span id="toHide64" style="display:none;"><br /><div style="display:inline"><p>Raised-line diagrams are widely used by visually impaired (VI) people to read maps, drawings or graphs. While previous work has identified general exploration strategies for raised-line drawings, we have limited knowledge on how this exploration is performed in detail and how it extends to other types of diagrams such as maps or graphs, frequently used in specialized schools. Such information can be crucial for the design of accessible interfaces on touchscreens. We conducted a study in which participants were asked to explore five types of raised-line diagrams (common drawings, perspective drawings, mathematical graphs, neighborhood maps, and geographical maps) while tracking both hands fingers. Relying on a first set of results, we proposed a set of design guidelines for touch interfaces.</p></div></span> <a id="expcoll64" href="JavaScript: expandcollapse('expcoll64',64)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Robots at Work &#38; Home</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025469&CFID=758305256&CFTOKEN=14863114">Sensing and Handling Engagement Dynamics in Human-Robot Interaction Involving Peripheral Computing Devices</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Mingfei Sun, Zhenjie Zhao, Xiaojuan Ma 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 556-567</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025469" title="DOI">10.1145/3025453.3025469</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025469&ftid=1870050&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow66" style="display:inline;"><br /><div style="display:inline">When human partners attend to peripheral computing devices while interacting with conversational robots, the inability of the robots to determine the actual engagement level of the human partners after gaze shift may cause communication breakdown. In ...</div></span>
          <span id="toHide66" style="display:none;"><br /><div style="display:inline"><p>When human partners attend to peripheral computing devices while interacting with conversational robots, the inability of the robots to determine the actual engagement level of the human partners after gaze shift may cause communication breakdown. In this paper, we propose a real-time perception model for robots to estimate human partners' engagement dynamics, and investigate different robot behavior strategies to handle ambiguities in humans' status and ensure the flow of the conversation. In particular, we define four novel types of engagement status and propose a real-time engagement inference model that weighs humans' social signals dynamically according to the involvement of the computing devices. We further design two robot behavior strategies (<i>explicit</i> and <i>implicit</i>) to help resolve uncertainties in engagement inference and mitigate the impact of uncoupling, based on an annotated human-human interaction video corpus. We conducted a within-subject experiment to assess the efficacy and usefulness of the proposed engagement inference model and behavior strategies. Results show that robots with our engagement model can deliver better service and smoother conversations as an assistant, and people find the implicit strategy more polite and appropriate.</p></div></span> <a id="expcoll66" href="JavaScript: expandcollapse('expcoll66',66)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025674&CFID=758305256&CFTOKEN=14863114">Managing Uncertainty in Time Expressions for Virtual Assistants</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Xin Rong, Adam Fourney, Robin N. Brewer, Meredith Ringel Morris, Paul N. Bennett 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 568-579</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025674" title="DOI">10.1145/3025453.3025674</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025674&ftid=1870010&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow67" style="display:inline;"><br /><div style="display:inline">"Remind me to get milk later this afternoon." In communications and planning, people often express uncertainty about time using imprecise temporal expressions (ITEs). Unfortunately, modern virtual assistants often lack system support to capture ...</div></span>
          <span id="toHide67" style="display:none;"><br /><div style="display:inline"><p>"Remind me to get milk <i>later this afternoon</i>." In communications and planning, people often express uncertainty about time using imprecise temporal expressions (ITEs). Unfortunately, modern virtual assistants often lack system support to capture the intents behind these expressions. This can result in unnatural interactions and undesirable interruptions (e.g., having a work reminder delivered at 12pm when out at lunch, because the user said "this afternoon"). In this paper we explore existing practices, expectations, and preferences surrounding the use of ITEs. Our mixed methods approach employs surveys, interviews, and an analysis of a large corpus of written communications. We find that people frequently use a diverse set of ITEs in both communication and planning. These uses reflect a variety of motivations, such as conveying uncertainty or task priority. In addition, we find that people have a variety of expectations about time input and management when interacting with virtual assistants. We conclude with design implications for future virtual assistants.</p></div></span> <a id="expcoll67" href="JavaScript: expandcollapse('expcoll67',67)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025786&CFID=758305256&CFTOKEN=14863114">Comparing Social Robot, Screen and Voice Interfaces for Smart-Home Control</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Michal Luria, Guy Hoffman, Oren Zuckerman 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 580-628</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025786" title="DOI">10.1145/3025453.3025786</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025786&ftid=1870032&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow68" style="display:inline;"><br /><div style="display:inline">With domestic technology on the rise, the quantity and complexity of smart-home devices are becoming an important interaction design challenge. We present a novel design for a home control interface in the form of a social robot, commanded via tangible ...</div></span>
          <span id="toHide68" style="display:none;"><br /><div style="display:inline"><p>With domestic technology on the rise, the quantity and complexity of smart-home devices are becoming an important interaction design challenge. We present a novel design for a home control interface in the form of a social robot, commanded via tangible icons and giving feedback through expressive gestures. We experimentally compare the robot to three common smart-home interfaces: a voice-control loudspeaker; a wall-mounted touch-screen; and a mobile application. Our findings suggest that interfaces that rate higher on flow rate lower on usability, and vice versa. Participants' sense of control is highest using familiar interfaces, and lowest using voice control. Situation awareness is highest using the robot, and also lowest using voice control. These findings raise questions about voice control as a smart-home interface, and suggest that embodied social robots could provide for an engaging interface with high situation awareness, but also that their usability remains a considerable design challenge.</p></div></span> <a id="expcoll68" href="JavaScript: expandcollapse('expcoll68',68)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Self-tracking Mental Health</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025750&CFID=758305256&CFTOKEN=14863114">Self-tracking for Mental Wellness: Understanding Expert Perspectives and Student Experiences</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Christina Kelley, Bongshin Lee, Lauren Wilcox 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 629-641</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025750" title="DOI">10.1145/3025453.3025750</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025750&ftid=1870143&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow70" style="display:inline;"><br /><div style="display:inline">Previous research suggests an important role for self-tracking in promoting mental wellness. Recent studies with college student populations have examined the feasibility of collecting everyday mood, activity, and social data. However, these studies ...</div></span>
          <span id="toHide70" style="display:none;"><br /><div style="display:inline"><p>Previous research suggests an important role for self-tracking in promoting mental wellness. Recent studies with college student populations have examined the feasibility of collecting everyday mood, activity, and social data. However, these studies do not account for students' experiences and challenges adopting self-tracking technologies to support mental wellness goals. We present two studies conducted to better understand self-tracking for stress management and mental wellness in student populations. First, focus groups and card sorting activities with 14 student health professionals reveal expert perspectives on the usefulness of tracking for three scenarios. Second, an online survey of 297 students examines personal experiences with self-tracking and attitudes toward sharing self-tracked data with others. We draw on findings from these studies to characterize students' motivations, challenges and preferences in collecting and viewing self-tracked data related to mental wellness, and we compare findings between students with diagnosed mental illnesses and those without. We conclude with a discussion of challenges and opportunities in leveraging self-tracking for mental wellness, highlighting several design considerations.</p></div></span> <a id="expcoll70" href="JavaScript: expandcollapse('expcoll70',70)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025591&CFID=758305256&CFTOKEN=14863114">"It's Definitely Been a Journey": A Qualitative Study on How Women with Eating Disorders Use Weight Loss Apps</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Elizabeth V. Eikey, Madhu C. Reddy 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 642-654</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025591" title="DOI">10.1145/3025453.3025591</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025591&ftid=1870118&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow71" style="display:inline;"><br /><div style="display:inline">Technology is often viewed as either positive or negative. On one hand, in HCI, weight loss apps are usually seen as a positive influence on users. From the sociocultural perspective, on the other hand, media and technology negatively impact body satisfaction ...</div></span>
          <span id="toHide71" style="display:none;"><br /><div style="display:inline"><p>Technology is often viewed as either positive or negative. On one hand, in HCI, weight loss apps are usually seen as a positive influence on users. From the sociocultural perspective, on the other hand, media and technology negatively impact body satisfaction and contribute to eating disorders; however, these studies fail to include weight loss apps. While these apps can be beneficial to users, they can also have negative effects on users with eating disorder behaviors. Yet few research studies have looked at weight loss apps in relation to eating disorders. In order to fill this gap, we conducted interviews with 16 women with a history of eating disorders who use(d) weight loss apps. While our findings suggest these apps can contribute to and exacerbate eating disorder behaviors, they also reveal a more complex picture of app usage. Women's use and perceptions of weight loss apps shift as they experience life and move to and from stages of change. This research troubles the binary view of technology and emphasizes the importance of looking at technology use as a dynamic process. Our study contributes to our understanding of weight loss app design.</p></div></span> <a id="expcoll71" href="JavaScript: expandcollapse('expcoll71',71)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025902&CFID=758305256&CFTOKEN=14863114">Conflict in Comments: Learning but Lowering Perceptions, with Limits</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          W. Ben Towne, Carolyn P. Ros&#233;, James D. Herbsleb 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 655-666</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025902" title="DOI">10.1145/3025453.3025902</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025902&ftid=1870163&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow72" style="display:inline;"><br /><div style="display:inline">Prior work and perception theory suggests that when exposed to discussion related to a particular piece of crowdsourced text content, readers generally perceive that content to be of lower quality than readers who do not see those comments, and that ...</div></span>
          <span id="toHide72" style="display:none;"><br /><div style="display:inline"><p>Prior work and perception theory suggests that when exposed to discussion related to a particular piece of crowdsourced text content, readers generally perceive that content to be of lower quality than readers who do not see those comments, and that the effect is stronger if the comments display conflict. This paper presents a controlled experiment with over 1000 participants testing to see if this effect carries over to other documents from the same platform, including those with similar content or by the same author. Although we do generally find that perceived quality of the commented-on document is affected, effects do not carry over to the second item and readers are able to judge the second in isolation from the comment on the first. We confirm a prior finding about the negative effects conflict can have on perceived quality but note that readers report learning more from constructive conflict comments.</p></div></span> <a id="expcoll72" href="JavaScript: expandcollapse('expcoll72',72)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025690&CFID=758305256&CFTOKEN=14863114">Identification and Classification of Usage Patterns in Long-Term Activity Tracking</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Jochen Meyer, Merlin Wasmann, Wilko Heuten, Abdallah El Ali, Susanne C.J. Boll 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 667-678</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025690" title="DOI">10.1145/3025453.3025690</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025690&ftid=1870130&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow73" style="display:inline;"><br /><div style="display:inline">Activity trackers are frequently used in health and well-being, but their application in effective interventions is challenging. While research for reasons of use and non-use is ongoing, little is known about the way activity trackers are used in everyday ...</div></span>
          <span id="toHide73" style="display:none;"><br /><div style="display:inline"><p>Activity trackers are frequently used in health and well-being, but their application in effective interventions is challenging. While research for reasons of use and non-use is ongoing, little is known about the way activity trackers are used in everyday life and over longer periods. We analyzed data of 104 individuals over 14,413 use days, and in total over 2.5 years. We describe general tracker use, periodic changes and overall changes over time, and identify characteristic patterns. While the use of trackers shows large individual heterogeneity, from our findings we could identify and classify general patterns for activity tracker use such as try-and-drop, slow-starter, experimenter, hop-on hop-off, intermittent and power user. Our findings contribute to the body of knowledge towards the successful design of effective health technologies, health interventions, and long-term health applications.</p></div></span> <a id="expcoll73" href="JavaScript: expandcollapse('expcoll73',73)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Smartwatch Interactions and Displays</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3026029&CFID=758305256&CFTOKEN=14863114">AirPanes: Two-Handed Around-Device Interaction for Pane Switching on Smartphones</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Khalad Hasan, David Ahlstr&#246;m, Junhyeok Kim, Pourang Irani 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 679-691</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3026029" title="DOI">10.1145/3025453.3026029</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3026029&ftid=1870164&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow75" style="display:inline;"><br /><div style="display:inline">In recent years, around device input has emerged as a complement to standard touch input, albeit in limited tasks and contexts, such as for item selection or map navigation. We push the boundaries for around device interactions to facilitate an entire ...</div></span>
          <span id="toHide75" style="display:none;"><br /><div style="display:inline"><p>In recent years, around device input has emerged as a complement to standard touch input, albeit in limited tasks and contexts, such as for item selection or map navigation. We push the boundaries for around device interactions to facilitate an entire smartphone application: browsing through large information lists to make a decision. To this end, we present AirPanes, a novel technique that allows two-handed in-air interactions, conjointly with touch input to perform analytic tasks, such as making a purchase decision. AirPanes resolves the inefficiencies of having to switch between multiple views or panes in common smartphone applications. We explore the design factors that make AirPanes efficient. In a controlled study, we find that AirPanes is on average 50% more efficient that standard touch input for an analytic task. We offer recommendations for implementing AirPanes in a broad range of applications.</p></div></span> <a id="expcoll75" href="JavaScript: expandcollapse('expcoll75',75)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3026027&CFID=758305256&CFTOKEN=14863114">Float: One-Handed and Touch-Free Target Selection on Smartwatches</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Ke Sun, Yuntao Wang, Chun Yu, Yukang Yan, Hongyi Wen, Yuanchun Shi 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 692-704</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3026027" title="DOI">10.1145/3025453.3026027</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3026027&ftid=1870166&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow76" style="display:inline;"><br /><div style="display:inline">Touch interaction on smartwatches suffers from the awkwardness of having to use two hands and the "fat finger" problem. We present Float, a wrist-to-finger input approach that enables one-handed and touch-free target selection on smartwatches with high ...</div></span>
          <span id="toHide76" style="display:none;"><br /><div style="display:inline"><p>Touch interaction on smartwatches suffers from the awkwardness of having to use two hands and the "fat finger" problem. We present Float, a wrist-to-finger input approach that enables one-handed and touch-free target selection on smartwatches with high efficiency and precision using only commercially-available built-in sensors. With Float, a user tilts the wrist to point and performs an in-air finger tap to click. To realize Float, we first explore the appropriate motion space for wrist tilt and determine the clicking action (finger tap) through a user-elicitation study. We combine the photoplethysmogram (PPG) signal with accelerometer and gyroscope to detect finger taps with a recall of 97.9% and a false discovery rate of 0.4%. Experiments show that using just one hand, Float allows users to acquire targets with size ranging from 2mm to 10mm in less than 2s to 1s, meanwhile achieve much higher accuracy than direct touch in both stationary (&gt;98.9%) and walking (&gt;71.5%) contexts.</p></div></span> <a id="expcoll76" href="JavaScript: expandcollapse('expcoll76',76)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/bp_award.jpg" alt="Best Paper" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025454&CFID=758305256&CFTOKEN=14863114">COMPASS: Rotational Keyboard on Non-Touch Smartwatches</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Xin Yi, Chun Yu, Weijie Xu, Xiaojun Bi, Yuanchun Shi 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 705-715</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025454" title="DOI">10.1145/3025453.3025454</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025454&ftid=1870158&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow77" style="display:inline;"><br /><div style="display:inline">Entering text is very challenging on smartwatches, especially on non-touch smartwatches where virtual keyboards are unavailable. In this paper, we designed and implemented COMPASS, a non-touch bezel-based text entry technique. COMPASS positions multiple ...</div></span>
          <span id="toHide77" style="display:none;"><br /><div style="display:inline"><p>Entering text is very challenging on smartwatches, especially on non-touch smartwatches where virtual keyboards are unavailable. In this paper, we designed and implemented COMPASS, a non-touch bezel-based text entry technique. COMPASS positions multiple cursors on a circular keyboard, with the location of each cursor dynamically optimized during typing to minimize rotational distance. To enter text, a user rotates the bezel to select keys with any nearby cursors. The design of COMPASS was justified by an iterative design process and user studies. Our evaluation showed that participants achieved a pick-up speed around 10 WPM and reached 12.5 WPM after 90-minute practice. COMPASS allows users to enter text on non-touch smartwatches, and also serves as an alternative for entering text on touch smartwatches when touch is unavailable (e.g., wearing gloves).</p></div></span> <a id="expcoll77" href="JavaScript: expandcollapse('expcoll77',77)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025852&CFID=758305256&CFTOKEN=14863114">WatchThru: Expanding Smartwatch Displays with Mid-air Visuals and Wrist-worn Augmented Reality</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Dirk Wenig, Johannes Sch&#246;ning, Alex Olwal, Mathias Oben, Rainer Malaka 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 716-721</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025852" title="DOI">10.1145/3025453.3025852</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025852&ftid=1870141&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow78" style="display:inline;"><br /><div style="display:inline">We introduce WatchThru, an interactive method for extended wrist-worn display on commercially-available smartwatches. To address the limited visual and interaction space, WatchThru expands the device into 3D through a transparent display. This enables ...</div></span>
          <span id="toHide78" style="display:none;"><br /><div style="display:inline"><p>We introduce WatchThru, an interactive method for extended wrist-worn display on commercially-available smartwatches. To address the limited visual and interaction space, WatchThru expands the device into 3D through a transparent display. This enables novel interactions that leverage and extend smartwatch glanceability. We describe three novel interaction techniques, <i>Pop-up Visuals</i>, <i>Second Perspective</i> and <i>Peek-through</i>, and discuss how they can complement interaction on current devices. We also describe two types of prototypes that helped us to explore standalone interactions, as well as, proof-of-concept AR interfaces using our platform.</p></div></span> <a id="expcoll78" href="JavaScript: expandcollapse('expcoll78',78)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025657&CFID=758305256&CFTOKEN=14863114">Evaluation of Korean Text Entry Methods for Smartwatches</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Ivaylo Ilinkin, Sunghee Kim 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 722-726</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025657" title="DOI">10.1145/3025453.3025657</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025657&ftid=1870153&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow79" style="display:inline;"><br /><div style="display:inline">This paper presents results from a user study designed to evaluate the effectiveness of Korean text entry methods for smartwatches. Specifically, the study compares the four popular text entry methods for smartphones in the context of smartwatch use ...</div></span>
          <span id="toHide79" style="display:none;"><br /><div style="display:inline"><p>This paper presents results from a user study designed to evaluate the effectiveness of Korean text entry methods for smartwatches. Specifically, the study compares the four popular text entry methods for smartphones in the context of smartwatch use (three multi-tap 3x4 keypad methods and a QWERTY-like method). A distinctive feature of text entry in Korea is that traditionally different manufacturers have developed their own text entry methods starting with particular physical layouts on feature phones that are now available as soft keypads on smartphones. This research considers the next step in this progression by studying the viability of adopting these text entry methods on smartwatches. The results from the user study indicate that existing methods can be effective for text entry on smartwatches; analysis of the data offers suggestions for improving the effectiveness of the methods.</p></div></span> <a id="expcoll79" href="JavaScript: expandcollapse('expcoll79',79)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Social &#38; Collaborative Technologies</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025484&CFID=758305256&CFTOKEN=14863114">"WhatsApp is for family; Messenger is for friends": Communication Places in App Ecosystems</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Midas Nouwens, Carla F. Griggio, Wendy E. Mackay 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 727-735</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025484" title="DOI">10.1145/3025453.3025484</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025484&ftid=1870116&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow81" style="display:inline;"><br /><div style="display:inline">Today's users communicate via multiple apps, even when they offer almost identical functionality. We studied how and why users distribute their contacts within their app ecosystem. We found that the contacts in an app affect a user's conversations with ...</div></span>
          <span id="toHide81" style="display:none;"><br /><div style="display:inline"><p>Today's users communicate via multiple apps, even when they offer almost identical functionality. We studied how and why users distribute their contacts within their app ecosystem. We found that the contacts in an app affect a user's conversations with other contacts, their communication patterns in the app, and the quality of their social relationships. Users appropriate the features and technical constraints of their apps to create idiosyncratic <i>communication places</i>, each with its own recursively defined membership rules, perceived purposes, and emotional connotations. Users also shift the boundaries of their communication places to accommodate changes in their contacts' behaviour, the dynamics of their relationships, and the restrictions of the technology. We argue that communication apps should support creating multiple communication places within the same app, relocating conversations across apps, and accessing functionality from other apps.</p></div></span> <a id="expcoll81" href="JavaScript: expandcollapse('expcoll81',81)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025709&CFID=758305256&CFTOKEN=14863114">I Need Your Encouragement!: Requesting Supportive Comments on Social Media Reduces Test Anxiety</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Robert Deloatch, Brian P. Bailey, Alex Kirlik, Craig Zilles 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 736-747</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025709" title="DOI">10.1145/3025453.3025709</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025709&ftid=1870119&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow82" style="display:inline;"><br /><div style="display:inline">Many students underperform on exams due to experiencing high test anxiety. We report on a study comparing a novel intervention of seeking support from one's social network to the more common approaches of expressive writing and studying task-relevant ...</div></span>
          <span id="toHide82" style="display:none;"><br /><div style="display:inline"><p>Many students underperform on exams due to experiencing high test anxiety. We report on a study comparing a novel intervention of seeking support from one's social network to the more common approaches of expressive writing and studying task-relevant materials for simulated open-ended test questions. We measured in-the-moment (state) anxiety before and after each intervention, and correctness of the solutions. We also surveyed students to learn about their perceptions of the interventions. Our results showed that social support decreased the anxiety of high test-anxious students by 21% with the reduction in anxiety correlating with the number of messages received. Social support also allowed high test-anxious students to score at the level of low test-anxious students. Expressive writing showed a similar effect, but increased the anxiety of low test-anxious students by 61%. Studying task materials had no effect on anxiety and high test-anxious students performed worse than low test-anxious students. Despite benefiting from social support, we found that students were uncomfortable soliciting support from their online social network. Realizing the benefits of this approach may therefore require different formulations of social support in practice.</p></div></span> <a id="expcoll82" href="JavaScript: expandcollapse('expcoll82',82)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025800&CFID=758305256&CFTOKEN=14863114">Goodbye Text, Hello Emoji: Mobile Communication on WeChat in China</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Rui Zhou, Jasmine Hentschel, Neha Kumar 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 748-759</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025800" title="DOI">10.1145/3025453.3025800</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025800&ftid=1870133&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow83" style="display:inline;"><br /><div style="display:inline">We present a qualitative study of mobile communication via WeChat in Southern China, focusing on the rapid proliferation of emoji and stickers and the lessening dependence on text. We use interview and observation data from 30 participants to investigate ...</div></span>
          <span id="toHide83" style="display:none;"><br /><div style="display:inline"><p>We present a qualitative study of mobile communication via WeChat in Southern China, focusing on the rapid proliferation of emoji and stickers and the lessening dependence on text. We use interview and observation data from 30 participants to investigate how rural, small town, and urban Chinese adults creatively and innovatively balance the use of emoji, stickers, and text in their mobile communication practices. We also discuss design implications of our research for the field of HCI, offering ways of leveraging the non-textual communication practices that we uncover, in scenarios where purely text-based communication may not suffice.</p></div></span> <a id="expcoll83" href="JavaScript: expandcollapse('expcoll83',83)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025839&CFID=758305256&CFTOKEN=14863114">A Kaleidoscope of Languages: When and How Non-Native English Speakers Shift between English and Their Native Language during Multilingual Teamwork</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Ge Gao, Susan R. Fussell 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 760-772</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025839" title="DOI">10.1145/3025453.3025839</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025839&ftid=1870139&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow84" style="display:inline;"><br /><div style="display:inline">Multilingual teams often include subgroups of members who share a native language different from the team's common language. Linguistic choices by members of these subgroups can have implications for information exchange at the team level. We reported ...</div></span>
          <span id="toHide84" style="display:none;"><br /><div style="display:inline"><p>Multilingual teams often include subgroups of members who share a native language different from the team's common language. Linguistic choices by members of these subgroups can have implications for information exchange at the team level. We reported a field study of language use in 3 multilingual teams, each of which consisted of some native English speakers (NS) and some non-native English speakers (NNS) who shared a native language with at least one other team member. We found that NNS often shifted between English and their native language. The way language shift happened differed for formal meetings, informal conversations, and instant messaging. Language variation was often associated with shifts in content, participants, and communication medium. Further analysis indicated that language shift had both benefits and costs for team communication, depending on the context in which it happened. Based on these findings, we outline suggestions for designing multilingual collaboration systems.</p></div></span> <a id="expcoll84" href="JavaScript: expandcollapse('expcoll84',84)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Sustainability and Public Service</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025858&CFID=758305256&CFTOKEN=14863114">The (Un)sustainability of Imagined Future Information Societies</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Daniel Pargman, Elina Eriksson, Mattias H&#246;jer, Ulrika Gunnarsson &#214;stling, Luciane Aguiar Borges 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 773-785</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025858" title="DOI">10.1145/3025453.3025858</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025858&ftid=1870124&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow86" style="display:inline;"><br /><div style="display:inline">The pathway to a sustainable society is not clear, and we need to consider different developmental possibilities. This paper describes the results of a research project in the intersection of HCI and Futures Studies as well as in the intersection between ...</div></span>
          <span id="toHide86" style="display:none;"><br /><div style="display:inline"><p>The pathway to a sustainable society is not clear, and we need to consider different developmental possibilities. This paper describes the results of a research project in the intersection of HCI and Futures Studies as well as in the intersection between "the future information society" and sustainability. We here present parts of the body of materials that were developed in a multi-year research project with the aim of describing and evaluating the sustainability impact of possible future information societies. We also discuss some of the lessons learned and what HCI and design fiction can learn from Futures Studies in general and from this project in particular. The main stakeholders in this project have been city administrators and corporate partners, and the overarching goal has primarily been to influence planning processes at the regional (Stockholm, Sweden) level.</p></div></span> <a id="expcoll86" href="JavaScript: expandcollapse('expcoll86',86)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025542&CFID=758305256&CFTOKEN=14863114">Means and Ends in Human-Computer Interaction: Sustainability through Disintermediation</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Barath Raghavan, Daniel Pargman 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 786-796</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025542" title="DOI">10.1145/3025453.3025542</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025542&ftid=1870154&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow87" style="display:inline;"><br /><div style="display:inline">There has been an increased interest in broader contexts from ecology and economics within the HCI community in recent years. These developments suggest that the HCI community should engage with and respond to concerns that are external to computing ...</div></span>
          <span id="toHide87" style="display:none;"><br /><div style="display:inline"><p>There has been an increased interest in broader contexts from ecology and economics within the HCI community in recent years. These developments suggest that the HCI community should engage with and respond to concerns that are external to computing yet profoundly impact human society. In this paper we observe that taking these broader contexts into account yields a fundamentally different way to think about sustainable interaction design, one in which the designer's focus must be on a) ecological limits, b) creating designs and artifacts that do not further a cornucopian paradigm, and c) fundamental human needs.</p> <p>It can be hard to be responsive to these contexts in practical HCI work. To address this, we propose that the design rubric of disintermediation can serve as a unifying approach for work that aims to meet the ecological and economic challenges outlined in the literature. After discussing the potential use and impact of disintermedation, we perform an analysis using this design rubric to several key application areas.</p></div></span> <a id="expcoll87" href="JavaScript: expandcollapse('expcoll87',87)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025979&CFID=758305256&CFTOKEN=14863114">Crowdfunding Platforms and the Design of Paying Publics</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Ann Light, Jo Briggs 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 797-809</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025979" title="DOI">10.1145/3025453.3025979</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025979&ftid=1870150&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow88" style="display:inline;"><br /><div style="display:inline">Crowdfunding enables groups to self-fund the changes they want to make in the world. In other words, digital financial platforms are proving capable of supporting new relations between groups of people as well as offering new ways to organize money. ...</div></span>
          <span id="toHide88" style="display:none;"><br /><div style="display:inline"><p>Crowdfunding enables groups to self-fund the changes they want to make in the world. In other words, digital financial platforms are proving capable of supporting new relations between groups of people as well as offering new ways to organize money. Taking an HCI lens, we look at how some crowdfunding platform owners are approaching social innovation, not only at the level of supporting individual community initiatives, but at the broader level of using their platform to change societal behavior. Through four case studies, we show how crowdfunding has been chosen as a tool to redesign society by promoting environmental or social sustainability. We argue that the groups constituted through these interactions are not merely "crowds", but deliberate constellations built round a thing of interest (or "paying publics"). Our interviews with managers and owners explore how interactions with and around platforms work to achieve these ends and we conclude with design considerations.</p></div></span> <a id="expcoll88" href="JavaScript: expandcollapse('expcoll88',88)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025637&CFID=758305256&CFTOKEN=14863114">Reappropriating Hackathons: The Production Work of the CHI4Good Day of Service</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Emily Porter, Chris Bopp, Elizabeth Gerber, Amy Voida 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 810-814</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025637" title="DOI">10.1145/3025453.3025637</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025637&ftid=1870134&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow89" style="display:inline;"><br /><div style="display:inline">The popularity of hackathons has increased as technology pervades more facets of our lives. Originally designed for programmers, hackathons are now being appropriated by new stakeholders across diverse sectors. Yet with this evolution in hackathons, ...</div></span>
          <span id="toHide89" style="display:none;"><br /><div style="display:inline"><p>The popularity of hackathons has increased as technology pervades more facets of our lives. Originally designed for programmers, hackathons are now being appropriated by new stakeholders across diverse sectors. Yet with this evolution in hackathons, we no longer adequately understand what is produced and, thereby, the value of these events. We conducted an interview study with 22 stakeholders - participants, representatives of nonprofit organizations, and organizers - of the CHI4Good Day of Service to understand what is produced through philanthropic hackathons. Whereas traditional hackathons are oriented around the production of code or prototypes, our analysis of interview data suggests that the production work of philanthropic hackathons also includes technical capacity and expertise, expanded social networks, an exposure to design process, affective experiences, and an opportunity for participants to shape their identities against a cross-sectoral, interdisciplinary backdrop. We conclude by reflecting on implications for the CHI community in carrying out philanthropic events styled after hackathons.</p></div></span> <a id="expcoll89" href="JavaScript: expandcollapse('expcoll89',89)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Understanding Data Visualization</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025977&CFID=758305256&CFTOKEN=14863114">Understanding Concept Maps: A Closer Look at How People Organise Ideas</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Stefano Padilla, Thomas S. Methven, David A. Robb, Mike J. Chantler 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 815-827</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025977" title="DOI">10.1145/3025453.3025977</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025977&ftid=1870125&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow91" style="display:inline;"><br /><div style="display:inline">Research into creating visualisations that organise ideas into concise concept maps often focuses on implicit mathematical and statistical theories which are built around algorithmic efficacy or visual complexity. Although there are multiple techniques ...</div></span>
          <span id="toHide91" style="display:none;"><br /><div style="display:inline"><p>Research into creating visualisations that organise ideas into concise concept maps often focuses on implicit mathematical and statistical theories which are built around algorithmic efficacy or visual complexity. Although there are multiple techniques which attempt to mathematically optimise this multi-dimensional problem, it is still unknown how to create concept maps that are immediately understandable to people. In this paper, we present an in-depth qualitative study observing the behaviour and discussing the strategy used by non-expert participants to create, interact, update and communicate a concept map that represents a collection of research ideas. Our results show non-expert individuals create concept maps differently to visualisation algorithms. We found that our participants prioritised narrative, landmarks, abstraction, clarity, and simplicity. Finally, we derive design recommendations from our results which we hope will inspire future algorithms that automatically create more usable and compelling concept maps better suited to the natural behaviours and needs of users.</p></div></span> <a id="expcoll91" href="JavaScript: expandcollapse('expcoll91',91)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025998&CFID=758305256&CFTOKEN=14863114">Increasing Users' Confidence in Uncertain Data by Aggregating Data from Multiple Sources</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Miriam Greis, Emre Avci, Albrecht Schmidt, Tonja Machulla 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 828-840</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025998" title="DOI">10.1145/3025453.3025998</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025998&ftid=1870140&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow92" style="display:inline;"><br /><div style="display:inline">We often base our decisions on uncertain data - for instance, when consulting the weather forecast before deciding what to wear. Due to their uncertainty, such forecasts can differ by provider. To make an informed decision, many people compare several ...</div></span>
          <span id="toHide92" style="display:none;"><br /><div style="display:inline"><p>We often base our decisions on uncertain data - for instance, when consulting the weather forecast before deciding what to wear. Due to their uncertainty, such forecasts can differ by provider. To make an informed decision, many people compare several forecasts, which is a time-consuming and cumbersome task. To facilitate comparison, we identified three aggregation mechanisms for forecasts: manual comparison and two mechanisms of computational aggregation. In a survey, we compared the mechanisms using different representations. We then developed a weather application to evaluate the most promising candidates in a real-world study. Our results show that aggregation increases users' confidence in uncertain data, independent of the type of representation. Further, we find that for daily events, users prefer to use computationally aggregated forecasts. However, for high-stakes events, they prefer manual comparison. We discuss how our findings inform the design of improved interfaces for comparison of uncertain data, including non-weather purposes.</p></div></span> <a id="expcoll92" href="JavaScript: expandcollapse('expcoll92',92)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025942&CFID=758305256&CFTOKEN=14863114">Bottom-up vs. Top-down: Trade-offs in Efficiency, Understanding, Freedom and Creativity with InfoVis Tools</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Gonzalo Gabriel M&#233;ndez, Uta Hinrichs, Miguel A. Nacenta 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 841-852</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025942" title="DOI">10.1145/3025453.3025942</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025942&ftid=1870145&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow93" style="display:inline;"><br /><div style="display:inline">The emergence of tools that support fast-and-easy visualization creation by non-experts has made the benefits of InfoVis widely accessible. Key features of these tools include attribute-level operations, automated mappings, and visualization templates. ...</div></span>
          <span id="toHide93" style="display:none;"><br /><div style="display:inline"><p>The emergence of tools that support fast-and-easy visualization creation by non-experts has made the benefits of InfoVis widely accessible. Key features of these tools include attribute-level operations, automated mappings, and visualization templates. However, these features shield people from lower-level visualization design steps, such as the specific mapping of data points to visuals. In contrast, recent research promotes constructive visualization where individual data units and visuals are directly manipulated. We present a qualitative study comparing people's visualization processes using two visualization tools: one promoting a top-down approach to visualization construction (Tableau Desktop) and one implementing a bottom-up constructive visualization approach (iVoLVER). Our results show how the two approaches influence: 1) the visualization process, 2) decisions on the visualization design, 3) the feeling of control and authorship, and 4) the willingness to explore alternative designs. We discuss the complex trade-offs between the two approaches and outline considerations for designing better visualization tools.</p></div></span> <a id="expcoll93" href="JavaScript: expandcollapse('expcoll93',93)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025485&CFID=758305256&CFTOKEN=14863114">What Happened in my Home?: An End-User Development Approach for Smart Home Data Visualization</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Nico Castelli, Corinna Ogonowski, Timo Jakobi, Martin Stein, Gunnar Stevens, Volker Wulf 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 853-866</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025485" title="DOI">10.1145/3025453.3025485</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025485&ftid=1870120&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow94" style="display:inline;"><br /><div style="display:inline">Smart home systems change the way we experience the home. While there are established research fields within HCI for visualizing specific use cases of a smart home, studies targeting user demands on visualizations spanning across multiple use cases are ...</div></span>
          <span id="toHide94" style="display:none;"><br /><div style="display:inline"><p>Smart home systems change the way we experience the home. While there are established research fields within HCI for visualizing specific use cases of a smart home, studies targeting user demands on visualizations spanning across multiple use cases are rare. Especially, individual data-related demands pose a challenge for usable visualizations. To investigate potentials of an end-user development (EUD) approach for flexibly supporting such demands, we developed a smart home system featuring both pre-defined visualizations and a visualization creation tool. To evaluate our concept, we installed our prototype in 12 households as part of a Living Lab study. Results are based on three interview studies, a design workshop and system log data. We identified eight overarching interests in home data and show how participants used pre-defined visualizations to get an overview and the creation tool to not only address specific use cases but also to answer questions by creating temporary visualizations.</p></div></span> <a id="expcoll94" href="JavaScript: expandcollapse('expcoll94',94)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Clinical Settings</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3026040&CFID=758305256&CFTOKEN=14863114">Opportunities and Design Considerations for Peer Support in a Hospital Setting</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Shefali Haldar, Sonali R. Mishra, Maher Khelifi, Ari H. Pollack, Wanda Pratt 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 867-879</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3026040" title="DOI">10.1145/3025453.3026040</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3026040&ftid=1870161&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow96" style="display:inline;"><br /><div style="display:inline">Although research has demonstrated improved outcomes for outpatients who receive peer support-such as through online health communities, support groups, and mentoring systems-hospitalized patients have few mechanisms to receive such valuable support. ...</div></span>
          <span id="toHide96" style="display:none;"><br /><div style="display:inline"><p>Although research has demonstrated improved outcomes for outpatients who receive peer support-such as through online health communities, support groups, and mentoring systems-hospitalized patients have few mechanisms to receive such valuable support. To explore the opportunities for a hospital-based peer support system, we administered a survey to 146 pediatric patients and caregivers, and conducted semi-structured interviews with twelve patients and three caregivers in a children's hospital. Our analysis revealed that hospitalized individuals need peer support for five key purposes: (1) to ask about medical details-such as procedures, treatments, and medications; (2) to learn about healthcare providers; (3) to report and prevent medical errors; (4) to exchange emotional support; and (5) to manage their time in the hospital. In this paper, we examine these themes and describe potential barriers to using a hospital-based peer support system. We then discuss the unique opportunities and challenges that the hospital environment presents when designing for peer support in this setting.</p></div></span> <a id="expcoll96" href="JavaScript: expandcollapse('expcoll96',96)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025978&CFID=758305256&CFTOKEN=14863114">Patient Strategies as Active Adaptation: Understanding Patient Behaviors During an Emergency Visit</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Sun Young Park, Yunan Chen 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 880-892</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025978" title="DOI">10.1145/3025453.3025978</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025978&ftid=1870159&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow97" style="display:inline;"><br /><div style="display:inline">Although the ability of patients to access their health information during ongoing care is considered crucial for better health outcomes and increased satisfaction, the current care model places patients in a passive role. To investigate the patient ...</div></span>
          <span id="toHide97" style="display:none;"><br /><div style="display:inline"><p>Although the ability of patients to access their health information during ongoing care is considered crucial for better health outcomes and increased satisfaction, the current care model places patients in a passive role. To investigate the patient experience in the hospital environment where information is lacking and in accessible, we conducted an ethnographic study with patients, caregivers, and healthcare providers in the emergency care setting. We report the three types of information breakdowns ED patients encountered during their emergency visits and the strategies they developed to cope. Our findings reveal a rich picture of the coping mechanisms ED patients use to proactively adapt to the nature of the ED care context. This work expands upon our understanding of the unique information challenges ED patients face, as well as the important adapting behaviors they engage in; it also uncovers design opportunities for supporting crucial, yet unmet, patient information needs.</p></div></span> <a id="expcoll97" href="JavaScript: expandcollapse('expcoll97',97)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025569&CFID=758305256&CFTOKEN=14863114">Itchtector: A Wearable-based Mobile System for Managing Itching Conditions</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Jongin Lee, Daeki Cho, Junhong Kim, Eunji Im, JinYeong Bak, Kyung ho Lee, Kwan Hong Lee, John Kim 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 893-905</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025569" title="DOI">10.1145/3025453.3025569</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025569&ftid=1870135&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow98" style="display:inline;"><br /><div style="display:inline">Severe itching conditions such as eczema or atopic dermatitis can have a significant impact on one's quality of life. Unfortunately, many of these conditions cannot be cured, and the focus is often on properly controlling or managing the condition. Thus, ...</div></span>
          <span id="toHide98" style="display:none;"><br /><div style="display:inline"><p>Severe itching conditions such as eczema or atopic dermatitis can have a significant impact on one's quality of life. Unfortunately, many of these conditions cannot be cured, and the focus is often on properly controlling or managing the condition. Thus, it is important to understand or objectively monitor how one's scratching behavior changes, based on medication or treatment or environmental conditions. In this work, we explore how wearable devices can support people with itching conditions to better manage their conditions. We carried out a three-phase study with 40 participants and 2 dermatologists to understand the implications of various system features and designs. Based on interviews with patients and doctors, we incorporated medical guidelines for treatment and patients' needs in the proposed Itchtector - a smartwatch-based mobile system to monitor itching behaviors and provide objective information about the user's scratching behaviors. Using the Itchtector prototype, we evaluated performance and possible acceptance with subjects.</p></div></span> <a id="expcoll98" href="JavaScript: expandcollapse('expcoll98',98)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Digital Privacy &#38; Security</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025961&CFID=758305256&CFTOKEN=14863114">Privacy, Security, and Surveillance in the Global South: A Study of Biometric Mobile SIM Registration in Bangladesh</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Syed Ishtiaque Ahmed, Md. Romael Haque, Shion Guha, Md. Rashidujjaman Rifat, Nicola Dell 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 906-918</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025961" title="DOI">10.1145/3025453.3025961</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025961&ftid=1870157&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow100" style="display:inline;"><br /><div style="display:inline">With the rapid growth of ICT adoption in the Global South, crimes over and through digital technologies have also increased. Consequently, governments have begun to undertake a variety of different surveillance programs, which in turn provoke questions ...</div></span>
          <span id="toHide100" style="display:none;"><br /><div style="display:inline"><p>With the rapid growth of ICT adoption in the Global South, crimes over and through digital technologies have also increased. Consequently, governments have begun to undertake a variety of different surveillance programs, which in turn provoke questions regarding citizens' privacy rights. However, both the concepts of privacy and of citizens' corresponding political rights have not been well-developed in HCI for non-Western contexts. This paper presents findings from a three-month long ethnography and online survey (n=606) conducted in Bangladesh, where the government recently imposed mandatory biometric registration for every mobile phone user. Our analysis surfaces important privacy and safety concerns regarding identity, ownership, and trust, and reveals the cultural and political challenges of imposing biometric registration program in Bangladesh. We also discuss how alternative designs of infrastructure, technology, and policy may better meet stakeholders' competing needs in the Global South.</p></div></span> <a id="expcoll100" href="JavaScript: expandcollapse('expcoll100',100)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025823&CFID=758305256&CFTOKEN=14863114">Youth Perspectives on Critical Data Literacies</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Samantha Hautea, Sayamindu Dasgupta, Benjamin Mako Hill 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 919-930</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025823" title="DOI">10.1145/3025453.3025823</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025823&ftid=1870126&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow101" style="display:inline;"><br /><div style="display:inline">As contemporary youth learn, play, and socialize online, their activities are often being recorded and analyzed. What should young people know about these data collection and analysis efforts? Although critiques of these new forms of data collection ...</div></span>
          <span id="toHide101" style="display:none;"><br /><div style="display:inline"><p>As contemporary youth learn, play, and socialize online, their activities are often being recorded and analyzed. What should young people know about these data collection and analysis efforts? Although critiques of these new forms of data collection and analysis have grown increasingly loud, the voices of users, and particularly youth, have largely been absent. This paper explores the critical perspectives of youth who are programming with public data about their own learning and social interaction in the Scratch online community. Using a bottom-up approach based on ethnographic observation of discussions among these young users, we identify a series of themes in how these youth critique, question, and debate the implications of data analytics. We connect these themes-framed in terms of critical data literacies-to expert critiques and discuss the implications of these findings for education and design.</p></div></span> <a id="expcoll101" href="JavaScript: expandcollapse('expcoll101',101)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025673&CFID=758305256&CFTOKEN=14863114">Where is the Digital Divide?: A Survey of Security, Privacy, and Socioeconomics</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Elissa M. Redmiles, Sean Kross, Michelle L. Mazurek 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 931-936</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025673" title="DOI">10.1145/3025453.3025673</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025673&ftid=1870129&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow102" style="display:inline;"><br /><div style="display:inline">The behavior of the least-secure user can influence security and privacy outcomes for everyone else. Thus, it is important to understand the factors that influence the security and privacy of a broad variety of people. Prior work has suggested that users ...</div></span>
          <span id="toHide102" style="display:none;"><br /><div style="display:inline"><p>The behavior of the least-secure user can influence security and privacy outcomes for everyone else. Thus, it is important to understand the factors that influence the security and privacy of a broad variety of people. Prior work has suggested that users with differing socioeconomic status (SES) may behave differently; however, no research has examined how SES, advice sources, and resources relate to the security and privacy incidents users report. To address this question, we analyze a 3,000 respondent, census-representative telephone survey. We find that, contrary to prior assumptions, people with lower educational attainment report equal or fewer incidents as more educated people, and that users' experiences are significantly correlated with their advice sources, regardless of SES or resources.</p></div></span> <a id="expcoll102" href="JavaScript: expandcollapse('expcoll102',102)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Educational Assessment</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025841&CFID=758305256&CFTOKEN=14863114">A Unified Framework for Knowledge Assessment and Progression Analysis and Design</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Shuhan Wang, Fang He, Erik Andersen 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 937-948</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025841" title="DOI">10.1145/3025453.3025841</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025841&ftid=1870162&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow104" style="display:inline;"><br /><div style="display:inline">Designing engaging learning content is important but difficult, and typically involves a lot of manual specification. We present a unified framework that utilizes automatic problem decomposition and partial ordering graph construction to facilitate multiple ...</div></span>
          <span id="toHide104" style="display:none;"><br /><div style="display:inline"><p>Designing engaging learning content is important but difficult, and typically involves a lot of manual specification. We present a unified framework that utilizes automatic problem decomposition and partial ordering graph construction to facilitate multiple workflows: knowledge assessment and progression analysis and design. We present results from a study with 847 participants in an online Japanese-language assessment tool demonstrating that our framework can efficiently measure student ability and predict student performance on specific problems. We also present results from analysis of curricula showing that the progressions of two different textbooks are surprisingly similar, and that our framework can lead to the discovery of general principles of expert progression design. Finally, we demonstrate automatic progression generation with desired sequencing and pacing, allowing for tailoring of progressions and mapping of parameters extracted from one curriculum onto another.</p></div></span> <a id="expcoll104" href="JavaScript: expandcollapse('expcoll104',104)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025789&CFID=758305256&CFTOKEN=14863114">HOBIT: Hybrid Optical Bench for Innovative Teaching</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          David Furi&#243;, St&#233;phanie Fleck, Bruno Bousquet, Jean-Paul Guillet, Lionel Canioni, Martin Hachet 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 949-959</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025789" title="DOI">10.1145/3025453.3025789</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025789&ftid=1870136&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow105" style="display:inline;"><br /><div style="display:inline">Practical work in optics allows supporting the construction of knowledge, in particular when the concept to be learned remains diffuse. To overcome the limitations of the current experimental setups, we have designed a hybrid system that combines physical ...</div></span>
          <span id="toHide105" style="display:none;"><br /><div style="display:inline"><p>Practical work in optics allows supporting the construction of knowledge, in particular when the concept to be learned remains diffuse. To overcome the limitations of the current experimental setups, we have designed a hybrid system that combines physical interaction and numerical simulation. This system relies on 3D-printed replicas of optical elements, which are augmented with pedagogical information. In this paper, we focus on the well-known Michelson interferometer experiment, widely studied in undergraduate programs of Science. A 3-months user study with 101 students and 6 teachers showed that, beyond the practical aspects offered by this system, such an approach enhances the technical and scientific learning compared to a standard Michelson interferometer experiment.</p></div></span> <a id="expcoll105" href="JavaScript: expandcollapse('expcoll105',105)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025819&CFID=758305256&CFTOKEN=14863114">PathViewer: Visualizing Pathways through Student Data</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Yiting Wang, Walker M. White, Erik Andersen 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 960-964</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025819" title="DOI">10.1145/3025453.3025819</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025819&ftid=1870137&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow106" style="display:inline;"><br /><div style="display:inline">Analysis of student data is critical for improving education. In particular, educators need to understand what approaches their students are taking to solve a problem. However, identifying student strategies and discovering areas of confusion is difficult ...</div></span>
          <span id="toHide106" style="display:none;"><br /><div style="display:inline"><p>Analysis of student data is critical for improving education. In particular, educators need to understand what approaches their students are taking to solve a problem. However, identifying student strategies and discovering areas of confusion is difficult because an educator may not know what queries to ask or what patterns to look for in the data. In this paper, we present a visualization tool, PathViewer, to model the paths that students follow when solving a problem. PathViewer leverages ideas from flow diagrams and natural language processing to visualize the sequences of intermediate steps that students take. Using PathViewer, we analyzed how several students solved a Python assignment, discovering interesting and unexpected patterns. Our results suggest that PathViewer can allow educators to quickly identify areas of interest, drill down into specific areas, and identify student approaches to the problem as well as misconceptions they may have.</p></div></span> <a id="expcoll106" href="JavaScript: expandcollapse('expcoll106',106)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Fabricating New Materials</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025619&CFID=758305256&CFTOKEN=14863114">WireFab: Mix-Dimensional Modeling and Fabrication for 3D Mesh Models</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Min Liu, Yunbo Zhang, Jing Bai, Yuanzhi Cao, Jeffrey M. Alperovich, Karthik Ramani 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 965-976</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025619" title="DOI">10.1145/3025453.3025619</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025619&ftid=1870122&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow108" style="display:inline;"><br /><div style="display:inline">Many rapid fabrication technologies are directed towards layer wise printing or laser based prototyping. We propose WireFab, a rapid modeling and prototyping system that uses bent metal wires as the structure framework. WireFab approximates both the ...</div></span>
          <span id="toHide108" style="display:none;"><br /><div style="display:inline"><p>Many rapid fabrication technologies are directed towards layer wise printing or laser based prototyping. We propose WireFab, a rapid modeling and prototyping system that uses bent metal wires as the structure framework. WireFab approximates both the skeletal articulation and the skin appearance of the corresponding virtual skin meshes, and it allows users to personalize the designs by (1) specifying joint positions and part segmentations, (2) defining joint types and motion ranges to build a wire-based skeletal model, and (3) abstracting the segmented meshes into mixed-dimensional appearance patterns or attachments.</p> <p>The WireFab is designed to allow the user to choose how to best preserve the fidelity of the topological structure and articulation motion while selectively maintaining the fidelity of the geometric appearance. Compared to 3D-printing based high-fidelity fabrication systems, WireFab increases prototyping speed by ignoring unnecessary geometric details while preserving structural integrity and articulation motion. In addition, other rapid or low-fidelity fabrication systems produce only static models, while WireFab produces posable articulated models and has the potential to enable personalized functional products larger than the machines that produce them.</p></div></span> <a id="expcoll108" href="JavaScript: expandcollapse('expcoll108',108)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025624&CFID=758305256&CFTOKEN=14863114">Digital Mechanical Metamaterials</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Alexandra Ion, Ludwig Wall, Robert Kovacs, Patrick Baudisch 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 977-988</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025624" title="DOI">10.1145/3025453.3025624</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025624&ftid=1870146&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow109" style="display:inline;"><br /><div style="display:inline">In this paper, we explore how to embody mechanical computation into 3D printed objects, i.e., without electronic sensors, actuators, or controllers typically used for this purpose. A key benefit of our approach is that the resulting objects can ...</div></span>
          <span id="toHide109" style="display:none;"><br /><div style="display:inline"><p>In this paper, we explore how to embody <i>mechanical</i> computation into 3D printed objects, i.e., without electronic sensors, actuators, or controllers typically used for this purpose. A key benefit of our approach is that the resulting objects can be 3D printed in one piece and thus do not require assembly. We are building on 3D printed cell structures, also known as <i>metamaterials</i>. We introduce a new type of cell that propagates a digital mechanical signal using an embedded bistable spring. When triggered, the embedded spring discharges and the resulting impulse triggers one or more neighboring cells, resulting in signal propagation. We extend this basic mechanism to implement simple logic functions. We demonstrate interactive objects based on this concept, such as a combination lock. We present a custom editor that allows users to model 3D objects, route signals, simulate signal flow, and synthesize cell patterns.</p></div></span> <a id="expcoll109" href="JavaScript: expandcollapse('expcoll109',109)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/bp_award.jpg" alt="Best Paper" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025952&CFID=758305256&CFTOKEN=14863114">Organic Primitives: Synthesis and Design of pH-Reactive Materials using Molecular I/O for Sensing, Actuation, and Interaction</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Viirj Kan, Emma Vargo, Noa Machover, Hiroshi Ishii, Serena Pan, Weixuan Chen, Yasuaki Kakehi 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 989-1000</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025952" title="DOI">10.1145/3025453.3025952</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025952&ftid=1870123&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow110" style="display:inline;"><br /><div style="display:inline">In this paper we present Organic Primitives, an enabling toolbox that expands upon the library of input-output devices in HCI and facilitates the design of interactions with organic, fluid-based systems. We formulated color, odor and shape changing material ...</div></span>
          <span id="toHide110" style="display:none;"><br /><div style="display:inline"><p>In this paper we present Organic Primitives, an enabling toolbox that expands upon the library of input-output devices in HCI and facilitates the design of interactions with organic, fluid-based systems. We formulated color, odor and shape changing material primitives which act as sensor-actuators that convert pH signals into human-readable outputs. Food-grade organic molecules anthocyanin, vanillin, and chitosan were employed as dopants to synthesize materials which output a spectrum of colors, degrees of shape deformation, and switch between odorous and non-odorous states. We evaluated the individual output properties of our sensor-actuators to assess the rate, range, and reversibility of the changes as a function of pH 2-10. We present a design space with techniques for enhancing the functionality of the material primitives, and offer passive and computational methods for controlling the material interfaces. Finally, we explore applications enabled by Organic Primitives under four contexts: environmental, cosmetic, edible, and interspecies.</p></div></span> <a id="expcoll110" href="JavaScript: expandcollapse('expcoll110',110)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025663&CFID=758305256&CFTOKEN=14863114">Flexibles: Deformation-Aware 3D-Printed Tangibles for Capacitive Touchscreens</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Martin Schmitz, J&#252;rgen Steimle, Jochen Huber, Niloofar Dezfuli, Max M&#252;hlh&#228;user 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1001-1014</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025663" title="DOI">10.1145/3025453.3025663</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025663&ftid=1870156&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow111" style="display:inline;"><br /><div style="display:inline">We introduce Flexibles: 3D-printed flexible tangibles that are deformation-aware and operate on capacitive touchscreens. Flexibles add expressive deformation input to interaction with on-screen tangibles. Based on different types of deformation ...</div></span>
          <span id="toHide111" style="display:none;"><br /><div style="display:inline"><p>We introduce <i>Flexibles</i>: 3D-printed flexible tangibles that are deformation-aware and operate on capacitive touchscreens. Flexibles add expressive deformation input to interaction with on-screen tangibles. Based on different types of deformation mapping, we contribute a set of 3D-printable mechanisms that capture pressing, squeezing, and bending input with multiple levels of intensities. They can be integrated into 3D printed objects with custom geometries and on different locations. A Flexible is printed in a single pass on a consumer-level 3D printer without requiring further assembly. Through a series of interactive prototypes, example applications and a technical evaluation, we show the technical feasibility and the wide applicability of Flexibles.</p></div></span> <a id="expcoll111" href="JavaScript: expandcollapse('expcoll111',111)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Human Factors</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Motivation in Games</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025577&CFID=758305256&CFTOKEN=14863114">Towards Personality-driven Persuasive Health Games and Gamified Systems</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Rita Orji, Lennart E. Nacke, Chrysanne Di Marco 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1015-1027</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025577" title="DOI">10.1145/3025453.3025577</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025577&ftid=1870151&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow114" style="display:inline;"><br /><div style="display:inline">Persuasive games and gamified systems are effective tools for motivating behavior change using various persuasive strategies. Research has shown that tailoring these systems can increase their efficacy. However, there is little knowledge on how game-based ...</div></span>
          <span id="toHide114" style="display:none;"><br /><div style="display:inline"><p>Persuasive games and gamified systems are effective tools for motivating behavior change using various persuasive strategies. Research has shown that tailoring these systems can increase their efficacy. However, there is little knowledge on how game-based persuasive systems can be tailored to individuals of various personality traits. To advance research in this area, we conducted a large-scale study of 660 participants to investigate how different personalities respond to various persuasive strategies that are used in persuasive health games and gamified systems. Our results reveal that people's personality traits play a significant role in the perceived persuasiveness of different strategies. Conscientious people tend to be motivated by <i>goal setting, simulation, self-monitoring and feedback</i>; people who are more open to experience are more likely to be demotivated by <i>rewards, competition, comparison</i>, and <i>cooperation</i>. We contribute to the CHI community by offering design guidelines for tailoring persuasive games and gamified designs to a particular group of personalities.</p></div></span> <a id="expcoll114" href="JavaScript: expandcollapse('expcoll114',114)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025638&CFID=758305256&CFTOKEN=14863114">Is Difficulty Overrated?: The Effects of Choice, Novelty and Suspense on Intrinsic Motivation in Educational Games</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          J. Derek Lomas, Kenneth Koedinger, Nirmal Patel, Sharan Shodhan, Nikhil Poonwala, Jodi L. Forlizzi 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1028-1039</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025638" title="DOI">10.1145/3025453.3025638</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025638&ftid=1870155&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow115" style="display:inline;"><br /><div style="display:inline">Many game designers aim to optimize difficulty to make games that are "not too hard, not too easy." However, recent experiments have shown that even moderate difficulty can reduce player engagement. The present work investigates other design factors ...</div></span>
          <span id="toHide115" style="display:none;"><br /><div style="display:inline"><p>Many game designers aim to optimize difficulty to make games that are "not too hard, not too easy." However, recent experiments have shown that even moderate difficulty can reduce player engagement. The present work investigates other design factors that may account for the purported benefits of difficulty, such as choice, novelty and suspense. These factors were manipulated in three design experiments involving over 20,000 play sessions of an online educational game.</p> <p>The first experiment (n=10,472) randomly assigned some players to a particular level of difficulty but allowed other players to freely choose their difficulty. Moderately difficult levels were most motivating when self-selected; yet, when difficulty was blindly assigned, the easiest games were most motivating. The second experiment (n=5,065) randomly assigned players to differing degrees of novelty. Moderate novelty was optimal, while too much or too little novelty reduced intrinsic motivation. A final experiment (n=6,511) investigated the role of suspense in "close games", where it was found to be beneficial. If difficulty decreases motivation while novelty and suspense increase it, then an implication for educational game designers is to make easy, interesting games that are "not too hard, not too boring."</p></div></span> <a id="expcoll115" href="JavaScript: expandcollapse('expcoll115',115)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025648&CFID=758305256&CFTOKEN=14863114">Why is This Happening to Me?: How Player Attribution can Broaden our Understanding of Player Experience</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Ansgar E. Depping, Regan L. Mandryk 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1040-1052</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025648" title="DOI">10.1145/3025453.3025648</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025648&ftid=1870149&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow116" style="display:inline;"><br /><div style="display:inline">Games user research (GUR) measures the performance and preference of digital game players, and interprets these measurements in the context of theories that explain human behavior. There are many validated approaches for measuring player experience that ...</div></span>
          <span id="toHide116" style="display:none;"><br /><div style="display:inline"><p>Games user research (GUR) measures the performance and preference of digital game players, and interprets these measurements in the context of theories that explain human behavior. There are many validated approaches for measuring player experience that are grounded in psychological theories on motivation and emotion. Attribution theory explains how people assign causes to events and how these attributions affect peoples' emotional reactions and motivations. In this paper we argue that attribution theory can provide additional value to the existing suite of GUR tools; however, there are currently no validated tools to assess player attribution in the context of games. This paper describes the conceptualization of player attribution based on literature, presents the development and validation of a scale to assess player attribution in games, and discusses the implications of adding player attribution to the toolbox of methods for the design and evaluation of digital games.</p></div></span> <a id="expcoll116" href="JavaScript: expandcollapse('expcoll116',116)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025982&CFID=758305256&CFTOKEN=14863114">Keeping Users Engaged through Feature Updates: A Long-Term Study of Using Wearable-Based Exergames</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Zhao Zhao, Ali Arya, Anthony Whitehead, Gerry Chan, S. Ali Etemad 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1053-1064</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025982" title="DOI">10.1145/3025453.3025982</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025982&ftid=1870131&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow117" style="display:inline;"><br /><div style="display:inline">Gamification and exergames in particular have been broadly employed in health and fitness as an attempt to promote exercise and more active life styles. Motivated by popularity and availability of wearable activity trackers, we present the design and ...</div></span>
          <span id="toHide117" style="display:none;"><br /><div style="display:inline"><p>Gamification and exergames in particular have been broadly employed in health and fitness as an attempt to promote exercise and more active life styles. Motivated by popularity and availability of wearable activity trackers, we present the design and findings of a study on the motivational effects of using activity tracker-based games to promote daily exercise. Furthermore, we have investigated user behaviors, usage patterns, engagement, and parameters that affect them. An exergame was developed with an accompanying wearable device, for which different variations of application updates were pushed out periodically over a 70-day period. The results of this long-term study show that the usage of wearable activity trackers during exercise, even when gamified for increased entertainment, sees a consistent decline over time. This decline, however, is observed to be reversible with periodic updates to the game. This work, we believe, can make a significant contribution to solving the user retention problem of wearable-based exergames.</p></div></span> <a id="expcoll117" href="JavaScript: expandcollapse('expcoll117',117)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Self-Monitored Healthcare</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025832&CFID=758305256&CFTOKEN=14863114">Supporting the Self-Management of Chronic Pain Conditions with Tailored Momentary Self-Assessments</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Phil Adams, Elizabeth L. Murnane, Michael Elfenbein, Elaine Wethington, Geri Gay 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1065-1077</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025832" title="DOI">10.1145/3025453.3025832</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025832&ftid=1870148&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow119" style="display:inline;"><br /><div style="display:inline">To better support the self-management of chronic pain, this paper investigates how those living with the condition prefer to self-assess their pain levels using smartphones. Our work consists of three stages: design ideation and review, an in-lab user ...</div></span>
          <span id="toHide119" style="display:none;"><br /><div style="display:inline"><p>To better support the self-management of chronic pain, this paper investigates how those living with the condition prefer to self-assess their pain levels using smartphones. Our work consists of three stages: design ideation and review, an in-lab user study with 10 participants resulting in nine candidate interfaces, and a 3 week field trial of two further honed measures with 12 participants. This research firstly yields a better understanding of participants' strong and sometimes contrasting preferences regarding their self-assessment of pain intensity. We additionally contribute two novel interfaces that support accurate, quick, and repeated use along with other participant-valued interactions (e.g., familiar, relatable, and highly usable). In particular, we focus on designing tailored measures that both enhance respondent motivation as well as minimize the difficulty of meaningful self-assessment by supporting the cognitive effort in translating a subjective experience into a single numerical value.</p></div></span> <a id="expcoll119" href="JavaScript: expandcollapse('expcoll119',119)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025680&CFID=758305256&CFTOKEN=14863114">Supporting Self-Care of Adolescents with Nut Allergy Through Video and Mobile Educational Tools</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Neil Davidson, John Vines, Tom Bartindale, Selina Sutton, David Green, Rob Comber, Madeline Balaam, Patrick Olivier, Gillian Vance 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1078-1092</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025680" title="DOI">10.1145/3025453.3025680</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025680&ftid=1870138&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow120" style="display:inline;"><br /><div style="display:inline">Anaphylaxis is a life-threatening allergic reaction which is rapid in onset. Adolescents living with anaphylaxis risk often lack the knowledge and skills required to safely manage their condition or talk to friends about it. We designed an educational ...</div></span>
          <span id="toHide120" style="display:none;"><br /><div style="display:inline"><p>Anaphylaxis is a life-threatening allergic reaction which is rapid in onset. Adolescents living with anaphylaxis risk often lack the knowledge and skills required to safely manage their condition or talk to friends about it. We designed an educational intervention comprising group discussion around videos of simulated anaphylaxis scenarios and a mobile application containing video-based branching anaphylaxis narratives. We trialed the intervention with 36 nut allergic adolescents. At 1-year follow-up participants had improved adrenaline auto-injector skills and carriage, disease- and age-specific Quality of Life and confidence in anaphylaxis management. At 3-year follow-up adrenaline carriage improved further and confidence remained higher. Participants expressed how the education session was a turning point in taking control of their allergy and how the app facilitated sharing about anaphylaxis with others. We contribute insights regarding design of mobile self-care and peer-support applications for health in adolescence, and discuss strengths and limitations of video-based mobile health interventions.</p></div></span> <a id="expcoll120" href="JavaScript: expandcollapse('expcoll120',120)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Toolkits and UIs</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3026042&CFID=758305256&CFTOKEN=14863114">AVUI: Designing a Toolkit for Audiovisual Interfaces</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Nuno N. Correia, Atau Tanaka 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1093-1104</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3026042" title="DOI">10.1145/3025453.3026042</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3026042&ftid=1870147&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow122" style="display:inline;"><br /><div style="display:inline">The combined use of sound and image has a rich history, from audiovisual artworks to research exploring the potential of data visualization and sonification. However, we lack standard tools or guidelines for audiovisual (AV) interaction design, particularly ...</div></span>
          <span id="toHide122" style="display:none;"><br /><div style="display:inline"><p>The combined use of sound and image has a rich history, from audiovisual artworks to research exploring the potential of data visualization and sonification. However, we lack standard tools or guidelines for audiovisual (AV) interaction design, particularly for live performance. We propose the AVUI (AudioVisual User Interface), where sound and image are used together in a cohesive way in the interface; and an enabling technology, the ofxAVUI toolkit. AVUI guidelines and ofxAVUI were developed in a three-stage process, together with AV producers: 1) participatory design activities; 2) prototype development; 3) encapsulation of prototype as a plug-in, evaluation, and roll out. Best practices identified include: reconfigurable interfaces and mappings; object-oriented packaging of AV and UI; diverse sound visualization; flexible media manipulation and management. The toolkit and a mobile app developed using it have been released as open-source. Guidelines and toolkit demonstrate the potential of AVUI and offer designers a convenient framework for AV interaction design.</p></div></span> <a id="expcoll122" href="JavaScript: expandcollapse('expcoll122',122)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025827&CFID=758305256&CFTOKEN=14863114">Suggesting API Usage to Novice Programmers with the Example Guru</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Michelle Ichinco, Wint Yee Hnin, Caitlin L. Kelleher 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1105-1117</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025827" title="DOI">10.1145/3025453.3025827</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025827&ftid=1870121&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow123" style="display:inline;"><br /><div style="display:inline">Programmers, especially novices, often have difficulty learning new APIs (Application Programming Interfaces). Existing research has not fully addressed novice programmers' unawareness of all available API methods. To help novices discover new and appropriate ...</div></span>
          <span id="toHide123" style="display:none;"><br /><div style="display:inline"><p>Programmers, especially novices, often have difficulty learning new APIs (Application Programming Interfaces). Existing research has not fully addressed novice programmers' unawareness of all available API methods. To help novices discover new and appropriate uses for API methods, we designed a system called the Example Guru. The Example Guru suggests context-relevant API methods based on each programmer's code. The suggestions provide contrasting examples to demonstrate how to use the API methods. To evaluate the effectiveness of the Example Guru, we ran a study comparing novice programmers' use of the Example Guru and documentation-inspired API information. We found that twice as many participants accessed the Example Guru suggestions compared to documentation and that participants used more than twice as many new API methods after accessing suggestions than documentation.</p></div></span> <a id="expcoll123" href="JavaScript: expandcollapse('expcoll123',123)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025599&CFID=758305256&CFTOKEN=14863114">Toward Everyday Gaze Input: Accuracy and Precision of Eye Tracking and Implications for Design</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Anna Maria Feit, Shane Williams, Arturo Toledo, Ann Paradiso, Harish Kulkarni, Shaun Kane, Meredith Ringel Morris 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1118-1130</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025599" title="DOI">10.1145/3025453.3025599</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025599&ftid=1870142&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow124" style="display:inline;"><br /><div style="display:inline">For eye tracking to become a ubiquitous part of our everyday interaction with computers, we first need to understand its limitations outside rigorously controlled labs, and develop robust applications that can be used by a broad range of users and in ...</div></span>
          <span id="toHide124" style="display:none;"><br /><div style="display:inline"><p>For eye tracking to become a ubiquitous part of our everyday interaction with computers, we first need to understand its limitations outside rigorously controlled labs, and develop robust applications that can be used by a broad range of users and in various environments. Toward this end, we collected eye tracking data from 80 people in a calibration-style task, using two different trackers in two lighting conditions. We found that accuracy and precision can vary between users and targets more than six-fold, and report on differences between lighting, trackers, and screen regions. We show how such data can be used to determine appropriate target sizes and to optimize the parameters of commonly used filters. We conclude with design recommendations and examples how our findings and methodology can inform the design of error-aware adaptive applications.</p></div></span> <a id="expcoll124" href="JavaScript: expandcollapse('expcoll124',124)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025965&CFID=758305256&CFTOKEN=14863114">Heat-Nav: Using Temperature Changes as Navigation Cues</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Jordan Tewell, Jon Bird, George R. Buchanan 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1131-1135</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025965" title="DOI">10.1145/3025453.3025965</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025965&ftid=1870160&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow125" style="display:inline;"><br /><div style="display:inline">HCI is increasingly exploring how temperature can be used as an interaction modality. One challenge is that temperature changes are perceived over the course of seconds. This can be attributed to both the slow response time of skin thermoreceptors and ...</div></span>
          <span id="toHide125" style="display:none;"><br /><div style="display:inline"><p>HCI is increasingly exploring how temperature can be used as an interaction modality. One challenge is that temperature changes are perceived over the course of seconds. This can be attributed to both the slow response time of skin thermoreceptors and the latency of the technology used to heat and cool the skin. For this reason, thermal cues are typically used to communicate single states, such as an emotion, and then there is a pause of tens of seconds to allow the skin to re-adapt to a neutral temperature before sending another signal. In contrast, this paper presents the first experimental demonstration that continuous temperature changes can guide behaviour: significantly improving performance in a 2D maze navigation task, without having to return to a neutral state before a new signal is sent. We discuss how continuous thermal feedback may be used for real world navigational tasks.</p></div></span> <a id="expcoll125" href="JavaScript: expandcollapse('expcoll125',125)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025876&CFID=758305256&CFTOKEN=14863114">CodePilot: Scaffolding End-to-End Collaborative Software Development for Novice Programmers</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Jeremy Warner, Philip J. Guo 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1136-1141</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025876" title="DOI">10.1145/3025453.3025876</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025876&ftid=1870128&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow126" style="display:inline;"><br /><div style="display:inline">Novice programmers often have trouble installing, configuring, and managing disparate tools (e.g., version control systems, testing infrastructure, bug trackers) that are required to become productive in a modern collaborative software development environment. ...</div></span>
          <span id="toHide126" style="display:none;"><br /><div style="display:inline"><p>Novice programmers often have trouble installing, configuring, and managing disparate tools (e.g., version control systems, testing infrastructure, bug trackers) that are required to become productive in a modern collaborative software development environment. To lower the barriers to entry into software development, we created a prototype IDE for novices called CodePilot, which is, to our knowledge, the first attempt to integrate coding, testing, bug reporting, and version control management into a real-time collaborative system. CodePilot enables multiple users to connect to a web-based programming session and work together on several major phases of software development. An eight-subject exploratory user study found that first-time users of CodePilot spontaneously used it to assume roles such as developer/tester and developer/assistant when creating a web application together in pairs. Users felt that CodePilot could aid in scaffolding for novices, situational awareness, and lowering barriers to impromptu collaboration.</p></div></span> <a id="expcoll126" href="JavaScript: expandcollapse('expcoll126',126)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Uniqueness of Geographic Information</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025917&CFID=758305256&CFTOKEN=14863114">Crowdsourcing GO: Effect of Worker Situation on Mobile Crowdsourcing Performance</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Kazushi Ikeda, Keiichiro Hoashi 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1142-1153</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025917" title="DOI">10.1145/3025453.3025917</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025917&ftid=1870127&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow128" style="display:inline;"><br /><div style="display:inline">The increasing popularity of mobile crowdsourcing platforms has enabled crowd workers to accept jobs wherever/whenever they are, and also provides opportunity for task requesters to order time/location specific tasks to workers. Since workers on mobile ...</div></span>
          <span id="toHide128" style="display:none;"><br /><div style="display:inline"><p>The increasing popularity of mobile crowdsourcing platforms has enabled crowd workers to accept jobs wherever/whenever they are, and also provides opportunity for task requesters to order time/location specific tasks to workers. Since workers on mobile platforms are working on the go, the situation of the workers is expected to influence their performance. However, the effects of mobile worker situations to task performance is an uninvestigated area. In this paper, our research question is, "do worker situations affect task completion, price and quality on mobile crowdsourcing platforms?" We draw on economics and psychology research to examine whether worker situations such as busyness, fatigue and presence of companions affect their performance. Our three-week between-subjects field experiment revealed that worker busyness caused 30.1% relative decrease of task completion rate. Mean accepted task price increased by 7.6% when workers are with companions. Worker fatigue caused 37.4% relative decrease of task quality.</p></div></span> <a id="expcoll128" href="JavaScript: expandcollapse('expcoll128',128)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025737&CFID=758305256&CFTOKEN=14863114">Understanding: A Systematic Study of Catastrophic Incidents Associated with Personal Navigation Technologies</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Allen Yilun Lin, Kate Kuehl, Johannes Sch&#246;ning, Brent Hecht 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1154-1166</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025737" title="DOI">10.1145/3025453.3025737</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025737&ftid=1870152&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow129" style="display:inline;"><br /><div style="display:inline">Catastrophic incidents associated with GPS devices and other personal navigation technologies are sufficiently common that these incidents have been given a colloquial nickname: "Death by GPS". While there is a significant body of work on the use of ...</div></span>
          <span id="toHide129" style="display:none;"><br /><div style="display:inline"><p>Catastrophic incidents associated with GPS devices and other personal navigation technologies are sufficiently common that these incidents have been given a colloquial nickname: "Death by GPS". While there is a significant body of work on the use of personal navigation technologies in everyday scenarios, no research has examined these technologies' roles in catastrophic incidents. In this paper, we seek to address this gap in the literature. Borrowing techniques from public health research and communication studies, we construct a corpus of 158 detailed news reports of unique catastrophic incidents associated with personal navigation technologies. We then identify key themes in these incidents and the roles that navigation technologies played in them, e.g. missing road characteristics data contributed to over 25% of these incidents. With the goal of reducing casualties associated with personal navigation technologies, we outline implications for design and research that emerge from our results, e.g. advancing "space usage rule" mapping, incorporating weather information in routing, and improving visual and audio instructions in complex situations.</p></div></span> <a id="expcoll129" href="JavaScript: expandcollapse('expcoll129',129)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3026015&CFID=758305256&CFTOKEN=14863114">The Effect of Population and</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Isaac Johnson, Connor McMahon, Johannes Sch&#246;ning, Brent Hecht 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1167-1178</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3026015" title="DOI">10.1145/3025453.3026015</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3026015&ftid=1870132&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow130" style="display:inline;"><br /><div style="display:inline">Much research has shown that social media platforms have substantial population biases. However, very little is known about how these population biases affect the many algorithms that rely on social media data. Focusing on the case study of geolocation ...</div></span>
          <span id="toHide130" style="display:none;"><br /><div style="display:inline"><p>Much research has shown that social media platforms have substantial population biases. However, very little is known about how these population biases affect the many algorithms that rely on social media data. Focusing on the case study of geolocation inference algorithms and their performance across the urban-rural spectrum, we establish that these algorithms exhibit significantly worse performance for underrepresented populations (i.e. rural users). We further establish that this finding is robust across both text- and network-based algorithm designs. However, we also show that some of this bias can be attributed to the design of algorithms themselves rather than population biases in the underlying data sources. For instance, in some cases, algorithms perform badly for rural users even when we substantially overcorrect for population biases by training exclusively on rural data. We discuss the implications of our findings for the design and study of social media-based algorithms.</p></div></span> <a id="expcoll130" href="JavaScript: expandcollapse('expcoll130',130)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025495&CFID=758305256&CFTOKEN=14863114">The Geography of Pok&#233;mon GO: Beneficial and Problematic Effects on Places and Movement</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Ashley Colley, Jacob Thebault-Spieker, Allen Yilun Lin, Donald Degraen, Benjamin Fischman, Jonna H&#228;kkil&#228;, Kate Kuehl, Valentina Nisi, Nuno Jardim Nunes, Nina Wenig, Dirk Wenig, Brent Hecht, Johannes Sch&#246;ning 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1179-1192</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025495" title="DOI">10.1145/3025453.3025495</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025495&ftid=1870167&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow131" style="display:inline;"><br /><div style="display:inline">The widespread popularity of Pok&#233;mon GO presents the first opportunity to observe the geographic effects of location-based gaming at scale. This paper reports the results of a mixed methods study of the geography of Pok&#233;mon GO that includes ...</div></span>
          <span id="toHide131" style="display:none;"><br /><div style="display:inline"><p>The widespread popularity of Pok&#233;mon GO presents the first opportunity to observe the geographic effects of location-based gaming at scale. This paper reports the results of a mixed methods study of the geography of Pok&#233;mon GO that includes a five-country field survey of 375 Pok&#233;mon GO players and a large scale geostatistical analysis of game elements. Focusing on the key geographic themes of places and movement, we find that the design of Pok&#233;mon GO reinforces existing geographically-linked biases (e.g. the game advantages urban areas and neighborhoods with smaller minority populations), that Pok&#233;mon GO may have instigated a relatively rare large-scale shift in global human mobility patterns, and that Pok&#233;mon GO has geographically-linked safety risks, but not those typically emphasized by the media. Our results point to geographic design implications for future systems in this space such as a means through which the geographic biases present in Pok&#233;mon GO may be counteracted.</p></div></span> <a id="expcoll131" href="JavaScript: expandcollapse('expcoll131',131)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Visual Perception based Decisions</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025882&CFID=758305256&CFTOKEN=14863114">Empirical Analysis of the Subjective Impressions and Objective Measures of Domain Scientists' Visual Analytic Judgments</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Aritra Dasgupta, Susannah Burrows, Kyungsik Han, Philip J. Rasch 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1193-1204</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025882" title="DOI">10.1145/3025453.3025882</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025882&ftid=1870165&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow133" style="display:inline;"><br /><div style="display:inline">Scientists often use specific data analysis and presentation methods familiar within their domain. But does high familiarity drive better analytical judgment? This question is especially relevant when familiar methods themselves can have shortcomings: ...</div></span>
          <span id="toHide133" style="display:none;"><br /><div style="display:inline"><p>Scientists often use specific data analysis and presentation methods familiar within their domain. But does high familiarity drive better analytical judgment? This question is especially relevant when familiar methods themselves can have shortcomings: many visualizations used conventionally for scientific data analysis and presentation do not follow established best practices. This necessitates new methods that might be unfamiliar yet prove to be more effective. But there is little empirical understanding of the relationships between scientists' subjective impressions about familiar and unfamiliar visualizations and objective measures of their visual analytic judgments. To address this gap and to study these factors, we focus on visualizations used for comparison of climate model performance. We report on a comprehensive survey-based user study with 47 climate scientists and present an analysis of: i) relationships among scientists' familiarity, their perceived levels of comfort, confidence, accuracy, and objective measures of accuracy, and ii) relationships among domain experience, visualization familiarity, and post-study preference.</p></div></span> <a id="expcoll133" href="JavaScript: expandcollapse('expcoll133',133)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025596&CFID=758305256&CFTOKEN=14863114">A Cognitive Model of How People Make Decisions Through Interaction with Visual Displays</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Xiuli Chen, Sandra Dorothee Starke, Chris Baber, Andrew Howes 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1205-1216</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025596" title="DOI">10.1145/3025453.3025596</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025596&ftid=1870144&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow134" style="display:inline;"><br /><div style="display:inline">In this paper we report a cognitive model of how people make decisions through interaction. The model is based on the assumption that interaction for decision making is an example of a Partially Observable Markov Decision Process (POMDP) in which observations ...</div></span>
          <span id="toHide134" style="display:none;"><br /><div style="display:inline"><p>In this paper we report a cognitive model of how people make decisions through interaction. The model is based on the assumption that interaction for decision making is an example of a Partially Observable Markov Decision Process (POMDP) in which observations are made by limited perceptual systems that model human foveated vision and decisions are made by strategies that are adapted to the task. We illustrate the model by applying it to the task of determining whether to block a credit card given a number of variables including the location of a transaction, its amount, and the customer history. Each of these variables have a different validity and users may weight them accordingly. The model solves the POMDP by learning patterns of eye movements (strategies) adapted to different presentations of the data. We compare the model behavior to human performance on the credit card transaction task.</p></div></span> <a id="expcoll134" href="JavaScript: expandcollapse('expcoll134',134)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025850&CFID=758305256&CFTOKEN=14863114">Building with Data: Architectural Models as Inspiration for Data Physicalization</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Carmen Hull, Wesley Willett 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1217-1264</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025850" title="DOI">10.1145/3025453.3025850</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025850&ftid=1870117&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow135" style="display:inline;"><br /><div style="display:inline">In this paper we analyze the role of physical scale models in the architectural design process and apply insights from architecture for the creation and use of data physicalizations. Based on a survey of the architecture literature on model making and ...</div></span>
          <span id="toHide135" style="display:none;"><br /><div style="display:inline"><p>In this paper we analyze the role of physical scale models in the architectural design process and apply insights from architecture for the creation and use of data physicalizations. Based on a survey of the architecture literature on model making and ten interviews with practicing architects, we describe the role of physical models as a tool for exploration and communication. From these observations, we identify trends in the use of physical models in architecture, which have the potential to inform the design of data physicalizations. We identify four functions of architectural modeling that can be directly adapted for use in the process of building rich data models. Finally, we discuss how the visualization community can apply observations from architecture to the design of new data physicalizations.</p></div></span> <a id="expcoll135" href="JavaScript: expandcollapse('expcoll135',135)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>All about Data</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025626&CFID=758305256&CFTOKEN=14863114">Variolite: Supporting Exploratory Programming by Data Scientists</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Mary Beth Kery, Amber Horvath, Brad Myers 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1265-1276</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025626" title="DOI">10.1145/3025453.3025626</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025626&ftid=1870079&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow137" style="display:inline;"><br /><div style="display:inline">How do people ideate through code? Using semi-structured interviews and a survey, we studied data scientists who program, often with small scripts, to experiment with data. These studies show that data scientists frequently code new analysis ideas by ...</div></span>
          <span id="toHide137" style="display:none;"><br /><div style="display:inline"><p>How do people ideate through code? Using semi-structured interviews and a survey, we studied data scientists who program, often with small scripts, to experiment with data. These studies show that data scientists frequently code new analysis ideas by building off of their code from a previous idea. They often rely on informal versioning interactions like copying code, keeping unused code, and commenting out code to repurpose older analysis code while attempting to keep those older analyses intact. Unlike conventional version control, these informal practices allow for fast versioning of any size code snippet, and quick comparisons by interchanging which versions are run. However, data scientists must maintain a strong mental map of their code in order to distinguish versions, leading to errors and confusion. We explore the needs for improving version control tools for exploratory tasks, and demonstrate a tool for lightweight local versioning, called Variolite, which programmers found usable and desirable in a preliminary usability study.</p></div></span> <a id="expcoll137" href="JavaScript: expandcollapse('expcoll137',137)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025838&CFID=758305256&CFTOKEN=14863114">The Trials and Tribulations of Working with Structured Data: -a Study on Information Seeking Behaviour</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Laura M. Koesten, Emilia Kacprzak, Jenifer F. A. Tennison, Elena Simperl 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1277-1289</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025838" title="DOI">10.1145/3025453.3025838</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025838&ftid=1870094&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow138" style="display:inline;"><br /><div style="display:inline">Structured data such as databases, spreadsheets and web tables is becoming critical in every domain and professional role. Yet we still do not know much about how people interact with it. Our research focuses on the information seeking behaviour of people ...</div></span>
          <span id="toHide138" style="display:none;"><br /><div style="display:inline"><p>Structured data such as databases, spreadsheets and web tables is becoming critical in every domain and professional role. Yet we still do not know much about how people interact with it. Our research focuses on the information seeking behaviour of people looking for new sources of structured data online, including the task context in which the data will be used, data search, and the identification of relevant datasets from a set of possible candidates. We present a mixed-methods study covering in-depth interviews with 20 participants with various professional backgrounds, supported by the analysis of search logs of a large data portal. Based on this study, we propose a framework for human structured-data interaction and discuss challenges people encounter when trying to find and assess data that helps their daily work. We provide design recommendations for data publishers and developers of online data platforms such as data catalogs and marketplaces. These recommendations highlight important questions for HCI research to improve how people engage and make use of this incredibly useful online resource.</p></div></span> <a id="expcoll138" href="JavaScript: expandcollapse('expcoll138',138)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025912&CFID=758305256&CFTOKEN=14863114">Same Stats, Different Graphs: Generating Datasets with Varied Appearance and Identical Statistics through Simulated Annealing</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Justin Matejka, George Fitzmaurice 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1290-1294</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025912" title="DOI">10.1145/3025453.3025912</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025912&ftid=1870108&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow139" style="display:inline;"><br /><div style="display:inline">Datasets which are identical over a number of statistical properties, yet produce dissimilar graphs, are frequently used to illustrate the importance of graphical representations when exploring data. This paper presents a novel method for generating ...</div></span>
          <span id="toHide139" style="display:none;"><br /><div style="display:inline"><p>Datasets which are identical over a number of statistical properties, yet produce dissimilar graphs, are frequently used to illustrate the importance of graphical representations when exploring data. This paper presents a novel method for generating such datasets, along with several examples. Our technique varies from previous approaches in that new datasets are iteratively generated from a seed dataset through random perturbations of individual data points, and can be directed towards a desired outcome through a simulated annealing optimization strategy. Our method has the benefit of being agnostic to the particular statistical properties that are to remain constant between the datasets, and allows for control over the graphical appearance of resulting output.</p></div></span> <a id="expcoll139" href="JavaScript: expandcollapse('expcoll139',139)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025576&CFID=758305256&CFTOKEN=14863114">Inferring Cognitive Models from Data using Approximate Bayesian Computation</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Antti Kangasr&#228;&#228;si&#246;, Kumaripaba Athukorala, Andrew Howes, Jukka Corander, Samuel Kaski, Antti Oulasvirta 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1295-1306</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025576" title="DOI">10.1145/3025453.3025576</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025576&ftid=1870097&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow140" style="display:inline;"><br /><div style="display:inline">An important problem for HCI researchers is to estimate the parameter values of a cognitive model from behavioral data. This is a difficult problem, because of the substantial complexity and variety in human behavioral strategies. We report an investigation ...</div></span>
          <span id="toHide140" style="display:none;"><br /><div style="display:inline"><p>An important problem for HCI researchers is to estimate the parameter values of a cognitive model from behavioral data. This is a difficult problem, because of the substantial complexity and variety in human behavioral strategies. We report an investigation into a new approach using approximate Bayesian computation (ABC) to condition model parameters to data and prior knowledge. As the case study we examine menu interaction, where we have click time data only to infer a cognitive model that implements a search behaviour with parameters such as fixation duration and recall probability. Our results demonstrate that ABC (i) improves estimates of model parameter values, (ii) enables meaningful comparisons between model variants, and (iii) supports fitting models to individual users. ABC provides ample opportunities for theoretical HCI research by allowing principled inference of model parameter values and their uncertainty.</p></div></span> <a id="expcoll140" href="JavaScript: expandcollapse('expcoll140',140)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025707&CFID=758305256&CFTOKEN=14863114">Effects of Frequency Distribution on Linear Menu Performance</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Wanyu Liu, Gilles Bailly, Andrew Howes 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1307-1312</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025707" title="DOI">10.1145/3025453.3025707</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025707&ftid=1870072&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow141" style="display:inline;"><br /><div style="display:inline">While it is well known that menu usage follows a Zipfian distribution, there has been little interest in the impact of menu item frequency distribution on user's behavior. In this note, we explore the effects of frequency distribution on average menu ...</div></span>
          <span id="toHide141" style="display:none;"><br /><div style="display:inline"><p>While it is well known that menu usage follows a Zipfian distribution, there has been little interest in the impact of menu item frequency distribution on user's behavior. In this note, we explore the effects of frequency distribution on average menu performance as well as individual item performance. We compare three frequency distributions of menu item usage: Uniform; Zipfian with s=1 and Zipfian with s=2. The results show that (1) user's behavior is sensitive to different frequency distributions at both menu and item level; (2) individual item selection time depends on, not only its frequency, but also the frequency of other items in the menu. Finally, we discuss how these findings might have impacts on menu design, empirical studies and menu modeling.</p></div></span> <a id="expcoll141" href="JavaScript: expandcollapse('expcoll141',141)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Design and Cognitive Impairment</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025558&CFID=758305256&CFTOKEN=14863114">DemYouth: Co-Designing and Enacting Tools to Support Young People's Engagement with People with Dementia</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Roisin McNaney, John Vines, Jamie Mercer, Leon Mexter, Daniel Welsh, Tony Young 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1313-1325</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025558" title="DOI">10.1145/3025453.3025558</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025558&ftid=1870085&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow143" style="display:inline;"><br /><div style="display:inline">There is a growing body of research examining the role of technology in supporting the care of--and relationships surrounding--people with dementia, yet little attention has been given to how this relates to younger family members. We conducted a qualitative ...</div></span>
          <span id="toHide143" style="display:none;"><br /><div style="display:inline"><p>There is a growing body of research examining the role of technology in supporting the care of--and relationships surrounding--people with dementia, yet little attention has been given to how this relates to younger family members. We conducted a qualitative study based on a series of 6 co-design workshops conducted with 14 young people who had personal experience with dementia. Initially, our workshops focused on understanding the difficulties that young people face when engaging, interacting and being with people with dementia. Initial analysis of workshop data informed the design of three digital tool concepts that were used as the basis for user enactment workshops. Our findings highlight the young people's desire to be more involved in their family discussions around dementia and a need for them to find new ways to connect with their loved ones with dementia. We offer a set of design considerations for future systems that support these needs and reflect on some of the complexities we faced around engaging young people in this difficult topic of discussion.</p></div></span> <a id="expcoll143" href="JavaScript: expandcollapse('expcoll143',143)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025527&CFID=758305256&CFTOKEN=14863114">The Value of Experience-Centred Design Approaches in Dementia Research Contexts</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Kellie Morrissey, John McCarthy, Nadia Pantidi 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1326-1338</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025527" title="DOI">10.1145/3025453.3025527</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025527&ftid=1870090&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow144" style="display:inline;"><br /><div style="display:inline">Experience-Centred Design (ECD) has been applied in numerous HCI projects to call attention to the particular and dialogical nature of people's experiences with technology. In this paper, we report on ECD within the context of publicly-funded, long-stay ...</div></span>
          <span id="toHide144" style="display:none;"><br /><div style="display:inline"><p>Experience-Centred Design (ECD) has been applied in numerous HCI projects to call attention to the particular and dialogical nature of people's experiences with technology. In this paper, we report on ECD within the context of publicly-funded, long-stay residential dementia care, where the approach helped to highlight aspects of participants' felt experience, and informed sensitive and meaningful design responses. This study contributes an extended understanding of the quality of experience and the means of making sense in dementia, as well as unpicking the potential of ECD to support enriched experience and contextual meaning-making for people with dementia. Finally, we delineate what it is about Experience-Centred Design that differentiates the approach from other often-used approaches in designing in dementia contexts: 1) explorative thinking, 2) working within 'cuttings-out of time and space', 3) careful yet expressive methodology and documentation, and 4) working together to imagine futures. We end with considerations of how the contributions of this research may extend to other experience-centred projects in challenging settings.</p></div></span> <a id="expcoll144" href="JavaScript: expandcollapse('expcoll144',144)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025715&CFID=758305256&CFTOKEN=14863114">Connecting Those That Care: Designing for Transitioning, Talking, Belonging and Escaping</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Kiel Long, Lyndsey L. Bakewell, Roisin C. McNaney, Konstantina Vasileiou, Mark Atkinson, Manuela Barreto, Julie Barnett, Michael Wilson, Shaun Lawson, John Vines 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1339-1351</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025715" title="DOI">10.1145/3025453.3025715</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025715&ftid=1870062&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow145" style="display:inline;"><br /><div style="display:inline">Care provision in many nations increasingly relies on the work of informal, or non-professional, carers. Often these carers experience substantial disruptions and reductions to their own sociality, weakened social support networks and, ultimately, a ...</div></span>
          <span id="toHide145" style="display:none;"><br /><div style="display:inline"><p>Care provision in many nations increasingly relies on the work of informal, or non-professional, carers. Often these carers experience substantial disruptions and reductions to their own sociality, weakened social support networks and, ultimately, a heightened risk of social isolation. We describe a qualitative study, comprised of interviews, design workshops and probes, that investigated the social and community support practices of carers. Our findings highlight issues related to becoming and recognising being a carer, and feelings of being ignored by, and isolated from, others. We also note the benefits that sharing between carers can bring, and routes to coping and relaxing from the burdens of care. We conclude with design considerations for facilitating new forms of digitally mediated support that connect those that care, emphasising design qualities related to transitioning, talking, belonging and escaping.</p></div></span> <a id="expcoll145" href="JavaScript: expandcollapse('expcoll145',145)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025676&CFID=758305256&CFTOKEN=14863114">Designing Game-Based Myoelectric Prosthesis Training</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Aaron Tabor, Scott Bateman, Erik Scheme, David R. Flatla, Kathrin Gerling 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1352-1363</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025676" title="DOI">10.1145/3025453.3025676</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025676&ftid=1870105&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow146" style="display:inline;"><br /><div style="display:inline">A myoelectric prosthesis (myo) is a dexterous artificial limb controlled by muscle contractions. Learning to use a myo can be challenging, so extensive training is often required to use a myo prosthesis effectively. Signal visualizations and simple muscle-controlled ...</div></span>
          <span id="toHide146" style="display:none;"><br /><div style="display:inline"><p>A myoelectric prosthesis (myo) is a dexterous artificial limb controlled by muscle contractions. Learning to use a myo can be challenging, so extensive training is often required to use a myo prosthesis effectively. Signal visualizations and simple muscle-controlled games are currently used to help patients train their muscles, but are boring and frustrating. Furthermore, current training systems require expensive medical equipment and clinician oversight, restricting training to infrequent clinical visits. To address these limitations, we developed a new game that promotes fun and success, and shows the viability of a low-cost myoelectric input device. We adapted a user-centered design (UCD) process to receive feedback from patients, clinicians, and family members as we iteratively addressed challenges to improve our game. Through this work, we introduce a free and open myo training game, provide new information about the design of myo training games, and reflect on an adapted UCD process for the practical iterative development of therapeutic games.</p></div></span> <a id="expcoll146" href="JavaScript: expandcollapse('expcoll146',146)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Evaluating Visual Perceptions</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3026041&CFID=758305256&CFTOKEN=14863114">Affective Color in Visualization</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Lyn Bartram, Abhisekh Patra, Maureen Stone 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1364-1374</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3026041" title="DOI">10.1145/3025453.3026041</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3026041&ftid=1870110&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow148" style="display:inline;"><br /><div style="display:inline">Communicating the right affect, a feeling, experience or emotion, is critical in creating engaging visual communication. We carried out three studies examining how different color properties (lightness, chroma and hue) and different palette properties ...</div></span>
          <span id="toHide148" style="display:none;"><br /><div style="display:inline"><p>Communicating the right affect, a feeling, experience or emotion, is critical in creating engaging visual communication. We carried out three studies examining how different color properties (lightness, chroma and hue) and different palette properties (combinations and distribution of colors) contribute to different affective interpretations in information visualization where the numbers of colors is typically smaller than the rich palettes used in design. Our results show how color and palette properties can be manipulated to achieve affective expressiveness even in the small sets of colors used for data encoding in information visualization.</p></div></span> <a id="expcoll148" href="JavaScript: expandcollapse('expcoll148',148)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/bp_award.jpg" alt="Best Paper" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025592&CFID=758305256&CFTOKEN=14863114">Explaining the Gap: Visualizing One's Predictions Improves Recall and Comprehension of Data</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Yea-Seul Kim, Katharina Reinecke, Jessica Hullman 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1375-1386</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025592" title="DOI">10.1145/3025453.3025592</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025592&ftid=1870055&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow149" style="display:inline;"><br /><div style="display:inline">Information visualizations use interactivity to enable user-driven querying of visualized data. However, users' interactions with their internal representations, including their expectations about data, are also critical for a visualization to support ...</div></span>
          <span id="toHide149" style="display:none;"><br /><div style="display:inline"><p>Information visualizations use interactivity to enable user-driven querying of visualized data. However, users' interactions with their internal representations, including their expectations about data, are also critical for a visualization to support learning. We present multiple graphically-based techniques for eliciting and incorporating a user's prior knowledge about data into visualization interaction. We use controlled experiments to evaluate how graphically eliciting forms of prior knowledge and presenting feedback on the gap between prior knowledge and the observed data impacts a user's ability to recall and understand the data. We find that participants who are prompted to reflect on their prior knowledge by predicting and self-explaining data outperform a control group in recall and comprehension. These effects persist when participants have moderate or little prior knowledge on the datasets. We discuss how the effects differ based on text versus visual presentations of data. We characterize the design space of graphical prediction and feedback techniques and describe design recommendations.</p></div></span> <a id="expcoll149" href="JavaScript: expandcollapse('expcoll149',149)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025922&CFID=758305256&CFTOKEN=14863114">Regression by Eye: Estimating Trends in Bivariate Visualizations</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Michael Correll, Jeffrey Heer 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1387-1396</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025922" title="DOI">10.1145/3025453.3025922</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025922&ftid=1870098&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow150" style="display:inline;"><br /><div style="display:inline">Observing trends and predicting future values are common tasks for viewers of bivariate data visualizations. As many charts do not explicitly include trend lines or related statistical summaries, viewers often visually estimate trends directly from a ...</div></span>
          <span id="toHide150" style="display:none;"><br /><div style="display:inline"><p>Observing trends and predicting future values are common tasks for viewers of bivariate data visualizations. As many charts do not explicitly include trend lines or related statistical summaries, viewers often visually estimate trends directly from a plot. How reliable are the inferences viewers draw when performing such <i>regression by eye</i>? Do particular visualization designs or data features bias trend perception? We present a series of crowdsourced experiments that assess the accuracy of trends estimated using regression by eye across a variety of bivariate visualizations, and examine potential sources of bias in these estimations. We find that viewers accurately estimate trends in many standard visualizations of bivariate data, but that both visual features (e.g., "within-the-bar" bias) and data features (e.g., the presence of outliers) can result in visual estimates that systematically diverge from standard least-squares regression models.</p></div></span> <a id="expcoll150" href="JavaScript: expandcollapse('expcoll150',150)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3026024&CFID=758305256&CFTOKEN=14863114">Evaluating Perceptually Complementary Views for Network Exploration Tasks</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Chunlei Chang, Benjamin Bach, Tim Dwyer, Kim Marriott 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1397-1407</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3026024" title="DOI">10.1145/3025453.3026024</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3026024&ftid=1870065&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow151" style="display:inline;"><br /><div style="display:inline">We explore the relative merits of matrix, node-link and combined side-by-side views for the visualisation of weighted networks with three controlled studies: (1) finding the most effective visual encoding for weighted edges in matrix representations; ...</div></span>
          <span id="toHide151" style="display:none;"><br /><div style="display:inline"><p>We explore the relative merits of matrix, node-link and combined side-by-side views for the visualisation of weighted networks with three controlled studies: (1) finding the most effective visual encoding for weighted edges in matrix representations; (2) comparing matrix, node-link and combined views for static weighted networks; and (3) comparing MatrixWave, Sankey and combined views of both for event-sequence data. Our studies underline that node-link and matrix views are suited to different analysis tasks. For the combined view, our studies show that there is a perceptually complementary effect in terms of improved accuracy for some tasks, but that there is a cost in terms of longer completion time than the faster of the two techniques alone. Eye-movement data shows that for many tasks participants strongly favour one of the two views, after trying both in the training phase.</p></div></span> <a id="expcoll151" href="JavaScript: expandcollapse('expcoll151',151)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>HCI/UX Education and Industry</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025541&CFID=758305256&CFTOKEN=14863114">How Design-inclusive UXR Influenced the Integration of Project Activities: Three Design Cases from Industry</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Janne van Kollenburg, Sander Bogers, Eva Deckers, Joep Frens, Caroline Hummels 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1408-1418</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025541" title="DOI">10.1145/3025453.3025541</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025541&ftid=1870113&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow153" style="display:inline;"><br /><div style="display:inline">In this paper, we discuss how the implementation of design-inclusive User Experience Research (UXR) has influenced the composition of UXR and design activities in the industrial setting of Philips Design. We present three design case studies that were ...</div></span>
          <span id="toHide153" style="display:none;"><br /><div style="display:inline"><p>In this paper, we discuss how the implementation of design-inclusive User Experience Research (UXR) has influenced the composition of UXR and design activities in the industrial setting of Philips Design. We present three design case studies that were executed in a time span of three years: a baby sleep project; a pregnancy project; and a baby bottle-feeding project. Through a retrospective analysis we conclude that the approach adopted in these cases progressed from complete separation of UXR and design activities to design-inclusive UXR in which design forms an integral part of research. This is reflected by a rearrangement of project activities to <i>identify, envision, enable</i> and <i>evaluate</i> user experiences. Previously the UXR (<i>identify</i> and <i>evaluate</i>) and design (<i>envision</i> and <i>enable</i>) activities were executed sequentially. Now, these four project activities merge in studying design interventions in context over a prolonged time, to iteratively explore and advance UX design qualities.</p></div></span> <a id="expcoll153" href="JavaScript: expandcollapse('expcoll153',153)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025860&CFID=758305256&CFTOKEN=14863114">Augmented Studio: Projection Mapping on Moving Body for Physiotherapy Education</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Thuong Hoang, Martin Reinoso, Zaher Joukhadar, Frank Vetere, David Kelly 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1419-1430</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025860" title="DOI">10.1145/3025453.3025860</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025860&ftid=1870114&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow154" style="display:inline;"><br /><div style="display:inline">Physiotherapy students often struggle to translate anatomical knowledge from textbooks into a dynamic understanding of the mechanics of body movements in real life patients. We present the Augmented Studio, an augmented reality system that uses ...</div></span>
          <span id="toHide154" style="display:none;"><br /><div style="display:inline"><p>Physiotherapy students often struggle to translate anatomical knowledge from textbooks into a dynamic understanding of the mechanics of body movements in real life patients. We present the <i>Augmented Studio</i>, an augmented reality system that uses body tracking to project anatomical structures and annotations over moving bodies for physiotherapy education. Through a user and learner centered design approach, we established an understanding that through <i>augmentation</i> and <i>annotation</i>, augmented reality technology can enhance physiotherapy education. Augmented Studio enables augmentation through projection mapping to display anatomical information such as muscles and skeleton in real time on the body as it moves. We created a technique for <i>annotation</i> to create projected hand-drawing on the moving body, to enable explicit communication of the teacher's clinical reasoning strategies to the students. Findings from our pilot usability study demonstrate a more engaging learning and teaching experience and increased communication between teacher and students when using Augmented Studio.</p></div></span> <a id="expcoll154" href="JavaScript: expandcollapse('expcoll154',154)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025805&CFID=758305256&CFTOKEN=14863114">Facilitating Development of Pragmatic Competence through a Voice-driven Video Learning Interface</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Gabriel Culbertson, Solace Shen, Malte Jung, Erik Andersen 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1431-1440</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025805" title="DOI">10.1145/3025453.3025805</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025805&ftid=1870059&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow155" style="display:inline;"><br /><div style="display:inline">Authentic foreign language videos are effective for developing pragmatic competence, or sensitivity to meanings expressed by tone and word choice, and the ability to effectively express these meanings. However, established methods for learning from foreign ...</div></span>
          <span id="toHide155" style="display:none;"><br /><div style="display:inline"><p>Authentic foreign language videos are effective for developing pragmatic competence, or sensitivity to meanings expressed by tone and word choice, and the ability to effectively express these meanings. However, established methods for learning from foreign language videos are primarily text-based (e.g.captioning). Using text, learners do not practice aspects of oral performance (e.g. intonation, pausing, and pitch) that are important to pragmatic competence. In this paper we present a voice-driven system where learners practice and learn a foreign language by repeating phrases out loud from any video. Utterances are transcribed and translated and, if captions are available, the system indicates the correctness of the utterance. In an evaluation with 27 participants, we show that participants more frequently used the voice-driven system than a comparison text-based system. Furthermore, ina field study of 130 independent learners, we show potential for community-driven resource collection.</p></div></span> <a id="expcoll155" href="JavaScript: expandcollapse('expcoll155',155)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025726&CFID=758305256&CFTOKEN=14863114">Advancing UX Education: A Model for Integrated Studio Pedagogy</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Mihaela Vorvoreanu, Colin M. Gray, Paul Parsons, Nancy Rasche 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1441-1446</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025726" title="DOI">10.1145/3025453.3025726</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025726&ftid=1870091&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow156" style="display:inline;"><br /><div style="display:inline">The rapid growth of the UX profession has led to an increased need for qualified practitioners and a proliferation of UX educational programs offered in both academia and industry. In this note, we present the design and initial evaluation of a new studio-based ...</div></span>
          <span id="toHide156" style="display:none;"><br /><div style="display:inline"><p>The rapid growth of the UX profession has led to an increased need for qualified practitioners and a proliferation of UX educational programs offered in both academia and industry. In this note, we present the design and initial evaluation of a new studio-based undergraduate program in UX--the first of its kind at a large, research-intensive US university. The program includes several curricular innovations, such as an integrated studio pedagogy in which six topical strands are interwoven across two types of studios. These studios are interconnected and span five semesters of the undergraduate experience. We present the curriculum model and the foundational principles that informed its design. We describe the two types of studios and their interconnection, and present early evaluation data showing that students are building valuable skills. The program described in this note provides a trailblazing model for UX pedagogy at the undergraduate level.</p></div></span> <a id="expcoll156" href="JavaScript: expandcollapse('expcoll156',156)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Novel Game Interfaces</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025463&CFID=758305256&CFTOKEN=14863114">Bendtroller:: An Exploration of In-Game Action Mappings with a Deformable Game Controller</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Paden Shorey, Audrey Girouard 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1447-1458</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025463" title="DOI">10.1145/3025453.3025463</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025463&ftid=1870058&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow158" style="display:inline;"><br /><div style="display:inline">We explore controller input mappings for games using a deformable prototype that combines deformation gestures with standard button input. In study one, we tested discrete gestures using three simple games. We categorized the control schemes as binary ...</div></span>
          <span id="toHide158" style="display:none;"><br /><div style="display:inline"><p>We explore controller input mappings for games using a deformable prototype that combines deformation gestures with standard button input. In study one, we tested discrete gestures using three simple games. We categorized the control schemes as binary (button only), action, and navigation, the latter two named based on the game mechanics mapped to the gestures. We found that the binary scheme performed the best, but gesture-based control schemes are stimulating and appealing. Results also suggest that the deformation gestures are best mapped to simple and natural tasks. In study two, we tested continuous gestures in a 3D racing game using the same control scheme categorization. Results were mostly consistent with study one but showed an improvement in performance and preference for the action control scheme.</p></div></span> <a id="expcoll158" href="JavaScript: expandcollapse('expcoll158',158)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025743&CFID=758305256&CFTOKEN=14863114">Inner Garden: Connecting Inner States to a Mixed Reality Sandbox for Mindfulness</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Joan Sol Roo, Renaud Gervais, Jeremy Frey, Martin Hachet 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1459-1470</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025743" title="DOI">10.1145/3025453.3025743</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025743&ftid=1870106&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow159" style="display:inline;"><br /><div style="display:inline">Digital technology has been completely integrated into our daily lives, yet the potential of technology to improve its users' life satisfaction is still largely untapped. Mindfulness, the act of paying a deliberate and non-judgmental attention to the ...</div></span>
          <span id="toHide159" style="display:none;"><br /><div style="display:inline"><p>Digital technology has been completely integrated into our daily lives, yet the potential of technology to improve its users' life satisfaction is still largely untapped. Mindfulness, the act of paying a deliberate and non-judgmental attention to the present moment, has been shown to have a positive impact on a person's health and subjective well-being--commonly called "happiness". Based on an iterative process with meditation teachers and practitioners, we designed a new tool to support mindfulness practices. This tool takes the shape of an augmented sandbox, designed to inspire the user's self-motivation and curiosity. By shaping the sand, the user creates a living miniature world that is projected back onto the sand. The natural elements of the garden are connected to real-time physiological measurements, such as breathing, helping the user to stay focused on the body. Moreover, using a Virtual Reality headset, they can travel inside their garden for a dedicated meditation session. Preliminary results seem to indicate that the system is well suited for mindfulness and induces a calm and mindful state on the user. The meditation teachers envisioned the use of Inner Garden in their practice.</p></div></span> <a id="expcoll159" href="JavaScript: expandcollapse('expcoll159',159)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025600&CFID=758305256&CFTOKEN=14863114">Providing Haptics to Walls &#38; Heavy Objects in Virtual Reality by Means of Electrical Muscle Stimulation</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Pedro Lopes, Sijing You, Lung-Pan Cheng, Sebastian Marwecki, Patrick Baudisch 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1471-1482</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025600" title="DOI">10.1145/3025453.3025600</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025600&ftid=1870073&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow160" style="display:inline;"><br /><div style="display:inline">We explore how to add haptics to walls and other heavy objects in virtual reality. When a user tries to push such an object, our system actuates the user's shoulder, arm, and wrist muscles by means of electrical muscle stimulation, creating a counter ...</div></span>
          <span id="toHide160" style="display:none;"><br /><div style="display:inline"><p>We explore how to add haptics to walls and other heavy objects in virtual reality. When a user tries to push such an object, our system actuates the user's shoulder, arm, and wrist muscles by means of electrical muscle stimulation, creating a counter force that pulls the user's arm backwards. Our device accomplishes this in a wearable form factor.</p> <p>In our first user study, participants wearing a head-mounted display interacted with objects provided with different types of EMS effects. The <i>repulsion</i> design (visualized as an electrical field) and the <i>soft</i> design (visualized as a magnetic field) received high scores on "prevented me from passing through" as well as "realistic".</p> <p>In a second study, we demonstrate the effectiveness of our approach by letting participants explore a virtual world in which all objects provide haptic EMS effects, including walls, gates, sliders, boxes, and projectiles.</p></div></span> <a id="expcoll160" href="JavaScript: expandcollapse('expcoll160',160)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025761&CFID=758305256&CFTOKEN=14863114">It wasn't really about the Pok&#233;mon: Parents' Perspectives on a Location-Based Mobile Game</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Kiley Sobel, Arpita Bhattacharya, Alexis Hiniker, Jin Ha Lee, Julie A. Kientz, Jason C. Yip 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1483-1496</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025761" title="DOI">10.1145/3025453.3025761</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025761&ftid=1870052&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow161" style="display:inline;"><br /><div style="display:inline">Though prior work shows parents worry about screen media experiences displacing physical activity and time outdoors, this research does not account for location-based mobile games like Pok&#233;mon GO, which specifically facilitate outdoor activity. ...</div></span>
          <span id="toHide161" style="display:none;"><br /><div style="display:inline"><p>Though prior work shows parents worry about screen media experiences displacing physical activity and time outdoors, this research does not account for location-based mobile games like <i>Pok&#233;mon GO</i>, which specifically facilitate outdoor activity. To fill this gap in the research, we surveyed and interviewed parents to understand (1) their values and perceptions of this type of gameplay and (2) how they co-play <i>Pok&#233;mon GO</i> with their children. Our findings provide empirical evidence that, in addition to appreciating the increased exercise and time outdoors, parents valued how play led to family bonding experiences. Furthermore, some traditional concerns about screen time persisted in this context, and new concerns about safety in real-world environments emerged. Parents mitigated these concerns with rules and gameplay choices, such as maintaining control of the mobile device, to ensure children were safe. This work contributes an empirical understanding of families as co-users of technology and offers a generative lens to study and design for joint media engagement among family members where gameplay differs from normative notions of screen time.</p></div></span> <a id="expcoll161" href="JavaScript: expandcollapse('expcoll161',161)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Novel Interfaces</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3026030&CFID=758305256&CFTOKEN=14863114">Placing and Recalling Virtual Items on the Skin</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Joanna Bergstrom-Lehtovirta, Sebastian Boring, Kasper Hornb&#230;k 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1497-1507</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3026030" title="DOI">10.1145/3025453.3026030</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3026030&ftid=1870069&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow163" style="display:inline;"><br /><div style="display:inline">The human skin provides an ample, always-on surface for input to smart watches, mobile phones, and remote displays. Using touch on bare skin to issue commands, however, requires users to recall the location of items without direct visual feedback. We ...</div></span>
          <span id="toHide163" style="display:none;"><br /><div style="display:inline"><p>The human skin provides an ample, always-on surface for input to smart watches, mobile phones, and remote displays. Using touch on bare skin to issue commands, however, requires users to recall the location of items without direct visual feedback. We present an in-depth study in which participants placed 30 items on the hand and forearm and attempted to recall their locations. We found that participants used a variety of landmarks, personal associations, and semantic groupings in placing the items on the skin. Although participants most frequently used anatomical landmarks (e.g., fingers, joints, and nails), recall rates were higher for items placed on personal landmarks, including scars and tattoos. We further found that personal associations between items improved recall, and that participants often grouped important items in similar areas, such as family members on the nails. We conclude by discussing the implications of our findings for design of skin-based interfaces.</p></div></span> <a id="expcoll163" href="JavaScript: expandcollapse('expcoll163',163)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025981&CFID=758305256&CFTOKEN=14863114">FLIPPIN': Exploring a Paper-based Book UI Design in a Public Space</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Koichi Yoshino, Koichi Obata, Satoru Tokuhisa 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1508-1517</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025981" title="DOI">10.1145/3025453.3025981</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025981&ftid=1870107&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow164" style="display:inline;"><br /><div style="display:inline">Digital information systems are increasingly being used in public spaces such as museums. Such systems should be easily accessible, arouse interest and offer useful information, and be easy to use. We present FLIPPIN' user interface (UI) system, which ...</div></span>
          <span id="toHide164" style="display:none;"><br /><div style="display:inline"><p>Digital information systems are increasingly being used in public spaces such as museums. Such systems should be easily accessible, arouse interest and offer useful information, and be easy to use. We present FLIPPIN' user interface (UI) system, which mimics the look, feel, and usability of traditional books. We explored how the paper-based book UI is designed to improve the usability problems in a public space while creating the prototypes with the aim of introducing Japanese cultural assets and conducting a field evaluation to compare the proposed system to a touch panel UI. The results of evaluation indicated the positive effects of the system, especially in terms of the usability and user's active appreciation derived from a physical book interaction. In addition, we present design guidelines derived from our findings. The suggested design guidelines are expected to facilitate the future development of effective interactive digital information systems in public spaces.</p></div></span> <a id="expcoll164" href="JavaScript: expandcollapse('expcoll164',164)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025531&CFID=758305256&CFTOKEN=14863114">Designing Interactive Advertisements for Public Displays</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Hasibullah Sahibzada, Eva Hornecker, Florian Echtler, Patrick Tobias Fischer 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1518-1529</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025531" title="DOI">10.1145/3025453.3025531</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025531&ftid=1870080&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow165" style="display:inline;"><br /><div style="display:inline">Although public displays are increasingly being deployed in everyday situations, they are still mostly used as auto-active information sources. Adding interactivity can help to attract and engage users. We report on the design and in-the-wild evaluation ...</div></span>
          <span id="toHide165" style="display:none;"><br /><div style="display:inline"><p>Although public displays are increasingly being deployed in everyday situations, they are still mostly used as auto-active information sources. Adding interactivity can help to attract and engage users. We report on the design and in-the-wild evaluation of an interactive advert for a public display in a tourist information center. We evaluate and compare 3 different variants - non-interactive, interaction using body tracking, and interaction using personal mobile devices - with respect to attracting the attention and interaction from passersby. We further compare these variants with an iterated version of the body tracking system with an extended tracking area. Our findings include an unexpected reluctance of passersby to use their mobile device in public, and the increased interactive area for body interaction resulting in increased engagement and spontaneous multi-user interaction, while removing the so-called 'landing effect'. Based on our findings, we suggest guidelines for interactive adverts on public displays.</p></div></span> <a id="expcoll165" href="JavaScript: expandcollapse('expcoll165',165)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Players, Spectators, Communities</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025563&CFID=758305256&CFTOKEN=14863114">Don't Talk Dirty to Me: How Sexist Beliefs Affect Experience in Sexist Games</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Jason T. Bowey, Ansgar E. Depping, Regan L. Mandryk 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1530-1543</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025563" title="DOI">10.1145/3025453.3025563</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025563&ftid=1870081&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow167" style="display:inline;"><br /><div style="display:inline">Research on sexism in digital games has suggested that women self-select out of playing sexist games; however, assuming a homogenous gender-based response does not account for the diversity of identities within a gender group. Gender-incongruent responses ...</div></span>
          <span id="toHide167" style="display:none;"><br /><div style="display:inline"><p>Research on sexism in digital games has suggested that women self-select out of playing sexist games; however, assuming a homogenous gender-based response does not account for the diversity of identities within a gender group. Gender-incongruent responses to recent events like #gamergate implies that the gender of the participant is not paramount to experience, but that their beliefs about gender roles are. To explore the role of sexist beliefs on experience in sexist games, we created three versions of a game that were identical except for the presence of sexist imagery and/or dialogue. We show that enjoyment of sexist games is not predicted by player gender, but by the player's pre-existing beliefs about gender. Furthermore, avatar identification is the pathway through which enjoyment is facilitated. Finally, sexist dialogue does not improve the play experience for anyone rather it harms experience for players of all genders who do not hold sexist beliefs.</p></div></span> <a id="expcoll167" href="JavaScript: expandcollapse('expcoll167',167)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025623&CFID=758305256&CFTOKEN=14863114">Understanding Gaming Perceptions and Experiences in a Women's College Community</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Orit Shaer, Lauren Westendorf, Nicholas A. Knouf, Claudia Pederson 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1544-1557</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025623" title="DOI">10.1145/3025453.3025623</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025623&ftid=1870082&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow168" style="display:inline;"><br /><div style="display:inline">Recent trends in gaming diversification have shown that women are both an increasingly significant pool of consumers and game producers, and regular victims of misogynistic harassment. Such observations stress the importance of investigating the complex ...</div></span>
          <span id="toHide168" style="display:none;"><br /><div style="display:inline"><p>Recent trends in gaming diversification have shown that women are both an increasingly significant pool of consumers and game producers, and regular victims of misogynistic harassment. Such observations stress the importance of investigating the complex relationships of women and gaming. In this paper, we draw upon perspectives from Feminist HCI to extend the current knowledge of issues in gaming that are specific to women. We present results from a mixed-methods study with 327 participants who are students and alumnae of a women's college. Our findings shed light on the complex relationships of women with games, with other gamers, and with gaming culture and industry. The results also indicate that in some cases gender-related negative experiences of gaming have lasting impact on the participation and self-confidence of young women. We conclude by discussing the implications of our findings for the design of games, game development education, and for the study of gaming.</p></div></span> <a id="expcoll168" href="JavaScript: expandcollapse('expcoll168',168)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025813&CFID=758305256&CFTOKEN=14863114">Ways of Spectating: Unravelling Spectator Participation in Kinect Play</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Burak S. Tekin, Stuart Reeves 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1558-1570</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025813" title="DOI">10.1145/3025453.3025813</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025813&ftid=1870086&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow169" style="display:inline;"><br /><div style="display:inline">We explore spectating on video game play as an interactional and participatory activity. Drawing on a corpus of video recordings capturing 'naturally occurring' Kinect gaming within home settings, we detail how the analytic 'work' of spectating is interactionally ...</div></span>
          <span id="toHide169" style="display:none;"><br /><div style="display:inline"><p>We explore spectating on video game play as an interactional and participatory activity. Drawing on a corpus of video recordings capturing 'naturally occurring' Kinect gaming within home settings, we detail how the analytic 'work' of spectating is interactionally accomplished as a matter of collaborative action with players and engagement in the game. We examine: spectators supporting players with continuous 'scaffolding'; spectators critiquing player technique during and between moments of play; spectators recognising and complimenting competent player conduct; and spectators reflecting on prior play to build instructions for the player. From this we draw out a number of points that shift the conversation in HCI about 'the spectator' towards understanding and designing for spectating as an interactional activity; that is, sequentially ordered and temporally coordinated. We also discuss bodily conduct and the particular ways of 'seeing' involved in spectating, and conclude with remarks on conceptual and design implications for HCI.</p></div></span> <a id="expcoll169" href="JavaScript: expandcollapse('expcoll169',169)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025708&CFID=758305256&CFTOKEN=14863114">Expanding Video Game Live-Streams with Enhanced Communication Channels: A Case Study</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Pascal Lessel, Alexander Vielhauer, Antonio Kr&#252;ger 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1571-1576</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025708" title="DOI">10.1145/3025453.3025708</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025708&ftid=1870053&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow170" style="display:inline;"><br /><div style="display:inline">Live-streaming of video games is a recent phenomenon. One driving factor is the direct communication between the streamer and the audience. Currently, besides the platform-integrated options such as text chats, streamers often use external sources to ...</div></span>
          <span id="toHide170" style="display:none;"><br /><div style="display:inline"><p>Live-streaming of video games is a recent phenomenon. One driving factor is the direct communication between the streamer and the audience. Currently, besides the platform-integrated options such as text chats, streamers often use external sources to let their community better articulate their opinions. In this paper we present a case study with our tool Helpstone, a live-streaming tool for the card game Hearthstone. Helpstone provides several new communication channels that allow for a better viewer-streamer interaction. We evaluated the tool within a live-streaming session with 23 viewers using Helpstone, and interviewed the streamer. The results indicate that not every implemented interactivity option is relevant. However, in general, new communication channels appear to be valuable and novel influence options are appreciated.</p></div></span> <a id="expcoll170" href="JavaScript: expandcollapse('expcoll170',170)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025602&CFID=758305256&CFTOKEN=14863114">"These are not my hands!": Effect of Gender on the Perception of Avatar Hands in Virtual Reality</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Valentin Schwind, Pascal Knierim, Cagri Tasci, Patrick Franczak, Nico Haas, Niels Henze 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1577-1582</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025602" title="DOI">10.1145/3025453.3025602</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025602&ftid=1870063&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow171" style="display:inline;"><br /><div style="display:inline">Rendering the user's body in virtual reality increases immersion and presence the illusion of "being there". Recent technology enables determining the pose and position of the hands to render them accordingly while interacting within the virtual environment. ...</div></span>
          <span id="toHide171" style="display:none;"><br /><div style="display:inline"><p>Rendering the user's body in virtual reality increases immersion and presence the illusion of "being there". Recent technology enables determining the pose and position of the hands to render them accordingly while interacting within the virtual environment. Virtual reality applications often use realistic male or female hands, mimic robotic hands, or cartoon hands. However, it is unclear how users perceive different hand styles. We conducted a study with 14 male and 14 female participants in virtual reality to investigate the effect of gender on the perception of six different hands. Quantitative and qualitative results show that women perceive lower levels of presence while using male avatar hands and male perceive lower levels of presence using non-human avatar hands. While women dislike male hands, men accept and feel presence with avatar hands of both genders. Our results highlight the importance of considering the users' diversity when designing virtual reality experiences.</p></div></span> <a id="expcoll171" href="JavaScript: expandcollapse('expcoll171',171)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Smart Monitoring in Physical Spaces</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025479&CFID=758305256&CFTOKEN=14863114">Looking Inside the Wires: Understanding Museum Visitor Learning with an Augmented Circuit Exhibit</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Elham Beheshti, David Kim, Gabrielle Ecanow, Michael S. Horn 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1583-1594</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025479" title="DOI">10.1145/3025453.3025479</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025479&ftid=1870088&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow173" style="display:inline;"><br /><div style="display:inline">Understanding electrical circuits can be difficult for novices of all ages. In this paper, we describe a science museum exhibit that enables visitors to make circuits on an interactive tabletop and observe a simulation of electrons flowing through the ...</div></span>
          <span id="toHide173" style="display:none;"><br /><div style="display:inline"><p>Understanding electrical circuits can be difficult for novices of all ages. In this paper, we describe a science museum exhibit that enables visitors to make circuits on an interactive tabletop and observe a simulation of electrons flowing through the circuit. Our goal is to use multiple representations to help convey basic concepts of current and resistance. To study visitor interaction and learning, we tested the design at a popular science museum with 60 parent-child dyads in three conditions: a control condition with no electron simulation; a condition with the simulation displayed alongside the circuit on the same screen; and an augmented reality condition, with the simulation displayed on a tablet that acts as a lens to see into the circuit. Our findings show that children did significantly better on a post-test in both experimental conditions, with children performing best in the AR condition. However, analysis of session videos shows unexpected parent-child collaboration in the AR condition.</p></div></span> <a id="expcoll173" href="JavaScript: expandcollapse('expcoll173',173)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025578&CFID=758305256&CFTOKEN=14863114">Log it While it's Hot: Designing Human Interaction with Smart Thermostats for Shared Work Environments</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Stephen Snow, Frederik Auffenberg, m. c. schraefel 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1595-1606</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025578" title="DOI">10.1145/3025453.3025578</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025578&ftid=1870074&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow174" style="display:inline;"><br /><div style="display:inline">Smart thermostats offer impressive scope for adapting to users' thermal comfort preferences and saving energy in shared work environments. Yet human interactions with smart thermostats thus far amount to an assumption from designers that users are willing ...</div></span>
          <span id="toHide174" style="display:none;"><br /><div style="display:inline"><p>Smart thermostats offer impressive scope for adapting to users' thermal comfort preferences and saving energy in shared work environments. Yet human interactions with smart thermostats thus far amount to an assumption from designers that users are willing and able to provide unbiased data at regular intervals; which may be unrealistic. In this paper we highlight the variety of social factors which complicate users' relationships with smart thermostats in shared work environments. These include social dynamics, expectations, and contextually specific factors that influence motivations for interaction with the system. In response we outline our framework towards a <i>Smarter Thermostat</i>: one which better accounts for these messy social inevitabilities, is equipped for a decline in user feedback over time and one which augments rather than attempts to replaces human intelligence- thereby ensuring a smarter thermostat does not create dumber humans.</p></div></span> <a id="expcoll174" href="JavaScript: expandcollapse('expcoll174',174)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025853&CFID=758305256&CFTOKEN=14863114">Community-Empowered Air Quality Monitoring System</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Yen-Chia Hsu, Paul Dille, Jennifer Cross, Beatrice Dias, Randy Sargent, Illah Nourbakhsh 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1607-1619</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025853" title="DOI">10.1145/3025453.3025853</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025853&ftid=1870070&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow175" style="display:inline;"><br /><div style="display:inline">Developing information technology to democratize scientific knowledge and support citizen empowerment is a challenging task. In our case, a local community suffered from air pollution caused by industrial activity. The residents lacked the technological ...</div></span>
          <span id="toHide175" style="display:none;"><br /><div style="display:inline"><p>Developing information technology to democratize scientific knowledge and support citizen empowerment is a challenging task. In our case, a local community suffered from air pollution caused by industrial activity. The residents lacked the technological fluency to gather and curate diverse scientific data to advocate for regulatory change. We collaborated with the community in developing an air quality monitoring system which integrated heterogeneous data over a large spatial and temporal scale. The system afforded strong scientific evidence by using animated smoke images, air quality data, crowdsourced smell reports, and wind data. In our evaluation, we report patterns of sharing smoke images among stakeholders. Our survey study shows that the scientific knowledge provided by the system encourages agonistic discussions with regulators, empowers the community to support policy making, and rebalances the power relationship between stakeholders.</p></div></span> <a id="expcoll175" href="JavaScript: expandcollapse('expcoll175',175)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025799&CFID=758305256&CFTOKEN=14863114">The Catch(es) with Smart Home: Experiences of a Living Lab Field Study</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Timo Jakobi, Corinna Ogonowski, Nico Castelli, Gunnar Stevens, Volker Wulf 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1620-1633</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025799" title="DOI">10.1145/3025453.3025799</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025799&ftid=1870102&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow176" style="display:inline;"><br /><div style="display:inline">Smart home systems are becoming an integral feature of the emerging home IT market. Under this general term, products mainly address issues of security, energy savings and comfort. Comprehensive systems that cover several use cases are typically operated ...</div></span>
          <span id="toHide176" style="display:none;"><br /><div style="display:inline"><p>Smart home systems are becoming an integral feature of the emerging home IT market. Under this general term, products mainly address issues of security, energy savings and comfort. Comprehensive systems that cover several use cases are typically operated and managed via a unified dashboard. Unfortunately, research targeting user experience (UX) design for smart home interaction that spans several use cases or covering the entire system is scarce. Furthermore, existing comprehensive and user-centered longterm studies on challenges and needs throughout phases of information collection, installation and operation of smart home systems are technologically outdated. Our 18-month Living Lab study covering 14 households equipped with smart home technology provides insights on how to design for improving smart home appropriation. This includes a stronger sensibility for household practices during setup and configuration, flexible visualizations for evolving demands and an extension of smart home beyond the location.</p></div></span> <a id="expcoll176" href="JavaScript: expandcollapse('expcoll176',176)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Social Computing and Health</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025909&CFID=758305256&CFTOKEN=14863114">A Social Media Based Index of Mental Well-Being in College Campuses</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Shrey Bagroy, Ponnurangam Kumaraguru, Munmun De Choudhury 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1634-1646</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025909" title="DOI">10.1145/3025453.3025909</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025909&ftid=1870060&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow178" style="display:inline;"><br /><div style="display:inline">Psychological distress in the form of depression, anxiety and other mental health challenges among college students is a growing health concern. Dearth of accurate, continuous, and multi-campus data on mental well-being presents significant challenges ...</div></span>
          <span id="toHide178" style="display:none;"><br /><div style="display:inline"><p>Psychological distress in the form of depression, anxiety and other mental health challenges among college students is a growing health concern. Dearth of accurate, continuous, and multi-campus data on mental well-being presents significant challenges to intervention and mitigation efforts in college campuses. We examine the potential of social media as a new "barometer" for quantifying the mental well-being of college populations. Utilizing student-contributed data in Reddit communities of over 100 universities, we first build and evaluate a transfer learning based classification approach that can detect mental health expressions with 97% accuracy. Thereafter, we propose a robust campus-specific Mental Well-being Index: MWI. We find that MWI is able to reveal meaningful temporal patterns of mental well-being in campuses, and to assess how their expressions relate to university attributes like size, academic prestige, and student demographics. We discuss the implications of our work for improving counselor efforts, and in the design of tools that can enable better assessment of the mental health climate of college campuses.</p></div></span> <a id="expcoll178" href="JavaScript: expandcollapse('expcoll178',178)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025654&CFID=758305256&CFTOKEN=14863114">When Fitness Meets Social Networks: Investigating Fitness Tracking and Social Practices on WeRun</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Xinning Gui, Yu Chen, Clara Caldeira, Dan Xiao, Yunan Chen 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1647-1659</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025654" title="DOI">10.1145/3025453.3025654</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025654&ftid=1870095&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow179" style="display:inline;"><br /><div style="display:inline">The last two decades have seen growing interest in promoting physical activities by using self-tracking technologies. Previous work has identified social interactions in self-tracking as a crucial factor in motivating users to exercise. However, it is ...</div></span>
          <span id="toHide179" style="display:none;"><br /><div style="display:inline"><p>The last two decades have seen growing interest in promoting physical activities by using self-tracking technologies. Previous work has identified social interactions in self-tracking as a crucial factor in motivating users to exercise. However, it is unclear how integrating fitness features into complex pre-existing social network affects users' fitness tracking practices and social interactions. In this research, we address this gap through a qualitative study of 32 users of WeRun--a fitness plugin of the widely adopted Chinese mobile social networking service WeChat. Our findings indicate that sharing fitness data with pre-existing social networks motivates users to continue self-tracking and enhances their existing social relationships. Nevertheless, users' concerns about their online personal images lead to challenges around privacy. We discuss how our study could advance understanding of the effects of fitness applications built on top of pre-existing social networks. We present implications for future social fitness applications design.</p></div></span> <a id="expcoll179" href="JavaScript: expandcollapse('expcoll179',179)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025796&CFID=758305256&CFTOKEN=14863114">"Be Grateful You Don't Have a Real Disease": Understanding Rare Disease Relationships</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Haley MacLeod, Grace Bastin, Leslie S. Liu, Katie Siek, Kay Connelly 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1660-1673</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025796" title="DOI">10.1145/3025453.3025796</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025796&ftid=1870066&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow180" style="display:inline;"><br /><div style="display:inline">We characterize how people with rare diseases consider their support needs as being met or neglected by different sources. After a 22-week study with 11 participants, we found that people with rare diseases identify strongly with their conditions but ...</div></span>
          <span id="toHide180" style="display:none;"><br /><div style="display:inline"><p>We characterize how people with rare diseases consider their support needs as being met or neglected by different sources. After a 22-week study with 11 participants, we found that people with rare diseases identify strongly with their conditions but demonstrate a range of outlooks on their condition (positive, negative, and accepting). We found that participants think of themselves as being in a separate "Rare World" from the "normal" people in their lives and that relationships with friends and family members are strained. On the other hand, online communities were described as valuable sources of many forms of support, but do not adequately compensate for the lack of <i>tangible</i> support in offline relationships. We propose an approach to facilitating tangible support that leverages existing research on social matching, towards facilitating support among people with <i>different</i> rare diseases to overcome geographic and symptomatic challenges of coordinating support between people with the <i>same</i> rare disease.</p></div></span> <a id="expcoll180" href="JavaScript: expandcollapse('expcoll180',180)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025747&CFID=758305256&CFTOKEN=14863114">When Personal Tracking Becomes Social: Examining the Use of Instagram for Healthy Eating</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Chia-Fang Chung, Elena Agapie, Jessica Schroeder, Sonali Mishra, James Fogarty, Sean A. Munson 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1674-1687</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025747" title="DOI">10.1145/3025453.3025747</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025747&ftid=1870103&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow181" style="display:inline;"><br /><div style="display:inline">Many people appropriate social media and online communities in their pursuit of personal health goals, such as healthy eating or increased physical activity. However, people struggle with impression management, and with reaching the right audiences when ...</div></span>
          <span id="toHide181" style="display:none;"><br /><div style="display:inline"><p>Many people appropriate social media and online communities in their pursuit of personal health goals, such as healthy eating or increased physical activity. However, people struggle with impression management, and with reaching the right audiences when they share health information on these platforms. Instagram, a popular photo-based social media platform, has attracted many people who post and share their food photos. We aim to inform the design of tools to support healthy behaviors by understanding how people appropriate Instagram to track and share food data, the benefits they obtain from doing so, and the challenges they encounter. We interviewed 16 women who consistently record and share what they eat on Instagram. Participants tracked to support themselves and others in their pursuit of healthy eating goals. They sought social support for their own tracking and healthy behaviors and strove to provide that support for others. People adapted their personal tracking practices to better receive and give this support. Applying these results to the design of health tracking tools has the potential to help people better access social support.</p></div></span> <a id="expcoll181" href="JavaScript: expandcollapse('expcoll181',181)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Supporting Local Space</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025745&CFID=758305256&CFTOKEN=14863114">Participatory Media: Creating Spaces for Storytelling in Neighbourhood Planning</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Jennifer Manuel, Geoff Vigar, Tom Bartindale, Rob Comber 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1688-1701</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025745" title="DOI">10.1145/3025453.3025745</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025745&ftid=1870109&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow183" style="display:inline;"><br /><div style="display:inline">Neighbourhood planning devolves power to communities to create their own planning policy but traditional forms of participation are still relied upon. And despite the ubiquitous nature of technology in society, digital participation methods are rarely ...</div></span>
          <span id="toHide183" style="display:none;"><br /><div style="display:inline"><p>Neighbourhood planning devolves power to communities to create their own planning policy but traditional forms of participation are still relied upon. And despite the ubiquitous nature of technology in society, digital participation methods are rarely used. In this paper, we outline fieldwork with two neighbourhood planning groups who used participatory media technology to improve engagement though the art of storytelling. We focus on the configuration of participatory media as a way to widen participation and enable story creation and sharing amongst citizens. We highlight that storytelling using media technology can provide a model of and a model for the way we "do" neighbourhood planning whilst emphasising the challenges of ensuring processes are linked to tangible actions and encouraging the multiplicity of stories.</p></div></span> <a id="expcoll183" href="JavaScript: expandcollapse('expcoll183',183)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3026035&CFID=758305256&CFTOKEN=14863114">Block Party: Synchronized Planning and Navigation Views for Neighbourhood Expeditions</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Huiyuan Zhou, Aisha Edrah, Bonnie MacKay, Derek Reilly 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1702-1713</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3026035" title="DOI">10.1145/3025453.3026035</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3026035&ftid=1870104&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow184" style="display:inline;"><br /><div style="display:inline">Mobile wayfinding and guide apps have become indispensable tools for navigating unfamiliar urban spaces. Such applications address targeted, "just-in-time" queries, but are not optimally designed for multi-point expeditions that can quickly build route ...</div></span>
          <span id="toHide184" style="display:none;"><br /><div style="display:inline"><p>Mobile wayfinding and guide apps have become indispensable tools for navigating unfamiliar urban spaces. Such applications address targeted, "just-in-time" queries, but are not optimally designed for multi-point expeditions that can quickly build route and survey-level familiarity with a neighbourhood. We first conducted an experimental simulation involving a homebuying scenario to assess the usefulness of a popular mobile wayfinding and search application (Google Maps) for exploring a neighbourhood. We then designed a prototype application called Block Party that addresses a number of limitations of Google Maps for this purpose, and evaluated it in a second replica study. The results suggested that application designs that facilitate switching among distinct but synchronized navigation views such as Block Party might support more efficient usage and the selection of task-appropriate views, leading to better overall spatial awareness.</p></div></span> <a id="expcoll184" href="JavaScript: expandcollapse('expcoll184',184)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025948&CFID=758305256&CFTOKEN=14863114">Designing for Cohabitation: Naturecultures, Hybrids, and Decentering the Human in Design</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Nancy Smith, Shaowen Bardzell, Jeffrey Bardzell 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1714-1725</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025948" title="DOI">10.1145/3025453.3025948</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025948&ftid=1870054&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow185" style="display:inline;"><br /><div style="display:inline">Recent research in urban informatics has presented the city as both a complex technological center and a diverse cultural, social, and political entity. However, there has been little research into the changing role that nature plays in urban space, ...</div></span>
          <span id="toHide185" style="display:none;"><br /><div style="display:inline"><p>Recent research in urban informatics has presented the city as both a complex technological center and a diverse cultural, social, and political entity. However, there has been little research into the changing role that nature plays in urban space, particularly when it comes to understanding how animals have adapted to life in technological and networked cities. In the wake of urbanization, new kinds of cohabitation, including increased interactions between humans and animals, has resulted in new challenges for those working in urban informatics. We leverage key concepts in the Anthropocene-naturecultures, hybrids, and decentering the human in design-to unpack the entanglements of animal-human-computer interaction in two design cases: The Big Cat Behavioral Tracking Initiative and The Phenology Clock. We contribute to urban informatics and HCI research by reflecting on ways in which design can promote new forms of cohabitation and support a broader conception of the city that sees animals as an essential part of the urban landscape.</p></div></span> <a id="expcoll185" href="JavaScript: expandcollapse('expcoll185',185)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025705&CFID=758305256&CFTOKEN=14863114">Stranger Searching in a Strange Land: The Impact of Familiarity on Local Search</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Isaac Johnson, Victoria Schwanda Sosik, Kacey Ballard 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1726-1730</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025705" title="DOI">10.1145/3025453.3025705</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025705&ftid=1870067&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow186" style="display:inline;"><br /><div style="display:inline">Local search entails looking for places, such as restaurants or hotels, in a geographically-constrained region. Within local search, it has been observed that an individual's familiarity with their environment (i.e. how well they know the area in a query ...</div></span>
          <span id="toHide186" style="display:none;"><br /><div style="display:inline"><p>Local search entails looking for places, such as restaurants or hotels, in a geographically-constrained region. Within local search, it has been observed that an individual's familiarity with their environment (i.e. how well they know the area in a query of the form "{places} in {area}") impacts which places they are most interested in visiting. Less well-understood though is how people's information preferences differ during 1) different phases of the search process and 2) based on their level of familiarity. Through a series of surveys in the domain of dining, we explore how familiarity moderates what level of information is useful to an individual about restaurant location when choosing a place to visit. We further examine how these preferences vary between regions and phases of local search (deciding on a restaurant or determining how to go). We contribute an understanding of people's information preferences during search, building on prior research of how offline context impacts online needs.</p></div></span> <a id="expcoll186" href="JavaScript: expandcollapse('expcoll186',186)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Temperature Interfaces</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025723&CFID=758305256&CFTOKEN=14863114">Ambiotherm: Enhancing Sense of Presence in Virtual Reality by Simulating Real-World Environmental Conditions</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Nimesha Ranasinghe, Pravar Jain, Shienny Karwita, David Tolley, Ellen Yi-Luen Do 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1731-1742</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025723" title="DOI">10.1145/3025453.3025723</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025723&ftid=1870076&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow188" style="display:inline;"><br /><div style="display:inline">In this paper, we present and evaluate Ambiotherm, a wearable accessory for Head Mounted Displays (HMD) that provides thermal and wind stimuli to simulate real-world environmental conditions, such as ambient temperatures and wind conditions, to enhance ...</div></span>
          <span id="toHide188" style="display:none;"><br /><div style="display:inline"><p>In this paper, we present and evaluate Ambiotherm, a wearable accessory for Head Mounted Displays (HMD) that provides thermal and wind stimuli to simulate real-world environmental conditions, such as ambient temperatures and wind conditions, to enhance the sense of presence in Virtual Reality (VR). Ambiotherm consists of a Ambient Temperature Module that is attached to the user's neck, a Wind Simulation Module focused towards the user's face, and a Control Module utilizing Bluetooth communication. We demonstrate Ambiotherm with two VR environments, a hot desert, and a snowy mountain, to showcase the different types of simulated environmental conditions. We conduct several studies to 1) address design factors of the system and 2) evaluate Ambiotherm's effect on factors related to a user's sense of presence. Our findings show that the addition of wind and thermal stimuli significantly improves sensory and realism factors, contributing towards an enhanced sense of presence when compared to traditional VR experiences.</p></div></span> <a id="expcoll188" href="JavaScript: expandcollapse('expcoll188',188)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025614&CFID=758305256&CFTOKEN=14863114">Multi-moji: Combining Thermal, Vibrotactile &#38; Visual Stimuli to Expand the Affective Range of Feedback</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Graham Wilson, Stephen A. Brewster 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1743-1755</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025614" title="DOI">10.1145/3025453.3025614</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025614&ftid=1870112&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow189" style="display:inline;"><br /><div style="display:inline">This paper explores the combination of multiple concurrent modalities for conveying emotional information in HCI: temperature, vibration and abstract visual displays. Each modality has been studied individually, but can only convey a limited range of ...</div></span>
          <span id="toHide189" style="display:none;"><br /><div style="display:inline"><p>This paper explores the combination of multiple concurrent modalities for conveying emotional information in HCI: temperature, vibration and abstract visual displays. Each modality has been studied individually, but can only convey a limited range of emotions within two-dimensional valence-arousal space. This paper is the first to systematically combine multiple modalities to expand the available affective range. Three studies were conducted: Study 1 measured the emotionality of vibrotactile feedback by itself; Study 2 measured the perceived emotional content of three bimodal combinations: vibrotactile + thermal, vibrotactile + visual and visual + thermal. Study 3 then combined all three modalities. Results show that combining modalities increases the available range of emotional states, particularly in the problematic top-right and bottom-left quadrants of the dimensional model. We also provide a novel lookup resource for designers to identify stimuli to convey a range of emotions</p></div></span> <a id="expcoll189" href="JavaScript: expandcollapse('expcoll189',189)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025844&CFID=758305256&CFTOKEN=14863114">The Heat is On: A Temperature Display for Conveying Affective Feedback</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Jordan Tewell, Jon Bird, George R. Buchanan 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1756-1767</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025844" title="DOI">10.1145/3025453.3025844</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025844&ftid=1870057&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow190" style="display:inline;"><br /><div style="display:inline">Previous research has investigated whether temperature can augment a range of media including music, images and video. We describe the first experiment to investigate whether temperature can augment emotion conveyed by text messages. A challenge in prior ...</div></span>
          <span id="toHide190" style="display:none;"><br /><div style="display:inline"><p>Previous research has investigated whether temperature can augment a range of media including music, images and video. We describe the first experiment to investigate whether temperature can augment emotion conveyed by text messages. A challenge in prior work has been ensuring users can discern different thermal signals. We present an improved technique for thermal feedback that uses an array of three thermal stimulators. We demonstrate that the Thermal Array Display (TAD) increases users' ability to identify temperatures within a narrower range, compared to using a single thermal stimulator. While text messages dominate valence in the absence of context for temperature, the TAD consistently conveys arousal, and can enhance arousal of text messages, especially those that are emotionally neutral. We discuss potential applications of augmenting text with temperature.</p></div></span> <a id="expcoll190" href="JavaScript: expandcollapse('expcoll190',190)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025471&CFID=758305256&CFTOKEN=14863114">Exploring Novice Approaches to Smartphone-based Thermographic Energy Auditing: A Field Study</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Matthew Louis Mauriello, Manaswi Saha, Erica Brown Brown, Jon E. Froehlich 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1768-1780</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025471" title="DOI">10.1145/3025453.3025471</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025471&ftid=1870092&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow191" style="display:inline;"><br /><div style="display:inline">The recent integration of thermal cameras with commodity smartphones presents an opportunity to engage the public in evaluating energy-efficiency issues in the built environment. However, it is unclear how novice users without professional experience ...</div></span>
          <span id="toHide191" style="display:none;"><br /><div style="display:inline"><p>The recent integration of thermal cameras with commodity smartphones presents an opportunity to engage the public in evaluating energy-efficiency issues in the built environment. However, it is unclear how novice users without professional experience or training approach thermographic energy auditing activities. In this paper, we recruited 10 participants for a four-week field study of end-user behavior exploring novice approaches to semi-structured thermographic energy auditing tasks. We analyze thermographic imagery captured by participants as well as weekly surveys and post-study debrief interviews. Our findings suggest that while novice users perceived thermal cameras as useful in identifying energy-efficiency issues in buildings, they struggled with interpretation and confidence. We characterize how novices perform thermographic-based energy auditing, synthesize key challenges, and discuss implications for design.</p></div></span> <a id="expcoll191" href="JavaScript: expandcollapse('expcoll191',191)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Behavior in Online Communities</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025956&CFID=758305256&CFTOKEN=14863114">"People Are Either Too Fake or Too Real": Opportunities and Challenges in Tie-Based Anonymity</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Xiao Ma, Nazanin Andalibi, Louise Barkhuus, Mor Naaman 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1781-1793</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025956" title="DOI">10.1145/3025453.3025956</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025956&ftid=1870115&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow193" style="display:inline;"><br /><div style="display:inline">In recent years, several mobile applications allowed individuals to anonymously share information with friends and contacts, without any persistent identity marker. The functions of these "tie-based" anonymity services may be notably different than other ...</div></span>
          <span id="toHide193" style="display:none;"><br /><div style="display:inline"><p>In recent years, several mobile applications allowed individuals to anonymously share information with friends and contacts, without any persistent identity marker. The functions of these "tie-based" anonymity services may be notably different than other social media services. We use semi-structured interviews to qualitatively examine motivations, practices and perceptions in two tie-based anonymity apps: Secret (now defunct, in the US) and Mimi (in China). Among the findings, we show that: (1) while users are more comfortable in self-disclosure, they still have specific practices and strategies to avoid or allow identification; (2) attempts for deidentification of others are prevalent and often elaborate; and (3) participants come to expect both negativity and support in response to posts. Our findings highlight unique opportunities and potential benefits for tie-based anonymity apps, including serving disclosure needs and social probing. Still, challenges for making such applications successful, for example the prevalence of negativity and bullying, are substantial.</p></div></span> <a id="expcoll193" href="JavaScript: expandcollapse('expcoll193',193)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Connect, Move, Touch, Build</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025465&CFID=758305256&CFTOKEN=14863114">Environment-Scale Fabrication: Replicating Outdoor Climbing Experiences</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Emily Whiting, Nada Ouf, Liane Makatura, Christos Mousas, Zhenyu Shu, Ladislav Kavan 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1794-1804</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025465" title="DOI">10.1145/3025453.3025465</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025465&ftid=1870099&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow195" style="display:inline;"><br /><div style="display:inline">Despite rapid advances in 3D printing, fabricating large, durable and robust artifacts is impractical with current technology. We focus on a particularly challenging environment-scale artifact: rock climbing routes. We propose a prototype fabrication ...</div></span>
          <span id="toHide195" style="display:none;"><br /><div style="display:inline"><p>Despite rapid advances in 3D printing, fabricating large, durable and robust artifacts is impractical with current technology. We focus on a particularly challenging environment-scale artifact: rock climbing routes. We propose a prototype fabrication method to replicate part of an outdoor climbing route and enable the same sensorimotor experience in an indoor gym. We start with 3D reconstruction of the rock wall using multi-view stereo and use reference videos of a climber in action to identify localized rock features that are necessary for ascent. We create 3D models akin to traditional indoor climbing holds, fabricated using rapid prototyping, molding and casting techniques. This results in robust holds accurately replicating the features and configuration of the original rock route. Validation was performed on two rock climbing sites in New Hampshire and Utah. We verified our results by comparing climbers' moves on the indoor replicas and original outdoor routes.</p></div></span> <a id="expcoll195" href="JavaScript: expandcollapse('expcoll195',195)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3026048&CFID=758305256&CFTOKEN=14863114">Why Tangibility Matters: A Design Case Study of At-Risk Children Learning to Read and Spell</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Min Fan, Alissa N. Antle, Maureen Hoskyn, Carman Neustaedter, Emily S. Cramer 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1805-1816</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3026048" title="DOI">10.1145/3025453.3026048</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3026048&ftid=1870061&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow196" style="display:inline;"><br /><div style="display:inline">Tangibles may be effective for reading applications. Letters can be represented as 3D physical objects. Words are spatially organized collections of letters. We explore how tangibility impacts reading and spelling acquisition for young Anglophone children ...</div></span>
          <span id="toHide196" style="display:none;"><br /><div style="display:inline"><p>Tangibles may be effective for reading applications. Letters can be represented as 3D physical objects. Words are spatially organized collections of letters. We explore how tangibility impacts reading and spelling acquisition for young Anglophone children who have dyslexia. We describe our theory-based design rationale and present a mixed-methods case study of eight children using our PhonoBlocks system. All children made significant gains in reading and spelling on trained and untrained (new) words, and could apply all spelling rules a month later. We discuss the design features of our system that contributed to effective learning processes, resulting in successful learning outcomes: dynamic colour cues embedded in 3D letters, which can draw attention to how letter(s) position changes their sounds; and the form of 3D tangible letters, which can enforce correct letter orientation and enable epistemic strategies in letter organization that simplify spelling tasks. We conclude with design guidelines for tangible reading systems.</p></div></span> <a id="expcoll196" href="JavaScript: expandcollapse('expcoll196',196)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3026036&CFID=758305256&CFTOKEN=14863114">WeBuild: Automatically Distributing Assembly Tasks Among Collocated Workers to Improve Coordination</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          C. Ailie Fraser, Tovi Grossman, George Fitzmaurice 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1817-1830</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3026036" title="DOI">10.1145/3025453.3026036</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3026036&ftid=1870064&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow197" style="display:inline;"><br /><div style="display:inline">Physical construction and assembly tasks are often carried out by groups of collocated workers, and they can be difficult to coordinate. Group members must spend time deciding how to split up the task, how to assign subtasks to each other, and in what ...</div></span>
          <span id="toHide197" style="display:none;"><br /><div style="display:inline"><p>Physical construction and assembly tasks are often carried out by groups of collocated workers, and they can be difficult to coordinate. Group members must spend time deciding how to split up the task, how to assign subtasks to each other, and in what order subtasks should be completed. Informed by an observational study examining group coordination challenges, we built a task distribution system called WeBuild. Our custom algorithm dynamically assigns subtasks to workers in a group, taking into account factors such as the dependencies between subtasks and the skills of each group member. Each worker views personalized step-by-step instructions on a mobile phone, while a dashboard visualizes the entire process. An initial study found that WeBuild reduced the start-up time needed to coordinate and begin a task, and provides direction for future research to build on toward improving group efficiency and coordination for complex tasks.</p></div></span> <a id="expcoll197" href="JavaScript: expandcollapse('expcoll197',197)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025890&CFID=758305256&CFTOKEN=14863114">Pressure-Based Gain Factor Control for Mobile 3D Interaction using Locally-Coupled Devices</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Lonni Besan&#231;on, Mehdi Ammi, Tobias Isenberg 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1831-1842</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025890" title="DOI">10.1145/3025453.3025890</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025890&ftid=1870100&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow198" style="display:inline;"><br /><div style="display:inline">We present the design and evaluation of pressure-based interactive control of 3D navigation precision. Specifically, we examine the control of gain factors in tangible 3D interactions using locally-coupled mobile devices. By focusing on pressure as a ...</div></span>
          <span id="toHide198" style="display:none;"><br /><div style="display:inline"><p>We present the design and evaluation of pressure-based interactive control of 3D navigation precision. Specifically, we examine the control of gain factors in tangible 3D interactions using locally-coupled mobile devices. By focusing on pressure as a separate input channel we can adjust gain factors independently from other input modalities used in 3D navigation, in particular for the exploration of 3D visualisations. We present two experiments. First, we determined that people strongly preferred higher pressures to be mapped to higher gain factors. Using this mapping, we compared pressure with rate control, velocity control, and slider-based control in a second study. Our results show that pressure-based gain control allows people to be more precise in the same amount of time compared to established input modalities. Pressure-based control was also clearly preferred by our participants. In summary, we demonstrate that pressure facilitates effective and efficient precision control for mobile 3D navigation.</p></div></span> <a id="expcoll198" href="JavaScript: expandcollapse('expcoll198',198)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Crowd-powered Systems</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025464&CFID=758305256&CFTOKEN=14863114">The Effect of Peripheral Micro-tasks on Crowd Ideation</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Victor Girotto, Erin Walker, Winslow Burleson 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1843-1854</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025464" title="DOI">10.1145/3025453.3025464</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025464&ftid=1870071&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow200" style="display:inline;"><br /><div style="display:inline">Research has explored different ways of improving crowd ideation, such as presenting examples or employing facilitators. While such support is usually generated through peripheral tasks delegated to crowd workers who are not part of the ideation, it ...</div></span>
          <span id="toHide200" style="display:none;"><br /><div style="display:inline"><p>Research has explored different ways of improving crowd ideation, such as presenting examples or employing facilitators. While such support is usually generated through peripheral tasks delegated to crowd workers who are not part of the ideation, it is possible that the ideators themselves could benefit from the extra thought involved in doing them. Therefore, we iterate over an ideation system in which ideators can perform one of three peripheral tasks (rating originality and usefulness, similarity, or idea combination) on demand. In controlled experiments with workers on Mechanical Turk, we compare the effects of these secondary tasks to simple idea exposure or no support at all, examining usage of the inspirations, fluency, breadth, and depth of ideas generated. We find tasks to be as good or better than exposure, although this depends on the period of ideation and the fluency level. We also discuss implications of inspiration size, homogeneity, and frequency.</p></div></span> <a id="expcoll200" href="JavaScript: expandcollapse('expcoll200',200)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025640&CFID=758305256&CFTOKEN=14863114">Respeak: A Voice-based, Crowd-powered Speech Transcription System</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Aditya Vashistha, Pooja Sethi, Richard Anderson 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1855-1866</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025640" title="DOI">10.1145/3025453.3025640</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025640&ftid=1870089&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow201" style="display:inline;"><br /><div style="display:inline">Speech transcription is an expensive service with high turnaround time for audio files containing languages spoken in developing countries and regional accents of well-represented languages. We present Respeak - a voice-based, crowd-powered system ...</div></span>
          <span id="toHide201" style="display:none;"><br /><div style="display:inline"><p>Speech transcription is an expensive service with high turnaround time for audio files containing languages spoken in developing countries and regional accents of well-represented languages. We present <i>Respeak</i> - a voice-based, crowd-powered system that capitalizes on the strengths of crowdsourcing and automatic speech recognition (instead of typing) to transcribe such audio files. We created <i>Respeak</i> and optimized its design through a series of cognitive experiments. We deployed it with 25 university students in India who completed 5464 micro-transcription tasks, transcribing 55 minutes of widely-varied audio content, and collectively earning USD 46 as mobile airtime. The <i>Respeak</i> engine aligned the transcript generated by five randomly selected users to transcribe Hindi and Indian English audio files with a word error rate (WER) of 8.6% and 15.2%, respectively. The cost of speech transcription was USD 0.83 per minute with a turnaround time of 39.8 hours, substantially less than industry standards. Using a mixed-methods analysis of cognitive experiments, system performance and qualitative interviews, we evaluate <i>Respeak's</i> design, user experience, strengths, and weaknesses. Our findings suggest that <i>Respeak</i> improves the quality of speech transcription while enhancing the earning potential of low-income populations in resource-constrained settings.</p></div></span> <a id="expcoll201" href="JavaScript: expandcollapse('expcoll201',201)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025687&CFID=758305256&CFTOKEN=14863114">Subcontracting Microwork</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Meredith Ringel Morris, Jeffrey P. Bigham, Robin Brewer, Jonathan Bragg, Anand Kulkarni, Jessie Li, Saiph Savage 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1867-1876</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025687" title="DOI">10.1145/3025453.3025687</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025687&ftid=1870101&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow202" style="display:inline;"><br /><div style="display:inline">Mainstream crowdwork platforms treat microtasks as indivisible units; however, in this article, we propose that there is value in re-examining this assumption. We argue that crowdwork platforms can improve their value proposition for all stakeholders ...</div></span>
          <span id="toHide202" style="display:none;"><br /><div style="display:inline"><p>Mainstream crowdwork platforms treat microtasks as indivisible units; however, in this article, we propose that there is value in re-examining this assumption. We argue that crowdwork platforms can improve their value proposition for all stakeholders by supporting subcontracting within microtasks. After describing the value proposition of <i>subcontracting</i>, we then define three models for microtask subcontracting: <i>real-time assistance, task management</i>, and <i>task improvement</i>, and reflect on potential use cases and implementation considerations associated with each. Finally, we describe the outcome of two tasks on Mechanical Turk meant to simulate aspects of subcontracting. We reflect on the implications of these findings for the design of future crowd work platforms that effectively harness the potential of subcontracting workflows.</p></div></span> <a id="expcoll202" href="JavaScript: expandcollapse('expcoll202',202)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025930&CFID=758305256&CFTOKEN=14863114">Scalable Annotation of Fine-Grained Categories Without Experts</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Timnit Gebru, Jonathan Krause, Jia Deng, Li Fei-Fei 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1877-1881</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025930" title="DOI">10.1145/3025453.3025930</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025930&ftid=1870068&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow203" style="display:inline;"><br /><div style="display:inline">We present a crowdsourcing workflow to collect image annotations for visually similar synthetic categories without requiring experts. In animals, there is a direct link between taxonomy and visual similarity: e.g. a collie (type of dog) looks more similar ...</div></span>
          <span id="toHide203" style="display:none;"><br /><div style="display:inline"><p>We present a crowdsourcing workflow to collect image annotations for visually similar synthetic categories without requiring experts. In animals, there is a direct link between taxonomy and visual similarity: e.g. a collie (type of dog) looks more similar to other collies (e.g. smooth collie) than a greyhound (another type of dog). However, in synthetic categories such as cars, objects with similar taxonomy can have very different appearance: e.g. a 2011 Ford F-150 Supercrew-HD looks the same as a 2011 Ford F-150 Supercrew-LL but very different from a 2011 Ford F-150 Supercrew-SVT. We introduce a graph based crowdsourcing algorithm to automatically group visually indistinguishable objects together. Using our workflow, we label 712,430 images by ~1,000 Amazon Mechanical Turk workers; resulting in the largest fine-grained visual dataset reported to date with 2,657 categories of cars annotated at 1/20th the cost of hiring experts.</p></div></span> <a id="expcoll203" href="JavaScript: expandcollapse('expcoll203',203)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025553&CFID=758305256&CFTOKEN=14863114">The Effect of Performance Feedback on Social Media Sharing at Volunteer-Based Online Experiment Platforms</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Bernd Huber, Katharina Reinecke, Krzysztof Z. Gajos 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1882-1886</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025553" title="DOI">10.1145/3025453.3025553</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025553&ftid=1870056&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow204" style="display:inline;"><br /><div style="display:inline">As an alternative to online labor markets, several platforms recruit unpaid online volunteers to participate in behavioral experiments that provide personalized feedback. These platforms rely on word-of-mouth sharing by previous participants for recruitment ...</div></span>
          <span id="toHide204" style="display:none;"><br /><div style="display:inline"><p>As an alternative to online labor markets, several platforms recruit unpaid online volunteers to participate in behavioral experiments that provide personalized feedback. These platforms rely on word-of-mouth sharing by previous participants for recruitment of new participants. We analyzed the impact of performance feedback provided at the end of an experiment on 81,131 participants' sharing behavior. We show that higher performing participants share significantly more. We also show that self-verification has a moderating effect: people who expected to do poorly are not affected by a high score, but people who expected to do as well as others or better, are. In a second experiment, we evaluate three distinct social comparison designs for the presentation of the results. As expected, the design that most emphasized participants' relative success led to most sharing. Contrary to our expectations, people who expected to do poorly benefited from the most optimistic social comparison more than participants who expected to do better than others.</p></div></span> <a id="expcoll204" href="JavaScript: expandcollapse('expcoll204',204)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Gesture as Input</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025508&CFID=758305256&CFTOKEN=14863114">Toward Realistic Hands Gesture Interface: Keeping it Simple for Developers and Machines</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Eyal Krupka, Kfir Karmon, Noam Bloom, Daniel Freedman, Ilya Gurvich, Aviv Hurvitz, Ido Leichter, Yoni Smolin, Yuval Tzairi, Alon Vinnikov, Aharon Bar-Hillel 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1887-1898</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025508" title="DOI">10.1145/3025453.3025508</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025508&ftid=1870111&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow206" style="display:inline;"><br /><div style="display:inline">Development of a rich hand-gesture-based interface is currently a tedious process, requiring expertise in computer vision and/or machine learning. We address this problem by introducing a simple language for pose and gesture description, a set of development ...</div></span>
          <span id="toHide206" style="display:none;"><br /><div style="display:inline"><p>Development of a rich hand-gesture-based interface is currently a tedious process, requiring expertise in computer vision and/or machine learning. We address this problem by introducing a simple language for pose and gesture description, a set of development tools for using it, and an algorithmic pipeline that recognizes it with high accuracy. The language is based on a small set of basic propositions, obtained by applying four predicate types to the fingers and to palm center: direction, relative location, finger touching and finger folding state. This enables easy development of a gesture-based interface, using coding constructs, gesture definition files or an editing GUI. The language is recognized from 3D camera input with an algorithmic pipeline composed of multiple classification/regression stages, trained on a large annotated dataset. Our experimental results indicate that the pipeline enables successful gesture recognition with a very low computational load, thus enabling a gesture-based interface on low-end processors.</p></div></span> <a id="expcoll206" href="JavaScript: expandcollapse('expcoll206',206)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3026001&CFID=758305256&CFTOKEN=14863114">Memory in Motion: The Influence of Gesture- and Touch-Based Input Modalities on Spatial Memory</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Johannes Zagermann, Ulrike Pfeil, Daniel Fink, Philipp von Bauer, Harald Reiterer 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1899-1910</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3026001" title="DOI">10.1145/3025453.3026001</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3026001&ftid=1870093&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow207" style="display:inline;"><br /><div style="display:inline">People's ability to remember and recall spatial information can be harnessed to improve navigation and search performances in interactive systems. In this paper, we investigate how display size and input modality influence spatial memory, especially ...</div></span>
          <span id="toHide207" style="display:none;"><br /><div style="display:inline"><p>People's ability to remember and recall spatial information can be harnessed to improve navigation and search performances in interactive systems. In this paper, we investigate how display size and input modality influence spatial memory, especially in relation to efficiency and user satisfaction. Based on an experiment with 28 participants, we analyze the effect of three input modalities (trackpad, direct touch, and gesture-based motion controller) and two display sizes (10.6" and 55") on people's ability to navigate to spatially spread items and recall their positions. Our findings show that the impact of input modality and display size on spatial memory is not straightforward, but characterized by trade-offs between spatial memory, efficiency, and user satisfaction.</p></div></span> <a id="expcoll207" href="JavaScript: expandcollapse('expcoll207',207)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025692&CFID=758305256&CFTOKEN=14863114"><i>EarFieldSensing</i>: A Novel In-Ear Electric Field Sensing to Enrich Wearable Gesture Input through Facial Expressions</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Denys J. C. Matthies, Bernhard A. Strecker, Bodo Urban 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1911-1922</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025692" title="DOI">10.1145/3025453.3025692</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025692&ftid=1870084&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow208" style="display:inline;"><br /><div style="display:inline">EarFieldSensing (EarFS) is a novel input method for mobile and wearable computing using facial expressions. Facial muscle movements induce both electric field changes and physical deformations, which are detectable with electrodes placed inside ...</div></span>
          <span id="toHide208" style="display:none;"><br /><div style="display:inline"><p><i>EarFieldSensing (EarFS)</i> is a novel input method for mobile and wearable computing using facial expressions. Facial muscle movements induce both electric field changes and physical deformations, which are detectable with electrodes placed inside the ear canal. The chosen ear-plug form factor is rather unobtrusive and allows for facial gesture recognition while utilizing the close proximity to the face. We collected 25 facial-related gestures and used them to compare the performance levels of several electric sensing technologies (EMG, CS, EFS, <i>EarFS</i>) with varying electrode setups. Our developed wearable fine-tuned electric field sensing employs differential amplification to effectively cancel out environmental noise while still being sensitive towards small facial-movement-related electric field changes and artifacts from ear canal deformations. By comparing a mobile with a stationary scenario, we found that <i>EarFS</i> continues to perform better in a mobile scenario. Quantitative results show <i>EarFS</i> to be capable of detecting a set of 5 facial gestures with a precision of 90% while sitting and 85.2% while walking. We provide detailed instructions to enable replication of our low-cost sensing device. Applying it to different positions of our body will also allow to sense a variety of other gestures and activities.</p></div></span> <a id="expcoll208" href="JavaScript: expandcollapse('expcoll208',208)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025807&CFID=758305256&CFTOKEN=14863114">EchoFlex: Hand Gesture Recognition using Ultrasound Imaging</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Jess McIntosh, Asier Marzo, Mike Fraser, Carol Phillips 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1923-1934</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025807" title="DOI">10.1145/3025453.3025807</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025807&ftid=1870087&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow209" style="display:inline;"><br /><div style="display:inline">Recent improvements in ultrasound imaging enable new opportunities for hand pose detection using wearable devices. Ultrasound imaging has remained under-explored in the HCI community despite being non-invasive, harmless and capable of imaging internal ...</div></span>
          <span id="toHide209" style="display:none;"><br /><div style="display:inline"><p>Recent improvements in ultrasound imaging enable new opportunities for hand pose detection using wearable devices. Ultrasound imaging has remained under-explored in the HCI community despite being non-invasive, harmless and capable of imaging internal body parts, with applications including smart-watch interaction, prosthesis control and instrument tuition. In this paper, we compare the performance of different forearm mounting positions for a wearable ultrasonographic device. Location plays a fundamental role in ergonomics and performance since the anatomical features differ among positions. We also investigate the performance decrease due to cross-session position shifts and develop a technique to compensate for this misalignment. Our gesture recognition algorithm combines image processing and neural networks to classify the flexion and extension of 10 discrete hand gestures with an accuracy above 98%. Furthermore, this approach can continuously track individual digit flexion with less than 5% NRMSE, and also differentiate between digit flexion at different joints.</p></div></span> <a id="expcoll209" href="JavaScript: expandcollapse('expcoll209',209)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Human Performance Gaming</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3026053&CFID=758305256&CFTOKEN=14863114">Virtuosos on the Screen: Playing Virtual Characters Like Instruments in Competitive Super Smash Bros. Melee</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Colin M. Ford 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1935-1948</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3026053" title="DOI">10.1145/3025453.3026053</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3026053&ftid=1870075&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow211" style="display:inline;"><br /><div style="display:inline">Previous research on virtual sociality in games suggests that players use custom avatars to reflect, alter, and perform new identities in digital spaces. However, this study explores an alternative theory of social performance by analyzing a competitive ...</div></span>
          <span id="toHide211" style="display:none;"><br /><div style="display:inline"><p>Previous research on virtual sociality in games suggests that players use custom avatars to reflect, alter, and perform new identities in digital spaces. However, this study explores an alternative theory of social performance by analyzing a competitive game, Super Smash Bros. Melee, where players face off in timed matches and interact through pre-designed characters. This study shows how Melee players treat virtual characters as performative instruments, similar to the violin or the piano. In forum posts and player-created media, Melee players emphasize the need to train one's hands, eyes, and mind in order to master a character's complexity and express style and skills in live matches. Instrumental embodiment in a competitive game like Melee thus positions players as virtuosos who perform for perceptive audiences. This research points to a range of ways that players may relate to virtual bodies, connected to distinct kinds of social activities.</p></div></span> <a id="expcoll211" href="JavaScript: expandcollapse('expcoll211',211)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025826&CFID=758305256&CFTOKEN=14863114">Designing Leaderboards for Gamification: Perceived Differences Based on User Ranking, Application Domain, and Personality Traits</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Yuan Jia, Yikun Liu, Xing Yu, Stephen Voida 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1949-1960</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025826" title="DOI">10.1145/3025453.3025826</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025826&ftid=1870083&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow212" style="display:inline;"><br /><div style="display:inline">Leaderboards, a common gamification technique, are used to enhance engagement through social comparisons. Prior research has demonstrated the overall utility of leaderboards but has not examined their effectiveness when individuals are ranked at particular ...</div></span>
          <span id="toHide212" style="display:none;"><br /><div style="display:inline"><p>Leaderboards, a common gamification technique, are used to enhance engagement through social comparisons. Prior research has demonstrated the overall utility of leaderboards but has not examined their effectiveness when individuals are ranked at particular levels or when the technique is applied in different application domains, such as social networking, fitness, or productivity. In this paper, we present a survey study investigating how preferences for leaderboards change based on individual differences (personality traits), ranking, social scoping, and application domains. Our results show that a respondent's position on the leaderboard had important effects on their perception of the leaderboard and the surrounding app, and that participants rated leaderboards most favorably in fitness apps and least favorably in social networking contexts. More extraverted people reported more positive experiences with leaderboards despite their ranking or the application domain. We present design implications for creating leaderboards targeted at different domains and for different audiences.</p></div></span> <a id="expcoll212" href="JavaScript: expandcollapse('expcoll212',212)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025678&CFID=758305256&CFTOKEN=14863114">Inferring Motion Direction using Commodity Wi-Fi for Interactive Exergames</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Kun Qian, Chenshu Wu, Zimu Zhou, Yue Zheng, Zheng Yang, Yunhao Liu 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1961-1972</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025678" title="DOI">10.1145/3025453.3025678</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025678&ftid=1870077&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow213" style="display:inline;"><br /><div style="display:inline">In-air interaction acts as a key enabler for ambient intelligence and augmented reality. As an increasing popular example, exergames, and the alike gesture recognition applications, have attracted extensive research in designing accurate, pervasive and ...</div></span>
          <span id="toHide213" style="display:none;"><br /><div style="display:inline"><p>In-air interaction acts as a key enabler for ambient intelligence and augmented reality. As an increasing popular example, exergames, and the alike gesture recognition applications, have attracted extensive research in designing accurate, pervasive and low-cost user interfaces. Recent advances in wireless sensing show promise for a ubiquitous gesture-based interaction interface with Wi-Fi. In this work, we extract complete information of motion-induced Doppler shifts with only commodity Wi-Fi. The key insight is to harness antenna diversity to carefully eliminate random phase shifts while retaining relevant Doppler shifts. We further correlate Doppler shifts with motion directions, and propose a light-weight pipeline to detect, segment, and recognize motions without training. On this basis, we present <i>WiDance</i>, a Wi-Fi-based user interface, which we utilize to design and prototype a contactless dance-pad exergame. Experimental results in typical indoor environment demonstrate a superior performance with an accuracy of 92%, remarkably outperforming prior approaches.</p></div></span> <a id="expcoll213" href="JavaScript: expandcollapse('expcoll213',213)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025934&CFID=758305256&CFTOKEN=14863114">Be Me or Be Mii?: A Study of Self-Presentation and Interaction in the Miitomo Mobile Application</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Anna Kasunic, Geoff Kaufman 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1973-1977</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025934" title="DOI">10.1145/3025453.3025934</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025934&ftid=1870096&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow214" style="display:inline;"><br /><div style="display:inline">In this study, we consider what Nintendo's widely downloaded Miitomo mobile application, which simultaneously promotes non-idealized self-fictionalization and authentic self-presentation, can suggest to us about self-presentation and technology design. ...</div></span>
          <span id="toHide214" style="display:none;"><br /><div style="display:inline"><p>In this study, we consider what Nintendo's widely downloaded Miitomo mobile application, which simultaneously promotes non-idealized self-fictionalization and authentic self-presentation, can suggest to us about self-presentation and technology design. Ten groups of four friends each (N=40), all novice users, engaged with Miitomo for one week, and completed supplementary pre- and post-use surveys. The data were analyzed to assess the extent to which participants' engagement in Miitomo reflected their "real life" selves and correlated with in-app and "real life" features, respectively. Although most participants believed that their behaviors within the app accurately reflected their "true selves," we found that in-app traits generally correlated more strongly with Miitomo engagement patterns than did users' "real life" traits and qualities. We discuss implications for social network and online community design, and propose future plans to study authenticity and self-distancing in online self-presentation.</p></div></span> <a id="expcoll214" href="JavaScript: expandcollapse('expcoll214',214)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025967&CFID=758305256&CFTOKEN=14863114">Why Players use Pings and Annotations in Dota 2</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Jason Wuertz, Scott Bateman, Anthony Tang 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 1978-2018</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025967" title="DOI">10.1145/3025453.3025967</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025967&ftid=1870078&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow215" style="display:inline;"><br /><div style="display:inline">Groupware research has long focused on representing gestures as a means to facilitate collaboration. However, this work has not led to wide support of gesturing in commercial groupware systems. In contrast, Dota 2, a popular MOBA game, provides two frequently-used ...</div></span>
          <span id="toHide215" style="display:none;"><br /><div style="display:inline"><p>Groupware research has long focused on representing gestures as a means to facilitate collaboration. However, this work has not led to wide support of gesturing in commercial groupware systems. In contrast, Dota 2, a popular MOBA game, provides two frequently-used gesturing tools: annotations - freely drawn lines on top of the gamespace - and pings - a combination of animation and sound indicating a point of interest. While gesturing tools are important for quickly coordinating with teammates in Dota 2, there is little information about how and why people use them. To gather this information, we performed two complementary studies: an interaction analysis of eight game replays, and a survey of 167 experienced players. Our findings include: six distinct motivations for the use of gesturing tools; when and how frequently gesture motivations occur during games; and, that players find pings an essential tool for winning, but not annotations. Our findings provide new directions for the design of gesturing tools in groupware and online games.</p></div></span> <a id="expcoll215" href="JavaScript: expandcollapse('expcoll215',215)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Interdisciplinary Techniques</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025862&CFID=758305256&CFTOKEN=14863114">Unpacking Visible Light Communication as a Material for Design</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Charles Windlin, Jarmo Laaksolahti 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2019-2023</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025862" title="DOI">10.1145/3025453.3025862</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025862&ftid=1870194&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow217" style="display:inline;"><br /><div style="display:inline">Communication through visible light (VLC) is gaining ground as an alternative to traditional radio communication in many settings. Effectively using VLC in creative design processes may however be difficult as the material properties of VLC can be hard ...</div></span>
          <span id="toHide217" style="display:none;"><br /><div style="display:inline"><p>Communication through visible light (VLC) is gaining ground as an alternative to traditional radio communication in many settings. Effectively using VLC in creative design processes may however be difficult as the material properties of VLC can be hard to grasp and therefore to use. This paper presents a design exploration where a set of artifacts was created to enable designers to play around with VLC and better understand its properties and their potential use for design. Each artifact was designed to illustrate a particular property of light communication ranging from inner workings of transmission protocols to properties of light in itself. The set was used in two small scale workshops where users played around with the artifacts and afterward were interviewed about their experiences. Interviews and observations from the workshops suggest that users gained insights into the material properties of light communication and were also inspired to think of creative uses for VLC based on those insights</p></div></span> <a id="expcoll217" href="JavaScript: expandcollapse('expcoll217',217)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025504&CFID=758305256&CFTOKEN=14863114">Tobiko: A Contact Array for Self-Configuring, Surface-Powered Sensors</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          C. K. Harnett 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2024-2028</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025504" title="DOI">10.1145/3025453.3025504</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025504&ftid=1870183&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow218" style="display:inline;"><br /><div style="display:inline">This paper describes a contact array that outputs the maximum and minimum voltages at its contacts. The goal is to extract power for a detachable touch sensor, display, or other human-computer interaction (HCI) device that is attached to a surface by ...</div></span>
          <span id="toHide218" style="display:none;"><br /><div style="display:inline"><p>This paper describes a contact array that outputs the maximum and minimum voltages at its contacts. The goal is to extract power for a detachable touch sensor, display, or other human-computer interaction (HCI) device that is attached to a surface by a user, and that does not have its own power source. Experimental results are shown for an array that has positive and negative outputs and a pass-through at each contact position. It solves the startup problem for a randomly-placed batteryless sensor patch or sticker, which can scan its ports to discover neighboring devices only after it obtains power. Applications include user-configurable electronic textile circuits, and new methods for prototyping and repairing large-area flexible circuits. This note describes construction of a 7x7 array, provides design rules, and examines the signal quality on two kinds of electronic surfaces.</p></div></span> <a id="expcoll218" href="JavaScript: expandcollapse('expcoll218',218)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025987&CFID=758305256&CFTOKEN=14863114">Live Physiological Sensing and Visualization Ecosystems: An Activity Theory Analysis</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Tamara Clegg, Leyla Norooz, Seokbin Kang, Virginia Byrne, Monica Katzen, Rafael Valez, Angelisa Plane, Vanessa Oguamanam, Thomas Outing, Jason Yip, Elizabeth Bonsignore, Jon Froehlich 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2029-2041</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025987" title="DOI">10.1145/3025453.3025987</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025987&ftid=1870199&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow219" style="display:inline;"><br /><div style="display:inline">Wearable sensing poses new opportunities to enhance personal connections to learning and authentic scientific inquiry experiences. In our work, we leverage the body and physical action as an engaging platform for learning through live physiological sensing ...</div></span>
          <span id="toHide219" style="display:none;"><br /><div style="display:inline"><p>Wearable sensing poses new opportunities to enhance personal connections to learning and authentic scientific inquiry experiences. In our work, we leverage the body and physical action as an engaging platform for learning through live physiological sensing and visualization (LPSV). Prior research suggests the potential of this approach, but was limited to single-session evaluations in informal environments. In this paper, we examine LPSV tools in a classroom environment during a four-day deployment. To highlight the complex interconnections between space, teachers, curriculum, and tool use, we analyze our data through the lens of Activity Theory. Our findings show the importance of integrating model-based representations for supporting exploration and analytic representations for scaffolding scientific inquiry. Activity Theory highlights leveraging life-relevant connections available within a physical space and considering policies and norms related to learners' physical bodies.</p></div></span> <a id="expcoll219" href="JavaScript: expandcollapse('expcoll219',219)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025983&CFID=758305256&CFTOKEN=14863114">Thin Grey Lines: Confrontations With Risk on Colorado's Front Range</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Robert Soden, Leah Sprain, Leysia Palen 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2042-2053</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025983" title="DOI">10.1145/3025453.3025983</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025983&ftid=1870196&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow220" style="display:inline;"><br /><div style="display:inline">This paper reports on two years of ethnographic observation of the science and politics of flood risk in Colorado, as well as design research that examines citizen interaction with expert knowledge about flooding in the region. We argue that the 100-year ...</div></span>
          <span id="toHide220" style="display:none;"><br /><div style="display:inline"><p>This paper reports on two years of ethnographic observation of the science and politics of flood risk in Colorado, as well as design research that examines citizen interaction with expert knowledge about flooding in the region. We argue that the 100-year floodplain standard that inform maps produced by the USA Federal Emergency Management Agency (FEMA)'s National Floodplain Insurance Program (NFIP) represent a problematic form of discursive closure of scientific understanding of flood hazard. We show that in order to meet the requirements of the NFIP, this standard acts as a closure that conveys a certainty that the underlying science does not warrant and foreshortens dialogue on disaster risk and public understanding of flood hazard. Engaging with literature in science and technology studies and human-centered computing, we investigate design opportunities for resisting closure and supporting public formation through encounters with the uncertainty and complexities of risk information.</p></div></span> <a id="expcoll220" href="JavaScript: expandcollapse('expcoll220',220)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025893&CFID=758305256&CFTOKEN=14863114">Deconstructing Cosmetic Virtual Goods Experiences in Dota 2</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Ilya Musabirov, Denis Bulygin, Paul Okopny, Alexander Sirotkin 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2054-2058</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025893" title="DOI">10.1145/3025453.3025893</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025893&ftid=1870186&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow221" style="display:inline;"><br /><div style="display:inline">Cosmetic items do not provide functional advantages in games, but, nevertheless, they play an important role in the overall player experience. Possessing predominantly socially-constructed dimensions of value, cosmetic items are chosen, discussed, assessed, ...</div></span>
          <span id="toHide221" style="display:none;"><br /><div style="display:inline"><p>Cosmetic items do not provide functional advantages in games, but, nevertheless, they play an important role in the overall player experience. Possessing predominantly socially-constructed dimensions of value, cosmetic items are chosen, discussed, assessed, and valuated in an ongoing iterative collaborative process by communities of players. In our study, we explore the case of Dota 2 and apply Topic Modeling to community-discussions data gathered from Reddit.com. We describe social experiences related to the valuation of cosmetic items in interaction and collision of various logics, including artificial scarcity, decomposition of visual effects, and connectedness to the game lore. Our findings connect the collective experience of players in the game and on online community platforms, suggesting that non-utility-based social value construction becomes an important part of game experience.</p></div></span> <a id="expcoll221" href="JavaScript: expandcollapse('expcoll221',221)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025944&CFID=758305256&CFTOKEN=14863114">Shift+Tap or Tap+LongPress?: The Upper Bound of Typing Speed on InScript</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Sanjay Ghosh, Anirudha Joshi, Manjiri Joshi, Nagraj Emmadi, Girish Dalvi, Shashank Ahire, Swati Rangale 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2059-2063</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025944" title="DOI">10.1145/3025453.3025944</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025944&ftid=1870185&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow222" style="display:inline;"><br /><div style="display:inline">This paper presents the results of a within-subject longitudinal evaluation on Inscript keyboard, which is the national standard layout for Indian scripts. We studied the practical upper bound speed and accuracy as well as the effect of practice. Through ...</div></span>
          <span id="toHide222" style="display:none;"><br /><div style="display:inline"><p>This paper presents the results of a within-subject longitudinal evaluation on Inscript keyboard, which is the national standard layout for Indian scripts. We studied the practical upper bound speed and accuracy as well as the effect of practice. Through longitudinal transcription task of 400 repeated attempts, we observed typing speeds for highly experienced users consistently peak close to 120 cpm i.e. 2.5 times that of fastest speeds reported in literature. Our analysis compared the lower bound times for Tap, Tap+LongPress and Shift+Tap, the three text input mechanisms in this keyboard. Among the two alternative methods, our findings established Tap+LongPress method to be faster than Shift+Tap method and almost equally accurate. Also, we derived a model which explains the influence of corrected errors and number of practice attempts on the typing speed.</p></div></span> <a id="expcoll222" href="JavaScript: expandcollapse('expcoll222',222)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>It Could Be This Way</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025658&CFID=758305256&CFTOKEN=14863114">Evaluation of Prototypes and the Problem of Possible Futures</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Antti Salovaara, Antti Oulasvirta, Giulio Jacucci 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2064-2077</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025658" title="DOI">10.1145/3025453.3025658</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025658&ftid=1870204&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow224" style="display:inline;"><br /><div style="display:inline">There is a blind spot in HCI's evaluation methodology: we rarely consider the implications of the fact that a prototype can never be fully evaluated in a study. A prototype under study exists firmly in the present world, in the circumstances created ...</div></span>
          <span id="toHide224" style="display:none;"><br /><div style="display:inline"><p>There is a blind spot in HCI's evaluation methodology: we rarely consider the implications of the fact that a prototype can never be fully evaluated in a study. A prototype under study exists firmly in the present world, in the circumstances created in the study, but its real context of use is a partially unknown future state of affairs. This present-future gap is implicit in any evaluation of prototypes, be they usability tests, controlled experiments, or field trials. A carelessly designed evaluation may inadvertently evaluate the wrong futures, contexts, or user groups, thereby leading to false conclusions and expensive design failures. The essay analyses evaluation methodology from this perspective, illuminating how to mitigate the present-future gap.</p></div></span> <a id="expcoll224" href="JavaScript: expandcollapse('expcoll224',224)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025696&CFID=758305256&CFTOKEN=14863114">Situated Dissemination through an HCI Workplace</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Ko-Le Chen, Rachel Clarke, Teresa Almeida, Matthew Wood, David S. Kirk 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2078-2090</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025696" title="DOI">10.1145/3025453.3025696</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025696&ftid=1870223&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow225" style="display:inline;"><br /><div style="display:inline">Researchers working in domains such as Research through Design and Feminist HCI have been questioning "dissemination practices" and their impact on our capacity to produce reflexive accounts of research in publications. This paper examines academic dissemination ...</div></span>
          <span id="toHide225" style="display:none;"><br /><div style="display:inline"><p>Researchers working in domains such as Research through Design and Feminist HCI have been questioning "dissemination practices" and their impact on our capacity to produce reflexive accounts of research in publications. This paper examines academic dissemination practices within HCI research communities from an institutional to individual level. We unpack the practice via a meta-review of recent literature published in CHI and other venues on 'What is HCI?'. We review the core text on this debate and other similar discussions on HCI methodologies and reflexive accounts of research in domains such as 'Research through Design' and 'Feminist HCI'. We highlight the importance of practicing reflexivity through dissemination and introduce 'Research Fictions' in the form of video essays and live performances, produced by the first author with her colleagues, based on their HCI submissions. Through experimenting with alternative dissemination formats, we argue that our exploratory processes engender a practice of reflexivity within a research lab.</p></div></span> <a id="expcoll225" href="JavaScript: expandcollapse('expcoll225',225)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3026022&CFID=758305256&CFTOKEN=14863114">A Survey of the Trajectories Conceptual Framework: Investigating Theory Use in HCI</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Raphael Velt, Steve Benford, Stuart Reeves 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2091-2105</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3026022" title="DOI">10.1145/3025453.3026022</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3026022&ftid=1870216&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow226" style="display:inline;"><br /><div style="display:inline">We present a case study of how Human-Computer Interaction (HCI) theory is reused within the field. We analyze the HCI literature in order to reveal the impact of one particular theory, the trajectories framework that has been cited as an example of both ...</div></span>
          <span id="toHide226" style="display:none;"><br /><div style="display:inline"><p>We present a case study of how Human-Computer Interaction (HCI) theory is reused within the field. We analyze the HCI literature in order to reveal the impact of one particular theory, the trajectories framework that has been cited as an example of both contemporary HCI theory and a strong concept that sits between theory and design practice. Our analysis of 60 papers that seriously engaged with trajectories reveals the purposes that the framework served and which parts of it they used. We compare our findings to the originally stated goals of trajectories and to subsequent claims of its status as both theory and strong concept. The results shed new light on what we mean by theory in HCI, including its relationship to practice and to other disciplines.</p></div></span> <a id="expcoll226" href="JavaScript: expandcollapse('expcoll226',226)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025498&CFID=758305256&CFTOKEN=14863114">ProtoMold: An Interactive Vacuum Forming System for Rapid Prototyping</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Junichi Yamaoka, Yasuaki Kakehi 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2106-2115</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025498" title="DOI">10.1145/3025453.3025498</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025498&ftid=1870224&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow227" style="display:inline;"><br /><div style="display:inline">In this paper, we propose a novel fabrication machine called ProtoMold, which uses interactive vacuum forming system for rapid prototyping. ProtoMold combines a dynamical shape-changing surface that consists of 12 &#215; 8 linear actuators and a vacuum ...</div></span>
          <span id="toHide227" style="display:none;"><br /><div style="display:inline"><p>In this paper, we propose a novel fabrication machine called ProtoMold, which uses interactive vacuum forming system for rapid prototyping. ProtoMold combines a dynamical shape-changing surface that consists of 12 &#215; 8 linear actuators and a vacuum forming system. According to the shape of the surface, this system can mold various 2.5 dimensional objects quickly. Another characteristic of this system is that users can reuse molded objects and change their design; by applying tension and heat to a molded object, the object becomes flat and can be molded again. We also designed user several interaction methods for manipulating ProtoMold. In addition to loading predesigned data, the user can control the shape of the pin display directly using gesture input or physical objects.</p> <p>We propose several use scenarios for ProtoMold: changing the design of a plate based on objects placed on it, fabricating a facemask with a printed texture, and fabricating electrical devices with printed electronic circuits. By using this system, we conducted a user test and discuss the known limitations and potential applications of our system.</p></div></span> <a id="expcoll227" href="JavaScript: expandcollapse('expcoll227',227)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Methods and Theories</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025937&CFID=758305256&CFTOKEN=14863114">Extracting Gait Velocity and Stride Length from Surrounding Radio Signals</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Chen-Yu Hsu, Yuchen Liu, Zachary Kabelac, Rumen Hristov, Dina Katabi, Christine Liu 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2116-2126</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025937" title="DOI">10.1145/3025453.3025937</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025937&ftid=1870210&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow229" style="display:inline;"><br /><div style="display:inline">Gait velocity and stride length are critical health indicators for older adults. A decade of medical research shows that they provide a predictor of future falls, hospitalization, and functional decline among seniors. However, currently these metrics ...</div></span>
          <span id="toHide229" style="display:none;"><br /><div style="display:inline"><p>Gait velocity and stride length are critical health indicators for older adults. A decade of medical research shows that they provide a predictor of future falls, hospitalization, and functional decline among seniors. However, currently these metrics are measured only occasionally during medical visits. Such infrequent measurements hamper the opportunity to detect changes and intervene early in the impairment process.</p> <p>In this paper, we develop a sensor that uses radio signals to continuously measure gait velocity and stride length at home. Our sensor hangs on a wall like a picture frame. It does not require the monitored person to wear or carry a device on her body. Our approach builds on recent advances in wireless systems which have shown that one can locate people based on how their bodies impact the surrounding radio signals. We demonstrate the accuracy of our method by comparing it to the gold standard in clinical tests, and the VICON motion tracking system. Our experience from deploying the sensor in 14 homes indicates comfort with the technology and a high acceptance rate.</p></div></span> <a id="expcoll229" href="JavaScript: expandcollapse('expcoll229',229)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3026003&CFID=758305256&CFTOKEN=14863114">Personas and Behavioral Theories: A Case Study Using Self-Determination Theory to Construct Overweight Personas</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Arne Jansen, Maarten Van Mechelen, Karin Slegers 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2127-2136</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3026003" title="DOI">10.1145/3025453.3026003</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3026003&ftid=1870239&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow230" style="display:inline;"><br /><div style="display:inline">Personas are a widely used tool to keep real users in mind, while avoiding stereotypical thinking in the design process. Yet, creating personas can be challenging. Starting from Cooper's approach for constructing personas, this paper details how behavioral ...</div></span>
          <span id="toHide230" style="display:none;"><br /><div style="display:inline"><p>Personas are a widely used tool to keep real users in mind, while avoiding stereotypical thinking in the design process. Yet, creating personas can be challenging. Starting from Cooper's approach for constructing personas, this paper details how behavioral theory can contribute substantially to the development of personas. We describe a case study in which Self-Determination Theory (SDT) is used to develop five distinctive personas for the design of a digital coach for sustainable weight loss. We show how behavioral theories such as SDT can help to understand what genuinely drives and motivates users to sustainably change their behavior. In our study, we used SDT to prepare and analyze interviews with envisioned users of the coach and to create complex, yet engaging and highly realistic personas that make users' basic psychological needs explicit. The paper ends with a critical reflection on the use of behavioral theories to create personas, discussing both challenges and strengths.</p></div></span> <a id="expcoll230" href="JavaScript: expandcollapse('expcoll230',230)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Perspectives on Cognitive Impairment</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025904&CFID=758305256&CFTOKEN=14863114">Designing for the "Universe of One": Personalized Interactive Media Systems for People with the Severe Cognitive Impairment Associated with Rett Syndrome</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Anthony Hornof, Haley Whitman, Marah Sutherland, Samuel Gerendasy, Joanna McGrenere 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2137-2148</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025904" title="DOI">10.1145/3025453.3025904</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025904&ftid=1870188&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow232" style="display:inline;"><br /><div style="display:inline">The needs and capabilities of a person with severe disabilities are often so specific that designing for the person is like designing for a "universe of one." This project addresses this problem for women with Rett syndrome, a disorder accompanied by ...</div></span>
          <span id="toHide232" style="display:none;"><br /><div style="display:inline"><p>The needs and capabilities of a person with severe disabilities are often so specific that designing for the person is like designing for a "universe of one." This project addresses this problem for women with Rett syndrome, a disorder accompanied by severe cognitive, communication, and motor impairment. The research team adapted participatory design techniques to work with five such women, and their families, to design and evaluate new assistive technology for these women. The process suggests a class of media-playing devices that would be generally useful to women with Rett syndrome: systems that can load multiple audio or video segments; be activated by many different switches; and respond instantly to switch-hits. As well, the systems should permit a caregiver to set the start and end time of each segment, and how the system advances through a sequence of segments. The paper also discusses patterns that were observed when collaborating with the families. For example, parents shared longstanding but untried ideas for new assistive technology; and expressed a strong interest in any device that would help their daughters do things for themselves.</p></div></span> <a id="expcoll232" href="JavaScript: expandcollapse('expcoll232',232)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025586&CFID=758305256&CFTOKEN=14863114">Supporting People with Dementia in Digital Social Sharing</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Amanda Lazar, Caroline Edasis, Anne Marie Piper 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2149-2162</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025586" title="DOI">10.1145/3025453.3025586</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025586&ftid=1870229&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow233" style="display:inline;"><br /><div style="display:inline">Sharing online is an important way in which people across the lifespan express themselves, maintain relationships, and connect with others. Yet, people with dementia are often not supported in engaging to the full extent of their abilities, particularly ...</div></span>
          <span id="toHide233" style="display:none;"><br /><div style="display:inline"><p>Sharing online is an important way in which people across the lifespan express themselves, maintain relationships, and connect with others. Yet, people with dementia are often not supported in engaging to the full extent of their abilities, particularly in their interaction with online technology. This paper presents a design case study that examines what it means to <i>design for agency</i> in online sharing involving individuals with dementia. Our work is situated in the context of art therapy for adults with dementia. We present the design and exploration of Moments, a system that allows individuals to share through artwork by manipulating their physical environment. We discuss how designing for agency calls attention to the ways in which the material workspace, including the tools we introduce, and the surrounding social context participate in the creation of agency.</p></div></span> <a id="expcoll233" href="JavaScript: expandcollapse('expcoll233',233)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025732&CFID=758305256&CFTOKEN=14863114">Care and Connect: Exploring Dementia-Friendliness Through an Online Community Commissioning Platform</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Kellie Morrissey, Andrew Garbett, Peter Wright, Patrick Olivier, Edward Ian Jenkins, Katie Brittain 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2163-2174</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025732" title="DOI">10.1145/3025453.3025732</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025732&ftid=1870217&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow234" style="display:inline;"><br /><div style="display:inline">In this paper, we present "Care and Connect", a mobile application created through the App Movement platform that aims to identify and rate public places (e.g., parks, shops, cafes) on their 'dementia-friendliness' - their suitability for people with ...</div></span>
          <span id="toHide234" style="display:none;"><br /><div style="display:inline"><p>In this paper, we present "Care and Connect", a mobile application created through the App Movement platform that aims to identify and rate public places (e.g., parks, shops, cafes) on their 'dementia-friendliness' - their suitability for people with dementia and their carers. Care and Connect saw significant support in its early stages on the online platform, yet failed to engage participants in its design phase and deployment. To unpick this, we contribute an account of its initial use in the community, and then describe findings from research engagements with carers and people with dementia. These workshops used Care and Connect to structure discussions of participants' own experiences of dementia-friendliness, and uncovered themes of 1) trust, 2) exclusion versus inclusion, 3) duration and quality of time, and 4) empathy becoming action. Using this evidence, we advance an account of online community commissioning as a process which needs to understand not only the general issues ongoing in communities facing significant life challenges, but also the particularity of community members' experiences.</p></div></span> <a id="expcoll234" href="JavaScript: expandcollapse('expcoll234',234)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/bp_award.jpg" alt="Best Paper" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025522&CFID=758305256&CFTOKEN=14863114">A Critical Lens on Dementia and Design in HCI</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Amanda Lazar, Caroline Edasis, Anne Marie Piper 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2175-2188</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025522" title="DOI">10.1145/3025453.3025522</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025522&ftid=1870179&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow235" style="display:inline;"><br /><div style="display:inline">Designing new technologies with and for individuals with dementia is a growing topic of interest within HCI. Yet, predominant societal views contribute to the positioning of individuals with dementia as deficient and declining, and treat technology as ...</div></span>
          <span id="toHide235" style="display:none;"><br /><div style="display:inline"><p>Designing new technologies with and for individuals with dementia is a growing topic of interest within HCI. Yet, predominant societal views contribute to the positioning of individuals with dementia as deficient and declining, and treat technology as filling a gap left by impairment. We present the perspective of <i>critical dementia</i> as a way of reflecting on these views in the context of recent epistemological shifts in HCI. In addition to articulating how HCI can leverage the perspective of critical dementia, we present a case analysis of technology design in art therapy involving people with dementia aimed at challenging conventional narratives. This paper calls attention to and helps solidify an agenda for how the CHI community approaches dementia, design, and technology.</p></div></span> <a id="expcoll235" href="JavaScript: expandcollapse('expcoll235',235)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Precautionary Behaviors</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
  
                  <img src="images/bp_award.jpg" alt="Best Paper" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025875&CFID=758305256&CFTOKEN=14863114">Stories from Survivors: Privacy &#38; Security Practices when Coping with Intimate Partner Abuse</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Tara Matthews, Kathleen O'Leary, Anna Turner, Manya Sleeper, Jill Palzkill Woelfer, Martin Shelton, Cori Manthorne, Elizabeth F. Churchill, Sunny Consolvo 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2189-2201</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025875" title="DOI">10.1145/3025453.3025875</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025875&ftid=1870181&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow237" style="display:inline;"><br /><div style="display:inline">We present a qualitative study of the digital privacy and security motivations, practices, and challenges of survivors of intimate partner abuse (IPA). This paper provides a framework for organizing survivors' technology practices and challenges into ...</div></span>
          <span id="toHide237" style="display:none;"><br /><div style="display:inline"><p>We present a qualitative study of the digital privacy and security motivations, practices, and challenges of survivors of intimate partner abuse (IPA). This paper provides a framework for organizing survivors' technology practices and challenges into three phases: physical control, escape, and life apart. This three-phase framework combines technology practices with three phases of abuse to provide an empirically sound method for technology creators to consider how survivors of IPA can leverage new and existing technologies. Overall, our results suggest that the usability of and control over privacy and security functions should be or continue to be high priorities for technology creators seeking ways to better support survivors of IPA.</p></div></span> <a id="expcoll237" href="JavaScript: expandcollapse('expcoll237',237)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025926&CFID=758305256&CFTOKEN=14863114">Self-Confidence Trumps Knowledge: A Cross-Cultural Study of Security Behavior</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Yukiko Sawaya, Mahmood Sharif, Nicolas Christin, Ayumu Kubota, Akihiro Nakarai, Akira Yamada 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2202-2214</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025926" title="DOI">10.1145/3025453.3025926</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025926&ftid=1870180&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow238" style="display:inline;"><br /><div style="display:inline">Computer security tools usually provide universal solutions without taking user characteristics (origin, income level, ...) into account. In this paper, we test the validity of using such universal security defenses, with a particular focus on culture. ...</div></span>
          <span id="toHide238" style="display:none;"><br /><div style="display:inline"><p>Computer security tools usually provide universal solutions without taking user characteristics (origin, income level, ...) into account. In this paper, we test the validity of using such universal security defenses, with a particular focus on culture. We apply the previously proposed Security Behavior Intentions Scale (SeBIS) to 3,500 participants from seven countries. We first translate the scale into seven languages while preserving its reliability and structure validity. We then build a regression model to study which factors affect participants' security behavior. We find that participants from different countries exhibit different behavior. For instance, participants from Asian countries, and especially Japan, tend to exhibit less secure behavior. Surprisingly to us, we also find that actual knowledge influences user behavior much less than user self-confidence in their computer security knowledge. Stated differently, what people think they know affects their security behavior more than what they do know.</p></div></span> <a id="expcoll238" href="JavaScript: expandcollapse('expcoll238',238)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025896&CFID=758305256&CFTOKEN=14863114">What Do We Really Know about How Habituation to Warnings Occurs Over Time?: A Longitudinal fMRI Study of Habituation and Polymorphic Warnings</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Anthony Vance, Brock Kirwan, Daniel Bjorn, Jeffrey Jenkins, Bonnie Brinton Anderson 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2215-2227</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025896" title="DOI">10.1145/3025453.3025896</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025896&ftid=1870221&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow239" style="display:inline;"><br /><div style="display:inline">A major inhibitor of the effectiveness of security warnings is habituation: decreased response to a repeated warning. Although habituation develops over time, previous studies have examined habituation and possible solutions to its effects only within ...</div></span>
          <span id="toHide239" style="display:none;"><br /><div style="display:inline"><p>A major inhibitor of the effectiveness of security warnings is habituation: decreased response to a repeated warning. Although habituation develops over time, previous studies have examined habituation and possible solutions to its effects only within a single experimental session, providing an incomplete view of the problem. To address this gap, we conducted a longitudinal experiment that examines how habituation develops over the course of a five-day workweek and how polymorphic warnings decrease habituation. We measured habituation using two complementary methods simultaneously: functional magnetic resonance imaging (fMRI) and eye tracking.</p> <p>Our results show a dramatic drop in attention throughout the workweek despite partial recovery between workdays. We also found that the polymorphic warning design was substantially more resistant to habituation compared to conventional warnings, and it sustained this advantage throughout the five-day experiment. Our findings add credibility to prior studies by showing that the pattern of habituation holds across a workweek, and indicate that cross-sectional habituation studies are valid proxies for longitudinal studies. Our findings also show that eye tracking is a valid measure of the mental process of habituation to warnings.</p></div></span> <a id="expcoll239" href="JavaScript: expandcollapse('expcoll239',239)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025911&CFID=758305256&CFTOKEN=14863114">Can People Self-Report Security Accurately?: Agreement Between Self-Report and Behavioral Measures</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Rick Wash, Emilee Rader, Chris Fennell 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2228-2232</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025911" title="DOI">10.1145/3025453.3025911</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025911&ftid=1870205&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow240" style="display:inline;"><br /><div style="display:inline">It is common for researchers to use self-report measures (e.g. surveys) to measure people's security behaviors. In the computer security community, we don't know what behaviors people understand well enough to self-report accurately, or how well those ...</div></span>
          <span id="toHide240" style="display:none;"><br /><div style="display:inline"><p>It is common for researchers to use self-report measures (e.g. surveys) to measure people's security behaviors. In the computer security community, we don't know what behaviors people understand well enough to self-report accurately, or how well those self-reports correlate with what people actually do. In a six week field study, we collected both behavior data and survey responses from 122 subjects. We found that a relatively small number of behaviors -- mostly related to tasks that require users to take a specific, regular action -- have non-zero correlations. Since security is almost never a user's primary task for everyday computer users, several important security behaviors that we directly measured were not self-reported accurately. These results suggest that security research based on self-report is only reliable for certain behaviors. Additionally, a number of important security behaviors are not sufficiently salient to users that they can self-report accurately.</p></div></span> <a id="expcoll240" href="JavaScript: expandcollapse('expcoll240',240)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025856&CFID=758305256&CFTOKEN=14863114">Toward Harmonizing Self-reported and Logged Social Data for Understanding Human Behavior</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Vivek K. Singh, Arushi Jain 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2233-2238</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025856" title="DOI">10.1145/3025453.3025856</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025856&ftid=1870215&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow241" style="display:inline;"><br /><div style="display:inline">While self-reporting remains the most common method to understand human behavior, recent advances in social networks, mobile technologies, and other computer-mediated communication technologies are allowing researchers to obtain detailed logs of human ...</div></span>
          <span id="toHide241" style="display:none;"><br /><div style="display:inline"><p>While self-reporting remains the most common method to understand human behavior, recent advances in social networks, mobile technologies, and other computer-mediated communication technologies are allowing researchers to obtain detailed logs of human behavior with ease. While the logged data is very useful (and accurate) at capturing the structure of the user's social network, the self-reported data provides an insight into the user's cognitive map of her social network. Based on a field study involving 47 users for a period of ten weeks we report that combining the two sets of data (self-reported and logged) gives higher predictive power than using either one of them individually. Further, the difference between the two types of values captures the level of dissonance between a user's actual and perceived social behavior and is found to be an important predictor of the person's social outcomes including social capital, social support and trust.</p></div></span> <a id="expcoll241" href="JavaScript: expandcollapse('expcoll241',241)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Second Screen</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025758&CFID=758305256&CFTOKEN=14863114">HeartChat: Heart Rate Augmented Mobile Chat to Support Empathy and Awareness</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Mariam Hassib, Daniel Buschek, PawelW W. Wozniak, Florian Alt 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2239-2251</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025758" title="DOI">10.1145/3025453.3025758</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025758&ftid=1870230&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow243" style="display:inline;"><br /><div style="display:inline">Textual communication via mobile phones suffers from a lack of context and emotional awareness. We present a mobile chat application, HeartChat, which integrates heart rate as a cue to increase awareness and empathy. Through a literature review and a ...</div></span>
          <span id="toHide243" style="display:none;"><br /><div style="display:inline"><p>Textual communication via mobile phones suffers from a lack of context and emotional awareness. We present a mobile chat application, HeartChat, which integrates heart rate as a cue to increase awareness and empathy. Through a literature review and a focus group, we identified design dimensions important for heart rate augmented chats. We created three concepts showing heart rate per message, in real-time, or sending it explicitly. We tested our system in a two week in-the-wild study with 14 participants (7 pairs). Interviews and questionnaires showed that HeartChat supports empathy between people, in particular close friends and partners. Sharing heart rate helped them to implicitly understand each other's context (e.g. location, physical activity) and emotional state, and sparked curiosity on special occasions. We discuss opportunities, challenges, and design implications for enriching mobile chats with physiological sensing.</p></div></span> <a id="expcoll243" href="JavaScript: expandcollapse('expcoll243',243)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025833&CFID=758305256&CFTOKEN=14863114">"I've been manipulated!": Designing Second Screen Experiences for Critical Viewing of Reality TV</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Tom Feltwell, Gavin Wood, Kiel Long, Phillip Brooker, Tom Schofield, Ioannis Petridis, Julie Barnett, John Vines, Shaun Lawson 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2252-2263</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025833" title="DOI">10.1145/3025453.3025833</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025833&ftid=1870200&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow244" style="display:inline;"><br /><div style="display:inline">The recent proliferation of a reality TV genre that focusses on welfare recipients has led to concerns that prime-time media experiences are exacerbating misconceptions, and stifling critical debate, around major societal issues such as welfare reform ...</div></span>
          <span id="toHide244" style="display:none;"><br /><div style="display:inline"><p>The recent proliferation of a reality TV genre that focusses on welfare recipients has led to concerns that prime-time media experiences are exacerbating misconceptions, and stifling critical debate, around major societal issues such as welfare reform and poverty. Motivated by arguments that 'second screening' practices offer opportunities to engage viewers with issues of political concern, we describe the design and evaluation of two smartphone apps that facilitate and promote more critical live-viewing of reality TV. Our apps, <i>Spotting Guide</i> and <i>Moral Compass</i>, encourage users to identify, categorise, tag and filter patterns and tropes within reality TV, as well as reinterpret social media posts associated with their broadcast. We show that such interactions encourage critical thinking around typical editing and production techniques and foster co-discussion and reflection amongst viewers. We discuss, more broadly, how these interactions encourage users to identify the wider consequences and framings of reality TV, and offer implications and considerations for design that provokes criticality and reflection in second screening contexts.</p></div></span> <a id="expcoll244" href="JavaScript: expandcollapse('expcoll244',244)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025459&CFID=758305256&CFTOKEN=14863114">Interaction with a TV Companion App as Synopsis and Supplement</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          John Dowell, Edward Anstead 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2264-2268</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025459" title="DOI">10.1145/3025453.3025459</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025459&ftid=1870207&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow245" style="display:inline;"><br /><div style="display:inline">Television companion apps on tablets and smartphones provide interactive content synchronized with TV shows. A key design question raised by this novel, multi-display, multimedia interface is whether the app's role is to be a synopsis of the show or ...</div></span>
          <span id="toHide245" style="display:none;"><br /><div style="display:inline"><p>Television companion apps on tablets and smartphones provide interactive content synchronized with TV shows. A key design question raised by this novel, multi-display, multimedia interface is whether the app's role is to be a synopsis of the show or a supplement. In other words, should the app help viewers better follow what they are watching on TV, or offer additional enriching content to respond to interest created by the show? We developed a companion app for a documentary with both synoptic and supplementary content. A laboratory study with 28 participants examined the effect of these different types of content on the experience of using the companion and the effect on engagement with the show in terms of participants' recall. Engagement with the show was not affected by supplementary content in the app but coordinated viewing of both screens was more difficult. Design guidelines evident from these results are discussed.</p></div></span> <a id="expcoll245" href="JavaScript: expandcollapse('expcoll245',245)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025611&CFID=758305256&CFTOKEN=14863114">Social Printers: A Physical Social Network for Political Debates</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Katerina Gorkovenko, Nick Taylor, Jon Rogers 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2269-2281</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025611" title="DOI">10.1145/3025453.3025611</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025611&ftid=1870201&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow246" style="display:inline;"><br /><div style="display:inline">Social Printers are physical devices that create a pseudonymous social network between households during televised political debates. Through studies conducted around the Scottish Parliamentary Election and EU Referendum in 2016, we aimed to understand ...</div></span>
          <span id="toHide246" style="display:none;"><br /><div style="display:inline"><p><i>Social Printers</i> are physical devices that create a pseudonymous social network between households during televised political debates. Through studies conducted around the Scottish Parliamentary Election and EU Referendum in 2016, we aimed to understand how physical devices could be used to engage viewers with televised political debates. By displacing the interaction from conventional social media and second screens we observed that the printers were successful in encouraging the participants to share their thoughts and create a personal social experience. Based on the results we discuss potential implications for conventional social media and second screens in the context of political television programs.</p></div></span> <a id="expcoll246" href="JavaScript: expandcollapse('expcoll246',246)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Civic Technology</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025915&CFID=758305256&CFTOKEN=14863114">A City in Common: A Framework to Orchestrate Large-scale Citizen Engagement around Urban Issues</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Mara Balestrini, Yvonne Rogers, Carolyn Hassan, Javi Creus, Martha King, Paul Marshall 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2282-2294</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025915" title="DOI">10.1145/3025453.3025915</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025915&ftid=1870235&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow248" style="display:inline;"><br /><div style="display:inline">Citizen sensing is an approach that develops and uses lightweight technologies with local communities to collect, share and act upon data. In doing so it enables them to become more aware of how they can tackle local issues. We report here on the development ...</div></span>
          <span id="toHide248" style="display:none;"><br /><div style="display:inline"><p>Citizen sensing is an approach that develops and uses lightweight technologies with local communities to collect, share and act upon data. In doing so it enables them to become more aware of how they can tackle local issues. We report here on the development and uptake of the 'City- Commons Framework for Citizen Sensing', a conceptual model that builds on Participatory Action Research with the aim of playing an integrating role: outlining the processes and mechanisms for ensuring sensing technologies are co-designed by citizens to address their concerns. At the heart of the framework is the idea of a city commons: a pool of community-managed resources. We discuss how the framework was used by communities in Bristol to measure and monitor the problem of damp housing.</p></div></span> <a id="expcoll248" href="JavaScript: expandcollapse('expcoll248',248)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025963&CFID=758305256&CFTOKEN=14863114">Creating a Sociotechnical API: Designing City-Scale Community Engagement</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Mariam Asad, Christopher A. Le Dantec, Becky Nielsen, Kate Diedrick 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2295-2306</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025963" title="DOI">10.1145/3025453.3025963</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025963&ftid=1870209&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow249" style="display:inline;"><br /><div style="display:inline">Community engagement is to cities what user experience is to computing: it signifies a large category that simultaneously speaks to general qualities of interaction and to specific ways of doing that interaction. Recently, digital civics has emerged ...</div></span>
          <span id="toHide249" style="display:none;"><br /><div style="display:inline"><p>Community engagement is to cities what user experience is to computing: it signifies a large category that simultaneously speaks to general qualities of interaction and to specific ways of doing that interaction. Recently, digital civics has emerged as a research area with a comprehensive approach to designing for civic encounters where community engagement is a primary concern for designing systems and processes that support broad civic interaction. In short, over the past year, we worked with municipal officials, service providers, and city residents to design a community engagement playbook detailing best practices for city-scale engagement. The playbook, as well as the collaborative process that produced it, provides a roadmap for thinking through the kinds of systems that might populate the design space of city-scale digital civics. This paper details our design-led research process and builds on emerging literature on designing for digital civic interaction.</p></div></span> <a id="expcoll249" href="JavaScript: expandcollapse('expcoll249',249)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/bp_award.jpg" alt="Best Paper" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025996&CFID=758305256&CFTOKEN=14863114">Empowered Participation: How Citizens Use Technology in Local Governance</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Sheena Erete, Jennifer O. Burrell 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2307-2319</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025996" title="DOI">10.1145/3025453.3025996</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025996&ftid=1870238&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow250" style="display:inline;"><br /><div style="display:inline">The partnership between local residents and city officials to inform policy and decision-making about government resources, or participatory governance, has been extensively studied. In addition to numerous ethnographic studies about how citizens engage ...</div></span>
          <span id="toHide250" style="display:none;"><br /><div style="display:inline"><p>The partnership between local residents and city officials to inform policy and decision-making about government resources, or participatory governance, has been extensively studied. In addition to numerous ethnographic studies about how citizens engage in-person, there has been increased focus in HCI to understand the impact of technology on citizen participation in local governance. Building upon those studies, this paper provides unique insight from a 3-year longitudinal study on the use of online tools that were organically adapted by citizens to engage in local governance in three diverse Chicago neighborhoods. Though the responsiveness of government officials varied across communities, our results suggest that citizens use technology to heighten the visibility of their concerns, to support mechanisms of government accountability, and to provide various options for resident participation in local governance. We argue that while communities may be effective in their use of ICTs, technology may not increase their political power.</p></div></span> <a id="expcoll250" href="JavaScript: expandcollapse('expcoll250',250)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025559&CFID=758305256&CFTOKEN=14863114">Community Conversational: Supporting and Capturing Political Deliberation in Local Consultation Processes</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Ian G. Johnson, Alistair MacDonald, Jo Briggs, Jennifer Manuel, Karen Salt, Emma Flynn, John Vines 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2320-2333</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025559" title="DOI">10.1145/3025453.3025559</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025559&ftid=1870219&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow251" style="display:inline;"><br /><div style="display:inline">The development of platforms for community decision-making has been of growing interest to the HCI community, yet the ways technology might be woven into traditional consultation processes has been under-studied. We conducted fieldwork at consultation ...</div></span>
          <span id="toHide251" style="display:none;"><br /><div style="display:inline"><p>The development of platforms for community decision-making has been of growing interest to the HCI community, yet the ways technology might be woven into traditional consultation processes has been under-studied. We conducted fieldwork at consultation events where residents were invited to discuss and map assets related to their neighbourhoods to inform community decision-making. The fieldwork highlighted problems with equality, turn taking, the evidencing and elaborating on opinions by residents, and challenges related to capturing and documenting the events. We developed Community Conversational-a hybrid table-top game and digital capture and review platform-in response to these issues. Community Conversational was designed to provide a flexible structure to consultation events related to 'place', and support the production, capture and review of deliberative 'talk' to support decision-making. We study how the platform was used in two consultation events, and discuss the implications of capturing and evidencing local people's opinions for the accountability of decision-makers and community organisations.</p></div></span> <a id="expcoll251" href="JavaScript: expandcollapse('expcoll251',251)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Crowdfunding and Crowdsourcing</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3026044&CFID=758305256&CFTOKEN=14863114">Revolt: Collaborative Crowdsourcing for Labeling Machine Learning Datasets</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Joseph Chee Chang, Saleema Amershi, Ece Kamar 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2334-2346</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3026044" title="DOI">10.1145/3025453.3026044</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3026044&ftid=1870190&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow253" style="display:inline;"><br /><div style="display:inline">Crowdsourcing provides a scalable and efficient way to construct labeled datasets for training machine learning systems. However, creating comprehensive label guidelines for crowdworkers is often prohibitive even for seemingly simple concepts. Incomplete ...</div></span>
          <span id="toHide253" style="display:none;"><br /><div style="display:inline"><p>Crowdsourcing provides a scalable and efficient way to construct labeled datasets for training machine learning systems. However, creating comprehensive label guidelines for crowdworkers is often prohibitive even for seemingly simple concepts. Incomplete or ambiguous label guidelines can then result in differing interpretations of concepts and inconsistent labels. Existing approaches for improving label quality, such as worker screening or detection of poor work, are ineffective for this problem and can lead to rejection of honest work and a missed opportunity to capture rich interpretations about data. We introduce Revolt, a collaborative approach that brings ideas from expert annotation workflows to crowd-based labeling. Revolt eliminates the burden of creating detailed label guidelines by harnessing crowd disagreements to identify ambiguous concepts and create rich structures (groups of semantically related items) for post-hoc label decisions. Experiments comparing Revolt to traditional crowdsourced labeling show that Revolt produces high quality labels without requiring label guidelines in turn for an increase in monetary cost. This up front cost, however, is mitigated by Revolt's ability to produce reusable structures that can accommodate a variety of label boundaries without requiring new data to be collected. Further comparisons of Revolt's collaborative and non-collaborative variants show that collaboration reaches higher label accuracy with lower monetary cost.</p></div></span> <a id="expcoll253" href="JavaScript: expandcollapse('expcoll253',253)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3026025&CFID=758305256&CFTOKEN=14863114">VoxPL: Programming with the Wisdom of the Crowd</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Daniel W. Barowy, Emery D. Berger, Daniel G. Goldstein, Siddharth Suri 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2347-2358</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3026025" title="DOI">10.1145/3025453.3026025</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3026025&ftid=1870178&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow254" style="display:inline;"><br /><div style="display:inline">Having a crowd estimate a numeric value is the original inspiration for the notion of "the wisdom of the crowd." Quality control for such estimated values is challenging because prior, consensus-based approaches for quality control in labeling tasks ...</div></span>
          <span id="toHide254" style="display:none;"><br /><div style="display:inline"><p>Having a crowd estimate a numeric value is the original inspiration for the notion of "the wisdom of the crowd." Quality control for such estimated values is challenging because prior, consensus-based approaches for quality control in labeling tasks are not applicable in estimation tasks. We present VoxPL, a high-level programming framework that automatically obtains high-quality crowdsourced estimates of values. The VoxPL domain-specific language lets programmers concisely specify complex estimation tasks with a desired level of confidence and budget. VoxPL's runtime system implements a novel quality control algorithm that automatically computes sample sizes and obtains high quality estimates from the crowd at low cost. To evaluate VoxPL, we implement four estimation applications, ranging from facial feature recognition to calorie counting. The resulting programs are concise---under 200 lines of code---and obtain high quality estimates from the crowd quickly and inexpensively.</p></div></span> <a id="expcoll254" href="JavaScript: expandcollapse('expcoll254',254)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025551&CFID=758305256&CFTOKEN=14863114">Embedding a Crowd inside a Relay Baton: A Case Study in a Non-Competitive Sporting Activity</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Franco Curmi, Maria Angela Ferrario, Jon Whittle 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2359-2370</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025551" title="DOI">10.1145/3025453.3025551</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025551&ftid=1870228&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow255" style="display:inline;"><br /><div style="display:inline">This paper presents a digital relay baton that connects long-distance runners with distributed online spectators. The baton broadcasts athletes? live locative data to a social network and communicates back remote-crowd support through haptic and audible ...</div></span>
          <span id="toHide255" style="display:none;"><br /><div style="display:inline"><p>This paper presents a digital relay baton that connects long-distance runners with distributed online spectators. The baton broadcasts athletes? live locative data to a social network and communicates back remote-crowd support through haptic and audible cheers. Our work takes an exploratory design approach to bring new insights into the design of real-time techno-mediated social support. The prototype was deployed during a 170-mile charity relay race across the UK with 13 participants, 261 on-line supporters, and gathered a total of 3,153 'cheers'. We report on the insights collected during the design and deployment process and identify three fundamental design considerations: the degree of spectator expression that the design affords, the context applicability, and the data flow within the social network.</p></div></span> <a id="expcoll255" href="JavaScript: expandcollapse('expcoll255',255)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025647&CFID=758305256&CFTOKEN=14863114">Prioritizing Flexibility and Intangibles: Medical Crowdfunding for Stigmatized Individuals</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Amy Gonzales, Nicole Fritz 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2371-2375</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025647" title="DOI">10.1145/3025453.3025647</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025647&ftid=1870202&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow256" style="display:inline;"><br /><div style="display:inline">HCI research on crowdfunding has primarily focused on creative or organizational endeavors. Yet a majority of crowdfunding campaigns are conducted by individuals in need, often for healthcare. To better understand and improve this common crowdfunding ...</div></span>
          <span id="toHide256" style="display:none;"><br /><div style="display:inline"><p>HCI research on crowdfunding has primarily focused on creative or organizational endeavors. Yet a majority of crowdfunding campaigns are conducted by individuals in need, often for healthcare. To better understand and improve this common crowdfunding experience, especially for those that inhabit a vulnerable social status, we conducted 20 interviews with transmen crowdfunding for top-surgery. Design choices that optimize <i>site flexibility</i> (e.g. control of personal information; enable cross-site communication) and foreground <i>intangibles</i>, such as political values and emotional support, are priorities for individuals from a stigmatized community. Findings differed from previous crowdfunding research and contribute to limited research on transgender identities in HCI. Overall they provide unique insights into how design choices can facilitate marginalized identity management in highly public online spaces.</p></div></span> <a id="expcoll256" href="JavaScript: expandcollapse('expcoll256',256)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025763&CFID=758305256&CFTOKEN=14863114">Understanding the Effects of Endorsements in Scientific Crowdfunding</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Sanorita Dey, Karrie Karahalios, Wai-Tat Fu 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2376-2381</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025763" title="DOI">10.1145/3025453.3025763</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025763&ftid=1870232&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow257" style="display:inline;"><br /><div style="display:inline">Understanding the factors that persuade backers to donate to research projects has become increasingly important with the rising popularity of scientific crowdfunding. Although there are many similarities between enterprise and scientific crowdfunding, ...</div></span>
          <span id="toHide257" style="display:none;"><br /><div style="display:inline"><p>Understanding the factors that persuade backers to donate to research projects has become increasingly important with the rising popularity of scientific crowdfunding. Although there are many similarities between enterprise and scientific crowdfunding, some factors differentiate these two forms of crowdfunding. One such factor is the use of endorsements. The endorsement helps backers gain trust based on expert opinions about the competency of the researchers and the usefulness of the projects. We analyzed 810 endorsements from scientific campaigns posted on Experiment.com and derived a taxonomy of topics discussed in the endorsements. A regression analysis revealed that when endorsers explained the skills of the campaign owners, the probability of success of the campaign improved; on the contrary, when endorsers reiterated the goal of the project, the campaign was less likely to succeed. We conclude with design implications formulated from our findings to better support scientific crowdfunding.</p></div></span> <a id="expcoll257" href="JavaScript: expandcollapse('expcoll257',257)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Designing for the Workplace</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025780&CFID=758305256&CFTOKEN=14863114">Calendar.help: Designing a Workflow-Based Scheduling Agent with Humans in the Loop</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Justin Cranshaw, Emad Elwany, Todd Newman, Rafal Kocielnik, Bowen Yu, Sandeep Soni, Jaime Teevan, Andr&#233;s Monroy-Hernandez 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2382-2393</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025780" title="DOI">10.1145/3025453.3025780</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025780&ftid=1870189&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow259" style="display:inline;"><br /><div style="display:inline">Although we may complain about meetings, they are an essential part of an information worker's work life. Consequently, busy people spend a significant amount of time scheduling meetings. We present Calendar.help, a system that provides fast, efficient ...</div></span>
          <span id="toHide259" style="display:none;"><br /><div style="display:inline"><p>Although we may complain about meetings, they are an essential part of an information worker's work life. Consequently, busy people spend a significant amount of time scheduling meetings. We present Calendar.help, a system that provides fast, efficient scheduling through structured workflows. Users interact with the system via email, delegating their scheduling needs to the system as if it were a human personal assistant. Common scheduling scenarios are broken down using well-defined workflows and completed as a series of microtasks that are automated when possible and executed by a human otherwise. Unusual scenarios fall back to a trained human assistant executing an unstructured macrotask. We describe the iterative approach we used to develop Calendar.help, and share the lessons learned from scheduling thousands of meetings during a year of real-world deployments. Our findings provide insight into how complex information tasks can be broken down into repeatable components that can be executed efficiently to improve productivity.</p></div></span> <a id="expcoll259" href="JavaScript: expandcollapse('expcoll259',259)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025621&CFID=758305256&CFTOKEN=14863114">Conversational Chat Circles: Being All Here Without Having to Hear It All</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Matthew K. Miller, John C. Tang, Gina Venolia, Gerard Wilkinson, Kori Inkpen 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2394-2404</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025621" title="DOI">10.1145/3025453.3025621</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025621&ftid=1870233&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow260" style="display:inline;"><br /><div style="display:inline">Live streaming services are a growing form of social media. Most live streaming platforms allow viewers to communicate with each other and the broadcaster via a text chat. However, interaction in a text chat does not work well with too many users. Existing ...</div></span>
          <span id="toHide260" style="display:none;"><br /><div style="display:inline"><p>Live streaming services are a growing form of social media. Most live streaming platforms allow viewers to communicate with each other and the broadcaster via a text chat. However, interaction in a text chat does not work well with too many users. Existing techniques to make text chat work with a larger number of participants often limit who can participate or how much users can participate. In this paper, we describe a new design for a text chat system that allows more people to participate without overwhelming users with too many messages. Our design strategically limits the number of messages a user sees based on the concept of neighborhoods, and emphasizes important messages through upvoting. We present a study comparing our system to a chat system similar to those found in commercial streaming services. Results of the study indicate that the Conversational Circle system is easier to understand and interact with, while supporting community among viewers and highlighting important content for the streamer.</p></div></span> <a id="expcoll260" href="JavaScript: expandcollapse('expcoll260',260)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025700&CFID=758305256&CFTOKEN=14863114">A Predictive Model of Emergency Physician Task Resumption Following Interruptions</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Allan Fong, A. Zachary Hettinger, Raj M. Ratwani 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2405-2410</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025700" title="DOI">10.1145/3025453.3025700</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025700&ftid=1870222&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow261" style="display:inline;"><br /><div style="display:inline">Interruptions in the emergency department (ED) can have serious patient safety consequences, and few solutions exist to mitigate the disruptiveness of interruptions. We developed a theoretically motivated model to predict the likelihood of emergency ...</div></span>
          <span id="toHide261" style="display:none;"><br /><div style="display:inline"><p>Interruptions in the emergency department (ED) can have serious patient safety consequences, and few solutions exist to mitigate the disruptiveness of interruptions. We developed a theoretically motivated model to predict the likelihood of emergency physicians returning to an interrupted task. Eighteen emergency physicians were observed individually for two-hour blocks of time, resulting in a total of 2160 minutes of observation and 231 interruptions. We used a mixed effects logistic regression model to predict the likelihood of primary task resumption after interruptions. The likelihood of primary task resumption was predicted by memory decay, measured by the duration of the interruption, workload, measured by the patient volume during the shift, and whether shift was day or night. With a better understanding of these interruptions, we can help design interventions to manage interruptions, minimize medical errors, and improve patient safety.</p></div></span> <a id="expcoll261" href="JavaScript: expandcollapse('expcoll261',261)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025552&CFID=758305256&CFTOKEN=14863114">Undertanding and Detecting Divided Attention in Mobile MOOC Learning</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Xiang Xiao, Jingtao Wang 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2411-2415</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025552" title="DOI">10.1145/3025453.3025552</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025552&ftid=1870193&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow262" style="display:inline;"><br /><div style="display:inline">The emergence of mobile apps for Massive Open Online Courses (MOOCs) allows learners to access quality learning materials at low cost and "to control where, what, how and with whom they learn". Unfortunately, when compared with traditional classroom ...</div></span>
          <span id="toHide262" style="display:none;"><br /><div style="display:inline"><p>The emergence of mobile apps for Massive Open Online Courses (MOOCs) allows learners to access quality learning materials at low cost and "to control where, what, how and with whom they learn". Unfortunately, when compared with traditional classroom education, learners face more distractions and are more likely to multitask when they study alone in an informal learning environment. In this paper, we investigate the impact of divided attention (DA) on both the learning process and learning outcomes in the context of mobile MOOC learning. We propose OneMind, a system and algorithm for detecting divided attention on unmodified mobile phones via implicit, camera-based heart rate tracking. In an 18-participant study, we found that internal divided attention has a significant negative impact on learning outcomes; and that the photoplethysmography (PPG) waveforms implicitly captured by OneMind can be used to detect the presence, type, and intensity of divided attention in mobile MOOC learning.</p></div></span> <a id="expcoll262" href="JavaScript: expandcollapse('expcoll262',262)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Designing Haptic Interfaces</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025971&CFID=758305256&CFTOKEN=14863114">PinPad: Touchpad Interaction with Fast and High-Resolution Tactile Output</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Jingun Jung, Eunhye Youn, Geehyuk Lee 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2416-2425</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025971" title="DOI">10.1145/3025453.3025971</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025971&ftid=1870234&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow264" style="display:inline;"><br /><div style="display:inline">We explored new interaction scenarios that can be realized when a touchpad outputs fast and high-resolution spatio-temporal tactile patterns to the touch-sensitive skin on the fingertips of a user. We first constructed a special tactile multi-touch touchpad ...</div></span>
          <span id="toHide264" style="display:none;"><br /><div style="display:inline"><p>We explored new interaction scenarios that can be realized when a touchpad outputs fast and high-resolution spatio-temporal tactile patterns to the touch-sensitive skin on the fingertips of a user. We first constructed a special tactile multi-touch touchpad called PinPad, which was capable of outputting fast and high-resolution tactile patterns using a 40 x 25 array of actuated pins. We then developed various interaction scenarios that could be realized using the prototype: 1) Tactile Target, 2) Guide and Constraint, 3) Multi-finger Output, and 4) Dynamic Partition. To evaluate the PinPad scenarios, we implemented demo applications, and conducted interviews with users to collect feedback about their experiences with PinPad and the PinPad scenarios. The participants confirmed the effectiveness of spatio-temporal outputs of PinPad in the scenarios. In particular, they provided diverse feedback regarding the unique tactile experiences of the fast and high-resolution outputs of PinPad.</p></div></span> <a id="expcoll264" href="JavaScript: expandcollapse('expcoll264',264)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025457&CFID=758305256&CFTOKEN=14863114">Agency in Mid-air Interfaces</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Patricia Ivette Cornelio Martinez, Silvana De Pirro, Chi Thanh Vi, Sriram Subramanian 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2426-2439</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025457" title="DOI">10.1145/3025453.3025457</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025457&ftid=1870197&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow265" style="display:inline;"><br /><div style="display:inline">Touchless interfaces allow users to view, control and manipulate digital content without physically touching an interface. They are being explored in a wide range of application scenarios from medical surgery to car dashboard controllers. One aspect ...</div></span>
          <span id="toHide265" style="display:none;"><br /><div style="display:inline"><p>Touchless interfaces allow users to view, control and manipulate digital content without physically touching an interface. They are being explored in a wide range of application scenarios from medical surgery to car dashboard controllers. One aspect of touchless interaction that has not been explored to date is the Sense of Agency (SoA). The SoA refers to the subjective experience of voluntary control over actions in the external world. In this paper, we investigated the SoA in touchless systems using the intentional binding paradigm. We first compare touchless systems with physical interactions and then augmented different types of haptic feedback to explore how different outcome modalities influence intentional binding. From our experiments, we demonstrated that an intentional binding effect is observed in both physical and touchless interactions with no statistical difference. Additionally, we found that haptic and auditory feedback help to increase SoA compared with visual feedback in touchless interfaces. We discuss these findings and identify design opportunities that take agency into consideration.</p></div></span> <a id="expcoll265" href="JavaScript: expandcollapse('expcoll265',265)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025655&CFID=758305256&CFTOKEN=14863114">Frozen Suit: Designing a Changeable Stiffness Suit and its Application to Haptic Games</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Ahmed Al Maimani, Anne Roudaut 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2440-2448</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025655" title="DOI">10.1145/3025453.3025655</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025655&ftid=1870236&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow266" style="display:inline;"><br /><div style="display:inline">We present the concept of Frozen Suit, a type of clothing that restricts users' movements at joint positions (e.g. elbow, knee) via a changeable stiffness jamming material. The suit can "freeze" users' body parts, for example during a game in order to ...</div></span>
          <span id="toHide266" style="display:none;"><br /><div style="display:inline"><p>We present the concept of Frozen Suit, a type of clothing that restricts users' movements at joint positions (e.g. elbow, knee) via a changeable stiffness jamming material. The suit can "freeze" users' body parts, for example during a game in order to provide the physical sensation of being frozen by an enemy. In this paper we first present the Frozen Suit concept and its potential applications. We then systematically investigate how to design jamming patches in order to sufficiently restrict an arm or a leg. In particular we used low-fidelity prototypes to explore the restricting power of different material and particles. In order to push this analysis further we conducted a controlled experiment in order to compare the perceived stiffness of different patches sizes attached to the elbow. We performed a paired comparison experience and used a Bradley-Terry-Luce model to analyze the subjective feedback from participants. We found that 20cm long x 7cm large is the most restrictive patch and that an increase in patch area correlates with an increase in perceived stiffness (quadratic). We finish by presenting a use case application with a game that we implemented where enemies can freeze the player.</p></div></span> <a id="expcoll266" href="JavaScript: expandcollapse('expcoll266',266)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025994&CFID=758305256&CFTOKEN=14863114">Haptic-Enabled Handheld Mobile Robots: Design and Analysis</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Ayberk &#214;zg&#252;r, Wafa Johal, Francesco Mondada, Pierre Dillenbourg 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2449-2461</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025994" title="DOI">10.1145/3025453.3025994</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025994&ftid=1870218&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow267" style="display:inline;"><br /><div style="display:inline">The Cellulo robots are small tangible robots that are designed to represent virtual interactive point-like objects that reside on a plane within carefully designed learning activities. In the context of these activities, our robots not only display autonomous ...</div></span>
          <span id="toHide267" style="display:none;"><br /><div style="display:inline"><p>The Cellulo robots are small tangible robots that are designed to represent virtual interactive point-like objects that reside on a plane within carefully designed learning activities. In the context of these activities, our robots not only display autonomous motion and act as tangible interfaces, but are also usable as haptic devices in order to exploit, for instance, kinesthetic learning. In this article, we present the design and analysis of the haptic interaction module of the Cellulo robots. We first detail our hardware and controller design that is low-cost and versatile. Then, we describe the task-based experimental procedure to evaluate the robot's haptic abilities. We show that our robot is usable in most of the tested tasks and extract perceptive and manipulative guidelines for the design of haptic elements to be integrated in future learning activities. We conclude with limitations of the system and future work.</p></div></span> <a id="expcoll267" href="JavaScript: expandcollapse('expcoll267',267)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Exertion, Sport, Bodies</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025816&CFID=758305256&CFTOKEN=14863114">A Thing of Beauty: Steering Behavior in an Interactive Playground</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Robby van Delden, Alejandro Moreno, Ronald Poppe, Dennis Reidsma, Dirk Heylen 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2462-2472</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025816" title="DOI">10.1145/3025453.3025816</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025816&ftid=1870182&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow269" style="display:inline;"><br /><div style="display:inline">Interactive playgrounds are spaces where players engage in collocated, playful activities, in which added digital technology can be designed to promote cognitive, social, and motor skills development. To promote such development, different strategies ...</div></span>
          <span id="toHide269" style="display:none;"><br /><div style="display:inline"><p>Interactive playgrounds are spaces where players engage in collocated, playful activities, in which added digital technology can be designed to promote cognitive, social, and motor skills development. To promote such development, different strategies can be used to implement game mechanics that change player's in-game behavior. One of such strategies is enticing players to take action through incentives akin to game achievements. We explored if this strategy could be used to influence players' proxemic behavior in the Interactive Tag Playground, an installation that enhances the traditional game of tag. We placed the ITP in an art gallery, observed hundreds of play sessions, and refined the mechanics, which consisted in projecting collectible particles around the tagger that upon collection by runners resulted only in the embellishment of their circles. We implemented the refined mechanics in a study with 48 children. The playground automatically collected the players' positions, and analyses show that runners got closer to and moved more towards taggers when using our enticing strategy. This suggests an enticing strategy can be used to influence physical in-game behavior.</p></div></span> <a id="expcoll269" href="JavaScript: expandcollapse('expcoll269',269)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025746&CFID=758305256&CFTOKEN=14863114">Five Lenses for Designing Exertion Experiences</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Florian 'Floyd' Mueller, Damon Young 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2473-2487</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025746" title="DOI">10.1145/3025453.3025746</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025746&ftid=1870198&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow270" style="display:inline;"><br /><div style="display:inline">The field of HCI has increasingly looked at ways to support the physically active human being, however, new work suggests that the field has only begun to understand the many virtues of exertion. To further the field, we present a set of five design ...</div></span>
          <span id="toHide270" style="display:none;"><br /><div style="display:inline"><p>The field of HCI has increasingly looked at ways to support the physically active human being, however, new work suggests that the field has only begun to understand the many virtues of exertion. To further the field, we present a set of five design lenses extended primarily from sports philosophy literature to help approach exertion not just as a means of deferring death, but also as an opportunity for personal growth. The lenses facilitate learning how to appreciate a void (Reverie), welcome pleasure (Pleasure), become humble (Humility), as well as be fearful and excited simultaneously (Sublime), whilst being more carefully aware of one's own body (Oneness). Using these lenses, we articulate associated technology opportunities through related work as well as our own craft knowledge. With our work, we aim to support designers who want to facilitate the many virtues of exertion so that ultimately more people profit from the many benefits of being physically active.</p></div></span> <a id="expcoll270" href="JavaScript: expandcollapse('expcoll270',270)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025476&CFID=758305256&CFTOKEN=14863114">Recording and Sharing Non-Visible Information on Body Movement while Skateboarding</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Hyung Kun Park, HyeonBeom Yi, Woohun Lee 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2488-2492</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025476" title="DOI">10.1145/3025453.3025476</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025476&ftid=1870237&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow271" style="display:inline;"><br /><div style="display:inline">Knowing your own body movement is an essential element of sports. Recently, the popularization of smartphones has enabled people to easily record their performance in most situations. However, these observations have limited applicability in assisting ...</div></span>
          <span id="toHide271" style="display:none;"><br /><div style="display:inline"><p>Knowing your own body movement is an essential element of sports. Recently, the popularization of smartphones has enabled people to easily record their performance in most situations. However, these observations have limited applicability in assisting with a clear understanding of body movement. In this paper, we propose the Motion Log Skateboard, which records and shares non-visible information about body movement that is difficult to obtain through current observation methods in skateboarding. A pressure-sensor matrix on a skateboard deck is used to record the pressure distribution data, which are then played using the video function of a smartphone camera. With this logged data, a user can access the feet positions, pressure intensity, and timing of the foot movements. To verify the proposed concept and determine the specific context of its use, an experimental session and interviews were conducted with skateboarders of various skill levels. Based on the results of this research, the shared experiences of non-visible information, which is perceived differently depending on the individual, are expected to become a standard for exploring and training body movement.</p></div></span> <a id="expcoll271" href="JavaScript: expandcollapse('expcoll271',271)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025871&CFID=758305256&CFTOKEN=14863114">The Pok&#233;mon GO Experience: A Location-Based Augmented Reality Mobile Game Goes Mainstream</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Janne Paavilainen, Hannu Korhonen, Kati Alha, Jaakko Stenros, Elina Koskinen, Frans Mayra 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2493-2498</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025871" title="DOI">10.1145/3025453.3025871</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025871&ftid=1870227&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow272" style="display:inline;"><br /><div style="display:inline">Pok&#233;mon GO is a location-based augmented reality mobile game based on the Pok&#233;mon franchise. After the game was launched globally in July 2016, it quickly became the most successful mobile game in both popularity and revenue generation ...</div></span>
          <span id="toHide272" style="display:none;"><br /><div style="display:inline"><p><i>Pok&#233;mon GO</i> is a location-based augmented reality mobile game based on the Pok&#233;mon franchise. After the game was launched globally in July 2016, it quickly became the most successful mobile game in both popularity and revenue generation at the time, and the first location-based augmented reality game to reach a mainstream status. We explore the game experiences through a qualitative survey (n=1000) in Finland focusing on the positive and the negative aspects of <i>Pok&#233;mon GO</i> as told by the players. The positive experiences are related to movement, sociability, game mechanics, and brand while the negative experiences emerge from technical problems, unequal gaming opportunities, bad behavior of other players and non-players, and unpolished game design. Interestingly, the augmented reality features, safety issues or the free-to-play revenue model did not receive considerable feedback. The findings are useful for academics and industry practitioners for studying and designing location-based augmented reality game experiences.</p></div></span> <a id="expcoll272" href="JavaScript: expandcollapse('expcoll272',272)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Human Computer Integration</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025629&CFID=758305256&CFTOKEN=14863114">Manifesting the Cyborg through Techno-Body Modification: From Human-Computer Interaction to Integration</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Lauren M. Britton, Bryan Semaan 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2499-2510</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025629" title="DOI">10.1145/3025453.3025629</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025629&ftid=1870226&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow274" style="display:inline;"><br /><div style="display:inline">A community of DIY cyborgs has emerged, known as 'grinders', who practice techno-body modification-the embedding of computing technology into the body. This paper reports on an ethnographic study following GrinderTech, an organization working to design, ...</div></span>
          <span id="toHide274" style="display:none;"><br /><div style="display:inline"><p>A community of DIY cyborgs has emerged, known as 'grinders', who practice techno-body modification-the embedding of computing technology into the body. This paper reports on an ethnographic study following GrinderTech, an organization working to design, build and sell these technological artifacts, as it shifts from hacker collective to biotech startup. As technologies are embedded in the body, the boundary between human and machine starts to blur. We find that GrinderTech members, through the design and making of technologies for embedding, do so as a means to move beyond social and gendered binary constructions-or, societal norms that are practiced and performed, and re-enforced through language, as a way of creating power differentials in society, e.g. citizen/scientist and man/woman. Moreover, their motivations for designing and making these devices reflects their desire to re-imagine society. Finally, we re-conceptualize Human-Computer Interaction to include Integration-when technology is embedded in the human body-and discuss the theoretical and design implications of human-computer integration.</p></div></span> <a id="expcoll274" href="JavaScript: expandcollapse('expcoll274',274)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025968&CFID=758305256&CFTOKEN=14863114">Factors in Fairness and Emotion in Online Case Resolution Systems</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Youyang Hou, Cliff Lampe, Maximilian Bulinski, J.J. Prescott 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2511-2522</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025968" title="DOI">10.1145/3025453.3025968</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025968&ftid=1870213&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow275" style="display:inline;"><br /><div style="display:inline">Courts are increasingly adopting online information and communication technology, creating a need to consider the potential consequences of these tools for the justice system. Using survey responses from 209 litigants who had recently used an online ...</div></span>
          <span id="toHide275" style="display:none;"><br /><div style="display:inline"><p>Courts are increasingly adopting online information and communication technology, creating a need to consider the potential consequences of these tools for the justice system. Using survey responses from 209 litigants who had recently used an online case resolution system, we investigate factors that influenced litigants' experiences of fairness and emotional feelings toward court officials. Our results show that ease of using the online case resolution system, the outcome of the case, and a litigant's perceptions of procedural justice are positively associated both with whether the litigant views the process as fair and whether the litigant ultimately feels positive emotions toward court officials. We also analyze the online explanations litigants offer in their arguments to courts and litigant answers to an open-ended question about their court experiences, and highlight design and practical implications for online systems seeking to improve access to justice.</p></div></span> <a id="expcoll275" href="JavaScript: expandcollapse('expcoll275',275)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025539&CFID=758305256&CFTOKEN=14863114">Us vs. Them: Understanding Artificial Intelligence Technophobia over the Google DeepMind Challenge Match</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Changhoon Oh, Taeyoung Lee, Yoojung Kim, SoHyun Park, Sae bom Kwon, Bongwon Suh 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2523-2534</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025539" title="DOI">10.1145/3025453.3025539</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025539&ftid=1870220&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow276" style="display:inline;"><br /><div style="display:inline">Various forms of artificial intelligence (AI), such as Apple's Siri and Google Now, have permeated our everyday lives. However, the advent of such "human-like" technology has stirred both awe and a great deal of fear. Many consider it a woe to have an ...</div></span>
          <span id="toHide276" style="display:none;"><br /><div style="display:inline"><p>Various forms of artificial intelligence (AI), such as Apple's Siri and Google Now, have permeated our everyday lives. However, the advent of such "human-like" technology has stirred both awe and a great deal of fear. Many consider it a woe to have an unimaginable future where human intelligence is exceeded by AI. This paper investigates how people perceive and understand AI with a case study of the Google DeepMind Challenge Match, a Go match between Lee Sedol and AlphaGo, in March 2016. This study explores the underlying and changing perspectives toward AI as users experienced this historic event. Interviews with 22 participants show that users tacitly refer to AlphaGo as an "other" as if it were comparable to a human, while dreading that it would come back to them as a potential existential threat. Our work illustrates a confrontational relationship between users and AI, and suggests the need to prepare for a new kind of user experience in this nascent socio- technological change. It calls for a collaborative research effort from the HCI community to study and accommodate users for a future where they interact with algorithms, not just interfaces.</p></div></span> <a id="expcoll276" href="JavaScript: expandcollapse('expcoll276',276)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Improving Gaze Mechanisms</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025757&CFID=758305256&CFTOKEN=14863114">Tell Me Where to Look: Investigating Ways for Assisting Focus in 360&#176; Video</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Yen-Chen Lin, Yung-Ju Chang, Hou-Ning Hu, Hsien-Tzu Cheng, Chi-Wen Huang, Min Sun 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2535-2545</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025757" title="DOI">10.1145/3025453.3025757</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025757&ftid=1870241&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow278" style="display:inline;"><br /><div style="display:inline">360&#176; videos give viewers a spherical view and immersive experience of surroundings. However, one challenge of watching 360&#176; videos is continuously focusing and re-focusing intended targets. To address this challenge, we developed two Focus ...</div></span>
          <span id="toHide278" style="display:none;"><br /><div style="display:inline"><p>360&#176; videos give viewers a spherical view and immersive experience of surroundings. However, one challenge of watching 360&#176; videos is continuously focusing and re-focusing intended targets. To address this challenge, we developed two Focus Assistance techniques: Auto Pilot (directly bringing viewers to the target), and Visual Guidance (indicating the direction of the target). We conducted an experiment to measure viewers' video-watching experience and discomfort using these techniques and obtained their qualitative feedback. We showed that: 1) Focus Assistance improved ease of focus. 2) Focus Assistance techniques have specificity to video content. 3) Participants' preference of and experience with Focus Assistance depended not only on individual difference but also on their goal of watching the video. 4) Factors such as view-moving-distance, salience of the intended target and guidance, and language comprehension affected participants' video-watching experience. Based on these findings, we provide design implications for better 360&#176; video focus assistance.</p></div></span> <a id="expcoll278" href="JavaScript: expandcollapse('expcoll278',278)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025794&CFID=758305256&CFTOKEN=14863114">ScreenGlint: Practical, In-situ Gaze Estimation on Smartphones</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Michael Xuelin Huang, Jiajia Li, Grace Ngai, Hong Va Leong 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2546-2557</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025794" title="DOI">10.1145/3025453.3025794</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025794&ftid=1870187&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow279" style="display:inline;"><br /><div style="display:inline">Gaze estimation has widespread applications. However, little work has explored gaze estimation on smartphones, even though they are fast becoming ubiquitous. This paper presents ScreenGlint, a novel approach which exploits the glint (reflection) of the ...</div></span>
          <span id="toHide279" style="display:none;"><br /><div style="display:inline"><p>Gaze estimation has widespread applications. However, little work has explored gaze estimation on smartphones, even though they are fast becoming ubiquitous. This paper presents ScreenGlint, a novel approach which exploits the glint (reflection) of the screen on the user's cornea for gaze estimation, using only the image captured by the front-facing camera. We first conduct a user study on common postures during smartphone use. We then design an experiment to evaluate the accuracy of ScreenGlint under varying face-to-screen distances. An in-depth evaluation involving multiple users is conducted and the impact of head pose variations is investigated. ScreenGlint achieves an overall angular error of 2.44&#186; without head pose variations, and 2.94&#186; with head pose variations. Our technique compares favorably to state-of-the-art research works, indicating that the glint of the screen is an effective and practical cue to gaze estimation on the smartphone platform. We believe that this work can open up new possibilities for practical and ubiquitous gaze-aware applications.</p></div></span> <a id="expcoll279" href="JavaScript: expandcollapse('expcoll279',279)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025517&CFID=758305256&CFTOKEN=14863114">Improving Dwell-Based Gaze Typing with Dynamic, Cascading Dwell Times</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Martez E. Mott, Shane Williams, Jacob O. Wobbrock, Meredith Ringel Morris 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2558-2570</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025517" title="DOI">10.1145/3025453.3025517</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025517&ftid=1870203&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow280" style="display:inline;"><br /><div style="display:inline">We present cascading dwell gaze typing, a novel approach to dwell-based eye typing that dynamically adjusts the dwell time of keys in an on-screen keyboard based on the likelihood that a key will be selected next, and the location of the key on ...</div></span>
          <span id="toHide280" style="display:none;"><br /><div style="display:inline"><p>We present <i>cascading dwell gaze typing</i>, a novel approach to dwell-based eye typing that dynamically adjusts the dwell time of keys in an on-screen keyboard based on the likelihood that a key will be selected next, and the location of the key on the keyboard. Our approach makes unlikely keys more difficult to select and likely keys easier to select by increasing and decreasing their required dwell times, respectively. To maintain a smooth typing rhythm for the user, we <i>cascade</i> the dwell time of likely keys, slowly decreasing the minimum allowable dwell time as a user enters text. Cascading the dwell time affords users the benefits of faster dwell times while causing little disruption to users' typing cadence. Results from a longitudinal study with 17 non-disabled participants show that our dynamic cascading dwell technique was significantly faster than a static dwell approach. Participants were able to achieve typing speeds of 12.39 WPM on average with our cascading technique, whereas participants were able to achieve typing speeds of 10.62 WPM on average with a static dwell time approach. In a small evaluation conducted with five people with ALS, participants achieved average typing speeds of 9.51 WPM with our cascading dwell approach. These results show that our dynamic cascading dwell technique has the potential to improve gaze typing for users with and without disabilities.</p></div></span> <a id="expcoll280" href="JavaScript: expandcollapse('expcoll280',280)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3026033&CFID=758305256&CFTOKEN=14863114">Looking Coordinated: Bidirectional Gaze Mechanisms for Collaborative Interaction with Virtual Characters</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Sean Andrist, Michael Gleicher, Bilge Mutlu 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2571-2582</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3026033" title="DOI">10.1145/3025453.3026033</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3026033&ftid=1870184&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow281" style="display:inline;"><br /><div style="display:inline">Successful collaboration relies on the coordination and alignment of communicative cues. In this paper, we present mechanisms of bidirectional gaze - the coordinated production and detection of gaze cues - by which a virtual character can coordinate ...</div></span>
          <span id="toHide281" style="display:none;"><br /><div style="display:inline"><p>Successful collaboration relies on the coordination and alignment of communicative cues. In this paper, we present mechanisms of bidirectional gaze - the coordinated production and detection of gaze cues - by which a virtual character can coordinate its gaze cues with those of its human user. We implement these mechanisms in a hybrid stochastic/heuristic model synthesized from data collected in human-human interactions. In three lab studies wherein a virtual character instructs participants in a sandwich-making task, we demonstrate how bidirectional gaze can lead to positive outcomes in error rate, completion time, and the agent's ability to produce quick, effective nonverbal references. The first study involved an on-screen agent and the participant wearing eye-tracking glasses. The second study demonstrates that these positive outcomes can be achieved using head-pose estimation in place of full eye tracking. The third study demonstrates that these effects also transfer into virtual-reality interactions.</p></div></span> <a id="expcoll281" href="JavaScript: expandcollapse('expcoll281',281)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Innovative Fabrication Techniques</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025652&CFID=758305256&CFTOKEN=14863114">Pineal: Bringing Passive Objects to Life with Embedded Mobile Devices</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          David Ledo, Fraser Anderson, Ryan Schmidt, Lora Oehlberg, Saul Greenberg, Tovi Grossman 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2583-2593</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025652" title="DOI">10.1145/3025453.3025652</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025652&ftid=1870231&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow283" style="display:inline;"><br /><div style="display:inline">Interactive, smart objects-customized to individuals and uses-are central to many movements, such as tangibles, the internet of things (IoT), and ubiquitous computing. Yet, rapid prototyping both the form and function of these custom objects can be problematic, ...</div></span>
          <span id="toHide283" style="display:none;"><br /><div style="display:inline"><p>Interactive, smart objects-customized to individuals and uses-are central to many movements, such as tangibles, the internet of things (IoT), and ubiquitous computing. Yet, rapid prototyping both the form and function of these custom objects can be problematic, particularly for those with limited electronics or programming experience. Designers often need to embed custom circuitry; program its workings; and create a form factor that not only reflects the desired user experience but can also house the required circuitry and electronics. To mitigate this, we created <i>Pineal</i>, a design tool that lets end-users: (1) modify 3D models to include a smart watch or phone as its heart; (2) specify high-level interactive behaviours through visual programming; and (3) have the phone or watch act out such behaviours as the objects' "smarts". Furthermore, a series of prototypes show how Pineal exploits mobile sensing and output, and automatically generates 3D printed form-factors for rich, interactive, objects.</p></div></span> <a id="expcoll283" href="JavaScript: expandcollapse('expcoll283',283)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025950&CFID=758305256&CFTOKEN=14863114">CalibMe: Fast and Unsupervised Eye Tracker Calibration for Gaze-Based Pervasive Human-Computer Interaction</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Thiago Santini, Wolfgang Fuhl, Enkelejda Kasneci 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2594-2605</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025950" title="DOI">10.1145/3025453.3025950</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025950&ftid=1870242&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow284" style="display:inline;"><br /><div style="display:inline">As devices around us become smart, our gaze is poised to become the next frontier of human-computer interaction (HCI). State-of-the-art mobile eye tracker systems typically rely on eye-model-based gaze estimation approaches, which do not require a calibration. ...</div></span>
          <span id="toHide284" style="display:none;"><br /><div style="display:inline"><p>As devices around us become smart, our gaze is poised to become the next frontier of human-computer interaction (HCI). State-of-the-art mobile eye tracker systems typically rely on eye-model-based gaze estimation approaches, which do not require a calibration. However, such approaches require specialized hardware (e.g., multiple cameras and glint points), can be significantly affected by glasses, and, thus, are not fit for ubiquitous gaze-based HCI. In contrast, regression-based gaze estimations are straightforward approaches requiring solely one eye and one scene camera but necessitate a calibration. Therefore, a fast and accurate calibration is a key development to enable ubiquitous gaze-based HCI. In this paper, we introduce CalibMe, a novel method that exploits collection markers (automatically detected fiducial markers) to allow eye tracker users to gather a large array of calibration points, remove outliers, and automatically reserve evaluation points in a fast and unsupervised manner. The proposed approach is evaluated against a nine-point calibration method, which is typically used due to its relatively short calibration time and adequate accuracy. CalibMe reached a mean angular error of 0.59 (0=0.23) in contrast to 0.82 (0=0.15) for a nine-point calibration, attesting for the efficacy of the method. Moreover, users are able to calibrate the eye tracker anywhere and independently in - 10 s using a cellphone to display the collection marker.</p></div></span> <a id="expcoll284" href="JavaScript: expandcollapse('expcoll284',284)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3026016&CFID=758305256&CFTOKEN=14863114">TrussFab: Fabricating Sturdy Large-Scale Structures on Desktop 3D Printers</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Robert Kovacs, Anna Seufert, Ludwig Wall, Hsiang-Ting Chen, Florian Meinel, Willi M&#252;ller, Sijing You, Maximilian Brehm, Jonathan Striebel, Yannis Kommana, Alexander Popiak, Thomas Bl&#228;sius, Patrick Baudisch 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2606-2616</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3026016" title="DOI">10.1145/3025453.3026016</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3026016&ftid=1870191&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow285" style="display:inline;"><br /><div style="display:inline">We present TrussFab, an integrated end-to-end system that allows users to fabricate large scale structures that are sturdy enough to carry human weight. TrussFab achieves the large scale by complementing 3D print with plastic bottles. It does not use ...</div></span>
          <span id="toHide285" style="display:none;"><br /><div style="display:inline"><p>We present TrussFab, an integrated end-to-end system that allows users to fabricate large scale structures that are sturdy enough to carry human weight. TrussFab achieves the large scale by complementing 3D print with plastic bottles. It does not use these bottles as "bricks" though, but as beams that form structurally sound node-link structures, also known as trusses, allowing it to handle the forces resulting from scale and load. TrussFab embodies the required engineering knowledge, allowing non-engineers to design such structures and to validate their design using integrated structural analysis. We have used TrussFab to design and fabricate tables and chairs, a 2.5 m long bridge strong enough to carry a human, a functional boat that seats two, and a 5 m diameter dome.</p></div></span> <a id="expcoll285" href="JavaScript: expandcollapse('expcoll285',285)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025938&CFID=758305256&CFTOKEN=14863114">StretchEBand: Enabling Fabric-based Interactions through Rapid Fabrication of Textile Stretch Sensors</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Anita Vogl, Patrick Parzer, Teo Babic, Joanne Leong, Alex Olwal, Michael Haller 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2617-2627</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025938" title="DOI">10.1145/3025453.3025938</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025938&ftid=1870211&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow286" style="display:inline;"><br /><div style="display:inline">The increased interest in interactive soft materials, such as smart clothing and responsive furniture, means that there is a need for flexible and deformable electronics. In this paper, we focus on stitch-based elastic sensors, which have the benefit ...</div></span>
          <span id="toHide286" style="display:none;"><br /><div style="display:inline"><p>The increased interest in interactive soft materials, such as smart clothing and responsive furniture, means that there is a need for flexible and deformable electronics. In this paper, we focus on stitch-based elastic sensors, which have the benefit of being manufacturable with textile craft tools that have been used in homes for centuries. We contribute to the understanding of stitch-based stretch sensors through four experiments and one user study that investigate conductive yarns from textile and technical perspectives, and analyze the impact of different stitch types and parameters. The insights informed our design of new stretch-based interaction techniques that emphasize eyes-free or causal interactions. We demonstrate with StretchEBand how soft, continuous sensors can be rapidly fabricated with different parameters and capabilities to support interaction with a wide range of performance requirements across wearables, mobile devices, clothing, furniture, and toys.</p></div></span> <a id="expcoll286" href="JavaScript: expandcollapse('expcoll286',286)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Intelligent Visualization Systems</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025866&CFID=758305256&CFTOKEN=14863114">GraphScape: A Model for Automated Reasoning about Visualization Similarity and Sequencing</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Younghoon Kim, Kanit Wongsuphasawat, Jessica Hullman, Jeffrey Heer 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2628-2638</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025866" title="DOI">10.1145/3025453.3025866</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025866&ftid=1870192&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow288" style="display:inline;"><br /><div style="display:inline">We present GraphScape, a directed graph model of the vi- sualization design space that supports automated reasoning about visualization similarity and sequencing. Graph nodes represent grammar-based chart specifications and edges rep- resent edits that ...</div></span>
          <span id="toHide288" style="display:none;"><br /><div style="display:inline"><p>We present GraphScape, a directed graph model of the vi- sualization design space that supports automated reasoning about visualization similarity and sequencing. Graph nodes represent grammar-based chart specifications and edges rep- resent edits that transform one chart to another. We weight edges with an estimated cost of the difficulty of interpreting a target visualization given a source visualization. We con- tribute (1) a method for deriving transition costs via a partial ordering of edit operations and the solution of a resulting lin- ear program, and (2) a global weighting term that rewards consistency across transition subsequences. In a controlled experiment, subjects rated visualization sequences covering a taxonomy of common transition types. In all but one case, GraphScape's highest-ranked suggestion aligns with subjects' top-rated sequences. Finally, we demonstrate applications of GraphScape to automatically sequence visualization presen- tations, elaborate transition paths between visualizations, and recommend design alternatives (e.g., to improve scalability while minimizing design changes).</p></div></span> <a id="expcoll288" href="JavaScript: expandcollapse('expcoll288',288)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3026006&CFID=758305256&CFTOKEN=14863114">GIAnT: Visualizing Group Interaction at Large Wall Displays</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Ulrich von Zadow, Raimund Dachselt 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2639-2647</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3026006" title="DOI">10.1145/3025453.3026006</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3026006&ftid=1870206&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow289" style="display:inline;"><br /><div style="display:inline">Large interactive displays are increasingly important and a relevant research topic, and several studies have focused on wall interaction. However, in many cases, thorough user studies currently require time-consuming video analysis and coding. We present ...</div></span>
          <span id="toHide289" style="display:none;"><br /><div style="display:inline"><p>Large interactive displays are increasingly important and a relevant research topic, and several studies have focused on wall interaction. However, in many cases, thorough user studies currently require time-consuming video analysis and coding. We present the Group Interaction Analysis Toolkit GIAnT, which provides a rich set of visualizations supporting investigation of multi-user interaction at large display walls. GIAnT focuses on visualizing time periods, making it possible to gain overview-level insights quickly. The toolkit is designed to be extensible and features several carefully crafted visualizations: A novel timeline visualization shows movement in front of the wall over time, a wall visualization shows interactions on the wall and gaze data, and a floor visualization displays user positions. In addition, GIAnT shows the captured video stream along with basic statistics. We validate our tool by analyzing how it supports investigating major research topics and by practical use in evaluating a cooperative game.</p></div></span> <a id="expcoll289" href="JavaScript: expandcollapse('expcoll289',289)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025768&CFID=758305256&CFTOKEN=14863114">Voyager 2: Augmenting Visual Analysis with Partial View Specifications</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Kanit Wongsuphasawat, Zening Qu, Dominik Moritz, Riley Chang, Felix Ouk, Anushka Anand, Jock Mackinlay, Bill Howe, Jeffrey Heer 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2648-2659</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025768" title="DOI">10.1145/3025453.3025768</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025768&ftid=1870208&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow290" style="display:inline;"><br /><div style="display:inline">Visual data analysis involves both open-ended and focused exploration. Manual chart specification tools support question answering, but are often tedious for early-stage exploration where systematic data coverage is needed. Visualization recommenders ...</div></span>
          <span id="toHide290" style="display:none;"><br /><div style="display:inline"><p>Visual data analysis involves both open-ended and focused exploration. Manual chart specification tools support question answering, but are often tedious for early-stage exploration where systematic data coverage is needed. Visualization recommenders can encourage broad coverage, but irrelevant suggestions may distract users once they commit to specific questions. We present <i>Voyager 2</i>, a mixed-initiative system that blends manual and automated chart specification to help analysts engage in both open-ended exploration and targeted question answering. We contribute two partial specification interfaces: <i>wildcards</i> let users specify multiple charts in parallel, while <i>related views</i> suggest visualizations relevant to the currently specified chart. We present our interface design and applications of the <i>CompassQL</i> visualization query language to enable these interfaces. In a controlled study we find that Voyager 2 leads to increased data field coverage compared to a traditional specification tool, while still allowing analysts to flexibly drill-down and answer specific questions.</p></div></span> <a id="expcoll290" href="JavaScript: expandcollapse('expcoll290',290)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025752&CFID=758305256&CFTOKEN=14863114">TouchPivot: Blending WIMP &#38; Post-WIMP Interfaces for Data Exploration on Tablet Devices</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Jaemin Jo, Sehi L'Yi, Bongshin Lee, Jinwook Seo 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2660-2671</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025752" title="DOI">10.1145/3025453.3025752</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025752&ftid=1870240&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow291" style="display:inline;"><br /><div style="display:inline">Recent advancements in tablet technology pose a great opportunity for information visualization to expand its horizons beyond desktops. In this paper, we present TouchPivot, a novel interface that assists visual data exploration on tablet devices. With ...</div></span>
          <span id="toHide291" style="display:none;"><br /><div style="display:inline"><p>Recent advancements in tablet technology pose a great opportunity for information visualization to expand its horizons beyond desktops. In this paper, we present TouchPivot, a novel interface that assists visual data exploration on tablet devices. With novices in mind, TouchPivot supports data transformations, such as pivoting and filtering, with simple pen and touch interactions, and facilitates understanding of the transformations through tight coupling between a data table and visualization. We bring in WIMP interfaces to TouchPivot, leveraging their familiarity and accessibility to novices. We report on a user study conducted to compare TouchPivot with two commercial interfaces, Tableau and Microsoft Excel's PivotTable. Our results show that novices not only answered data-driven questions faster, but also created a larger number of meaningful charts during freeform exploration with TouchPivot than others. Finally, we discuss the main hurdles novices encountered during our study and possible remedies for them.</p></div></span> <a id="expcoll291" href="JavaScript: expandcollapse('expcoll291',291)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Mindfulness and Reflection</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025914&CFID=758305256&CFTOKEN=14863114">A Framework for Interactive Mindfulness Meditation Using Attention-Regulation Process</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Kavous Salehzadeh Niksirat, Chaklam Silpasuwanchai, Mahmoud Mohamed Hussien Ahmed, Peng Cheng, Xiangshi Ren 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2672-2684</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025914" title="DOI">10.1145/3025453.3025914</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025914&ftid=1870214&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow293" style="display:inline;"><br /><div style="display:inline">We are often overwhelmed by everyday stressors. Mindfulness meditation can help slow things down and bring one's attention into the present moment. Given the prevalence of smartphones, mindfulness-based mobile applications (MBMAs) have received much ...</div></span>
          <span id="toHide293" style="display:none;"><br /><div style="display:inline"><p>We are often overwhelmed by everyday stressors. Mindfulness meditation can help slow things down and bring one's attention into the present moment. Given the prevalence of smartphones, mindfulness-based mobile applications (MBMAs) have received much attention. Current MBMAs mainly use the guided meditation method which may not be always effective, e.g., users may not be able to follow the pace of instructions and they need a private environment. This paper presents a framework for interactive MBMAs which allows users to self-regulate their attention according to their abilities and conditions. The framework is described by an <i>Attention-Regulation Process</i> and has two components: (1) <i>Relaxation Response</i> and (2) <i>Attention Restoration Theory</i>. The framework is validated by our experiment. It also informs future development for interactive meditation and has broad implications for designing mindfulness and well-being.</p></div></span> <a id="expcoll293" href="JavaScript: expandcollapse('expcoll293',293)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025590&CFID=758305256&CFTOKEN=14863114">Designing Digital Mindfulness: Presence-In and Presence-With versus Presence-Through</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Bin Zhu, Anders Hedman, Haibo Li 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2685-2695</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025590" title="DOI">10.1145/3025453.3025590</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025590&ftid=1870212&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow294" style="display:inline;"><br /><div style="display:inline">The digital health and wellbeing movement has led to development of digital mindfulness applications that aim to help people to become mindful. In this paper we suggest a broad scheme for classifying and ordering apps intended to support mindfulness. ...</div></span>
          <span id="toHide294" style="display:none;"><br /><div style="display:inline"><p>The digital health and wellbeing movement has led to development of digital mindfulness applications that aim to help people to become mindful. In this paper we suggest a broad scheme for classifying and ordering apps intended to support mindfulness. This scheme consists of four levels of what we here term digital mindfulness. One crucial aspect of the fourth level is that artifacts at this level allow for what we term as presence-with and presence-in as opposed to presence-through, which occurs at the first three levels. We articulate our four levels along with specific design qualities through concrete examples of existing mindfulness apps and through research through design (RtD) work conducted with design fiction examples. We then use a working design case prototype to further illustrate the possibilities of presence-with and presence-in. We hope our four levels of digital mindfulness framework will be found useful by other researchers in discussing and planning the design of their own mindfulness apps and digital artifacts.</p></div></span> <a id="expcoll294" href="JavaScript: expandcollapse('expcoll294',294)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/bp_award.jpg" alt="Best Paper" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025516&CFID=758305256&CFTOKEN=14863114">Reflective Practicum: A Framework of Sensitising Concepts to Design for Transformative Reflection</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Petr Slov&#225;k, Christopher Frauenberger, Geraldine Fitzpatrick 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2696-2707</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025516" title="DOI">10.1145/3025453.3025516</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025516&ftid=1870225&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow295" style="display:inline;"><br /><div style="display:inline">Designing for reflection is becoming an increasingly important part of many HCI systems in a wide range of application domains. However, there is a gap in our understanding of how the process of reflection can be supported through technology. In fact, ...</div></span>
          <span id="toHide295" style="display:none;"><br /><div style="display:inline"><p>Designing for reflection is becoming an increasingly important part of many HCI systems in a wide range of application domains. However, there is a gap in our understanding of how the process of reflection can be supported through technology. In fact, an implicit assumption in the majority of existing work is that, just by providing access to well-selected data, in-depth reflection can and will occur. To counter this view, we draw on Sch&#246;n's notion of reflective practicum and apply it as a sensitising concept to identify the complex interplay of factors that support transformative reflection in the context of two social-emotional learning (SEL) studies. The results highlight the need to carefully scaffold the process of reflection, rather than simply assume that the capability to reflect is a broadly available trait to be 'triggered' through data. Building on this analysis, we develop a conceptual framework that extends the concept of the reflective practicum towards identifying appropriate roles of technology to support transformative reflection. While our case is within the context of SEL, we argue that a deeper understanding of these opportunities can also benefit designing for reflection in other areas.</p></div></span> <a id="expcoll295" href="JavaScript: expandcollapse('expcoll295',295)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/bp_award.jpg" alt="Best Paper" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025918&CFID=758305256&CFTOKEN=14863114">mHealth for Maternal Mental Health: Everyday Wisdom in Ethical Design</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Marguerite Barry, Kevin Doherty, Jose Marcano Belisario, Josip Car, Cecily Morrison, Gavin Doherty 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2708-2756</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025918" title="DOI">10.1145/3025453.3025918</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025918&ftid=1870195&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow296" style="display:inline;"><br /><div style="display:inline">Health and wellbeing applications increasingly raise ethical issues for design. User-centred and participatory design approaches, while grounded in everyday wisdom, cannot be expected to address ethical reflection consistently, as multiple value systems ...</div></span>
          <span id="toHide296" style="display:none;"><br /><div style="display:inline"><p>Health and wellbeing applications increasingly raise ethical issues for design. User-centred and participatory design approaches, while grounded in everyday wisdom, cannot be expected to address ethical reflection consistently, as multiple value systems come into play. We explore the potential of phronesis, a concept from Aristotelian virtue ethics, for mHealth design. Phronesis describes wisdom and judgment garnered from practical experience of specific situations in context. Applied phronesis contributes everyday wisdom to challenging issues for vulnerable target users. Drawing on research into mHealth technologies for psychological wellbeing, we explore how phronesis can inform ethical design. Using a case study on an app for self-reporting symptoms of depression during pregnancy, we present a framework for incorporating a phronetic approach into design, involving: (a) a wide feedback net to capture phronetic input early in design; (b) observing the order of feedback, which directly affects value priorities in design; (c) ethical pluralism recognising different coexisting value systems; (d) acknowledging subjectivity in the disclosure and recognition of individual researcher and participant values. We offer insights into how a phronetic approach can contribute everyday wisdom to designing mHealth technologies to help designers foster the values that promote human flourishing.</p></div></span> <a id="expcoll296" href="JavaScript: expandcollapse('expcoll296',296)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Supporting Low Resource Communities</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025470&CFID=758305256&CFTOKEN=14863114">Uncovering the Values and Constraints of Real-time Ridesharing for Low-resource Populations</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Tawanna R. Dillahunt, Vaishnav Kameswaran, Linfeng Li, Tanya Rosenblat 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2757-2769</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025470" title="DOI">10.1145/3025453.3025470</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025470&ftid=1870274&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow298" style="display:inline;"><br /><div style="display:inline">Real-time ridesharing services (e.g., Uber and Lyft) are often touted as sharing-economy leaders and dramatically lower the cost of transportation. However, how to make these services work better among low-income and transportation-scarce households, ...</div></span>
          <span id="toHide298" style="display:none;"><br /><div style="display:inline"><p>Real-time ridesharing services (e.g., Uber and Lyft) are often touted as sharing-economy leaders and dramatically lower the cost of transportation. However, how to make these services work better among low-income and transportation-scarce households, how these individuals experience these services, and whether they encounter barriers in enlisting these services is unknown. To address these questions, we onboarded 13 low-income individuals living in transportation-scarce environments to Uber as passengers. Our participants found these services to be reliable and benefited from rich social interactions with drivers; however, barriers such as cost, limited payment methods, and low digital literacy can make such services infeasible. We contribute platform designs that could lead to increased digital literacy and application transparency. To be more inclusive and to reach critical mass, we suggest that these companies foster belief in commons and community trust by coordinating with local businesses in low-resource areas with lower digital literacy.</p></div></span> <a id="expcoll298" href="JavaScript: expandcollapse('expcoll298',298)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025514&CFID=758305256&CFTOKEN=14863114">Supporting Community Health Workers in India through Voice- and Web-Based Feedback</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Brian DeRenzi, Nicola Dell, Jeremy Wacksman, Scott Lee, Neal Lesh 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2770-2781</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025514" title="DOI">10.1145/3025453.3025514</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025514&ftid=1870246&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow299" style="display:inline;"><br /><div style="display:inline">Our research aims to support community health workers (CHWs) in low-resource settings by providing them with personalized information regarding their work. This information is delivered through a combination of voice- and web-based feedback that is derived ...</div></span>
          <span id="toHide299" style="display:none;"><br /><div style="display:inline"><p>Our research aims to support community health workers (CHWs) in low-resource settings by providing them with personalized information regarding their work. This information is delivered through a combination of voice- and web-based feedback that is derived from data already collected by CHWs. We describe the in situ participatory design approach used to create usable and appropriate feedback for low-literate CHWs and present usage data from a 12-month study with 71 CHWs in India. We show how the system supported and motivated CHWs, and how they used <i>both</i> the web- and voice-based systems, and each of the visualizations, for different reasons. We also show that the comparative feedback provided by the system introduced elements of competition that discouraged some CHWs while motivating others. Taken together, our findings suggest that providing personalized voice- and web-based feedback could be an effective way to support and motivate CHWs in low-resource settings.</p></div></span> <a id="expcoll299" href="JavaScript: expandcollapse('expcoll299',299)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025593&CFID=758305256&CFTOKEN=14863114">We Play We Learn: Exploring the Value of Digital Educational Games in Rural Egypt</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Shaimaa Lazem, Hussein Aly Jad 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2782-2791</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025593" title="DOI">10.1145/3025453.3025593</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025593&ftid=1870271&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow300" style="display:inline;"><br /><div style="display:inline">The Egyptian education system faces urgent challenges. Proposed governmental reforms tend to focus on increasing access to physical and digital resources. There is insufficient understanding as to how the provided resources are currently used in rural ...</div></span>
          <span id="toHide300" style="display:none;"><br /><div style="display:inline"><p>The Egyptian education system faces urgent challenges. Proposed governmental reforms tend to focus on increasing access to physical and digital resources. There is insufficient understanding as to how the provided resources are currently used in rural areas. We explored the extent to which digital technology could motivate primary students to collaboratively learn a challenging topic in the National Mathematics Curriculum. We designed and researched a digital game to support memorizing multiplication facts. We used an incentive structure that encouraged individual learning with rewarding teamwork. The game was tested with mixed ability and gender groups of students using the Teams-Game-Tournament collaboration technique. A key outcome was that the students with educationally disadvantaged backgrounds benefited from using the game format. They devised their own play and study strategies. We discuss implications on future designs of the game, and considerations for its integration in Egyptian schools.</p></div></span> <a id="expcoll300" href="JavaScript: expandcollapse('expcoll300',300)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025958&CFID=758305256&CFTOKEN=14863114">Sidestepping the Elephant in the Classroom: Using Culturally Localized Technology To Teach Around Taboos</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Piya Sorcar, Benjamin Strauber, Prashant Loyalka, Neha Kumar, Shelley Goldman 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2792-2804</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025958" title="DOI">10.1145/3025453.3025958</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025958&ftid=1870282&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow301" style="display:inline;"><br /><div style="display:inline">Cultural taboos can restrict student learning on topics of critical importance. In India, such taboos have led multiple states to ban materials intended to educate youth about HIV, putting millions at risk. We present the design of TeachAIDS, a software ...</div></span>
          <span id="toHide301" style="display:none;"><br /><div style="display:inline"><p>Cultural taboos can restrict student learning on topics of critical importance. In India, such taboos have led multiple states to ban materials intended to educate youth about HIV, putting millions at risk. We present the design of TeachAIDS, a software application that leverages cultural insights, learning science, and affordances of technology to provide comprehensive HIV education while circumventing taboos. Using a mixed-methods evaluation, we demonstrate that this software leaves students with significantly increased knowledge about HIV and reduced stigma toward individuals infected with the virus. Validating the effectiveness of TeachAIDS in circumventing taboos, students report comfort in learning from the software, and it has since been deployed in tens of thousands of schools throughout India. The methodology presented here has broader implications for the design and implementation of interactive technologies for providing education on sensitive topics in health and other areas.</p></div></span> <a id="expcoll301" href="JavaScript: expandcollapse('expcoll301',301)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Technology Augmented Driving</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
  
                  <img src="images/bp_award.jpg" alt="Best Paper" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025929&CFID=758305256&CFTOKEN=14863114">What Can Be Predicted from Six Seconds of Driver Glances?</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Lex Fridman, Heishiro Toyoda, Sean Seaman, Bobbie Seppelt, Linda Angell, Joonbum Lee, Bruce Mehler, Bryan Reimer 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2805-2813</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025929" title="DOI">10.1145/3025453.3025929</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025929&ftid=1870287&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow303" style="display:inline;"><br /><div style="display:inline">We consider a large dataset of real-world, on-road driving from a 100-car naturalistic study to explore the predictive power of driver glances and, specifically, to answer the following question: what can be predicted about the state of the driver and ...</div></span>
          <span id="toHide303" style="display:none;"><br /><div style="display:inline"><p>We consider a large dataset of real-world, on-road driving from a 100-car naturalistic study to explore the predictive power of driver glances and, specifically, to answer the following question: what can be predicted about the state of the driver and the state of the driving environment from a 6-second sequence of macro-glances? The context-based nature of such glances allows for application of supervised learning to the problem of vision-based gaze estimation, making it robust, accurate, and reliable in messy, real-world conditions. So, it's valuable to ask whether such macro-glances can be used to infer behavioral, environmental, and demographic variables? We analyze 27 binary classification problems based on these variables. The takeaway is that glance can be used as part of a multi-sensor real-time system to predict radio-tuning, fatigue state, failure to signal, talking, and several environment variables.</p></div></span> <a id="expcoll303" href="JavaScript: expandcollapse('expcoll303',303)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025634&CFID=758305256&CFTOKEN=14863114">Using Advisory 3D Sound Cues to Improve Drivers' Performance and Situation Awareness</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          MinJuan Wang, Sus Lundgren Lyckvi, Chenhui Chen, Palle Dahlstedt, Fang Chen 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2814-2825</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025634" title="DOI">10.1145/3025453.3025634</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025634&ftid=1870289&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow304" style="display:inline;"><br /><div style="display:inline">Within vehicle Human Machine Interface design, visual displays are predominant, taking up more and more of the visual channel for each new system added to the car, e.g. navigation systems, blind spot information and forward collision warnings. Sounds ...</div></span>
          <span id="toHide304" style="display:none;"><br /><div style="display:inline"><p>Within vehicle Human Machine Interface design, visual displays are predominant, taking up more and more of the visual channel for each new system added to the car, e.g. navigation systems, blind spot information and forward collision warnings. Sounds however, are mainly used to alert or warn drivers together with visual information. In this study we investigated the design of auditory displays for advisory information, by designing a 3D auditory advisory traffic information system (3DAATIS) which was evaluated in a drive simulator study with 30 participants. Our findings indicate that overall, drivers' performance and situation awareness improved when using this system. But, more importantly, the results also point towards the advantages and limitations of the use of advisory 3D-sounds in cars, e.g. attention capture vs. limited auditory resolution. These findings are discussed and expressed as design implications.</p></div></span> <a id="expcoll304" href="JavaScript: expandcollapse('expcoll304',304)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/bp_award.jpg" alt="Best Paper" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025511&CFID=758305256&CFTOKEN=14863114">Designing Gamified Applications that Make Safe Driving More Engaging</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Fabius Steinberger, Ronald Schroeter, Marcus Foth, Daniel Johnson 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2826-2839</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025511" title="DOI">10.1145/3025453.3025511</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025511&ftid=1870266&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow305" style="display:inline;"><br /><div style="display:inline">Low levels of engagement while driving can pose road safety risks, e.g., inattention during low traffic or routine trips. Interactive technologies that increase task engagement could therefore offer safety benefits, e.g., through performance feedback, ...</div></span>
          <span id="toHide305" style="display:none;"><br /><div style="display:inline"><p>Low levels of engagement while driving can pose road safety risks, e.g., inattention during low traffic or routine trips. Interactive technologies that increase task engagement could therefore offer safety benefits, e.g., through performance feedback, increased challenge, and incentives. As a means to build upon these notions, we chose to explore gamification of the driving task. The research aim was to study how to design gamified applications that make safe driving more engaging. We present six design lenses which bring into focus considerations most relevant to creating engaging car applications. A user study enhanced our understanding of design requirements and revealed user personas to support the development of such applications. These lenses and personas informed two prototypes, which we evaluated in driving simulator studies. Our results indicate that the gamified conditions increased driver engagement and reduced driving speeds. As such, our work contributes towards the design of engaging applications that are both appropriate to the safety-critical driving context and compelling to users.</p></div></span> <a id="expcoll305" href="JavaScript: expandcollapse('expcoll305',305)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025713&CFID=758305256&CFTOKEN=14863114">Tunneled In: Drivers with Active Secondary Tasks Need More Time to Transition from Automation</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Brian Mok, Mishel Johns, David Miller, Wendy Ju 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2840-2844</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025713" title="DOI">10.1145/3025453.3025713</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025713&ftid=1870252&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow306" style="display:inline;"><br /><div style="display:inline">In partially automated driving, rapid transitions of control present a severe hazard. How long does it take a driver to take back control of the vehicle when engaged with other non-driving tasks? In this driving simulator study, we examined the performance ...</div></span>
          <span id="toHide306" style="display:none;"><br /><div style="display:inline"><p>In partially automated driving, rapid transitions of control present a severe hazard. How long does it take a driver to take back control of the vehicle when engaged with other non-driving tasks? In this driving simulator study, we examined the performance of participants (N=30) after an abrupt loss of automated vehicle control. We tested three transition time conditions, with an unstructured transition of control occurring 2s, 5s, or 8s before entering a curve. As participants were occupied with an active secondary task (playing a game on a tablet) while the automated driving mode was enabled, they needed to disengage from the task and regain control of the car when the transition occurred. Few drivers in the 2 second condition were able to safely negotiate the road hazard situation, while the majority of drivers in the 5 or 8 second conditions were able to navigate the hazard situation safely.</p></div></span> <a id="expcoll306" href="JavaScript: expandcollapse('expcoll306',306)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025736&CFID=758305256&CFTOKEN=14863114">An Evaluation of Input Controls for In-Car Interactions</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Alexander Ng, Stephen A. Brewster, Frank Beruscha, Wolfgang Krautter 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2845-2852</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025736" title="DOI">10.1145/3025453.3025736</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025736&ftid=1870280&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow307" style="display:inline;"><br /><div style="display:inline">The way drivers operate in-car systems is rapidly changing as traditional physical controls, such as buttons and dials, are being replaced by touchscreens and touch-sensing surfaces. This has the potential to increase driver distraction and error as ...</div></span>
          <span id="toHide307" style="display:none;"><br /><div style="display:inline"><p>The way drivers operate in-car systems is rapidly changing as traditional physical controls, such as buttons and dials, are being replaced by touchscreens and touch-sensing surfaces. This has the potential to increase driver distraction and error as controls may be harder to find and use. This paper presents an in-car, on the road driving study which examined three key types of input controls to investigate their effects: a physical dial, pressure-based input on a touch surface and touch input on a touchscreen. The physical dial and pressure-based input were also evaluated with and without haptic feedback. The study was conducted with users performing a list-based targeting task using the different controls while driving on public roads. Eye-gaze was recorded to measure distraction from the primary task of driving. The results showed that target accuracy was high across all input methods (greater than 94%). Pressure-based targeting was the slowest while directly tapping on the targets was the faster selection method. Pressure-based input also caused the largest number of glances towards to the touchscreen but the duration of each glance was shorter than directly touching the screen. Our study will enable designers to make more appropriate design choices for future in-car interactions.</p></div></span> <a id="expcoll307" href="JavaScript: expandcollapse('expcoll307',307)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Autism, disabilities and assistive technology</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025785&CFID=758305256&CFTOKEN=14863114">When Empathy Is Not Enough: Assessing the Experiences of Autistic Children with Technologies</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Katharina Spiel, Christopher Frauenberger, Eva Hornecker, Geraldine Fitzpatrick 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2853-2864</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025785" title="DOI">10.1145/3025453.3025785</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025785&ftid=1870286&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow309" style="display:inline;"><br /><div style="display:inline">Capturing and describing the multi-faceted experiences autistic children have with technologies provides a unique research challenge. Approaches based on pragmatist notions of experience, which mostly rely on empathy, are particularly limited if used ...</div></span>
          <span id="toHide309" style="display:none;"><br /><div style="display:inline"><p>Capturing and describing the multi-faceted experiences autistic children have with technologies provides a unique research challenge. Approaches based on pragmatist notions of experience, which mostly rely on empathy, are particularly limited if used alone. To address this we have developed an approach that combines Actor-Network Theory and Critical Discourse Analysis. Drawing on this approach, we discuss the experiences autistic children had with technologies resulting from the collaborative design process in the OutsideTheBox project. We construct a holistic picture of the experience by drawing on diverse data sources ranging from interviews to log-data, and most importantly, the first-hand perspective of autistic children. In four case studies, we demonstrate how this approach allowed us to develop unique individual and structural insights into the experiences of autistic children with technology.</p></div></span> <a id="expcoll309" href="JavaScript: expandcollapse('expcoll309',309)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3026014&CFID=758305256&CFTOKEN=14863114">ProCom: Designing and Evaluating a Mobile and Wearable System to Support Proximity Awareness for People with Autism</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          LouAnne E. Boyd, Xinlong Jiang, Gillian R. Hayes 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2865-2877</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3026014" title="DOI">10.1145/3025453.3026014</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3026014&ftid=1870290&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow310" style="display:inline;"><br /><div style="display:inline">People with autism are at risk for social isolation due to differences in their perception and engagement with the social world. In this work, we aim to address one specific concern related to socialization the understanding, awareness, and use of interpersonal ...</div></span>
          <span id="toHide310" style="display:none;"><br /><div style="display:inline"><p>People with autism are at risk for social isolation due to differences in their perception and engagement with the social world. In this work, we aim to address one specific concern related to socialization the understanding, awareness, and use of interpersonal space. Over the course of a year, we iteratively designed and tested a series of concepts for supporting children with autism in perceiving, understanding, and responding to physical proximity with other people. During this process, we developed ProCom, a prototype system for measuring proximity without requiring instrumentation of the environment or another person. We used a variety of low and high fidelity prototypes, culminating in ProCom, to assess the feasibility, utility, and challenges of this approach. The results of these iterative design engagements indicate that wearable assistive technologies can support people in developing awareness of physical proximity in social settings. However, challenges related to both personal and collective use remain</p></div></span> <a id="expcoll310" href="JavaScript: expandcollapse('expcoll310',310)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025790&CFID=758305256&CFTOKEN=14863114">Smartphone-Based Gaze Gesture Communication for People with Motor Disabilities</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Xiaoyi Zhang, Harish Kulkarni, Meredith Ringel Morris 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2878-2889</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025790" title="DOI">10.1145/3025453.3025790</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025790&ftid=1870261&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow311" style="display:inline;"><br /><div style="display:inline">Current eye-tracking input systems for people with ALS or other motor impairments are expensive, not robust under sunlight, and require frequent re-calibration and substantial, relatively immobile setups. Eye-gaze transfer (e-tran) boards, a low-tech ...</div></span>
          <span id="toHide311" style="display:none;"><br /><div style="display:inline"><p>Current eye-tracking input systems for people with ALS or other motor impairments are expensive, not robust under sunlight, and require frequent re-calibration and substantial, relatively immobile setups. Eye-gaze transfer (e-tran) boards, a low-tech alternative, are challenging to master and offer slow communication rates. To mitigate the drawbacks of these two status quo approaches, we created GazeSpeak, an eye gesture communication system that runs on a smartphone, and is designed to be low-cost, robust, portable, and easy-to-learn, with a higher communication bandwidth than an e-tran board. GazeSpeak can interpret eye gestures in real time, decode these gestures into predicted utterances, and facilitate communication, with different user interfaces for speakers and interpreters. Our evaluations demonstrate that GazeSpeak is robust, has good user satisfaction, and provides a speed improvement with respect to an e-tran board; we also identify avenues for further improvement to low-cost, low-effort gaze-based communication technologies.</p></div></span> <a id="expcoll311" href="JavaScript: expandcollapse('expcoll311',311)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025610&CFID=758305256&CFTOKEN=14863114">Exploring the Design Space of AAC Awareness Displays</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Kiley Sobel, Alexander Fiannaca, Jon Campbell, Harish Kulkarni, Ann Paradiso, Ed Cutrell, Meredith Ringel Morris 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2890-2903</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025610" title="DOI">10.1145/3025453.3025610</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025610&ftid=1870288&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow312" style="display:inline;"><br /><div style="display:inline">Augmentative and alternative communication (AAC) devices are a critical technology for people with disabilities that affect their speech. One challenge with AAC systems is their inability to portray aspects of nonverbal communication that typically accent, ...</div></span>
          <span id="toHide312" style="display:none;"><br /><div style="display:inline"><p>Augmentative and alternative communication (AAC) devices are a critical technology for people with disabilities that affect their speech. One challenge with AAC systems is their inability to portray aspects of nonverbal communication that typically accent, complement, regulate, or substitute for verbal speech. In this paper, we explore the design space of awareness displays that can supplement AAC devices, considering their output features and their effects on the perceptions of interlocutors. Through designing prototypes and getting feedback on our designs from people with ALS, their primary caregivers, and other communication partners, we consider (1) the consistent tensions that arose between abstractness and clarity in meaning for these designs and (2) the ways in which these designs can further mark users as "other." Overall, we contribute a generative understanding of designing AAC awareness displays to augment and contextualize communication.</p></div></span> <a id="expcoll312" href="JavaScript: expandcollapse('expcoll312',312)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Big Data Intelligent Visualization Systems</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025456&CFID=758305256&CFTOKEN=14863114">Trust, but Verify: Optimistic Visualizations of Approximate Queries for Exploring Big Data</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Dominik Moritz, Danyel Fisher, Bolin Ding, Chi Wang 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2904-2915</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025456" title="DOI">10.1145/3025453.3025456</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025456&ftid=1870263&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow314" style="display:inline;"><br /><div style="display:inline">Analysts need interactive speed for exploratory analysis, but big data systems are often slow. With sampling, data systems can produce approximate answers fast enough for exploratory visualization, at the cost of accuracy and trust. We propose optimistic ...</div></span>
          <span id="toHide314" style="display:none;"><br /><div style="display:inline"><p>Analysts need interactive speed for exploratory analysis, but big data systems are often slow. With sampling, data systems can produce approximate answers fast enough for exploratory visualization, at the cost of accuracy and trust. We propose optimistic visualization, which approaches these issues from a user experience perspective. This method lets analysts explore approximate results interactively, and provides a way to detect and recover from errors later. Pangloss implements these ideas. We discuss design issues raised by optimistic visualization systems. We test this concept with five expert visualizers in a laboratory study and three case studies at Microsoft. Analysts reported that they felt more confident in their results, and used optimistic visualization to check that their preliminary results were correct.</p></div></span> <a id="expcoll314" href="JavaScript: expandcollapse('expcoll314',314)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025628&CFID=758305256&CFTOKEN=14863114">iSphere: Focus+Context Sphere Visualization for Interactive Large Graph Exploration</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Fan Du, Nan Cao, Yu-Ru Lin, Panpan Xu, Hanghang Tong 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2916-2927</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025628" title="DOI">10.1145/3025453.3025628</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025628&ftid=1870256&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow315" style="display:inline;"><br /><div style="display:inline">Interactive exploration plays a critical role in large graph visualization. Existing techniques, such as zoom-and-pan on a 2D plane and hyperbolic browser facilitate large graph exploration by showing both the details of a focal area and its surrounding ...</div></span>
          <span id="toHide315" style="display:none;"><br /><div style="display:inline"><p>Interactive exploration plays a critical role in large graph visualization. Existing techniques, such as zoom-and-pan on a 2D plane and hyperbolic browser facilitate large graph exploration by showing both the details of a focal area and its surrounding context that guides the exploration process. However, existing techniques for large graph exploration are limited in either providing too little context or presenting graphs with too much distortion. In this paper, we propose a novel focus+context technique, iSphere, to address the limitation. iSphere maps a large graph onto a Riemann Sphere that better preserves graph structures and shows greater context information. We conduct extensive experiment studies on different graph exploration tasks under various conditions. The results show that iSphere performs the best in task completion time compared to the baseline techniques in link and path exploration tasks. This research also contributes to understanding large graph exploration on small screens.</p></div></span> <a id="expcoll315" href="JavaScript: expandcollapse('expcoll315',315)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025868&CFID=758305256&CFTOKEN=14863114">TagRefinery: A Visual Tool for Tag Wrangling</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Christoph Kralj, Mohsen Kamalzadeh, Torsten M&#246;ller 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2928-2939</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025868" title="DOI">10.1145/3025453.3025868</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025868&ftid=1870267&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow316" style="display:inline;"><br /><div style="display:inline">We present TagRefinery, an interactive visual application aiding the cleaning and processing of open tag spaces, such as those in Last.fm or YouTube. Our pre-design analysis showed a need to support a spectrum of user expertise from novice to advanced, ...</div></span>
          <span id="toHide316" style="display:none;"><br /><div style="display:inline"><p>We present TagRefinery, an interactive visual application aiding the cleaning and processing of open tag spaces, such as those in Last.fm or YouTube. Our pre-design analysis showed a need to support a spectrum of user expertise from novice to advanced, which resulted in two distinct interface modes. Summative evaluations of TagRefinery showed that it could effectively guide the novice users through the workflow by giving them brief but helpful explanations on why each step was required, and providing visual and statistical aids to help them in making important decisions. This is while our more expert users greatly appreciated the amount of control and granularity over the workflow that our more advanced interface mode offered. Both the underlying tag cleaning workflow and the interface were designed iteratively in a participatory design process in collaboration with research on a music recommendation interface based on Last.fm tags.</p></div></span> <a id="expcoll316" href="JavaScript: expandcollapse('expcoll316',316)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025801&CFID=758305256&CFTOKEN=14863114">TopoGroups: Context-Preserving Visual Illustration of Multi-Scale Spatial Aggregates</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Jiawei Zhang, Abish Malik, Benjamin Ahlbrand, Niklas Elmqvist, Ross Maciejewski, David S. Ebert 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2940-2951</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025801" title="DOI">10.1145/3025453.3025801</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025801&ftid=1870268&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow317" style="display:inline;"><br /><div style="display:inline">Spatial datasets, such as tweets in a geographic area, often exhibit different distribution patterns at multiple levels of scale, such as live updates about events occurring in very specific locations on the map. Navigating in such multi-scale data-rich ...</div></span>
          <span id="toHide317" style="display:none;"><br /><div style="display:inline"><p>Spatial datasets, such as tweets in a geographic area, often exhibit different distribution patterns at multiple levels of scale, such as live updates about events occurring in very specific locations on the map. Navigating in such multi-scale data-rich spaces is often inefficient, requires users to choose between overview or detail information, and does not support identifying spatial patterns at varying scales. In this paper, we propose TopoGroups, a novel context-preserving technique that aggregates spatial data into hierarchical clusters to improve exploration and navigation at multiple spatial scales. The technique uses a boundary distortion algorithm to minimize the visual clutter caused by overlapping aggregates. Our user study explores multiple visual encoding strategies for TopoGroups including color, transparency, shading, and shapes in order to convey the hierarchical and statistical information of the geographical aggregates at different scales.</p></div></span> <a id="expcoll317" href="JavaScript: expandcollapse('expcoll317',317)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Data as Design Material</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025837&CFID=758305256&CFTOKEN=14863114">A Design Perspective on Data</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Melanie Feinberg 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2952-2963</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025837" title="DOI">10.1145/3025453.3025837</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025837&ftid=1870250&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow319" style="display:inline;"><br /><div style="display:inline">Empirical studies invariably show that data generation is situationally contingent and interpretively flexible, even when data is collected automatically. This essay situates data generation within a design perspective, demonstrating how data creation ...</div></span>
          <span id="toHide319" style="display:none;"><br /><div style="display:inline"><p>Empirical studies invariably show that data generation is situationally contingent and interpretively flexible, even when data is collected automatically. This essay situates data generation within a design perspective, demonstrating how data creation can be understood as a multilayered set of interlocking design activities. By showing how data is infused with design, this paper argues that any "use" of data represents a continuation of its design. We are always designers of data, never its mere appropriators.</p></div></span> <a id="expcoll319" href="JavaScript: expandcollapse('expcoll319',319)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025878&CFID=758305256&CFTOKEN=14863114">Bitbarista: Exploring Perceptions of Data Transactions in the Internet of Things</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Larissa Pschetz, Ella Tallyn, Rory Gianni, Chris Speed 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2964-2975</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025878" title="DOI">10.1145/3025453.3025878</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025878&ftid=1870259&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow320" style="display:inline;"><br /><div style="display:inline">We are surrounded by a proliferation of connected devices performing increasingly complex data transactions. Traditional design methods tend to simplify or conceal this complexity to improve ease of use. However, the hidden nature of data is causing ...</div></span>
          <span id="toHide320" style="display:none;"><br /><div style="display:inline"><p>We are surrounded by a proliferation of connected devices performing increasingly complex data transactions. Traditional design methods tend to simplify or conceal this complexity to improve ease of use. However, the hidden nature of data is causing increasing discomfort. This paper presents BitBarista, a coffee machine designed to explore perceptions of data processes in the Internet of Things. BitBarista reveals social, environmental, qualitative and economic aspects of coffee supply chains. It allows people to choose a source of future coffee beans, situating their choices within the pool of decisions previously made. In doing so, it attempts to engage them in the transactions that are required to produce coffee. Initial studies of BitBarista with 42 participants reveal challenges of designing for connected systems, particularly in terms of perceptions of data gathering and sharing, as well as assumptions generated by current models of consumption. A discussion is followed by a series of suggestions for increasing positive attitudes towards data use in interactive systems.</p></div></span> <a id="expcoll320" href="JavaScript: expandcollapse('expcoll320',320)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3026012&CFID=758305256&CFTOKEN=14863114">Centralized, Parallel, and Distributed Information Processing during Collective Sensemaking</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Peter Krafft, Kaitlyn Zhou, Isabelle Edwards, Kate Starbird, Emma S. Spiro 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2976-2987</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3026012" title="DOI">10.1145/3025453.3026012</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3026012&ftid=1870275&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow321" style="display:inline;"><br /><div style="display:inline">Widespread rumoring can hinder attempts to make sense of what is going on during disaster scenarios. Understanding how and why rumors spread in these contexts could assist in the design of systems that facilitate timely and accurate sensemaking. We address ...</div></span>
          <span id="toHide321" style="display:none;"><br /><div style="display:inline"><p>Widespread rumoring can hinder attempts to make sense of what is going on during disaster scenarios. Understanding how and why rumors spread in these contexts could assist in the design of systems that facilitate timely and accurate sensemaking. We address a basic question in this line: To what extent does rumor evolution occur (1) through reliance on a centralized information source, (2) in parallel information silos, or (3) through a web of complex informational interactions? We develop a conceptual model and associated analysis algorithms that allow us to distinguish between these possibilities. We analyze a case of rumoring on Twitter during the Boston Marathon Bombing. We find that rumor spreading was predominantly a parallel process in this case, which is consistent with a hypothesis that information silos may underlie the persistence of false rumors. Special attention towards detecting and resolving parallel information threads during collective sensemaking may hence be warranted.</p></div></span> <a id="expcoll321" href="JavaScript: expandcollapse('expcoll321',321)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025670&CFID=758305256&CFTOKEN=14863114">Quietto: An Interactive Timepiece Molded in Concrete and Milled Wood</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Kyung-Ryong Lee, Geon-il Goh, Young-Woo Park 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2988-2992</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025670" title="DOI">10.1145/3025453.3025670</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025670&ftid=1870276&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow322" style="display:inline;"><br /><div style="display:inline">We introduce Quietto: an interactive timepiece made of molded concrete and milled wood. It shows upcoming daily schedules and the time through the quiet, ambient motions of a clock hand and light through the concrete touch interface. The results of an ...</div></span>
          <span id="toHide322" style="display:none;"><br /><div style="display:inline"><p>We introduce Quietto: an interactive timepiece made of molded concrete and milled wood. It shows upcoming daily schedules and the time through the quiet, ambient motions of a clock hand and light through the concrete touch interface. The results of an in-field user observation of 10 participants over 3 days showed the possibilities of using concrete as a unique and attractive material for designing a tangible interface due to its unexpected haptic feeling. We also found that Quietto provides an intuitive and effective representation of its users' daily schedules and can be used as a private, personal device. Through its distinctive design, Quietto can provide a new way of understanding scheduling through its concrete texture and amusing interaction qualities.</p></div></span> <a id="expcoll322" href="JavaScript: expandcollapse('expcoll322',322)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025617&CFID=758305256&CFTOKEN=14863114">Locked or Not?: Mental Models of IoT Feature Interaction</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Lana Yarosh, Pamela Zave 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2993-2997</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025617" title="DOI">10.1145/3025453.3025617</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025617&ftid=1870270&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow323" style="display:inline;"><br /><div style="display:inline">Internet of Things (IoT) frequently involves conflicting interactions between devices and features that must be resolved to a single system state. The problem of feature interaction (FI) resolution has been investigated in Software Engineering through ...</div></span>
          <span id="toHide323" style="display:none;"><br /><div style="display:inline"><p>Internet of Things (IoT) frequently involves conflicting interactions between devices and features that must be resolved to a single system state. The problem of feature interaction (FI) resolution has been investigated in Software Engineering through approaches that focus on verifiability but usually do not include the user in the evaluation. This paper bridges the gap between IoT approaches in HCI and Software Engineering by applying qualitative methods to understanding users' mental models of one representative FI resolution mechanism. Our contributions are in identifying common mental model errors and biases and how these may inform future IoT systems and research.</p></div></span> <a id="expcoll323" href="JavaScript: expandcollapse('expcoll323',323)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Designing Gaze-based Gestures and Features</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025601&CFID=758305256&CFTOKEN=14863114">Robust Gaze Features for Enabling Language Proficiency Awareness</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Jakob Karolus, Pawe&#322; W. Wozniak, Lewis L. Chuang, Albrecht Schmidt 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 2998-3010</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025601" title="DOI">10.1145/3025453.3025601</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025601&ftid=1870253&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow325" style="display:inline;"><br /><div style="display:inline">We are often confronted with information interfaces designed in an unfamiliar language, especially in an increasingly globalized world, where the language barrier inhibits interaction with the system. In our work, we explore the design space for building ...</div></span>
          <span id="toHide325" style="display:none;"><br /><div style="display:inline"><p>We are often confronted with information interfaces designed in an unfamiliar language, especially in an increasingly globalized world, where the language barrier inhibits interaction with the system. In our work, we explore the design space for building interfaces that can detect the user's language proficiency. Specifically, we look at how a user's gaze properties can be used to detect whether the interface is presented in a language they understand. We report a study (N=21) where participants were presented with questions in multiple languages, whilst being recorded for gaze behavior. We identified fixation and blink durations to be effective indicators of the participants' language proficiencies. Based on these findings, we propose a classification scheme and technical guidelines for enabling language proficiency awareness on information displays using gaze data.</p></div></span> <a id="expcoll325" href="JavaScript: expandcollapse('expcoll325',325)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025644&CFID=758305256&CFTOKEN=14863114">A Multifaceted Study on Eye Contact based Speaker Identification in Three-party Conversations</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Yu Ding, Yuting Zhang, Meihua Xiao, Zhigang Deng 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3011-3021</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025644" title="DOI">10.1145/3025453.3025644</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025644&ftid=1870272&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow326" style="display:inline;"><br /><div style="display:inline">To precisely understand human gaze behaviors in three-party conversations, this work is dedicated to look into whether the speaker can be reliably identified from the interlocutors in a three-party conversation on the basis of the interactive behaviors ...</div></span>
          <span id="toHide326" style="display:none;"><br /><div style="display:inline"><p>To precisely understand human gaze behaviors in three-party conversations, this work is dedicated to look into whether the speaker can be reliably identified from the interlocutors in a three-party conversation on the basis of the interactive behaviors of eye contact, where speech signals are not provided. Derived from a pre-recorded, multimodal, and three-party conversational behavior dataset, a statistical framework is pro- posed to determine <i>who is the speaker</i> from the interactive behaviors of eye contact. Additionally, with the aid of virtual human technologies, a user study is conducted to study whether subjects are capable of distinguishing the speaker from the listeners according to the gaze behaviors of the interlocutors alone. Our results show that eye contact provides a reliable cue for the identification of the speaker in three-party conversations.</p></div></span> <a id="expcoll326" href="JavaScript: expandcollapse('expcoll326',326)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025920&CFID=758305256&CFTOKEN=14863114">Supporting Making Fixations and the Effect on Gaze Gesture Performance</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Howell Istance, Aulikki I. Hyrskykari 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3022-3033</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025920" title="DOI">10.1145/3025453.3025920</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025920&ftid=1870300&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow327" style="display:inline;"><br /><div style="display:inline">Gaze gestures are deliberate patterns of eye movements that can be used to invoke commands. These are less reliant on accurate measurement and calibration than other gaze-based interaction techniques. These may be used with wearable displays fitted with ...</div></span>
          <span id="toHide327" style="display:none;"><br /><div style="display:inline"><p>Gaze gestures are deliberate patterns of eye movements that can be used to invoke commands. These are less reliant on accurate measurement and calibration than other gaze-based interaction techniques. These may be used with wearable displays fitted with eye tracking capability, or as part of an assistive technology. The visual stimuli in the information on the display that can act as fixation targets may or may not be sparse and will vary over time. The paper describes an experiment to investigate how the amount of information provided on a display to assist making fixations affects gaze gesture performance. The impact of providing visualization guides and small fixation targets on the time to complete gestures and error rates is presented. The number and durations of fixations made during gesture completion is used to explain differences in performance as a result of practice and direction of eye movement.</p></div></span> <a id="expcoll327" href="JavaScript: expandcollapse('expcoll327',327)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025455&CFID=758305256&CFTOKEN=14863114">GazeEverywhere: Enabling Gaze-only User Interaction on an Unmodified Desktop PC in Everyday Scenarios</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Simon Schenk, Marc Dreiser, Gerhard Rigoll, Michael Dorr 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3034-3044</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025455" title="DOI">10.1145/3025453.3025455</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025455&ftid=1870248&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow328" style="display:inline;"><br /><div style="display:inline">Eye tracking is becoming more and more affordable, and thus gaze has the potential to become a viable input modality for human-computer interaction. We present the GazeEverywhere solution that can replace the mouse with gaze control by adding a transparent ...</div></span>
          <span id="toHide328" style="display:none;"><br /><div style="display:inline"><p>Eye tracking is becoming more and more affordable, and thus gaze has the potential to become a viable input modality for human-computer interaction. We present the GazeEverywhere solution that can replace the mouse with gaze control by adding a transparent layer on top of the system GUI. It comprises three parts: i) the SPOCK interaction method that is based on smooth pursuit eye movements and does not suffer from the Midas touch problem; ii) an online recalibration algorithm that continuously improves gaze-tracking accuracy using the SPOCK target projections as reference points; and iii) an optional hardware setup utilizing head-up display technology to project superimposed dynamic stimuli onto the PC screen where a software modification of the system is not feasible. In validation experiments, we show that GazeEverywhere's throughput according to ISO 9241-9 was improved over dwell time based interaction methods and nearly reached trackpad level. Online recalibration reduced interaction target ('button') size by about 25%. Finally, a case study showed that users were able to browse the internet and successfully run Wikirace using gaze only, without any plug-ins or other modifications.</p></div></span> <a id="expcoll328" href="JavaScript: expandcollapse('expcoll328',328)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Enabling Healthy Behaviors</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3026054&CFID=758305256&CFTOKEN=14863114">Trajectories of Engagement and Disengagement with a Story-Based Smoking Cessation App</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Wally Smith, Bernd Ploderer, Greg Wadley, Sarah Webber, Ron Borland 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3045-3056</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3026054" title="DOI">10.1145/3025453.3026054</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3026054&ftid=1870298&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow330" style="display:inline;"><br /><div style="display:inline">Strong user engagement with digital technologies for behaviour change is often taken as a precursor to their longer-term efficacy. We critically examine this assumption through a qualitative study of a smoking cessation app, called NewLeaf, which allows ...</div></span>
          <span id="toHide330" style="display:none;"><br /><div style="display:inline"><p>Strong user engagement with digital technologies for behaviour change is often taken as a precursor to their longer-term efficacy. We critically examine this assumption through a qualitative study of a smoking cessation app, called NewLeaf, which allows quitters to swap personal stories. The study examined what influenced people to engage or disengage with NewLeaf, and how the app was deployed in quit attempts during a four week trial. Several properties of swapped stories were reported to promote engagement, including: authenticity, currency, contextualization of advice, and evoking a sense of community. But while the resulting engagement was sometimes productive in supporting quitting, other trajectories of use were observed involving counterproductive engagement, and a surprising pattern of productive disengagement especially among stronger quitters. We discuss how this analysis of different trajectories problematizes any simple interpretation of user engagement as an early indicator of success for behaviour change technologies.</p></div></span> <a id="expcoll330" href="JavaScript: expandcollapse('expcoll330',330)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025725&CFID=758305256&CFTOKEN=14863114">Lessons from Practice: Designing Tools to Facilitate Individualized Support for Quitting Smoking</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Arpita Bhattacharya, Roger Vilardaga, Julie A. Kientz, Sean A. Munson 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3057-3070</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025725" title="DOI">10.1145/3025453.3025725</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025725&ftid=1870264&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow331" style="display:inline;"><br /><div style="display:inline">Many health care providers, with a variety of trainings, counsel clients on quitting smoking on a day-to-day basis. In their clinical practice, they draw from and adapt guidelines and research-based strategies to fit individual client situations and ...</div></span>
          <span id="toHide331" style="display:none;"><br /><div style="display:inline"><p>Many health care providers, with a variety of trainings, counsel clients on quitting smoking on a day-to-day basis. In their clinical practice, they draw from and adapt guidelines and research-based strategies to fit individual client situations and challenges. Designers of technologies to support quitting smoking can learn from these real world practices to create tools that better adapt to individual differences. We present findings from interviews with 28 providers with diverse experiences in smoking cessation counselling. Through analysis of their individualization strategies, challenges, and perceptions of technology, we find that providers: (1) individualize context appropriate coping strategies by involving clients in brainstorming, (2) emphasize the need to support nicotine withdrawal in clients, (3) mitigate social triggers and mediate social support for clients, and (4) need to navigate dependencies with other providers for managing medications and comorbid health conditions of clients. With this empirical understanding, we extend the discussion on the design of technology to support quitting smoking, highlight current barriers to individualization, and suggest future opportunities to address these barriers.</p></div></span> <a id="expcoll331" href="JavaScript: expandcollapse('expcoll331',331)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3026013&CFID=758305256&CFTOKEN=14863114">Toward Usable Evidence: Optimizing Knowledge Accumulation in HCI Research on Health Behavior Change</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Predrag Klasnja, Eric B. Hekler, Elizabeth V. Korinek, John Harlow, Sonali R. Mishra 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3071-3082</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3026013" title="DOI">10.1145/3025453.3026013</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3026013&ftid=1870251&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow332" style="display:inline;"><br /><div style="display:inline">Over the last ten years, HCI researchers have introduced a range of novel ways to support health behavior change, from glanceable displays to sophisticated game dynamics. Yet, this research has not had as much impact as its originality warrants. A key ...</div></span>
          <span id="toHide332" style="display:none;"><br /><div style="display:inline"><p>Over the last ten years, HCI researchers have introduced a range of novel ways to support health behavior change, from glanceable displays to sophisticated game dynamics. Yet, this research has not had as much impact as its originality warrants. A key reason for this is that common forms of evaluation used in HCI make it difficult to effectively accumulate-and use-knowledge across research projects. This paper proposes a strategy for HCI research on behavior change that retains the field's focus on novel technical contributions while enabling accumulation of evidence that can increase impact of individual research projects both in HCI and the broader behavior-change science. The core of this strategy is an emphasis on the discovery of causal effects of individual components of behavior-change technologies and the precise ways in which those effects vary with individual differences, design choices, and contexts in which those technologies are used.</p></div></span> <a id="expcoll332" href="JavaScript: expandcollapse('expcoll332',332)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Haptics on Skin</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025501&CFID=758305256&CFTOKEN=14863114">Investigating Haptic Perception of and Physiological Responses to Air Vortex Rings on a User's Cheek</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Yuka Sato, Ryoko Ueoka 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3083-3094</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025501" title="DOI">10.1145/3025453.3025501</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025501&ftid=1870291&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow334" style="display:inline;"><br /><div style="display:inline">Haptic perception is one of the primary means of interaction with the world. Recent research on affective haptics suggests that it can affect emotional and behavioral responses. In this study, we evaluate user perceptions of haptic stimuli generated ...</div></span>
          <span id="toHide334" style="display:none;"><br /><div style="display:inline"><p>Haptic perception is one of the primary means of interaction with the world. Recent research on affective haptics suggests that it can affect emotional and behavioral responses. In this study, we evaluate user perceptions of haptic stimuli generated by air vortex rings on the cheek and investigate the effects on their physiological responses. To develop a cheek haptic display, we investigated and found that the cheek had enough resolution to perceive the differences in haptic stimuli in a two-point discrimination threshold test of the face. Additionally, the intensities of the haptic stimuli for experiments were determined by investigating the subjective impressions of different stimuli pairs. Finally, we conducted experiments to evaluate quantitatively the effects of four different combinations of haptic stimuli on the physiological responses in terms of stress modification, brainwave activities, task performance, and subjective assessment. The results suggest that different stimuli affect physiological responses and task performance.</p></div></span> <a id="expcoll334" href="JavaScript: expandcollapse('expcoll334',334)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025704&CFID=758305256&CFTOKEN=14863114">SkinMarks: Enabling Interactions on Body Landmarks Using Conformal Skin Electronics</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Martin Weigel, Aditya Shekhar Nittala, Alex Olwal, J&#252;rgen Steimle 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3095-3105</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025704" title="DOI">10.1145/3025453.3025704</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025704&ftid=1870249&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow335" style="display:inline;"><br /><div style="display:inline">The body provides many recognizable landmarks due to the underlying skeletal structure and variations in skin texture, elasticity, and color. The visual and spatial cues of such body landmarks can help in localizing on-body interfaces, guide input on ...</div></span>
          <span id="toHide335" style="display:none;"><br /><div style="display:inline"><p>The body provides many recognizable landmarks due to the underlying skeletal structure and variations in skin texture, elasticity, and color. The visual and spatial cues of such body landmarks can help in localizing on-body interfaces, guide input on the body, and allow for easy recall of mappings. Our main contribution are SkinMarks, novel skin-worn I/O devices for precisely localized input and output on fine body landmarks. SkinMarks comprise skin electronics on temporary rub-on tattoos. They conform to fine wrinkles and are compatible with strongly curved and elastic body locations. We identify five types of body landmarks and demonstrate novel interaction techniques that leverage SkinMarks' unique touch, squeeze and bend sensing with integrated visual output. Finally, we detail on the conformality and evaluate sub-millimeter electrodes for touch sensing. Taken together, SkinMarks expands the on-body interaction space to more detailed, highly curved and challenging areas on the body.</p></div></span> <a id="expcoll335" href="JavaScript: expandcollapse('expcoll335',335)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025703&CFID=758305256&CFTOKEN=14863114">tactoRing: A Skin-Drag Discrete Display</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Seungwoo Je, Brendan Rooney, Liwei Chan, Andrea Bianchi 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3106-3114</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025703" title="DOI">10.1145/3025453.3025703</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025703&ftid=1870293&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow336" style="display:inline;"><br /><div style="display:inline">Smart rings are an emerging wearable technology particularly suitable for discrete notifications based on haptic cues. Previous work mostly focused on tactile actuators that stimulate only specific skin receptors on the finger, resulting in limited information ...</div></span>
          <span id="toHide336" style="display:none;"><br /><div style="display:inline"><p>Smart rings are an emerging wearable technology particularly suitable for discrete notifications based on haptic cues. Previous work mostly focused on tactile actuators that stimulate only specific skin receptors on the finger, resulting in limited information expressiveness. We propose tactoRing, a novel tactile display that, by dragging a small tactor on the skin around the finger, excites multiple skin areas resulting in more accurate cue recognition. In this paper, we present the hardware and a perception study to understand the ability of users to recognize eight distinct points around the finger. Moreover, we show two different techniques to encode information through skin-dragging motion with accuracy up to 94%. We finally showcase a set of applications that, by combining sequences of tactile stimuli, achieve higher expressiveness than prior methods.</p></div></span> <a id="expcoll336" href="JavaScript: expandcollapse('expcoll336',336)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/bp_award.jpg" alt="Best Paper" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025744&CFID=758305256&CFTOKEN=14863114">Fingertip Tactile Devices for Virtual Object Manipulation and Exploration</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Samuel B. Schorr, Allison M. Okamura 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3115-3119</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025744" title="DOI">10.1145/3025453.3025744</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025744&ftid=1870244&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow337" style="display:inline;"><br /><div style="display:inline">One of the main barriers to immersivity during object manipulation in virtual reality is the lack of realistic haptic feedback. Our goal is to convey compelling interactions with virtual objects, such as grasping, squeezing, pressing, lifting, and stroking, ...</div></span>
          <span id="toHide337" style="display:none;"><br /><div style="display:inline"><p>One of the main barriers to immersivity during object manipulation in virtual reality is the lack of realistic haptic feedback. Our goal is to convey compelling interactions with virtual objects, such as grasping, squeezing, pressing, lifting, and stroking, without requiring a bulky, world-grounded kinesthetic feedback device (traditional haptics) or the use of predetermined passive objects (haptic retargeting). To achieve this, we use a pair of finger-mounted haptic feedback devices that deform the skin on the fingertips to convey cutaneous force information from object manipulation. We show that users can perceive differences in virtual object weight and that they apply increasing grasp forces when lifting virtual objects as rendered mass is increased. Moreover, we show how naive users perceive changes of a virtual object's physical properties when we use skin deformation to render objects with varying mass, friction, and stiffness. These studies demonstrate that fingertip skin deformation devices can provide a compelling haptic experience appropriate for virtual reality scenarios involving object manipulation.</p></div></span> <a id="expcoll337" href="JavaScript: expandcollapse('expcoll337',337)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025759&CFID=758305256&CFTOKEN=14863114">BrushTouch: Exploring an Alternative Tactile Method for Wearable Haptics</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Evan Strasnick, Jessica R. Cauchard, James A. Landay 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3120-3125</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025759" title="DOI">10.1145/3025453.3025759</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025759&ftid=1870283&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow338" style="display:inline;"><br /><div style="display:inline">Haptic interfaces are ideal in situations where visual/auditory attention is impossible, unsafe, or socially unacceptable. However, conventional (vibrotactile) wearable interfaces often possess a limited bandwidth for expressing information. We explore ...</div></span>
          <span id="toHide338" style="display:none;"><br /><div style="display:inline"><p>Haptic interfaces are ideal in situations where visual/auditory attention is impossible, unsafe, or socially unacceptable. However, conventional (vibrotactile) wearable interfaces often possess a limited bandwidth for expressing information. We explore a novel form of tactile stimulation through brushing, and demonstrate BrushTouch, a wearable prototype for brushing haptics. We also present schemes for conveying information such as time and direction through multi-tactor wrist-worn haptic interfaces. To evaluate BrushTouch, two user studies were run, comparing it to a conventional vibrotactile wristband across a number of tasks in both lab and mobile conditions. We show that for certain cues brushing can be more accurately recognized than vibration, enabling more effective spatial schemes for presenting information through haptic means. We then show that BrushTouch is capable of greater information transfer using such cues. We believe that brushing, as with other non-vibrotactile haptic techniques, merits further investigation as potential vehicles for richer haptic feedback.</p></div></span> <a id="expcoll338" href="JavaScript: expandcollapse('expcoll338',338)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>HCI and Collective Action</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025490&CFID=758305256&CFTOKEN=14863114">HCI, Solidarity Movements and the Solidarity Economy</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Vasillis Vlachokyriakos, Clara Crivellaro, Pete Wright, Evika Karamagioli, Eleni-Revekka Staiou, Dimitris Gouscos, Rowan Thorpe, Antonio Kr&#252;ger, Johannes Sch&#246;ning, Matt Jones, Shaun Lawson, Patrick Olivier 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3126-3137</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025490" title="DOI">10.1145/3025453.3025490</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025490&ftid=1870262&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow340" style="display:inline;"><br /><div style="display:inline">The financial crisis and austerity politics in Europe has had a devastating impact on public services, social security and vulnerable populations. Greek civil society responded quickly by establishing solidarity structures aimed at helping vulnerable ...</div></span>
          <span id="toHide340" style="display:none;"><br /><div style="display:inline"><p>The financial crisis and austerity politics in Europe has had a devastating impact on public services, social security and vulnerable populations. Greek civil society responded quickly by establishing solidarity structures aimed at helping vulnerable citizens to meet their basic needs and empower them to co-create an anti-austerity movement. While digital technology and social media played an important role in the initiation of the movement, it has a negligible role in the movement's on-going practices. Through embedded work with several solidarity structures in Greece, we have begun to understand the "solidarity economy" (SE) as an experiment in direct democracy and self-organization. Working with a range of solidarity structures we are developing a vision for a "Solidarity HCI" committed to designing to support personal, social and institutional transformation through processes of agonistic pluralism and contestation, where the aims and objectives of the SE are continuously re-formulated and put into practice.</p></div></span> <a id="expcoll340" href="JavaScript: expandcollapse('expcoll340',340)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025667&CFID=758305256&CFTOKEN=14863114">Environmental Protection and Agency: Motivations, Capacity, and Goals in Participatory Sensing</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Paul Aoki, Allison Woodruff, Baladitya Yellapragada, Wesley Willett 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3138-3150</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025667" title="DOI">10.1145/3025453.3025667</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025667&ftid=1870278&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow341" style="display:inline;"><br /><div style="display:inline">In this paper we consider various genres of citizen science from the perspective of citizen participants. As a mode of scientific inquiry, citizen science has the potential to "scale up" scientific data collection efforts and increase lay engagement ...</div></span>
          <span id="toHide341" style="display:none;"><br /><div style="display:inline"><p>In this paper we consider various genres of citizen science from the perspective of citizen participants. As a mode of scientific inquiry, citizen science has the potential to "scale up" scientific data collection efforts and increase lay engagement with science. However, current technological directions risk losing sight of the ways in which citizen science is actually practiced. As citizen science is increasingly used to describe a wide range of activities, we begin by presenting a framework of citizen science genres. We then present findings from four interlocking qualitative studies and technological interventions of community air quality monitoring efforts, examining the motivations and capacities of citizen participants and characterizing their alignment with different types of citizen science. Based on these studies, we suggest that data acquisition involves complex multi-dimensional tradeoffs, and the commonly held view that citizen science systems are a win-win for citizens and science may be overstated.</p></div></span> <a id="expcoll341" href="JavaScript: expandcollapse('expcoll341',341)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025627&CFID=758305256&CFTOKEN=14863114">Providing Online Crisis Information: An Analysis of Official Sources during the 2014 Carlton Complex Wildfire</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Apoorva Chauhan, Amanda L. Hughes 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3151-3162</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025627" title="DOI">10.1145/3025453.3025627</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025627&ftid=1870296&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow342" style="display:inline;"><br /><div style="display:inline">Using the 2014 Carlton Complex Wildfire as a case study, we examine who contributes official information online during a crisis event, and the timeliness and relevance of the information provided. We identify and describe the communication behaviors ...</div></span>
          <span id="toHide342" style="display:none;"><br /><div style="display:inline"><p>Using the 2014 Carlton Complex Wildfire as a case study, we examine who contributes official information online during a crisis event, and the timeliness and relevance of the information provided. We identify and describe the communication behaviors of four types of official information sources (Event Based Resources, Local Responders, Local News Media, and Cooperating Agencies), and collect message data from each source's website, public Facebook page, and/or Twitter account. The data show that the Local News Media provided the highest quantity of relevant information and the timeliest information. Event Based Resources shared the highest percentage of relevant information, however, it was often unclear who managed these resources and the credibility of the information. Based on these findings, we offer suggestions for how providers of official crisis information might better manage their online communications and ways that the public can find more timely and relevant online crisis information from official sources.</p></div></span> <a id="expcoll342" href="JavaScript: expandcollapse('expcoll342',342)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025659&CFID=758305256&CFTOKEN=14863114">"Algorithms ruin everything": #RIPTwitter, Folk Theories, and Resistance to Algorithmic Change in Social Media</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Michael A. DeVito, Darren Gergle, Jeremy Birnholtz 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3163-3174</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025659" title="DOI">10.1145/3025453.3025659</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025659&ftid=1870257&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow343" style="display:inline;"><br /><div style="display:inline">As algorithmically-driven content curation has become an increasingly common feature of social media platforms, user resistance to algorithmic change has become more frequent and visible. These incidents of user backlash point to larger issues such as ...</div></span>
          <span id="toHide343" style="display:none;"><br /><div style="display:inline"><p>As algorithmically-driven content curation has become an increasingly common feature of social media platforms, user resistance to algorithmic change has become more frequent and visible. These incidents of user backlash point to larger issues such as inaccurate understandings of how algorithmic systems work as well as mismatches between designer and user intent. Using a content analysis of 102,827 tweets from #RIPTwitter, a recent hashtag-based backlash to rumors about introducing algorithmic curation to Twitter's timeline, this study addresses the nature of user resistance in the form of the complaints being expressed, folk theories of the algorithmic system espoused by users, and how these folk theories potentially frame user reactions. We find that resistance to algorithmic change largely revolves around expectation violation, with folk theories acting as frames for reactions such that more detailed folk theories are expressed through more specific reactions to algorithmic change.</p></div></span> <a id="expcoll343" href="JavaScript: expandcollapse('expcoll343',343)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Online Content</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3026018&CFID=758305256&CFTOKEN=14863114">The Bag of Communities: Identifying Abusive Behavior Online with Preexisting Internet Data</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Eshwar Chandrasekharan, Mattia Samory, Anirudh Srinivasan, Eric Gilbert 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3175-3187</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3026018" title="DOI">10.1145/3025453.3026018</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3026018&ftid=1870247&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow345" style="display:inline;"><br /><div style="display:inline">Since its earliest days, harassment and abuse have plagued the Internet. Recent research has focused on in-domain methods to detect abusive content and faces several challenges, most notably the need to obtain large training corpora. In this paper, we ...</div></span>
          <span id="toHide345" style="display:none;"><br /><div style="display:inline"><p>Since its earliest days, harassment and abuse have plagued the Internet. Recent research has focused on in-domain methods to detect abusive content and faces several challenges, most notably the need to obtain large training corpora. In this paper, we introduce a novel computational approach to address this problem called Bag of Communities (BoC)---a technique that leverages large-scale, preexisting data from other Internet communities. We then apply BoC toward identifying abusive behavior within a major Internet community. Specifically, we compute a post's similarity to 9 other communities from 4chan, Reddit, Voat and MetaFilter. We show that a BoC model can be used on communities "off the shelf" with roughly 75% accuracy---no training examples are needed from the target community. A dynamic BoC model achieves 91.18% accuracy after seeing 100,000 human-moderated posts, and uniformly outperforms in-domain methods. Using this conceptual and empirical work, we argue that the BoC approach may allow communities to deal with a range of common problems, like abusive behavior, faster and with fewer engineering resources.</p></div></span> <a id="expcoll345" href="JavaScript: expandcollapse('expcoll345',345)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025631&CFID=758305256&CFTOKEN=14863114">PersaLog: Personalization of News Article Content</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Eytan Adar, Carolyn Gearig, Ayshwarya Balasubramanian, Jessica Hullman 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3188-3200</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025631" title="DOI">10.1145/3025453.3025631</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025631&ftid=1870273&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow346" style="display:inline;"><br /><div style="display:inline">Content personalization automatically modifying text and multimedia features within articles based on the reader's individual features'is evolving as a new form of journalism. Informed by constraints articulated through a survey of journalists, ...</div></span>
          <span id="toHide346" style="display:none;"><br /><div style="display:inline"><p><i>Content personalization</i> automatically modifying text and multimedia features <i>within</i> articles based on the reader's individual features'is evolving as a new form of journalism. Informed by constraints articulated through a survey of journalists, we have implemented PersaLog, a novel system for creating personalized content (e.g., text and interactive visualizations). Because crafting, and validating, personalized content can be challenging to scale across articles (unlike feed personalization), we offer a simple Domain Specific Language (DSL), and editing environment, to support this task. PersaLog is particularly designed to support the personalization of existing text and visualizations. Our work provides guidelines for personalization as well as a system that allows for both subtle and dramatic personalization-driven content changes. We validate PersaLog using case and lab studies.</p></div></span> <a id="expcoll346" href="JavaScript: expandcollapse('expcoll346',346)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/bp_award.jpg" alt="Best Paper" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3026011&CFID=758305256&CFTOKEN=14863114">You Want Me to Work with <i>Who</i>?: Stakeholder Perceptions of Automated Team Formation in Project-based Courses</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Farnaz Jahanbakhsh, Wai-Tat Fu, Karrie Karahalios, Darko Marinov, Brian Bailey 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3201-3212</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3026011" title="DOI">10.1145/3025453.3026011</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3026011&ftid=1870245&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow347" style="display:inline;"><br /><div style="display:inline">Instructors are increasingly using algorithmic tools for team formation, yet little is known about how these tools are applied or how students and instructors perceive their use. We studied a representative team formation tool (CATME) in eight project-based ...</div></span>
          <span id="toHide347" style="display:none;"><br /><div style="display:inline"><p>Instructors are increasingly using algorithmic tools for team formation, yet little is known about how these tools are applied or how students and instructors perceive their use. We studied a representative team formation tool (CATME) in eight project-based courses. An instructor uses the tool to form teams by surveying students' working styles, skills, and demographics; then configuring these criteria as input into an algorithm that assigns teams. We surveyed students (N=277) in the courses to gauge their perceptions of the strengths and weaknesses of the tool and ideas for improving it. We also interviewed instructors (N=13) different from those who taught the eight courses to learn about their criteria selections and perceptions of the tool. Students valued the rational basis for forming teams but desired a stronger voice in criteria selection and explanations as to why they were assigned to a particular team. Instructors appreciated the efficiency of team formation but wanted to view exemplars of criteria used in similar courses. This work contributes recommendations for deploying team formation tools in educational settings and for better satisfying the goals of all stakeholders.</p></div></span> <a id="expcoll347" href="JavaScript: expandcollapse('expcoll347',347)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025985&CFID=758305256&CFTOKEN=14863114">Multimodal Classification of Moderated Online Pro-Eating Disorder Content</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Stevie Chancellor, Yannis Kalantidis, Jessica A. Pater, Munmun De Choudhury, David A. Shamma 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3213-3226</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025985" title="DOI">10.1145/3025453.3025985</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025985&ftid=1870281&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow348" style="display:inline;"><br /><div style="display:inline">Social media sites are challenged by both the scale and variety of deviant behavior online. While algorithms can detect spam and obscenity, behaviors that break community guidelines on some sites are difficult because they have multimodal subtleties ...</div></span>
          <span id="toHide348" style="display:none;"><br /><div style="display:inline"><p>Social media sites are challenged by both the scale and variety of deviant behavior online. While algorithms can detect spam and obscenity, behaviors that break community guidelines on some sites are difficult because they have multimodal subtleties (images and/or text). Identifying these posts is often regulated to a few moderators. In this paper, we develop a deep learning classifier that jointly models textual and visual characteristics of pro-eating disorder content that violates community guidelines. Using a million Tumblr photo posts, our classifier discovers deviant content efficiently while also maintaining high recall (85%). Our approach uses human sensitivity throughout to guide the creation, curation, and understanding of this approach to challenging, deviant content. We discuss how automation might impact community moderation, and the ethical and social obligations of this area.</p></div></span> <a id="expcoll348" href="JavaScript: expandcollapse('expcoll348',348)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Pens, Ink, Input</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025664&CFID=758305256&CFTOKEN=14863114"><i>WritLarge</i>: Ink Unleashed by Unified Scope, Action, &#38; Zoom</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Haijun Xia, Ken Hinckley, Michel Pahud, Xiao Tu, Bill Buxton 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3227-3240</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025664" title="DOI">10.1145/3025453.3025664</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025664&ftid=1870292&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow350" style="display:inline;"><br /><div style="display:inline">WritLarge is a freeform canvas for early-stage design on electronic whiteboards with pen+touch input. The system aims to support a higher-level flow of interaction by 'chunking' the traditionally disjoint steps of selection and action ...</div></span>
          <span id="toHide350" style="display:none;"><br /><div style="display:inline"><p><i>WritLarge</i> is a freeform canvas for early-stage design on electronic whiteboards with pen+touch input. The system aims to support a higher-level flow of interaction by 'chunking' the traditionally disjoint steps of <i>selection</i> and <i>action</i> into unified <i>selection-action</i> phrases. This holistic goal led us to address two complementary aspects: SELECTION, for which we devise a new technique known as the <i>Zoom-Catcher</i> that integrates pinch-to-zoom and selection in a single gesture for fluidly selecting and acting on content; plus: ACTION, where we demonstrate how this addresses the combined issues of navigating, selecting, and manipulating content. In particular, the designer can transform select ink strokes in flexible and easily-reversible representations via <i>semantic, structural</i>, and <i>temporal</i> axes of movement that are defined as conceptual 'moves' relative to the specified content.</p> <p>This approach dovetails zooming with lightweight specification of scope as well as the evocation of context-appropriate commands, at-hand, in a location-independent manner. This establishes powerful new primitives that can help to scaffold higher-level tasks, thereby unleashing the expressive power of ink in a compelling manner.</p></div></span> <a id="expcoll350" href="JavaScript: expandcollapse('expcoll350',350)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025716&CFID=758305256&CFTOKEN=14863114">As We May Ink?: Learning from Everyday Analog Pen Use to Improve Digital Ink Experiences</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Yann Riche, Nathalie Henry Riche, Ken Hinckley, Sheri Panabaker, Sarah Fuelling, Sarah Williams 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3241-3253</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025716" title="DOI">10.1145/3025453.3025716</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025716&ftid=1870260&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow351" style="display:inline;"><br /><div style="display:inline">This paper sheds light on gaps and discrepancies between the experiences afforded by analog pens and their digital counterparts. Despite the long history (and recent renaissance) of digital pens, the literature still lacks a comprehensive survey of what ...</div></span>
          <span id="toHide351" style="display:none;"><br /><div style="display:inline"><p>This paper sheds light on gaps and discrepancies between the experiences afforded by analog pens and their digital counterparts. Despite the long history (and recent renaissance) of digital pens, the literature still lacks a comprehensive survey of what types of marks people make and what motivates them to use ink-both analog and digital in daily life. To capture the diversity of inking behaviors and tease out the unique affordances of pen-and ink, we conducted a diary study with 26 participants from diverse backgrounds. From analysis of 493 diary entries we identified 8 analog pen-and-ink activities, and 9 affordances of pens. We contextualized and contrasted these findings using a survey with 1,633 respondents and a follow-up diary study with 30 participants, observing digital pens. Our analysis reveals gaps and research opportunities based on pen affordances not yet fully explored in the literature.</p></div></span> <a id="expcoll351" href="JavaScript: expandcollapse('expcoll351',351)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025567&CFID=758305256&CFTOKEN=14863114">Thumb + Pen Interaction on Tablets</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Ken Pfeuffer, Ken Hinckley, Michel Pahud, Bill Buxton 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3254-3266</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025567" title="DOI">10.1145/3025453.3025567</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025567&ftid=1870295&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow352" style="display:inline;"><br /><div style="display:inline">Modern tablets support simultaneous pen and touch input, but it remains unclear how to best leverage this capability for bimanual input when the nonpreferred hand holds the tablet. We explore Thumb + Pen interactions that support simultaneous pen and ...</div></span>
          <span id="toHide352" style="display:none;"><br /><div style="display:inline"><p>Modern tablets support simultaneous pen and touch input, but it remains unclear how to best leverage this capability for bimanual input when the nonpreferred hand holds the tablet. We explore Thumb + Pen interactions that support simultaneous pen and touch interaction, with both hands, in such situations. Our approach engages the thumb of the device-holding hand, such that the thumb interacts with the touch screen in an <i>indirect</i> manner, thereby complementing the <i>direct</i> input provided by the preferred hand. For instance, the thumb can determine how pen actions (articulated with the opposite hand) are interpreted. Alternatively, the pen can point at an object, while the thumb manipulates one or more of its parameters through indirect touch. Our techniques integrate concepts in a novel way that derive from marking menus, spring-loaded modes, indirect input, and multi-touch conventions. Our overall approach takes the form of a set of probes, each representing a meaningfully distinct class of application. They serve as an initial exploration of the design space at a level which will help determine the feasibility of supporting bimanual interaction in such contexts, and the viability of the Thumb + Pen techniques in so doing.</p></div></span> <a id="expcoll352" href="JavaScript: expandcollapse('expcoll352',352)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025865&CFID=758305256&CFTOKEN=14863114">Experimental Analysis of Mode Switching Techniques in Touch-based User Interfaces</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Hemant Bhaskar Surale, Fabrice Matulic, Daniel Vogel 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3267-3280</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025865" title="DOI">10.1145/3025453.3025865</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025865&ftid=1870297&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow353" style="display:inline;"><br /><div style="display:inline">This paper presents the results of a 36 participant empirical comparison of touch mode-switching. Six techniques are evaluated, spanning current and future techniques: long press, non-dominant hand, two-fingers, hard press, knuckle, and thumb-on-finger. ...</div></span>
          <span id="toHide353" style="display:none;"><br /><div style="display:inline"><p>This paper presents the results of a 36 participant empirical comparison of touch mode-switching. Six techniques are evaluated, spanning current and future techniques: long press, non-dominant hand, two-fingers, hard press, knuckle, and thumb-on-finger. Two poses are controlled for, seated with the tablet on a desk and standing with the tablet held on the forearm. Findings indicate pose has no effect on mode switching time and little effect on error rate; using two-fingers is fastest while long press is much slower; non-preferred hand and thumb-on-finger also rate highly in subjective scores. The experiment protocol is based on Li et al.'s pen mode-switching study, enabling a comparison of touch and pen mode switching. Among the common techniques, the non-dominant hand is faster than pressure with touch, whereas no significant difference had been found for pen. Our work addresses the lack of empirical evidence comparing touch mode-switching techniques and provides guidance to practitioners when choosing techniques and to researchers when designing new mode-switching methods.</p></div></span> <a id="expcoll353" href="JavaScript: expandcollapse('expcoll353',353)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Sensing and Input</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025605&CFID=758305256&CFTOKEN=14863114">ForceEdge: Controlling Autoscroll on Both Desktop and Mobile Computers Using the Force</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Axel Antoine, Sylvain Malacria, G&#233;ry Casiez 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3281-3292</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025605" title="DOI">10.1145/3025453.3025605</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025605&ftid=1870294&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow355" style="display:inline;"><br /><div style="display:inline">Operating systems support autoscroll to allow users to scroll a view while in dragging mode: the user moves the pointer near the window's edge to trigger an "automatic" scrolling whose rate is typically proportional to the distance between the pointer ...</div></span>
          <span id="toHide355" style="display:none;"><br /><div style="display:inline"><p>Operating systems support autoscroll to allow users to scroll a view while in dragging mode: the user moves the pointer near the window's edge to trigger an "automatic" scrolling whose rate is typically proportional to the distance between the pointer and the window's edge. This approach suffers from several problems, especially when the window is maximized, resulting in a very limited space around it. Another problem is that for some operations, such as object drag-and-drop, the source and destination might be located in different windows, making it complicated for the computer to understand user's intention. In this paper, we present ForceEdge, a novel autoscroll technique relying on touch surfaces with force-sensing capabilities to alleviate the problems related to autoscroll. We report on the results of three controlled experiments showing that it improves over macOS and iOS systems baselines for top-to-bottom select and move tasks.</p></div></span> <a id="expcoll355" href="JavaScript: expandcollapse('expcoll355',355)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025808&CFID=758305256&CFTOKEN=14863114">Finding Common Ground: A Survey of Capacitive Sensing in Human-Computer Interaction</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Tobias Grosse-Puppendahl, Christian Holz, Gabe Cohn, Raphael Wimmer, Oskar Bechtold, Steve Hodges, Matthew S. Reynolds, Joshua R. Smith 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3293-3315</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025808" title="DOI">10.1145/3025453.3025808</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025808&ftid=1870269&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow356" style="display:inline;"><br /><div style="display:inline">For more than two decades, capacitive sensing has played a prominent role in human-computer interaction research. Capacitive sensing has become ubiquitous on mobile, wearable, and stationary devices - enabling fundamentally new interaction techniques ...</div></span>
          <span id="toHide356" style="display:none;"><br /><div style="display:inline"><p>For more than two decades, capacitive sensing has played a prominent role in human-computer interaction research. Capacitive sensing has become ubiquitous on mobile, wearable, and stationary devices - enabling fundamentally new interaction techniques on, above, and around them. The research community has also enabled human position estimation and whole-body gestural interaction in instrumented environments. However, the broad field of capacitive sensing research has become fragmented by different approaches and terminology used across the various domains. This paper strives to unify the field by advocating consistent terminology and proposing a new taxonomy to classify capacitive sensing approaches. Our extensive survey provides an analysis and review of past research and identifies challenges for future work. We aim to create a common understanding within the field of human-computer interaction, for researchers and practitioners alike, and to stimulate and facilitate future research in capacitive sensing.</p></div></span> <a id="expcoll356" href="JavaScript: expandcollapse('expcoll356',356)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025829&CFID=758305256&CFTOKEN=14863114">bioSync: A Paired Wearable Device for Blending Kinesthetic Experience</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Jun Nishida, Kenji Suzuki 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3316-3327</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025829" title="DOI">10.1145/3025453.3025829</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025829&ftid=1870277&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow357" style="display:inline;"><br /><div style="display:inline">We present a novel, paired, wearable system for combining the kinesthetic experiences of two persons. These devices allow users to sense and combine muscle contraction and joint rigidity bi-directionally. This is achieved through kinesthetic channels ...</div></span>
          <span id="toHide357" style="display:none;"><br /><div style="display:inline"><p>We present a novel, paired, wearable system for combining the kinesthetic experiences of two persons. These devices allow users to sense and combine muscle contraction and joint rigidity bi-directionally. This is achieved through kinesthetic channels based on electromyogram (EMG) measurement and electrical muscle stimulation (EMS). We developed a pair of wearable kinesthetic input-output (I/O) devices called bioSync that uses specially designed electrodes to perform biosignal measurement and stimulation simultaneously on the same electrodes.</p> <p>In a user study, participants successfully evaluated the strength of their partners' muscle contractions while exerting their own muscles. We confirmed that the pair of devices could help participants synchronize their hand movements through tapping, without visual and auditory feedback. The proposed interpersonal kinesthetic communication system can be used to enhance interactions such as clinical gait rehabilitation and sports training, and facilitate sharing of physical experiences with Parkinson's patients, thereby enhancing understanding of the physical challenges they face in daily life.</p></div></span> <a id="expcoll357" href="JavaScript: expandcollapse('expcoll357',357)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025523&CFID=758305256&CFTOKEN=14863114">Modeling Cumulative Arm Fatigue in Mid-Air Interaction based on Perceived Exertion and Kinetics of Arm Motion</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Sujin Jang, Wolfgang Stuerzlinger, Satyajit Ambike, Karthik Ramani 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3328-3339</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025523" title="DOI">10.1145/3025453.3025523</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025523&ftid=1870285&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow358" style="display:inline;"><br /><div style="display:inline">Quantifying cumulative arm muscle fatigue is a critical factor in understanding, evaluating, and optimizing user experience during prolonged mid-air interaction. A reasonably accurate estimation of fatigue requires an estimate of an individual's strength. ...</div></span>
          <span id="toHide358" style="display:none;"><br /><div style="display:inline"><p>Quantifying cumulative arm muscle fatigue is a critical factor in understanding, evaluating, and optimizing user experience during prolonged mid-air interaction. A reasonably accurate estimation of fatigue requires an estimate of an individual's strength. However, there is no easy-to-access method to measure individual strength to accommodate inter-individual differences. Furthermore, fatigue is influenced by both psychological and physiological factors, but no current HCI model provides good estimates of cumulative subjective fatigue. We present a new, simple method to estimate the maximum shoulder torque through a mid-air pointing task, which agrees with direct strength measurements. We then introduce a cumulative fatigue model informed by subjective and biomechanical measures. We evaluate the performance of the model in estimating cumulative subjective fatigue in mid-air interaction by performing multiple cross-validations and a comparison with an existing fatigue metric. Finally, we discuss the potential of our approach for real-time evaluation of subjective fatigue as well as future challenges.</p></div></span> <a id="expcoll358" href="JavaScript: expandcollapse('expcoll358',358)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Social Justice</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025532&CFID=758305256&CFTOKEN=14863114">Women's Safety in Public Spaces: Examining the Efficacy of Panic Buttons in New Delhi</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Naveena Karusala, Neha Kumar 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3340-3351</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025532" title="DOI">10.1145/3025453.3025532</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025532&ftid=1870254&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow360" style="display:inline;"><br /><div style="display:inline">We present a qualitative inquiry through the lens of feminist Human-Computer Interaction (HCI) into women's perceptions of personal safety in New Delhi, India. Since a brutal gang-rape incident took place in Delhi in December 2012 and received global ...</div></span>
          <span id="toHide360" style="display:none;"><br /><div style="display:inline"><p>We present a qualitative inquiry through the lens of feminist Human-Computer Interaction (HCI) into women's perceptions of personal safety in New Delhi, India. Since a brutal gang-rape incident took place in Delhi in December 2012 and received global attention, women's safety has been the focus of much attention India-wide. In April 2016, the Indian government issued a mandate that all mobile phones sold in India 2017 onwards must include a panic button for women's safety. We draw on interview and survey data to examine women's responses to the mandate, also investigating what factors influence their perceptions of safety, positively and negatively. Our findings indicate that women's sense of safety may be deconstructed into a multitude of factors--personal, public, social, technological--that must align for this sense of safety to be preserved. We then discuss the implications these factors have for the success and (re-)design of the panic button and similar interventions.</p></div></span> <a id="expcoll360" href="JavaScript: expandcollapse('expcoll360',360)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025615&CFID=758305256&CFTOKEN=14863114">Technologies and Social Justice Outcomes in Sex Work Charities: Fighting Stigma, Saving Lives</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Angelika Strohmayer, Mary Laing, Rob Comber 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3352-3364</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025615" title="DOI">10.1145/3025453.3025615</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025615&ftid=1870301&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow361" style="display:inline;"><br /><div style="display:inline">Sex workers' rights are human rights, and as such are an issue inherently based in social, criminal, and political justice debates. As HCI continues to move towards feminist and social justice oriented research and design approaches, we argue that we ...</div></span>
          <span id="toHide361" style="display:none;"><br /><div style="display:inline"><p>Sex workers' rights are human rights, and as such are an issue inherently based in social, criminal, and political justice debates. As HCI continues to move towards feminist and social justice oriented research and design approaches, we argue that we need to take into consideration the difficulties faced by sex workers; and explore how technology can and does mediate social justice outcomes for them. We contribute directly to this challenge by providing an empirical account of a charity whose work is built on the underlying move towards social and criminal justice for sex workers in the UK. Through ethnographic fieldwork, meetings, interviews, surveys, and creative workshops we describe the different points of view associated with the charity from a variety of stakeholders. We discuss their service provision and the ways in which HCI is uniquely positioned to be able respond to the needs of and to support sex work support services.</p></div></span> <a id="expcoll361" href="JavaScript: expandcollapse('expcoll361',361)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025884&CFID=758305256&CFTOKEN=14863114">A Human-Centered Approach to Algorithmic Services: Considerations for Fair and Motivating Smart Community Service Management that Allocates Donations to Non-Profit Organizations</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Min Kyung Lee, Ji Tae Kim, Leah Lizarondo 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3365-3376</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025884" title="DOI">10.1145/3025453.3025884</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025884&ftid=1870258&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow362" style="display:inline;"><br /><div style="display:inline">Algorithms are increasingly being incorporated into diverse services that orchestrate multiple stakeholders' needs and interests. How can we design these algorithmic services to make decisions that are not only efficient, but also fair and motivating? ...</div></span>
          <span id="toHide362" style="display:none;"><br /><div style="display:inline"><p>Algorithms are increasingly being incorporated into diverse services that orchestrate multiple stakeholders' needs and interests. How can we design these algorithmic services to make decisions that are not only efficient, but also fair and motivating? We take a human-centered approach to identify and address challenges in building human-centered algorithmic services. We are in the process of building an allocation algorithm for 412 Food Rescue, an organization that matches food donations with non-profit organizations. As part of this ongoing project, we conducted interviews with multiple stakeholders in the service-organization staff, donors, volunteers, recipient non-profits and their clients, and everyday citizens-in order to understand how the allocation algorithm, interfaces, and surrounding work practices should be designed. The findings suggest that we need to understand and account for varying fairness notions held by stakeholders; consider people, contexts, and interfaces for algorithms to work fairly in the real world; and preserve meaningfulness and social interaction in automation in order to build fair and motivating algorithmic services.</p></div></span> <a id="expcoll362" href="JavaScript: expandcollapse('expcoll362',362)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025921&CFID=758305256&CFTOKEN=14863114">Class Confessions: Restorative Properties in Online Experiences of Socioeconomic Stigma</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Eugenia Ha Rim Rho, Oliver L. Haimson, Nazanin Andalibi, Melissa Mazmanian, Gillian R. Hayes 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3377-3389</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025921" title="DOI">10.1145/3025453.3025921</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025921&ftid=1870255&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow363" style="display:inline;"><br /><div style="display:inline">In this paper, we examine stigma related to class identity online through an empirical examination of Elite University Class Confessions (EUCC). EUCC is an online space that includes a Facebook page and a surrounding sociotechnical ecosystem. It is a ...</div></span>
          <span id="toHide363" style="display:none;"><br /><div style="display:inline"><p>In this paper, we examine stigma related to class identity online through an empirical examination of Elite University Class Confessions (EUCC). EUCC is an online space that includes a Facebook page and a surrounding sociotechnical ecosystem. It is a community of, for, and about low-income and first generation students at an elite university. By bringing in a community that learns and engages with users' socioeconomic struggles, EUCC engenders unique restorative properties for students experiencing class stigma. EUCC's restorative properties foster new ways of understanding one's stigmatized identity through meaning- making interactions in a networked sociotechnical system. We discuss how EUCC's design shapes the nature of user interactions around class stigma, and explore in depth how people experience stigma differently through the restorative properties of EUCC.</p></div></span> <a id="expcoll363" href="JavaScript: expandcollapse('expcoll363',363)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Wild Methods</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025990&CFID=758305256&CFTOKEN=14863114">Activitity as the Ultimate Particular of Interaction Design</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Annika Waern, Jon Back 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3390-3402</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025990" title="DOI">10.1145/3025453.3025990</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025990&ftid=1870284&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow365" style="display:inline;"><br /><div style="display:inline">In the turn towards practice-oriented research in interaction design, one of the most important proposals has been the emphasis on the 'ultimate particulars' produced by design, as embodiments of design knowledge. In current HCI research, those particulars ...</div></span>
          <span id="toHide365" style="display:none;"><br /><div style="display:inline"><p>In the turn towards practice-oriented research in interaction design, one of the most important proposals has been the emphasis on the 'ultimate particulars' produced by design, as embodiments of design knowledge. In current HCI research, those particulars are almost always taken to be 'things' artefacts or singular systems. We argue that this emphasis may have come at a cost that can be described as a loss of identity; interaction design research was never primarily concerned with the design of artefacts, but with how humans act and interact with each other with and through artefacts. We propose a complementary perspective by looking at design projects and traditions where the 'ultimate particulars' can be considered to be activities rather than things. The article is concerned with how knowledge needs to be articulated in the scholarly engagement with such design practices. We argue that engagement with activity-centric design gets design research one step closer towards understanding salient contemporary design practices and what Buchanan calls 'environmental design'.</p></div></span> <a id="expcoll365" href="JavaScript: expandcollapse('expcoll365',365)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025534&CFID=758305256&CFTOKEN=14863114">Intuition in Design: Reflections on the Iterative Aesthetics of Form</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Haakon Faste 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3403-3413</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025534" title="DOI">10.1145/3025453.3025534</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025534&ftid=1870279&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow366" style="display:inline;"><br /><div style="display:inline">Curious to reflect on the factors contributing to the internal decision-making processes of intuitive design, a reflective study was established to systematically examine and document the practice of intuition while performing an iterative aesthetic ...</div></span>
          <span id="toHide366" style="display:none;"><br /><div style="display:inline"><p>Curious to reflect on the factors contributing to the internal decision-making processes of intuitive design, a reflective study was established to systematically examine and document the practice of intuition while performing an iterative aesthetic task. Autoethnographic techniques were used to document the reflective practices that occurred over numerous iterations spanning several weeks of activity. Our analysis concludes with a summary of reflections on how intuition informs judgment in design cognition. We examine four dimensions of intuition in design - efficiency, inspiration, curiosity, and insight - and the reflective and sensory inputs that drive intuitive speculation and impulse.</p></div></span> <a id="expcoll366" href="JavaScript: expandcollapse('expcoll366',366)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/bp_award.jpg" alt="Best Paper" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025598&CFID=758305256&CFTOKEN=14863114">Understanding Public Evaluation: Quantifying Experimenter Intervention</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Julie R. Williamson, John Williamson 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3414-3425</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025598" title="DOI">10.1145/3025453.3025598</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025598&ftid=1870299&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow367" style="display:inline;"><br /><div style="display:inline">Public evaluations are popular because some research questions can only be answered by turning "to the wild." Different approaches place experimenters in different roles during deployment, which has implications for the kinds of data that can be collected ...</div></span>
          <span id="toHide367" style="display:none;"><br /><div style="display:inline"><p>Public evaluations are popular because some research questions can only be answered by turning "to the wild." Different approaches place experimenters in different roles during deployment, which has implications for the kinds of data that can be collected and the potential bias introduced by the experimenter. This paper expands our understanding of how experimenter roles impact public evaluations and provides an empirical basis to consider different evaluation approaches. We completed an evaluation of a playful gesture-controlled display not to understand interaction at the display but to compare different evaluation approaches. The conditions placed the experimenter in three roles, steward observer, overt observer, and covert observer, to measure the effect of experimenter presence and analyse the strengths and weaknesses of each approach.</p></div></span> <a id="expcoll367" href="JavaScript: expandcollapse('expcoll367',367)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025798&CFID=758305256&CFTOKEN=14863114">Challenges in Public Display Deployments: A Taxonomy of External Factors</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Ville M&#228;kel&#228;, Sumita Sharma, Jaakko Hakulinen, Tomi Heimonen, Markku Turunen 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3426-3475</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025798" title="DOI">10.1145/3025453.3025798</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025798&ftid=1870265&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow368" style="display:inline;"><br /><div style="display:inline">Public display deployments are often subjected to various surprising and unwanted effects. These effects are frequently due to external factors properties and phenomena that are unrelated to the deployment. Therefore, we conducted a literature review ...</div></span>
          <span id="toHide368" style="display:none;"><br /><div style="display:inline"><p>Public display deployments are often subjected to various surprising and unwanted effects. These effects are frequently due to external factors properties and phenomena that are unrelated to the deployment. Therefore, we conducted a literature review within the public display domain to investigate the causes behind the reported issues. This work presents a taxonomy of external factors affecting deployments, consisting of six categories: weather, events, surroundings, space, inhabitants, and vandalism. Apart from a few positive examples, we predominantly found negative effects arising from these factors. We then identified four ways of addressing the effects: ignoring, adapting, solving, and embracing. Of these, ignoring and adapting are substantially more frequent responses than solving and embracing emphasizing the need for researchers to adapt. We present real-world examples and insights on how researchers and practitioners can address the effects to better manage their deployments.</p></div></span> <a id="expcoll368" href="JavaScript: expandcollapse('expcoll368',368)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Chatbot Interfaces</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025919&CFID=758305256&CFTOKEN=14863114">Typefaces and the Perception of Humanness in Natural Language Chatbots</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Heloisa Candello, Claudio Pinhanez, Flavio Figueiredo 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3476-3487</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025919" title="DOI">10.1145/3025453.3025919</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025919&ftid=1870339&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow370" style="display:inline;"><br /><div style="display:inline">How much do visual aspects influence the perception of users about whether they are conversing with a human being or a machine in a mobile-chat environment? This paper describes a study on the influence of typefaces using a blind Turing test-inspired ...</div></span>
          <span id="toHide370" style="display:none;"><br /><div style="display:inline"><p>How much do visual aspects influence the perception of users about whether they are conversing with a human being or a machine in a mobile-chat environment? This paper describes a study on the influence of typefaces using a blind Turing test-inspired approach. The study consisted of two user experiments. First, three different typefaces (OCR, Georgia, Helvetica) and three neutral dialogues between a human and a financial adviser were shown to participants. The second experiment applied the same study design but OCR font was substituted by Bradley font. For each of our two independent experiments, participants were shown three dialogue transcriptions and three typefaces counterbalanced. For each dialogue typeface pair, participants had to classify adviser conversations as human or chatbot-like. The results showed that machine-like typefaces biased users towards perceiving the adviser as machines but, unexpectedly, handwritten-like typefaces had not the opposite effect. Those effects were, however, influenced by the familiarity of the user to artificial intelligence and other participants' characteristics.</p></div></span> <a id="expcoll370" href="JavaScript: expandcollapse('expcoll370',370)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025830&CFID=758305256&CFTOKEN=14863114">"Could You Define That in Bot Terms"?: Requesting, Creating and Using Bots on Reddit</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Kiel Long, John Vines, Selina Sutton, Phillip Brooker, Tom Feltwell, Ben Kirman, Julie Barnett, Shaun Lawson 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3488-3500</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025830" title="DOI">10.1145/3025453.3025830</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025830&ftid=1870738&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow371" style="display:inline;"><br /><div style="display:inline">Bots are estimated to account for well over half of all web traffic, yet they remain an understudied topic in HCI. In this paper we present the findings of an analysis of 2284 submissions across three discussion groups dedicated to the request, creation ...</div></span>
          <span id="toHide371" style="display:none;"><br /><div style="display:inline"><p>Bots are estimated to account for well over half of all web traffic, yet they remain an understudied topic in HCI. In this paper we present the findings of an analysis of 2284 submissions across three discussion groups dedicated to the request, creation and discussion of bots on Reddit. We set out to examine the qualities and functionalities of bots and the practical and social challenges surrounding their creation and use. Our findings highlight the prevalence of misunderstandings around the capabilities of bots, misalignments in discourse between novices who request and more expert members who create them, and the prevalence of requests that are deemed to be inappropriate for the Reddit community. In discussing our findings, we suggest future directions for the design and development of tools that support more carefully guided and reflective approaches to bot development for novices, and tools to support exploring the consequences of contextually-inappropriate bot ideas.</p></div></span> <a id="expcoll371" href="JavaScript: expandcollapse('expcoll371',371)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025649&CFID=758305256&CFTOKEN=14863114">Response Times when Interpreting Artificial Subtle Expressions are Shorter than with Human-like Speech Sounds</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Takanori Komatsu, Kazuki Kobayashi, Seiji Yamada, Kotaro Funakoshi, Mikio Nakano 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3501-3505</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025649" title="DOI">10.1145/3025453.3025649</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025649&ftid=1870335&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow372" style="display:inline;"><br /><div style="display:inline">Artificial subtle expressions (ASEs) are machine-like expressions used to convey a system's confidence level to users intuitively. In this paper, we focus on the cognitive loads of users in interpreting ASEs in this study. Specifically, we assume that ...</div></span>
          <span id="toHide372" style="display:none;"><br /><div style="display:inline"><p>Artificial subtle expressions (ASEs) are machine-like expressions used to convey a system's confidence level to users intuitively. In this paper, we focus on the cognitive loads of users in interpreting ASEs in this study. Specifically, we assume that a shorter response time indicates less cognitive load, and we hypothesize that users will show a shorter response time when interpreting ASEs compared with speech sounds. We succeeded in verifying our hypothesis in a web-based investigation done to comprehend participants' cognitive loads by measuring their response times in interpreting ASEs and speeches.</p></div></span> <a id="expcoll372" href="JavaScript: expandcollapse('expcoll372',372)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025496&CFID=758305256&CFTOKEN=14863114">A New Chatbot for Customer Service on Social Media</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Anbang Xu, Zhe Liu, Yufan Guo, Vibha Sinha, Rama Akkiraju 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3506-3510</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025496" title="DOI">10.1145/3025453.3025496</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025496&ftid=1870727&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow373" style="display:inline;"><br /><div style="display:inline">Users are rapidly turning to social media to request and receive customer service; however, a majority of these requests were not addressed timely or even not addressed at all. To overcome the problem, we create a new conversational system to automatically ...</div></span>
          <span id="toHide373" style="display:none;"><br /><div style="display:inline"><p>Users are rapidly turning to social media to request and receive customer service; however, a majority of these requests were not addressed timely or even not addressed at all. To overcome the problem, we create a new conversational system to automatically generate responses for users requests on social media. Our system is integrated with state-of-the-art deep learning techniques and is trained by nearly 1M Twitter conversations between users and agents from over 60 brands. The evaluation reveals that over 40% of the requests are emotional, and the system is about as good as human agents in showing empathy to help users cope with emotional situations. Results also show our system outperforms information retrieval system based on both human judgments and an automatic evaluation metric.</p></div></span> <a id="expcoll373" href="JavaScript: expandcollapse('expcoll373',373)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Collaborative Crowdwork</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025781&CFID=758305256&CFTOKEN=14863114">CrowdVerge: Predicting If People Will Agree on the Answer to a Visual Question</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Danna Gurari, Kristen Grauman 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3511-3522</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025781" title="DOI">10.1145/3025453.3025781</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025781&ftid=1870741&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow375" style="display:inline;"><br /><div style="display:inline">Visual question answering systems empower users to ask any question about any image and receive a valid answer. However, existing systems do not yet account for the fact that a visual question can lead to a single answer or multiple different answers. ...</div></span>
          <span id="toHide375" style="display:none;"><br /><div style="display:inline"><p>Visual question answering systems empower users to ask any question about any image and receive a valid answer. However, existing systems do not yet account for the fact that a visual question can lead to a single answer or multiple different answers. While a crowd often agrees, disagreements do arise for many reasons including that visual questions are ambiguous, subjective, or difficult. We propose a model, CrowdVerge, for automatically predicting from a visual question whether a crowd would agree on one answer. We then propose how to exploit these predictions in a novel application to efficiently collect all valid answers to visual questions. Specifically, we solicit fewer human responses when answer agreement is expected and more human responses otherwise. Experiments on 121,811 visual questions asked by sighted and blind people show that, compared to existing crowdsourcing systems, our system captures the same answer diversity with typically 14-23% less crowd involvement.</p></div></span> <a id="expcoll375" href="JavaScript: expandcollapse('expcoll375',375)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/bp_award.jpg" alt="Best Paper" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025811&CFID=758305256&CFTOKEN=14863114">Flash Organizations: Crowdsourcing Complex Work by Structuring Crowds As Organizations</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Melissa A. Valentine, Daniela Retelny, Alexandra To, Negar Rahmati, Tulsee Doshi, Michael S. Bernstein 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3523-3537</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025811" title="DOI">10.1145/3025453.3025811</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025811&ftid=1870338&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow376" style="display:inline;"><br /><div style="display:inline">This paper introduces flash organizations: crowds structured like organizations to achieve complex and open-ended goals. Microtask workflows, the dominant crowdsourcing structures today, only enable goals that are so simple and modular that their path ...</div></span>
          <span id="toHide376" style="display:none;"><br /><div style="display:inline"><p>This paper introduces flash organizations: crowds structured like organizations to achieve complex and open-ended goals. Microtask workflows, the dominant crowdsourcing structures today, only enable goals that are so simple and modular that their path can be entirely pre-defined. We present a system that organizes crowd workers into computationally-represented structures inspired by those used in organizations - roles, teams, and hierarchies - which support emergent and adaptive coordination toward open-ended goals. Our system introduces two technical contributions: 1) encoding the crowd's division of labor into de-individualized roles, much as movie crews or disaster response teams use roles to support coordination between on-demand workers who have not worked together before; and 2) reconfiguring these structures through a model inspired by version control, enabling continuous adaptation of the work and the division of labor. We report a deployment in which flash organizations successfully carried out open-ended and complex goals previously out of reach for crowdsourcing, including product design, software development, and game production. This research demonstrates digitally networked organizations that flexibly assemble and reassemble themselves from a globally distributed online workforce to accomplish complex work.</p></div></span> <a id="expcoll376" href="JavaScript: expandcollapse('expcoll376',376)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025867&CFID=758305256&CFTOKEN=14863114">Facilitating Pervasive Community Policing on the Road with Mobile Roadwatch</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Sangkeun Park, Emilia-Stefania Ilincai, Jeungmin Oh, Sujin Kwon, Rabeb Mizouni, Uichin Lee 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3538-3550</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025867" title="DOI">10.1145/3025453.3025867</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025867&ftid=1870334&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow377" style="display:inline;"><br /><div style="display:inline">We consider community policing on the road with pervasive recording technologies such as dashcams and smartphones where citizens are actively volunteering to capture and report various threats to traffic safety to the police via mobile apps. This kind ...</div></span>
          <span id="toHide377" style="display:none;"><br /><div style="display:inline"><p>We consider community policing on the road with pervasive recording technologies such as dashcams and smartphones where citizens are actively volunteering to capture and report various threats to traffic safety to the police via mobile apps. This kind of novel community policing has recently gained significant popularity in Korea and India. In this work, we identify people's general attitude and concerns toward community policing on the road through an online survey. We then address the major concerns by building a mobile app that supports easy event capture/access, context tagging, and privacy preservation. Our two-week user study (n = 23) showed Roadwatch effectively supported community policing activities on the road. Further, we found that the critical factors for reporting are personal involvement and seriousness of risks, and participants were mainly motivated by their contribution to traffic safety. Finally, we discuss several practical design implications to facilitate community policing on the road.</p></div></span> <a id="expcoll377" href="JavaScript: expandcollapse('expcoll377',377)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025969&CFID=758305256&CFTOKEN=14863114">ReTool: Interactive Microtask and Workflow Design through Demonstration</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Chen Chen, Xiaojun Meng, Shengdong Zhao, Morten Fjeld 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3551-3556</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025969" title="DOI">10.1145/3025453.3025969</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025969&ftid=1870739&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow378" style="display:inline;"><br /><div style="display:inline">In addition to simple form filling, there is an increasing need for crowdsourcing workers to perform freeform interactions directly on content in microtask crowdsourcing (e.g. proofreading articles or specifying object boundary in an image). Such microtasks ...</div></span>
          <span id="toHide378" style="display:none;"><br /><div style="display:inline"><p>In addition to simple form filling, there is an increasing need for crowdsourcing workers to perform freeform interactions directly on content in microtask crowdsourcing (e.g. proofreading articles or specifying object boundary in an image). Such microtasks are often organized within well-designed workflows to optimize task quality and workload distribution. However, designing and implementing the interface and workflow for such microtasks is challenging because it typically requires programming knowledge and tedious manual effort. We present ReTool, a web-based tool for requesters to design and publish interactive microtasks and workflows by demonstrating the microtasks for text and image content. We evaluated ReTool against a task-design tool from a popular crowdsourcing platform and showed the advantages of ReTool over the existing approach.</p></div></span> <a id="expcoll378" href="JavaScript: expandcollapse('expcoll378',378)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Contextual Smartwatch Use</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025538&CFID=758305256&CFTOKEN=14863114">Always On(line)?: User Experience of Smartwatches and their Role within Multi-Device Ecologies</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Marta E. Cecchinato, Anna L. Cox, Jon Bird 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3557-3568</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025538" title="DOI">10.1145/3025453.3025538</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025538&ftid=1870305&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow380" style="display:inline;"><br /><div style="display:inline">Users have access to a growing ecosystem of devices (desktop, mobile and wearable) that can deliver notifications and help people to stay in contact. Smartwatches are gaining popularity, yet little is known about the user experience and their impact ...</div></span>
          <span id="toHide380" style="display:none;"><br /><div style="display:inline"><p>Users have access to a growing ecosystem of devices (desktop, mobile and wearable) that can deliver notifications and help people to stay in contact. Smartwatches are gaining popularity, yet little is known about the user experience and their impact on our increasingly always online culture. We report on a qualitative study with existing users on their everyday use of smartwatches to understand both the added value and the challenges of being constantly connected at the wrist. Our findings show that users see a large benefit in receiving notifications on their wrist, especially in terms of helping manage expectations of availability. Moreover, we find that response rates after viewing a notification on a smartwatch change based on the other devices available: laptops prompt quicker replies than smartphones. Finally, there are still many costs associated with using smartwatches, thus we make a series of design recommendations to improve the user experience of smartwatches.</p></div></span> <a id="expcoll380" href="JavaScript: expandcollapse('expcoll380',380)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025817&CFID=758305256&CFTOKEN=14863114">Quantifying Sources and Types of Smartwatch Usage Sessions</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Aku Visuri, Zhanna Sarsenbayeva, Niels van Berkel, Jorge Goncalves, Reza Rawassizadeh, Vassilis Kostakos, Denzil Ferreira 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3569-3581</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025817" title="DOI">10.1145/3025453.3025817</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025817&ftid=1870306&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow381" style="display:inline;"><br /><div style="display:inline">We seek to quantify smartwatch use, and establish differences and similarities to smartphone use. Our analysis considers use traces from 307 users that include over 2.8 million notifications and 800,000 screen usage events, and we compare our findings ...</div></span>
          <span id="toHide381" style="display:none;"><br /><div style="display:inline"><p>We seek to quantify smartwatch use, and establish differences and similarities to smartphone use. Our analysis considers use traces from 307 users that include over 2.8 million notifications and 800,000 screen usage events, and we compare our findings to previous work that quantifies smartphone use. The results show that smartwatches are used more briefly and more frequently throughout the day, with half the sessions lasting less than 5 seconds. Interaction with notifications is similar across both types of devices, both in terms of response times and preferred application types. We also analyse the differences between our smartwatch dataset and a dataset aggregated from four previously conducted smartphone studies. The similarities and differences between smartwatch and smartphone use suggest effect on usage that go beyond differences in form factor.</p></div></span> <a id="expcoll381" href="JavaScript: expandcollapse('expcoll381',381)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025993&CFID=758305256&CFTOKEN=14863114">Situating Wearables: Smartwatch Use in Context</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Donald McMillan, Barry Brown, Airi Lampinen, Moira McGregor, Eve Hoggan, Stefania Pizza 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3582-3594</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025993" title="DOI">10.1145/3025453.3025993</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025993&ftid=1870733&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow382" style="display:inline;"><br /><div style="display:inline">Drawing on 168 hours of video recordings of smartwatch use, this paper studies how context influences smartwatch use. We explore the effects of the presence of others, activity, location and time of day on 1,009 instances of use. Watch interaction is ...</div></span>
          <span id="toHide382" style="display:none;"><br /><div style="display:inline"><p>Drawing on 168 hours of video recordings of smartwatch use, this paper studies how context influences smartwatch use. We explore the effects of the presence of others, activity, location and time of day on 1,009 instances of use. Watch interaction is significantly shorter when in conversation than when alone. Activity also influences watch use with significantly longer use while eating than when socialising or performing domestic tasks. One surprising finding is that length of use is similar at home and work. We note that usage peaks around lunchtime, with an average of 5.3 watch uses per hour throughout a day. We supplement these findings with qualitative analysis of the videos, focusing on how use is modified by the presence of others, and the lack of impact of watch glances on conversation. Watch use is clearly a context-sensitive activity and in discussion we explore how smartwatches could be designed taking this into consideration.</p></div></span> <a id="expcoll382" href="JavaScript: expandcollapse('expcoll382',382)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3026021&CFID=758305256&CFTOKEN=14863114">BreakSense: Combining Physiological and Location Sensing to Promote Mobility during Work-Breaks</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Scott A. Cambo, Daniel Avrahami, Matthew L. Lee 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3595-3607</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3026021" title="DOI">10.1145/3025453.3026021</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3026021&ftid=1870728&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow383" style="display:inline;"><br /><div style="display:inline">Work breaks can play an important role in the mental and physical well-being of workers and contribute positively to productivity. In this paper we explore the use of activity-, physiological-, and indoor-location sensing to promote mobility during work-breaks. ...</div></span>
          <span id="toHide383" style="display:none;"><br /><div style="display:inline"><p>Work breaks can play an important role in the mental and physical well-being of workers and contribute positively to productivity. In this paper we explore the use of activity-, physiological-, and indoor-location sensing to promote mobility during work-breaks. While the popularity of devices and applications to promote physical activity is growing, prior research highlights important constraints when designing for the workplace. With these constraints in mind, we developed BreakSense, a mobile application that uses a Bluetooth beacon infrastructure, a smartphone and a smartwatch to encourage mobility during breaks with a game-like design. We discuss constraints imposed by design for work and the workplace, and highlight challenges associated with the use of noisy sensors and methods to overcome them. We then describe a short deployment of BreakSense within our lab that examined bound vs. unbound augmented breaks and how they affect users' sense of completion and readiness to work.</p></div></span> <a id="expcoll383" href="JavaScript: expandcollapse('expcoll383',383)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Data Culture</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025694&CFID=758305256&CFTOKEN=14863114">Disempowered by Data: Nonprofits, Social Enterprises, and the Consequences of Data-Driven Work</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Chris Bopp, Ellie Harmon, Amy Voida 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3608-3619</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025694" title="DOI">10.1145/3025453.3025694</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025694&ftid=1870309&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow385" style="display:inline;"><br /><div style="display:inline">Organizations across many sectors are under intense pressure to become data-driven. Yet, for mission-driven organizations, the path to becoming and value of being data-driven is not always clear. We present results from an interview-based study of the ...</div></span>
          <span id="toHide385" style="display:none;"><br /><div style="display:inline"><p>Organizations across many sectors are under intense pressure to become data-driven. Yet, for mission-driven organizations, the path to becoming and value of being data-driven is not always clear. We present results from an interview-based study of the role of data in the monitoring and evaluation practices of mission-driven organizations. Instead of leading to productive and empowering data-driven decision making, monitoring and evaluation work is characterized by the <i>erosion of autonomy, data drift</i>, and <i>data fragmentation</i>. Together, these consequences of monitoring and evaluation practices play into a cycle of increasing disempowerment for the mission-driven organization. These findings suggest that the design of information systems should work towards empowering organizations in ways that make sense for their unique data needs and those of their constituents.</p></div></span> <a id="expcoll385" href="JavaScript: expandcollapse('expcoll385',385)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025847&CFID=758305256&CFTOKEN=14863114">Scratch Community Blocks: Supporting Children as Data Scientists</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Sayamindu Dasgupta, Benjamin Mako Hill 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3620-3631</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025847" title="DOI">10.1145/3025453.3025847</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025847&ftid=1870302&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow386" style="display:inline;"><br /><div style="display:inline">In this paper, we present Scratch Community Blocks, a new system that enables children to programmatically access, analyze, and visualize data about their participation in Scratch, an online community for learning computer programming. At its ...</div></span>
          <span id="toHide386" style="display:none;"><br /><div style="display:inline"><p>In this paper, we present <i>Scratch Community Blocks</i>, a new system that enables children to programmatically access, analyze, and visualize data about their participation in Scratch, an online community for learning computer programming. At its core, our approach involves a shift in who analyzes data: from adult data scientists to young learners themselves. We first introduce the goals and design of the system and then demonstrate it by describing example projects that illustrate its functionality. Next, we show through a series of case studies how the system engages children in not only representing data and answering questions with data but also in self-reflection about their own learning and participation.</p></div></span> <a id="expcoll386" href="JavaScript: expandcollapse('expcoll386',386)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/bp_award.jpg" alt="Best Paper" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025892&CFID=758305256&CFTOKEN=14863114">Supporting the Use of User Generated Content in Journalistic Practice</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Peter Tolmie, Rob Procter, David William Randall, Mark Rouncefield, Christian Burger, Geraldine Wong Sak Hoi, Arkaitz Zubiaga, Maria Liakata 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3632-3644</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025892" title="DOI">10.1145/3025453.3025892</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025892&ftid=1870321&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow387" style="display:inline;"><br /><div style="display:inline">Social media and user-generated content (UGC) are increasingly important features of journalistic work in a number of different ways. However, their use presents major challenges, not least because information posted on social media is not always reliable ...</div></span>
          <span id="toHide387" style="display:none;"><br /><div style="display:inline"><p>Social media and user-generated content (UGC) are increasingly important features of journalistic work in a number of different ways. However, their use presents major challenges, not least because information posted on social media is not always reliable and therefore its veracity needs to be checked before it can be considered as fit for use in the reporting of news. We report on the results of a series of in-depth ethnographic studies of journalist work practices undertaken as part of the requirements gathering for a prototype of a social media verification 'dashboard' and its subsequent evaluation. We conclude with some reflections upon the broader implications of our findings for the design of tools to support journalistic work.</p></div></span> <a id="expcoll387" href="JavaScript: expandcollapse('expcoll387',387)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025738&CFID=758305256&CFTOKEN=14863114">How Data Workers Cope with Uncertainty: A Task Characterisation Study</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Nadia Boukhelifa, Marc-Emmanuel Perrin, Samuel Huron, James Eagan 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3645-3656</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025738" title="DOI">10.1145/3025453.3025738</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025738&ftid=1870736&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow388" style="display:inline;"><br /><div style="display:inline">Uncertainty plays an important and complex role in data analysis, where the goal is to find pertinent patterns, build robust models, and support decision making. While these endeavours are often associated with professional data scientists, many domain ...</div></span>
          <span id="toHide388" style="display:none;"><br /><div style="display:inline"><p>Uncertainty plays an important and complex role in data analysis, where the goal is to find pertinent patterns, build robust models, and support decision making. While these endeavours are often associated with professional data scientists, many domain experts engage in such activities with varying skill levels. To understand how these domain experts (or "data workers") analyse uncertain data we conducted a qualitative user study with 12 participants from a variety of domains. In this paper, we describe their various coping strategies to understand, minmise, exploit or even ignore this uncertainty. The choice of the coping strategy is influenced by accepted domain practices, but appears to depend on the types and sources of uncertainty and whether participants have access to support tools. Based on these findings, we propose a new process model of how data workers analyse various types of uncertain data and conclude with design considerations for uncertainty-aware data analytics.</p></div></span> <a id="expcoll388" href="JavaScript: expandcollapse('expcoll388',388)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Fabrication and DIY</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025491&CFID=758305256&CFTOKEN=14863114">Cardboard Machine Kit: Modules for the Rapid Prototyping of Rapid Prototyping Machines</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Nadya Peek, James Coleman, Ilan Moyer, Neil Gershenfeld 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3657-3668</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025491" title="DOI">10.1145/3025453.3025491</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025491&ftid=1870331&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow390" style="display:inline;"><br /><div style="display:inline">Digital fabrication machines (such as laser cutters or 3D printers) can be instructed to produce any part geometry within their application space. However, machines' application spaces are not easily modified or extended. How can we enable the production ...</div></span>
          <span id="toHide390" style="display:none;"><br /><div style="display:inline"><p>Digital fabrication machines (such as laser cutters or 3D printers) can be instructed to produce any part geometry within their application space. However, machines' application spaces are not easily modified or extended. How can we enable the production of application-specific computer-controlled machines by machine building novices? How can we facilitate rapid prototyping of rapid prototyping tools? We propose a novel set of modules, the Cardboard Machine Kit, for the construction of digital fabrication machines. These open-source modules are implemented using cardboard frames, stepper motors, and networked electronics controlled through a Python library. We evaluated the kit both through machine building workshops and by studying the usage of the kit in the wild. In the wild we observed more than 500 novice machine builders who built 125 different machines for 15 different application types. We argue that this breadth demonstrates the efficacy of this modular approach. Finally we discuss the limitations of the Cardboard Machine Kit and discuss how it could inform future machine building infrastructure.</p></div></span> <a id="expcoll390" href="JavaScript: expandcollapse('expcoll390',390)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025898&CFID=758305256&CFTOKEN=14863114">Printflatables: Printing Human-Scale, Functional and Dynamic Inflatable Objects</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Harpreet Sareen, Udayan Umapathi, Patrick Shin, Yasuaki Kakehi, Jifei Ou, Hiroshi Ishii, Pattie Maes 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3669-3680</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025898" title="DOI">10.1145/3025453.3025898</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025898&ftid=1870328&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow391" style="display:inline;"><br /><div style="display:inline">Printflatables is a design and fabrication system for human-scale, functional and dynamic inflatable objects. We use inextensible thermoplastic fabric as the raw material with the key principle of introducing folds and thermal sealing. Upon inflation, ...</div></span>
          <span id="toHide391" style="display:none;"><br /><div style="display:inline"><p>Printflatables is a design and fabrication system for human-scale, functional and dynamic inflatable objects. We use inextensible thermoplastic fabric as the raw material with the key principle of introducing folds and thermal sealing. Upon inflation, the sealed object takes the expected three dimensional shape. The workflow begins with the user specifying an intended 3D model which is decomposed to two dimensional fabrication geometry. This forms the input for a numerically controlled thermal contact iron that seals layers of thermoplastic fabric. In this paper, we discuss the system design in detail, the pneumatic primitives that this technique enables and merits of being able to make large, functional and dynamic pneumatic artifacts. We demonstrate the design output through multiple objects which could motivate fabrication of inflatable media and pressure-based interfaces.</p></div></span> <a id="expcoll391" href="JavaScript: expandcollapse('expcoll391',391)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025774&CFID=758305256&CFTOKEN=14863114">Sketching CuddleBits: Coupled Prototyping of Body and Behaviour for an Affective Robot Pet</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Paul Bucci, Xi Laura Cang, Anasazi Valair, David Marino, Lucia Tseng, Merel Jung, Jussi Rantala, Oliver S. Schneider, Karon E. MacLean 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3681-3692</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025774" title="DOI">10.1145/3025453.3025774</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025774&ftid=1870332&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow392" style="display:inline;"><br /><div style="display:inline">Social robots that physically display emotion invite natural communication with their human interlocutors, enabling applications like robot-assisted therapy where a complex robot's breathing influences human emotional and physiological state. Using DIY ...</div></span>
          <span id="toHide392" style="display:none;"><br /><div style="display:inline"><p>Social robots that physically display emotion invite natural communication with their human interlocutors, enabling applications like robot-assisted therapy where a complex robot's breathing influences human emotional and physiological state. Using DIY fabrication and assembly, we explore how simple 1-DOF robots can express affect with economy and user customizability, leveraging open-source designs.</p> <p>We developed low-cost techniques for coupled iteration of a simple robot's body and behaviour, and evaluated its potential to display emotion. Through two user studies, we (1) validated these CuddleBits' ability to express emotions (N=20); (2) sourced a corpus of 72 robot emotion behaviours from participants (N=10); and (3) analyzed it to link underlying parameters to emotional perception (N=14).</p> <p>We found that CuddleBits can express arousal (activation), and to a lesser degree valence (pleasantness). We also show how a sketch-refine paradigm combined with DIY fabrication and novel input methods enable parametric design of physical emotion display, and discuss how mastering this parsimonious case can give insight into layering simple behaviours in more complex robots.</p></div></span> <a id="expcoll392" href="JavaScript: expandcollapse('expcoll392',392)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025792&CFID=758305256&CFTOKEN=14863114">WireDraw: 3D Wire Sculpturing Guided with Mixed Reality</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Ya-Ting Yue, Xiaolong Zhang, Yongliang Yang, Gang Ren, Yi-King Choi, Wenping Wang 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3693-3704</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025792" title="DOI">10.1145/3025453.3025792</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025792&ftid=1870737&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow393" style="display:inline;"><br /><div style="display:inline">The availability of commodity 3D extruder pen allows direct drawing of 3D wire sculptures for novice users, enabling many novel applications such as intuitive spatial intelligence development for school students. However, the lack of spatial and structural ...</div></span>
          <span id="toHide393" style="display:none;"><br /><div style="display:inline"><p>The availability of commodity 3D extruder pen allows direct drawing of 3D wire sculptures for novice users, enabling many novel applications such as intuitive spatial intelligence development for school students. However, the lack of spatial and structural cues among individual pen strokes makes the 3D drawing process challenging, which often leads to highly distorted and even incomplete wire sculptures. We present a mixed reality system, called `WireDraw', to immersively guide the 3D drawing for easy wire sculpturing. The system design is based on novel 3D drawing principles and the subsequent optimization, making the stroke sequence of the wire model drawable and easy to draw. On-the-fly edits on unsatisfactory strokes are also allowed for creative design. We demonstrate the effectiveness of our system by testing on a variety of wire models and a user study. The results show that the visual guidance provided by our system is extremely helpful for drawing high-quality wire sculptures.</p></div></span> <a id="expcoll393" href="JavaScript: expandcollapse('expcoll393',393)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>FnT: Personal Fabrication</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Haptic Feedback</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025782&CFID=758305256&CFTOKEN=14863114">Sparkle: Hover Feedback with Touchable Electric Arcs</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Daniel Spelmezan, Deepak Ranjan Sahoo, Sriram Subramanian 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3705-3717</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025782" title="DOI">10.1145/3025453.3025782</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025782&ftid=1870744&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow396" style="display:inline;"><br /><div style="display:inline">Many finger sensing input devices now support proximity input, enabling users to perform in-air gestures. While near-surface interactions increase the input vocabulary, they lack tactile feedback, making it hard for users to perform gestures or to know ...</div></span>
          <span id="toHide396" style="display:none;"><br /><div style="display:inline"><p>Many finger sensing input devices now support proximity input, enabling users to perform in-air gestures. While near-surface interactions increase the input vocabulary, they lack tactile feedback, making it hard for users to perform gestures or to know when the interaction takes place. Sparkle stimulates the fingertip with touchable electric arcs above a hover sensing device to give users in-air tactile or thermal feedback, sharper and more feelable than acoustic mid-air haptic devices. We present the design of a high voltage resonant transformer with a low-loss soft ferrite core and self-tuning driver circuit, with which we create electric arcs 6 mm in length, and combine this technology with infrared proximity sensing in two proof-of-concept devices with form factor and functionality similar to a button and a touchpad. We provide design guidelines for Sparkle devices and examples of stimuli in application scenarios, and report the results of a user study on the perceived sensations. Sparkle is the first step towards providing a new type of hover feedback, and it does not require users to wear tactile stimulators.</p></div></span> <a id="expcoll396" href="JavaScript: expandcollapse('expcoll396',396)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025753&CFID=758305256&CFTOKEN=14863114">Sparse Haptic Proxy: Touch Feedback in Virtual Environments Using a General Passive Prop</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Lung-Pan Cheng, Eyal Ofek, Christian Holz, Hrvoje Benko, Andrew D. Wilson 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3718-3728</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025753" title="DOI">10.1145/3025453.3025753</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025753&ftid=1870318&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow397" style="display:inline;"><br /><div style="display:inline">We propose a class of passive haptics that we call Sparse Haptic Proxy: a set of geometric primitives that simulate touch feedback in elaborate virtual reality scenes. Unlike previous passive haptics that replicate the virtual environment in physical ...</div></span>
          <span id="toHide397" style="display:none;"><br /><div style="display:inline"><p>We propose a class of passive haptics that we call Sparse Haptic Proxy: a set of geometric primitives that simulate touch feedback in elaborate virtual reality scenes. Unlike previous passive haptics that replicate the virtual environment in physical space, a Sparse Haptic Proxy simulates a scene's detailed geometry by redirecting the user's hand to a matching primitive of the proxy. To bridge the divergence of the scene from the proxy, we augment an existing Haptic Retargeting technique with an on-the-fly target remapping: We predict users' intentions during interaction in the virtual space by analyzing their gaze and hand motions, and consequently redirect their hand to a matching part of the proxy. We conducted three user studies on haptic retargeting technique and implemented a system from three main results: 1) The maximum angle participants found acceptable for retargeting their hand is 40&#176;, with an average rating of 4.6 out of 5. 2) Tracking participants' eye gaze reliably predicts their touch intentions (97.5%), even while simultaneously manipulating the user's hand-eye coordination for retargeting. 3) Participants preferred minimized retargeting distances over better-matching surfaces of our Sparse Haptic Proxy when receiving haptic feedback for single-finger touch input. We demonstrate our system with two virtual scenes: a flight cockpit and a room quest game. While their scene geometries differ substantially, both use the same sparse haptic proxy to provide haptic feedback to the user during task completion.</p></div></span> <a id="expcoll397" href="JavaScript: expandcollapse('expcoll397',397)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025684&CFID=758305256&CFTOKEN=14863114">HapticHead: A Spherical Vibrotactile Grid around the Head for 3D Guidance in Virtual and Augmented Reality</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Oliver Beren Kaul, Michael Rohs 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3729-3740</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025684" title="DOI">10.1145/3025453.3025684</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025684&ftid=1870742&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow398" style="display:inline;"><br /><div style="display:inline">Current virtual and augmented reality head-mounted displays usually include no or only a single vibration motor for haptic feedback and do not use it for guidance. We present HapticHead, a system utilizing multiple vibrotactile actuators distributed ...</div></span>
          <span id="toHide398" style="display:none;"><br /><div style="display:inline"><p>Current virtual and augmented reality head-mounted displays usually include no or only a single vibration motor for haptic feedback and do not use it for guidance. We present HapticHead, a system utilizing multiple vibrotactile actuators distributed in three concentric ellipses around the head for intuitive haptic guidance through moving tactile cues. We conducted three experiments, which indicate that HapticHead vibrotactile feedback is both faster (2.6 s vs. 6.9 s) and more precise (96.4% vs. 54.2% success rate) than spatial audio (generic head-related transfer function) for finding visible virtual objects in 3D space around the user. The baseline of visual feedback is as expected more precise (99.7% success rate) and faster (1.3 s) in comparison, but there are many applications in which visual feedback is not desirable or available due to lighting conditions, visual overload, or visual impairments. Mean final precision with HapticHead feedback on invisible targets is 2.3&#176; compared to 0.8&#176; with visual feedback. We successfully navigated blindfolded users to real household items at different heights using HapticHead vibrotactile feedback independently of a head-mounted display.</p></div></span> <a id="expcoll398" href="JavaScript: expandcollapse('expcoll398',398)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025894&CFID=758305256&CFTOKEN=14863114">Passive yet Expressive TouchTokens</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Rafael Morales Gonz&#225;lez, Caroline Appert, Gilles Bailly, Emmanuel Pietriga 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3741-3745</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025894" title="DOI">10.1145/3025453.3025894</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025894&ftid=1870310&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow399" style="display:inline;"><br /><div style="display:inline">TouchTokens are passive tokens that can be recognized on any capacitive surface based on the spatial configuration of the fingers that hold them. However, interaction with these tokens is confined to the basic two-state model of touch interaction as ...</div></span>
          <span id="toHide399" style="display:none;"><br /><div style="display:inline"><p>TouchTokens are passive tokens that can be recognized on any capacitive surface based on the spatial configuration of the fingers that hold them. However, interaction with these tokens is confined to the basic two-state model of touch interaction as the system only knows the tokens' position and cannot detect tokens that are not touched. We increase the expressive power of TouchTokens by introducing laser-cut lattice hinges in their design, so as to make them flexible. A new recognizer, that analyzes the micro-movements of the fingers that hold the tokens, enables the system to detect when a token is left on the surface rather than taken off it. It can also detect bend events that can be mapped to command triggers, and a squeezed state that can be used for quasi-modal interaction.</p></div></span> <a id="expcoll399" href="JavaScript: expandcollapse('expcoll399',399)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025555&CFID=758305256&CFTOKEN=14863114">Enhancing Pen-based Interaction using Electrovibration and Vibration Haptic Feedback</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Qinglong Wang, Xiangshi Ren, Xiaoying Sun 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3746-3750</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025555" title="DOI">10.1145/3025453.3025555</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025555&ftid=1870336&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow400" style="display:inline;"><br /><div style="display:inline">This paper presents the EV2-Pen which leverages electrovibration technology and vibration technology in pen interaction. Electrovibration technology can produce multisensory feedback when the pen is in motion (sliding/moving ...</div></span>
          <span id="toHide400" style="display:none;"><br /><div style="display:inline"><p>This paper presents the <i>EV<sup>2</sup>-Pen</i> which leverages <i>electrovibration</i> technology and <i>vibration</i> technology in pen interaction. Electrovibration technology can produce multisensory feedback when the pen is in motion (sliding/moving on the screen), and vibration technology can provide vibrative feedback when the pen is stationary (pointing/resting on the screen). We conducted an experiment to investigate user performance with the EV<sup>2</sup>-Pen. The results indicated that the EV<sup>2</sup>-Pen outperformed the EV-Pen [18, 19] in pointing-steering tasks. Finally, we discuss the characteristics of the EV<sup>2</sup>-Pen, and explore some possible applications and scenarios.</p></div></span> <a id="expcoll400" href="JavaScript: expandcollapse('expcoll400',400)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Passwords and Authentication</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025461&CFID=758305256&CFTOKEN=14863114">Stay Cool! Understanding Thermal Attacks on Mobile-based User Authentication</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Yomna Abdelrahman, Mohamed Khamis, Stefan Schneegass, Florian Alt 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3751-3763</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025461" title="DOI">10.1145/3025453.3025461</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025461&ftid=1870743&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow402" style="display:inline;"><br /><div style="display:inline">PINs and patterns remain among the most widely used knowledge-based authentication schemes. As thermal cameras become ubiquitous and affordable, we foresee a new form of threat to user privacy on mobile devices. Thermal cameras allow performing thermal ...</div></span>
          <span id="toHide402" style="display:none;"><br /><div style="display:inline"><p>PINs and patterns remain among the most widely used knowledge-based authentication schemes. As thermal cameras become ubiquitous and affordable, we foresee a new form of threat to user privacy on mobile devices. Thermal cameras allow performing thermal attacks, where heat traces, resulting from authentication, can be used to reconstruct passwords. In this work we investigate in details the viability of exploiting thermal imaging to infer PINs and patterns on mobile devices. We present a study (N=18) where we evaluated how properties of PINs and patterns influence their thermal attacks resistance. We found that thermal attacks are indeed viable on mobile devices; overlapping patterns significantly decrease successful thermal attack rate from 100% to 16.67%, while PINs remain vulnerable (&gt;72% success rate) even with duplicate digits. We conclude by recommendations for users and designers of authentication schemes on how to resist thermal attacks.</p></div></span> <a id="expcoll402" href="JavaScript: expandcollapse('expcoll402',402)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025991&CFID=758305256&CFTOKEN=14863114">Thumprint: Socially-Inclusive Local Group Authentication Through Shared Secret Knocks</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Sauvik Das, Gierad Laput, Chris Harrison, Jason I. Hong 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3764-3774</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025991" title="DOI">10.1145/3025453.3025991</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025991&ftid=1870729&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow403" style="display:inline;"><br /><div style="display:inline">Small, local groups who share protected resources (e.g., families, work teams, student organizations) have unmet authentication needs. For these groups, existing authentication strategies either create unnecessary social divisions (e.g., biometrics), ...</div></span>
          <span id="toHide403" style="display:none;"><br /><div style="display:inline"><p>Small, local groups who share protected resources (e.g., families, work teams, student organizations) have unmet authentication needs. For these groups, existing authentication strategies either create unnecessary social divisions (e.g., biometrics), do not identify individuals (e.g., shared passwords), do not equitably distribute security responsibility (e.g., individual passwords), or make it difficult to share or revoke access (e.g., physical keys). To explore an alternative, we designed Thumprint: inclusive group authentication with a shared secret knock. All group members share one secret knock, but individual expressions of the secret are discernible. We evaluated the usability and security of our concept through two user studies with 30 participants. Our results suggest that (1) individuals who enter the same shared thumprint are distinguishable from one another, (2) that people can enter thumprints consistently over time, and (3) that thumprints are resilient to casual adversaries.</p></div></span> <a id="expcoll403" href="JavaScript: expandcollapse('expcoll403',403)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/bp_award.jpg" alt="Best Paper" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3026050&CFID=758305256&CFTOKEN=14863114">Design and Evaluation of a Data-Driven Password Meter</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Blase Ur, Felicia Alfieri, Maung Aung, Lujo Bauer, Nicolas Christin, Jessica Colnago, Lorrie Faith Cranor, Henry Dixon, Pardis Emami Naeini, Hana Habib, Noah Johnson, William Melicher 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3775-3786</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3026050" title="DOI">10.1145/3025453.3026050</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3026050&ftid=1870313&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow404" style="display:inline;"><br /><div style="display:inline">Despite their ubiquity, many password meters provide inaccurate strength estimates. Furthermore, they do not explain to users what is wrong with their password or how to improve it. We describe the development and evaluation of a data-driven password ...</div></span>
          <span id="toHide404" style="display:none;"><br /><div style="display:inline"><p>Despite their ubiquity, many password meters provide inaccurate strength estimates. Furthermore, they do not explain to users what is wrong with their password or how to improve it. We describe the development and evaluation of a data-driven password meter that provides accurate strength measurement and actionable, detailed feedback to users. This meter combines neural networks and numerous carefully combined heuristics to score passwords and generate data-driven text feedback about the user's password. We describe the meter's iterative development and final design. We detail the security and usability impact of the meter's design dimensions, examined through a 4,509-participant online study. Under the more common password-composition policy we tested, we found that the data-driven meter with detailed feedback led users to create more secure, and no less memorable, passwords than a meter with only a bar as a strength indicator.</p></div></span> <a id="expcoll404" href="JavaScript: expandcollapse('expcoll404',404)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025733&CFID=758305256&CFTOKEN=14863114">Can Unicorns Help Users Compare Crypto Key Fingerprints?</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Joshua Tan, Lujo Bauer, Joseph Bonneau, Lorrie Faith Cranor, Jeremy Thomas, Blase Ur 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3787-3798</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025733" title="DOI">10.1145/3025453.3025733</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025733&ftid=1870330&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow405" style="display:inline;"><br /><div style="display:inline">Many authentication schemes ask users to manually compare compact representations of cryptographic keys, known as fingerprints. If the fingerprints do not match, that may signal a man-in-the-middle attack. An adversary performing an attack may use a ...</div></span>
          <span id="toHide405" style="display:none;"><br /><div style="display:inline"><p>Many authentication schemes ask users to manually compare compact representations of cryptographic keys, known as fingerprints. If the fingerprints do not match, that may signal a man-in-the-middle attack. An adversary performing an attack may use a fingerprint that is similar to the target fingerprint, but not an exact match, to try to fool inattentive users. Fingerprint representations should thus be both usable and secure. We tested the usability and security of eight fingerprint representations under different configurations. In a 661-participant between-subjects experiment, participants compared fingerprints under realistic conditions and were subjected to a simulated attack. The best configuration allowed attacks to succeed 6% of the time; the worst 72%. We find the seemingly effective compare-and-select approach performs poorly for key fingerprints and that graphical fingerprint representations, while intuitive and fast, vary in performance. We identify some fingerprint representations as particularly promising.</p></div></span> <a id="expcoll405" href="JavaScript: expandcollapse('expcoll405',405)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Social Media Privacy</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025903&CFID=758305256&CFTOKEN=14863114">FDVT: Data Valuation Tool for Facebook Users</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Jos&#233; Gonz&#225;lez Caba&#241;as, &#193;ngel Cuevas, Rub&#233;n Cuevas 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3799-3809</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025903" title="DOI">10.1145/3025453.3025903</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025903&ftid=1870740&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow407" style="display:inline;"><br /><div style="display:inline">The OECD, the European Union and other public and private initiatives are claiming for the necessity of tools that create awareness among Internet users about the monetary value associated to the commercial exploitation of their online personal information. ...</div></span>
          <span id="toHide407" style="display:none;"><br /><div style="display:inline"><p>The OECD, the European Union and other public and private initiatives are claiming for the necessity of tools that create awareness among Internet users about the monetary value associated to the commercial exploitation of their online personal information. This paper presents the first tool addressing this challenge, the Facebook Data Valuation Tool (FDVT). The FDVT provides Facebook users with a personalized and real-time estimation of the revenue they generate for Facebook. Relying on the FDVT, we are able to shed light into several relevant HCI research questions that require a data valuation tool in place. The obtained results reveal that (i) there exists a deep lack of awareness among Internet users regarding the monetary value of personal information, (ii) data valuation tools such as the FDVT are useful means to reduce such knowledge gap, (iii) 1/3 of the users testing the FDVT show a substantial engagement with the tool.</p></div></span> <a id="expcoll407" href="JavaScript: expandcollapse('expcoll407',407)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025901&CFID=758305256&CFTOKEN=14863114">Characterizing Social Insider Attacks on Facebook</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Wali Ahmed Usmani, Diogo Marques, Ivan Beschastnikh, Konstantin Beznosov, Tiago Guerreiro, Lu&#237;s Carri&#231;o 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3810-3820</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025901" title="DOI">10.1145/3025453.3025901</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025901&ftid=1870734&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow408" style="display:inline;"><br /><div style="display:inline">Facebook accounts are secured against unauthorized access through passwords and device-level security. Those defenses, however, may not be sufficient to prevent social insider attacks, where attackers know their victims, and gain access to a victim's ...</div></span>
          <span id="toHide408" style="display:none;"><br /><div style="display:inline"><p>Facebook accounts are secured against unauthorized access through passwords and device-level security. Those defenses, however, may not be sufficient to prevent social insider attacks, where attackers know their victims, and gain access to a victim's account by interacting directly with their device. To characterize these attacks, we ran two MTurk studies. In the first (n = 1,308), using the list experiment method, we estimated that 24% of participants had perpetrated social insider attacks and that 21% had been victims (and knew about it). In the second study (n = 45), participants wrote stories detailing personal experiences with such attacks. Using thematic analysis, we typified attacks around five motivations (fun, curiosity, jealousy, animosity, and utility), and explored dimensions associated with each type. Our combined findings indicate that social insider attacks are common, often have serious emotional consequences, and have no simple mitigation.</p></div></span> <a id="expcoll408" href="JavaScript: expandcollapse('expcoll408',408)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025668&CFID=758305256&CFTOKEN=14863114">Photo Privacy Conflicts in Social Media: A Large-scale Empirical Study</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Jose M. Such, Joel Porter, S&#246;ren Preibusch, Adam Joinson 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3821-3832</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025668" title="DOI">10.1145/3025453.3025668</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025668&ftid=1870337&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow409" style="display:inline;"><br /><div style="display:inline">Items in social media such as photos may be co-owned by multiple users, i.e., the sharing decisions of the ones who upload them have the potential to harm the privacy of the others. Previous works uncovered coping strategies by co-owners to manage their ...</div></span>
          <span id="toHide409" style="display:none;"><br /><div style="display:inline"><p>Items in social media such as photos may be co-owned by multiple users, i.e., the sharing decisions of the ones who upload them have the potential to harm the privacy of the others. Previous works uncovered coping strategies by co-owners to manage their privacy, but mainly focused on general practices and experiences. We establish an empirical base for the prevalence, context and severity of privacy conflicts over co-owned photos. To this aim, a parallel survey of pre-screened 496 uploaders and 537 co-owners collected occurrences and type of conflicts over co-owned photos, and any actions taken towards resolving them. We uncover nuances and complexities not known before, including co-ownership types, and divergences in the assessment of photo audiences. We also find that an all-or-nothing approach seems to dominate conflict resolution, even when parties actually interact and talk about the conflict. Finally, we derive key insights for designing systems to mitigate these divergences and facilitate consensus.</p></div></span> <a id="expcoll409" href="JavaScript: expandcollapse('expcoll409',409)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025698&CFID=758305256&CFTOKEN=14863114">Towards Understanding Differential Privacy: When Do People Trust Randomized Response Technique?</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Brooke Bullek, Stephanie Garboski, Darakhshan J. Mir, Evan M. Peck 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3833-3837</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025698" title="DOI">10.1145/3025453.3025698</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025698&ftid=1870322&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow410" style="display:inline;"><br /><div style="display:inline">As a consequence of living in a data ecosystem, we often relinquish personal information to be used in contexts in which we have no control. In this paper, we begin to examine the usability of differential privacy, a mechanism that proposes to promise ...</div></span>
          <span id="toHide410" style="display:none;"><br /><div style="display:inline"><p>As a consequence of living in a data ecosystem, we often relinquish personal information to be used in contexts in which we have no control. In this paper, we begin to examine the usability of differential privacy, a mechanism that proposes to promise privacy with a mathematical "proof" to the data donor. Do people trust this promise and adjust their privacy decisions if the interfaces through which they interact make differential privacy less opaque? In a study with 228 participants, we measured comfort, understanding, and trust using a variant of differential privacy known as Randomized Response Technique (RRT). We found that allowing individuals to see the amount of obfuscation applied to their responses increased their trust in the privacy-protecting mechanism. However, participants who associated obfuscating privacy mechanisms with deception did not make the "safest" privacy decisions, even as they demonstrated an understanding of RRT. We demonstrate that prudent privacy-related decisions can be cultivated with simple explanations of usable privacy.</p></div></span> <a id="expcoll410" href="JavaScript: expandcollapse('expcoll410',410)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025925&CFID=758305256&CFTOKEN=14863114">Was my message read?: Privacy and Signaling on Facebook Messenger</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Roberto Hoyle, Srijita Das, Apu Kapadia, Adam J. Lee, Kami Vaniea 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3838-3842</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025925" title="DOI">10.1145/3025453.3025925</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025925&ftid=1870311&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow411" style="display:inline;"><br /><div style="display:inline">Major online messaging services such as Facebook Messenger and WhatsApp are starting to provide users with real-time information about when people read their messages, while useful, the feature has the potential to negatively impact privacy as well as ...</div></span>
          <span id="toHide411" style="display:none;"><br /><div style="display:inline"><p>Major online messaging services such as Facebook Messenger and WhatsApp are starting to provide users with real-time information about when people read their messages, while useful, the feature has the potential to negatively impact privacy as well as cause concern over access to self. We report on two surveys using Mechanical Turk which looked at senders' (N=402} use of and reactions to the `message seen' feature, and recipients' (N=316) privacy and signaling behaviors in the face of such visibility. Our findings indicate that senders experience a range of emotions when their message is not read, or is read but not answered immediately. Recipients also engage in various signaling behaviors in the face of visibility by both replying or not replying immediately.</p></div></span> <a id="expcoll411" href="JavaScript: expandcollapse('expcoll411',411)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Technology &#38; Spatial Landmarks</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025497&CFID=758305256&CFTOKEN=14863114">The Effects of Artificial Landmarks on Learning and Performance in Spatial-Memory Interfaces</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Md. Sami Uddin, Carl Gutwin, Andy Cockburn 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3843-3855</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025497" title="DOI">10.1145/3025453.3025497</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025497&ftid=1870329&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow413" style="display:inline;"><br /><div style="display:inline">Spatial memory is a powerful way for users to become expert with an interface, because remembering item locations means that users do not have to carry out slow visual search. Spatial learning in the real world benefits greatly from landmarks in the ...</div></span>
          <span id="toHide413" style="display:none;"><br /><div style="display:inline"><p>Spatial memory is a powerful way for users to become expert with an interface, because remembering item locations means that users do not have to carry out slow visual search. Spatial learning in the real world benefits greatly from landmarks in the environment, but user interfaces often provide very few visual landmarks. In this paper we explore the use of <i>artificial</i> landmarks as a way to improve people's spatial memory in spatially-stable grid menus called CommandMaps. We carried out three studies to test the effects of three types of artificial landmarks (standard grid, simple anchor marks, and a transparent image) on spatial learning. We found that for small grid menus, the artificial landmarks had little impact on performance, whereas for medium and large grids, the simple anchor marks significantly improved performance. The simple visual anchors were faster and less error-prone than the visually richer transparent image. Our studies show that artificial landmarks can be a valuable addition to spatial interfaces.</p></div></span> <a id="expcoll413" href="JavaScript: expandcollapse('expcoll413',413)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3026055&CFID=758305256&CFTOKEN=14863114">Studying Space Use: Bringing HCI Tools to Architectural Projects</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Himanshu Verma, Hamed S. Alavi, Denis Lalanne 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3856-3866</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3026055" title="DOI">10.1145/3025453.3026055</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3026055&ftid=1870303&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow414" style="display:inline;"><br /><div style="display:inline">Understanding how people use different spaces in a building can inform design interventions aimed at improving the utility of that building, but can also inform the design of future buildings. We studied space use in an office building following a method ...</div></span>
          <span id="toHide414" style="display:none;"><br /><div style="display:inline"><p>Understanding how people use different spaces in a building can inform design interventions aimed at improving the utility of that building, but can also inform the design of future buildings. We studied space use in an office building following a method we have designed to reveal the occupancy rate and navigational patterns. Our method involves two key components: <i>1</i>) a pervasive sensing system that is scalable for large buildings, and high number of occupants, and <i>2</i>) participatory data analysis engaging stakeholders including interior architects and building performance engineers, to refine the questions and define the needs for further analyses through multiple iterations.</p> <p>In this paper, we describe our method in detail, and exemplify how HCI methods and approaches can contribute to professional building design projects.</p></div></span> <a id="expcoll414" href="JavaScript: expandcollapse('expcoll414',414)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025728&CFID=758305256&CFTOKEN=14863114">Locating the Internet in the Parks of Havana</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Michaelanne Dye, David Nemer, Laura R. Pina, Nithya Sambasivan, Amy S. Bruckman, Neha Kumar 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3867-3878</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025728" title="DOI">10.1145/3025453.3025728</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025728&ftid=1870316&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow415" style="display:inline;"><br /><div style="display:inline">Since March 2015, the public squares of Havana have been transformed from places where people stroll and children play to places where crowds gather to try to connect to the internet at all hours of the day and night. We present a field investigation ...</div></span>
          <span id="toHide415" style="display:none;"><br /><div style="display:inline"><p>Since March 2015, the public squares of Havana have been transformed from places where people stroll and children play to places where crowds gather to try to connect to the internet at all hours of the day and night. We present a field investigation of public WiFi hotspots in Havana, Cuba, and examine the possibilities of internet access these limited and expensive hotspots present to individuals, many of who are experiencing the internet for the first time. Drawing on fieldwork conducted in 2015-2016, we underscore the reconfigurations that have resulted from this access, as evolving internet users reconfigure their interactions with place, time, and individuals in their efforts to locate the internet. We also discuss the implications our findings have for the design of internet access interventions in Cuba and in other low-resource environments across the world, as well as the broader implications for social computing across diverse geographies.</p></div></span> <a id="expcoll415" href="JavaScript: expandcollapse('expcoll415',415)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Wearable Technology</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025561&CFID=758305256&CFTOKEN=14863114">TriTap: Identifying Finger Touches on Smartwatches</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Hyunjae Gil, DoYoung Lee, Seunggyu Im, Ian Oakley 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3879-3890</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025561" title="DOI">10.1145/3025453.3025561</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025561&ftid=1870326&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow417" style="display:inline;"><br /><div style="display:inline">The small screens of smartwatches provide limited space for input tasks. Finger identification is a promising technique to address this problem by associating different functions with different fingers. However, current technologies for finger identification ...</div></span>
          <span id="toHide417" style="display:none;"><br /><div style="display:inline"><p>The small screens of smartwatches provide limited space for input tasks. Finger identification is a promising technique to address this problem by associating different functions with different fingers. However, current technologies for finger identification are unavailable or unsuitable for smartwatches. To address this problem, this paper observes that normal smartwatch use takes places with a relatively static pose between the two hands. In this situation, we argue that the touch and angle profiles generated by different fingers on a standard smartwatch touch screen will differ sufficiently to support reliable identification. The viability of this idea is explored in two studies that capture touches in natural and exaggerated poses during tapping and swiping tasks. Machine learning models report accuracies of up to 93% and 98% respectively, figures that are sufficient for many common interaction tasks. Furthermore, the exaggerated poses show modest costs (in terms of time/errors) compared to the natural touches. We conclude by presenting examples and discussing how interaction designs using finger identification can be adapted to the smartwatch form factor.</p></div></span> <a id="expcoll417" href="JavaScript: expandcollapse('expcoll417',417)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3026005&CFID=758305256&CFTOKEN=14863114">WatchSense: On- and Above-Skin Input Sensing through a Wearable Depth Sensor</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Srinath Sridhar, Anders Markussen, Antti Oulasvirta, Christian Theobalt, Sebastian Boring 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3891-3902</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3026005" title="DOI">10.1145/3025453.3026005</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3026005&ftid=1870324&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow418" style="display:inline;"><br /><div style="display:inline">This paper contributes a novel sensing approach to support on- and above-skin finger input for interaction on the move. WatchSense uses a depth sensor embedded in a wearable device to expand the input space to neighboring areas of skin and the space ...</div></span>
          <span id="toHide418" style="display:none;"><br /><div style="display:inline"><p>This paper contributes a novel sensing approach to support on- and above-skin finger input for interaction on the move. WatchSense uses a depth sensor embedded in a wearable device to expand the input space to neighboring areas of skin and the space above it. Our approach addresses challenging camera-based tracking conditions, such as oblique viewing angles and occlusions. It can accurately detect fingertips, their locations, and whether they are touching the skin or hovering above it. It extends previous work that supported either mid-air or multitouch input by simultaneously supporting both. We demonstrate feasibility with a compact, wearable prototype attached to a user's forearm (simulating an integrated depth sensor). Our prototype---which runs in real-time on consumer mobile devices---enables a 3D input space on the back of the hand. We evaluated the accuracy and robustness of the approach in a user study. We also show how WatchSense increases the expressiveness of input by interweaving mid-air and multitouch for several interactive applications.</p></div></span> <a id="expcoll418" href="JavaScript: expandcollapse('expcoll418',418)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025947&CFID=758305256&CFTOKEN=14863114">Supporting Everyday Function in Chronic Pain Using Wearable Technology</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Aneesha Singh, Nadia Bianchi-Berthouze, Amanda CdeC Williams 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3903-3915</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025947" title="DOI">10.1145/3025453.3025947</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025947&ftid=1870333&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow419" style="display:inline;"><br /><div style="display:inline">While most rehabilitation technologies target situated exercise sessions and associated performance metrics, physiotherapists recommend physical activities that are integrated with everyday functioning. We conducted a 1-2 week home study to explore how ...</div></span>
          <span id="toHide419" style="display:none;"><br /><div style="display:inline"><p>While most rehabilitation technologies target situated exercise sessions and associated performance metrics, physiotherapists recommend physical activities that are integrated with everyday functioning. We conducted a 1-2 week home study to explore how people with chronic pain use wearable technology that senses and sonifies movement (i.e., movement mapped to sound in real-time) to do functional activity (e.g., loading the dishwasher). Our results show that real-time movement sonification led to an increased sense of control during challenging everyday tasks. Sonification calibrated to functional activity facilitated application of pain management techniques such as pacing. When calibrated to individual needs, sonification enabled serendipitous discovery of physical capabilities otherwise obscured by a focus on pain or a dysfunctional proprioceptive system. A physiotherapist was invited to comment on the implications of our findings. We conclude by discussing opportunities provided by wearable sensing technology to enable better functioning, the ultimate goal of physical rehabilitation.</p></div></span> <a id="expcoll419" href="JavaScript: expandcollapse('expcoll419',419)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025489&CFID=758305256&CFTOKEN=14863114">SoPhy: A Wearable Technology for Lower Limb Assessment in Video Consultations of Physiotherapy</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Deepti Aggarwal, Weiyi Zhang, Thuong Hoang, Bernd Ploderer, Frank Vetere, Mark Bradford 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3916-3928</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025489" title="DOI">10.1145/3025453.3025489</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025489&ftid=1870735&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow420" style="display:inline;"><br /><div style="display:inline">Physiotherapists are increasingly using video conferencing tools for their teleconsultations. Yet, the assessment of subtle differences in body movements remains a challenge. To support lower limb assessment in video consultations, we present SoPhy, ...</div></span>
          <span id="toHide420" style="display:none;"><br /><div style="display:inline"><p>Physiotherapists are increasingly using video conferencing tools for their teleconsultations. Yet, the assessment of subtle differences in body movements remains a challenge. To support lower limb assessment in video consultations, we present <i>SoPhy</i>, a wearable technology consisting of a pair of socks with embedded sensors for patients to wear; and a web interface that displays information about range of weight distribution, foot movement, and foot orientation for physiotherapists in real-time. We conducted a laboratory study of 40 video consultations, in which postgraduate physiotherapy students assessed lower limb function. We compare assessment with and without <i>SoPhy</i>. Findings show that <i>SoPhy</i> increased the confidence in assessing squats exercise and fewer repetitions were required to assess patients when using <i>SoPhy</i>. We discuss the significance of <i>SoPhy</i> to address the challenges of assessing bodily information over video, and present considerations for its integration with clinical practices and tools.</p></div></span> <a id="expcoll420" href="JavaScript: expandcollapse('expcoll420',420)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Camera-based Tracking</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025562&CFID=758305256&CFTOKEN=14863114">EagleSense: Tracking People and Devices in Interactive Spaces using Real-Time Top-View Depth-Sensing</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Chi-Jui Wu, Steven Houben, Nicolai Marquardt 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3929-3942</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025562" title="DOI">10.1145/3025453.3025562</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025562&ftid=1870732&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow422" style="display:inline;"><br /><div style="display:inline">Real-time tracking of people's location, orientation and activities is increasingly important for designing novel ubiquitous computing applications. Top-view camera-based tracking avoids occlusion when tracking people while collaborating, but often requires ...</div></span>
          <span id="toHide422" style="display:none;"><br /><div style="display:inline"><p>Real-time tracking of people's location, orientation and activities is increasingly important for designing novel ubiquitous computing applications. Top-view camera-based tracking avoids occlusion when tracking people while collaborating, but often requires complex tracking systems and advanced computer vision algorithms. To facilitate the prototyping of ubiquitous computing applications for interactive spaces, we developed <i>EagleSense</i>, a real-time human posture and activity recognition system with a single top-view depth-sensing camera. We contribute our novel algorithm and processing pipeline, including details for calculating silhouette-extremities features and applying gradient tree boosting classifiers for activity recognition optimized for top-view depth sensing. <i>EagleSense</i> provides easy access to the real-time tracking data and includes tools for facilitating the integration into custom applications. We report the results of a technical evaluation with 12 participants and demonstrate the capabilities of <i>EagleSense</i> with application case studies.</p></div></span> <a id="expcoll422" href="JavaScript: expandcollapse('expcoll422',422)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025685&CFID=758305256&CFTOKEN=14863114">Interactive Visual Calibration of Volumetric Head-Tracked 3D Displays</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Andrew John Wagemakers, Dylan Brodie Fafard, Ian Stavness 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3943-3953</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025685" title="DOI">10.1145/3025453.3025685</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025685&ftid=1870314&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow423" style="display:inline;"><br /><div style="display:inline">Head-tracked 3D displays can provide a compelling 3D effect, but even small inaccuracies in the calibration of the participant's viewpoint to the display can disrupt the 3D illusion. We propose a novel interactive procedure for a participant to easily ...</div></span>
          <span id="toHide423" style="display:none;"><br /><div style="display:inline"><p>Head-tracked 3D displays can provide a compelling 3D effect, but even small inaccuracies in the calibration of the participant's viewpoint to the display can disrupt the 3D illusion. We propose a novel interactive procedure for a participant to easily and accurately calibrate a head-tracked display by visually aligning patterns across a multi-screen display. Head-tracker measurements are then calibrated to these known viewpoints. We conducted a user study to evaluate the effectiveness of different visual patterns and different display shapes. We found that the easiest to align shape was the spherical display and the best calibration pattern was the combination of circles and lines. We performed a quantitative camera-based calibration of a cubic display and found visual calibration outperformed manual tuning and generated viewpoint calibrations accurate to within a degree. Our work removes the usual, burdensome step of manual calibration when using head-tracked displays and paves the way for wider adoption of this inexpensive and effective 3D display technology.</p></div></span> <a id="expcoll423" href="JavaScript: expandcollapse('expcoll423',423)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025795&CFID=758305256&CFTOKEN=14863114">Changing the Appearance of Real-World Objects By Modifying Their Surroundings</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          David Lindlbauer, J&#246;rg Mueller, Marc Alexa 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3954-3965</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025795" title="DOI">10.1145/3025453.3025795</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025795&ftid=1870730&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow424" style="display:inline;"><br /><div style="display:inline">We present an approach to alter the perceived appearance of physical objects by controlling their surrounding space. Many real-world objects cannot easily be equipped with displays or actuators in order to change their shape. While common approaches ...</div></span>
          <span id="toHide424" style="display:none;"><br /><div style="display:inline"><p>We present an approach to alter the perceived appearance of physical objects by controlling their surrounding space. Many real-world objects cannot easily be equipped with displays or actuators in order to change their shape. While common approaches such as projection mapping enable changing the appearance of objects without modifying them, certain surface properties (e.g. highly reflective or transparent surfaces) can make employing these techniques difficult. In this work, we present a conceptual design exploration on how the appearance of an object can be changed by solely altering the space around it, rather than the object itself. In a proof-of-concept implementation, we place objects onto a tabletop display and track them together with users to display perspective-corrected 3D graphics for augmentation. This enables controlling properties such as the perceived size, color, or shape of objects. We characterize the design space of our approach and demonstrate potential applications. For example, we change the contour of a wallet to notify users when their bank account is debited. We envision our approach to gain in importance with increasing ubiquity of display surfaces.</p></div></span> <a id="expcoll424" href="JavaScript: expandcollapse('expcoll424',424)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025533&CFID=758305256&CFTOKEN=14863114">HeadPhones: Ad Hoc Mobile Multi-Display Environments through Head Tracking</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Jens Grubert, Matthias Kranz 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3966-3971</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025533" title="DOI">10.1145/3025453.3025533</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025533&ftid=1870726&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow425" style="display:inline;"><br /><div style="display:inline">We present HeadPhones (Headtracking + smartPhones), a novel approach for the spatial registration of multiple mobile devices into an ad hoc multi-display environment. We propose to employ the user's head as external reference frame for the registration ...</div></span>
          <span id="toHide425" style="display:none;"><br /><div style="display:inline"><p>We present HeadPhones (Headtracking + smartPhones), a novel approach for the spatial registration of multiple mobile devices into an ad hoc multi-display environment. We propose to employ the user's head as external reference frame for the registration of multiple mobile devices into a common coordinate system. Our approach allows for dynamic repositioning of devices during runtime without the need for external infrastructure such as separate cameras or fiducials. Specifically, our only requirements are local network connections and mobile devices with built-in front facing cameras. This way, HeadPhones enables spatially-aware multi-display applications in mobile contexts. A user study and accuracy evaluation indicate the feasibility of our approach.</p></div></span> <a id="expcoll425" href="JavaScript: expandcollapse('expcoll425',425)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Ubiquitous Sensing</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025536&CFID=758305256&CFTOKEN=14863114">Zensei: Embedded, Multi-electrode Bioimpedance Sensing for Implicit, Ubiquitous User Recognition</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Munehiko Sato, Rohan S. Puri, Alex Olwal, Yosuke Ushigome, Lukas Franciszkiewicz, Deepak Chandra, Ivan Poupyrev, Ramesh Raskar 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3972-3985</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025536" title="DOI">10.1145/3025453.3025536</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025536&ftid=1870320&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow427" style="display:inline;"><br /><div style="display:inline">Interactions and connectivity is increasingly expanding to shared objects and environments, such as furniture, vehicles, lighting, and entertainment systems. For transparent personalization in such contexts, we see an opportunity for embedded recognition, ...</div></span>
          <span id="toHide427" style="display:none;"><br /><div style="display:inline"><p>Interactions and connectivity is increasingly expanding to shared objects and environments, such as furniture, vehicles, lighting, and entertainment systems. For transparent personalization in such contexts, we see an opportunity for embedded recognition, to complement traditional, explicit authentication. We introduce Zensei, an implicit sensing system that leverages bio-sensing, signal processing and machine learning to classify uninstrumented users by their body's electrical properties. Zensei could allow many objects to recognize users. E.g., phones that unlock when held, cars that automatically adjust mirrors and seats, or power tools that restore user settings. We introduce wide-spectrum bioimpedance hardware that measures both amplitude and phase. It extends previous approaches through multi-electrode sensing and high-speed wireless data collection for embedded devices. We implement the sensing in devices and furniture, where unique electrode configurations generate characteristic profiles based on user's unique electrical properties. Finally, we discuss results from a comprehensive longitudinal 22-day data collection experiment with 46 subjects. Our analysis shows promising classification accuracy and low false acceptance rate.</p></div></span> <a id="expcoll427" href="JavaScript: expandcollapse('expcoll427',427)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025773&CFID=758305256&CFTOKEN=14863114">Synthetic Sensors: Towards General-Purpose Sensing</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Gierad Laput, Yang Zhang, Chris Harrison 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 3986-3999</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025773" title="DOI">10.1145/3025453.3025773</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025773&ftid=1870323&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow428" style="display:inline;"><br /><div style="display:inline">The promise of smart environments and the Internet of Things (IoT) relies on robust sensing of diverse environmental facets. Traditional approaches rely on direct and distributed sensing, most often by measuring one particular aspect of an environment ...</div></span>
          <span id="toHide428" style="display:none;"><br /><div style="display:inline"><p>The promise of smart environments and the Internet of Things (IoT) relies on robust sensing of diverse environmental facets. Traditional approaches rely on direct and distributed sensing, most often by measuring one particular aspect of an environment with a special purpose sensor. This approach can be costly to deploy, hard to maintain, and aesthetically and socially obtrusive. In this work, we explore the notion of <i>general purpose sensing</i>, wherein a single enhanced sensor can indirectly monitor a large context, without direct instrumentation of objects. Further, through what we call <i>Synthetic Sensors</i>, we can virtualize raw sensor data into actionable feeds, whilst simultaneously mitigating immediate privacy issues. A series of structured, formative studies informed the development of our new sensor hardware and accompanying information architecture. We deployed our system across many months and environments, the results of which show the versatility, accuracy and potential utility of our approach.</p></div></span> <a id="expcoll428" href="JavaScript: expandcollapse('expcoll428',428)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025828&CFID=758305256&CFTOKEN=14863114">Deus EM Machina: On-Touch Contextual Functionality for Smart IoT Appliances</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Robert Xiao, Gierad Laput, Yang Zhang, Chris Harrison 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4000-4008</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025828" title="DOI">10.1145/3025453.3025828</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025828&ftid=1870304&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow429" style="display:inline;"><br /><div style="display:inline">Homes, offices and many other environments will be increasingly saturated with connected, computational appliances, forming the "Internet of Things" (IoT). At present, most of these devices rely on mechanical inputs, webpages, or smartphone apps for ...</div></span>
          <span id="toHide429" style="display:none;"><br /><div style="display:inline"><p>Homes, offices and many other environments will be increasingly saturated with connected, computational appliances, forming the "Internet of Things" (IoT). At present, most of these devices rely on mechanical inputs, webpages, or smartphone apps for control. However, as IoT devices proliferate, these existing interaction methods will become increasingly cumbersome. Will future smart-home owners have to scroll though pages of apps to select and dim their lights? We propose an approach where users simply tap a smartphone to an appliance to discover and rapidly utilize contextual functionality. To achieve this, our prototype smartphone recognizes physical contact with uninstrumented appliances, and summons appliance-specific interfaces. Our user study suggests high accuracy 98.8% recognition accuracy among 17 appliances. Finally, to underscore the immediate feasibility and utility of our system, we built twelve example applications, including six fully functional end-to-end demonstrations.</p></div></span> <a id="expcoll429" href="JavaScript: expandcollapse('expcoll429',429)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025530&CFID=758305256&CFTOKEN=14863114">Seeing, Sensing and Recognizing Laban Movement Qualities</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Sarah Fdili Alaoui, Jules Fran&#231;oise, Thecla Schiphorst, Karen Studd, Frederic Bevilacqua 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4009-4020</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025530" title="DOI">10.1145/3025453.3025530</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025530&ftid=1870325&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow430" style="display:inline;"><br /><div style="display:inline">Human movement has historically been approached as a functional component of interaction within human computer interaction. Yet movement is not only functional, it is also highly expressive. In our research, we explore how movement expertise as articulated ...</div></span>
          <span id="toHide430" style="display:none;"><br /><div style="display:inline"><p>Human movement has historically been approached as a functional component of interaction within human computer interaction. Yet movement is not only functional, it is also highly expressive. In our research, we explore how movement expertise as articulated in Laban Movement Analysis (LMA) can contribute to the design of computational models of movement's expressive qualities as defined in the framework of Laban Efforts. We include experts in LMA in our design process, in order to select a set of suitable multimodal sensors as well as to compute features that closely correlate to the definitions of Efforts in LMA. Evaluation of our model shows that multimodal data combining positional, dynamic and physiological information allows for a better characterization of Laban Efforts. We conclude with implications for design that illustrate how our methodology and our approach to multimodal capture and recognition of Effort qualities can be integrated to design interactive applications.</p></div></span> <a id="expcoll430" href="JavaScript: expandcollapse('expcoll430',430)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Experiences with Virtual Reality</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
  
                  <img src="images/bp_award.jpg" alt="Best Paper" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025683&CFID=758305256&CFTOKEN=14863114">ShareVR: Enabling Co-Located Experiences for Virtual Reality between HMD and Non-HMD Users</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Jan Gugenheimer, Evgeny Stemasov, Julian Frommel, Enrico Rukzio 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4021-4033</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025683" title="DOI">10.1145/3025453.3025683</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025683&ftid=1870327&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow432" style="display:inline;"><br /><div style="display:inline">Virtual reality (VR) head-mounted displays (HMD) allow for a highly immersive experience and are currently becoming part of the living room entertainment. Current VR systems focus mainly on increasing the immersion and enjoyment for the user wearing ...</div></span>
          <span id="toHide432" style="display:none;"><br /><div style="display:inline"><p>Virtual reality (VR) head-mounted displays (HMD) allow for a highly immersive experience and are currently becoming part of the living room entertainment. Current VR systems focus mainly on increasing the immersion and enjoyment for the user wearing the HMD (HMD user), resulting in all the bystanders (Non-HMD users) being excluded from the experience. We propose ShareVR, a proof-of-concept prototype using floor projection and mobile displays in combination with positional tracking to visualize the virtual world for the Non-HMD user, enabling them to interact with the HMD user and become part of the VR experience. We designed and implemented ShareVR based on the insights of an initial online survey (n=48) with early adopters of VR HMDs. We ran a user study (n=16) comparing ShareVRto a baseline condition showing how the interaction using ShareVR led to an increase of enjoyment, presence and social interaction. In a last step we implemented several experiences for ShareVR, exploring its design space and giving insights for designers of co-located asymmetric VR experiences.</p></div></span> <a id="expcoll432" href="JavaScript: expandcollapse('expcoll432',432)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025665&CFID=758305256&CFTOKEN=14863114">CarVR: Enabling In-Car Virtual Reality Entertainment</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Philipp Hock, Sebastian Benedikter, Jan Gugenheimer, Enrico Rukzio 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4034-4044</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025665" title="DOI">10.1145/3025453.3025665</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025665&ftid=1870317&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow433" style="display:inline;"><br /><div style="display:inline">Mobile virtual reality (VR) head-mounted displays (HMDs) allow users to experience highly immersive entertainment whilst being in a mobile scenario. Long commute times make casual gaming in public transports and cars a common occupation. However, VR ...</div></span>
          <span id="toHide433" style="display:none;"><br /><div style="display:inline"><p>Mobile virtual reality (VR) head-mounted displays (HMDs) allow users to experience highly immersive entertainment whilst being in a mobile scenario. Long commute times make casual gaming in public transports and cars a common occupation. However, VR HMDs can currently not be used in moving vehicles since the car's rotation affects the HMD's sensors and simulator sickness occurs when the visual and vestibular system are stimulated with incongruent information. We present CarVR, a solution to enable VR in moving vehicles by subtracting the car's rotation and mapping vehicular movements with the visual information. This allows the user to actually feel correct kinesthetic forces during the VR experience. In a user study (n = 21), we compared CarVR inside a moving vehicle with the baseline of using VR without vehicle movements. We show that the perceived kinesthetic forces caused by CarVR increase enjoyment and immersion significantly while simulator sickness is reduced compared to a stationary VR experience. Finally, we explore the design space of in-car VR entertainment applications using real kinesthetic forces and derive design considerations for practitioners.</p></div></span> <a id="expcoll433" href="JavaScript: expandcollapse('expcoll433',433)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3026028&CFID=758305256&CFTOKEN=14863114">Effects of Sharing Physiological States of Players in a Collaborative Virtual Reality Gameplay</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Arindam Dey, Thammathip Piumsomboon, Youngho Lee, Mark Billinghurst 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4045-4056</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3026028" title="DOI">10.1145/3025453.3026028</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3026028&ftid=1870312&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow434" style="display:inline;"><br /><div style="display:inline">Interfaces for collaborative tasks, such as multiplayer games can enable more effective and enjoyable collaboration. However, in these systems, the emotional states of the users are often not communicated properly due to their remoteness from one another. ...</div></span>
          <span id="toHide434" style="display:none;"><br /><div style="display:inline"><p>Interfaces for collaborative tasks, such as multiplayer games can enable more effective and enjoyable collaboration. However, in these systems, the emotional states of the users are often not communicated properly due to their remoteness from one another. In this paper, we investigate the effects of showing emotional states of one collaborator to the other during an immersive Virtual Reality (VR) gameplay experience. We created two collaborative immersive VR games that display the real-time heart-rate of one player to the other. The two different games elicited different emotions, one joyous and the other scary. We tested the effects of visualizing heart-rate feedback in comparison with conditions where such a feedback was absent. The games had significant main effects on the overall emotional experience.</p></div></span> <a id="expcoll434" href="JavaScript: expandcollapse('expcoll434',434)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025566&CFID=758305256&CFTOKEN=14863114">VRRRRoom: Virtual Reality for Radiologists in the Reading Room</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Maur&#237;cio Sousa, Daniel Mendes, Soraia Paulo, Nuno Matela, Joaquim Jorge, Daniel Sim&#245;es Lopes 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4057-4062</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025566" title="DOI">10.1145/3025453.3025566</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025566&ftid=1870307&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow435" style="display:inline;"><br /><div style="display:inline">Reading room conditions such as illumination, ambient light, human factors and display luminance, play an important role on how radiologists analyze and interpret images. Indeed, serious diagnostic errors can appear when observing images through everyday ...</div></span>
          <span id="toHide435" style="display:none;"><br /><div style="display:inline"><p>Reading room conditions such as illumination, ambient light, human factors and display luminance, play an important role on how radiologists analyze and interpret images. Indeed, serious diagnostic errors can appear when observing images through everyday monitors. Typically, these occur whenever professionals are ill-positioned with respect to the display or visualize images under improper light and luminance conditions. In this work, we show that virtual reality can assist radiodiagnostics by considerably diminishing or cancel out the effects of unsuitable ambient conditions. Our approach combines immersive head-mounted displays with interactive surfaces to support professional radiologists in analyzing medical images and formulating diagnostics. We evaluated our prototype with two senior medical doctors and four seasoned radiology fellows. Results indicate that our approach constitutes a viable, flexible, portable and cost-efficient option to traditional radiology reading rooms.</p></div></span> <a id="expcoll435" href="JavaScript: expandcollapse('expcoll435',435)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025521&CFID=758305256&CFTOKEN=14863114">Handsfree Omnidirectional VR Navigation using Head Tilt</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Sam Tregillus, Majed Al Zayer, Eelke Folmer 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4063-4068</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025521" title="DOI">10.1145/3025453.3025521</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025521&ftid=1870315&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow436" style="display:inline;"><br /><div style="display:inline">Navigating mobile virtual reality (VR) is a challenge due to limited input options and/or a requirement for handsfree interaction. Walking-in-place (WIP) is considered to offer a higher presence than controller input but only allows unidirectional navigation ...</div></span>
          <span id="toHide436" style="display:none;"><br /><div style="display:inline"><p>Navigating mobile virtual reality (VR) is a challenge due to limited input options and/or a requirement for handsfree interaction. Walking-in-place (WIP) is considered to offer a higher presence than controller input but only allows unidirectional navigation in the direction of the user's gaze--which impedes navigation efficiency. Leaning input enables omnidirectional navigation but currently relies on bulky controllers, which aren't feasible in mobile VR contexts. This note evaluates the use of head-tilt - implemented using inertial sensing - to allow for handsfree omnidirectional VR navigation on mobile VR platforms. A user study with 24 subjects compared three input methods using an obstacle avoidance navigation task: (1) head-tilt alone (TILT) (2) a hybrid method (WIP-TILT) that uses head tilting for direction and WIP to control speed; and (3) traditional controller input. TILT was significantly faster than WIP-TILT and joystick input, while WIP-TILT and TILT offered the highest presence. There was no difference in cybersickness between input methods.</p></div></span> <a id="expcoll436" href="JavaScript: expandcollapse('expcoll436',436)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Food &#38; Nutrition</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025656&CFID=758305256&CFTOKEN=14863114">Rice Today, Roti Tomorrow: Diets and Diabetes in Urban Indian Households</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Jasmine Hentschel, Samyukta Manjayya Sherugar, Rui Zhou, Vaishnav Kameswaran, Rajesh Chandwani, Neha Kumar 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4069-4081</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025656" title="DOI">10.1145/3025453.3025656</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025656&ftid=1870731&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow438" style="display:inline;"><br /><div style="display:inline">In India, where diabetes is a growing concern and approximately 69 million are affected, we investigate the factors that influence diet management, a critical component of living with the disease. Taking the middle-income diabetes-affected household ...</div></span>
          <span id="toHide438" style="display:none;"><br /><div style="display:inline"><p>In India, where diabetes is a growing concern and approximately 69 million are affected, we investigate the factors that influence diet management, a critical component of living with the disease. Taking the middle-income diabetes-affected household as our unit of analysis, we use a combination of semi-structured interviews and a design probe to understand if and how diets are monitored, tailored, and balanced. We research the various information-seeking behaviors of our participants and their culturally situated approaches to food and eating. Our findings illuminate how contextual nuances shape individuals' beliefs around dealing with diabetes and the ways in which family, friends, and broader social networks influence dietary decisions. We conclude by offering a framework of <i>Learning-Being-Doing</i> to inform the holistic design of technologies for managing diets and diabetes.</p></div></span> <a id="expcoll438" href="JavaScript: expandcollapse('expcoll438',438)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3026052&CFID=758305256&CFTOKEN=14863114">Monster Appetite: Effects of Subversive Framing on Nutritional Choices in a Digital Game Environment</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Maria L. Hwang, Lena Mamykina 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4082-4096</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3026052" title="DOI">10.1145/3025453.3026052</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3026052&ftid=1870319&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow439" style="display:inline;"><br /><div style="display:inline">Americans' health has reached a dangerous obesity epidemic from overconsumption and unhealthy food choices. In response, persuasive games for health encourage healthier lifestyles typically by providing positive reinforcement for the desired behaviors. ...</div></span>
          <span id="toHide439" style="display:none;"><br /><div style="display:inline"><p>Americans' health has reached a dangerous obesity epidemic from overconsumption and unhealthy food choices. In response, persuasive games for health encourage healthier lifestyles typically by providing positive reinforcement for the desired behaviors. However, positive reinforcement is only one of the many possibly effective approaches. We explore two types of message framing in a nutrition game, Monster Appetite (MA). In MA, players' choices of high or low calorie snacks impact visual appearance of their monster avatar. MA utilizes two types of health messages: subversive, which encourages players to make unhealthy choices and focuses on costs, and inoculation, which encourages players to eventually defend healthy choices and focuses on benefits. We test message framing's effect by tracking users' purchasing behavior in our online snack shop, Snackazon. The study showed that when positive messages were embedded in MA mixed with negative visuals through the monster avatars, participants exhibited better snack choices post-gameplay.</p></div></span> <a id="expcoll439" href="JavaScript: expandcollapse('expcoll439',439)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025874&CFID=758305256&CFTOKEN=14863114">The Role of Explanations in Casual Observational Learning about Nutrition</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Marissa Burgermaster, Krzysztof Z. Gajos, Patricia Davidson, Lena Mamykina 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4097-4145</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025874" title="DOI">10.1145/3025453.3025874</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025874&ftid=1870308&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow440" style="display:inline;"><br /><div style="display:inline">The ubiquity of internet-based nutrition information sharing indicates an opportunity to use social computing platforms to promote nutrition literacy and healthy nutritional choices. We conducted a series of experiments with unpaid volunteers using an ...</div></span>
          <span id="toHide440" style="display:none;"><br /><div style="display:inline"><p>The ubiquity of internet-based nutrition information sharing indicates an opportunity to use social computing platforms to promote nutrition literacy and healthy nutritional choices. We conducted a series of experiments with unpaid volunteers using an online Nutrition Knowledge Test. The test asked participants to examine pairs of photographed meals and identify meals higher in a specific macronutrient (e.g., carbohydrate). After each answer, participants received no feedback on the accuracy of their answers, viewed proportions of peers choosing each response, received correctness feedback from an expert dietitian with or without expert-generated explanations, or received correctness feedback with crowd-generated explanations. The results showed that neither viewing peer responses nor correctness feedback alone improved learning. However, correctness feedback with explanations (i.e., modeling) led to significant learning gains, with no significant difference between explanations generated by experts or peers. This suggests the importance of explanations in social computing-based casual learning about nutrition and the potential for scaling this approach via crowdsourcing.</p></div></span> <a id="expcoll440" href="JavaScript: expandcollapse('expcoll440',440)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Impaired Vision and Navigation</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025518&CFID=758305256&CFTOKEN=14863114">Audible Beacons and Wearables in Schools: Helping Young Visually Impaired Children Play and Move Independently</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Euan Freeman, Graham Wilson, Stephen Brewster, Gabriel Baud-Bovy, Charlotte Magnusson, Hector Caltenco 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4146-4157</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025518" title="DOI">10.1145/3025453.3025518</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025518&ftid=1870368&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow442" style="display:inline;"><br /><div style="display:inline">Young children with visual impairments tend to engage less with their surroundings, limiting the benefits from activities at school. We investigated novel ways of using sound from a bracelet, such as speech or familiar noises, to tell children about ...</div></span>
          <span id="toHide442" style="display:none;"><br /><div style="display:inline"><p>Young children with visual impairments tend to engage less with their surroundings, limiting the benefits from activities at school. We investigated novel ways of using sound from a bracelet, such as speech or familiar noises, to tell children about nearby people, places and activities, to encourage them to engage more during play and help them move independently. We present a series of studies, the first two involving visual impairment educators, that give insight into challenges faced by visually impaired children at school and how sound might help them. We then present a focus group with visually impaired children that gives further insight into the effective use of sound. Our findings reveal novel ways of combining sounds from wearables with sounds from the environment, motivating audible beacons, devices for audio output and proximity estimation. We present scenarios, findings and a design space that show the novel ways such devices could be used alongside wearables to help visually impaired children at school.</p></div></span> <a id="expcoll442" href="JavaScript: expandcollapse('expcoll442',442)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025528&CFID=758305256&CFTOKEN=14863114">Embracing Errors: Examining How Context of Use Impacts Blind Individuals' Acceptance of Navigation Aid Errors</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Ali Abdolrahmani, William Easley, Michele Williams, Stacy Branham, Amy Hurst 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4158-4169</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025528" title="DOI">10.1145/3025453.3025528</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025528&ftid=1870391&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow443" style="display:inline;"><br /><div style="display:inline">Prevention of errors has been an orienting goal within the field of Human-Computer Interaction since its inception, with particular focus on minimizing human errors through appropriate technology design. However, there has been relatively little ...</div></span>
          <span id="toHide443" style="display:none;"><br /><div style="display:inline"><p>Prevention of errors has been an orienting goal within the field of Human-Computer Interaction since its inception, with particular focus on minimizing <i>human</i> errors through appropriate technology design. However, there has been relatively little exploration into how designers can best support users of <i>technologies</i> that will inevitably make errors. We present a mixed-methods study in the domain of navigation technology for visually impaired individuals. We examined how users respond to device errors made in realistic scenarios of use. Contrary to conventional wisdom that usable systems must be error-free, we found that 42% of errors were acceptable to users. Acceptance of errors depends on error type, building feature, and environmental context. Further, even when a technical error is acceptable to the user, the misguided social responses of others nearby can negatively impact user experience. We conclude with design recommendations that embrace errors while also supporting user management of errors in technical systems.</p></div></span> <a id="expcoll443" href="JavaScript: expandcollapse('expcoll443',443)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025949&CFID=758305256&CFTOKEN=14863114">Understanding Low Vision People's Visual Perception on Commercial Augmented Reality Glasses</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Yuhang Zhao, Michele Hu, Shafeka Hashash, Shiri Azenkot 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4170-4181</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025949" title="DOI">10.1145/3025453.3025949</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025949&ftid=1870362&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow444" style="display:inline;"><br /><div style="display:inline">People with low vision have a visual impairment that affects their ability to perform daily activities. Unlike blind people, low vision people have functional vision and can potentially benefit from smart glasses that provide dynamic, always-available ...</div></span>
          <span id="toHide444" style="display:none;"><br /><div style="display:inline"><p>People with low vision have a visual impairment that affects their ability to perform daily activities. Unlike blind people, low vision people have functional vision and can potentially benefit from smart glasses that provide dynamic, always-available visual information. We sought to determine what low vision people could see on mainstream commercial augmented reality (AR) glasses, despite their visual limitations and the device's constraints. We conducted a study with 20 low vision participants and 18 sighted controls, asking them to identify virtual shapes and text in different sizes, colors, and thicknesses. We also evaluated their ability to see the virtual elements while walking. We found that low vision participants were able to identify basic shapes and read short phrases on the glasses while sitting and walking. Identifying virtual elements had a similar effect on low vision and sighted people's walking speed, slowing it down slightly. Our study yielded preliminary evidence that mainstream AR glasses can be powerful accessibility tools. We derive guidelines for presenting visual output for low vision people and discuss opportunities for accessibility applications on this platform.</p></div></span> <a id="expcoll444" href="JavaScript: expandcollapse('expcoll444',444)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025906&CFID=758305256&CFTOKEN=14863114">Synthesizing Stroke Gestures Across User Populations: A Case for Users with Visual Impairments</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Luis A. Leiva, Daniel Mart&#237;n-Albo, Radu-Daniel Vatavu 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4182-4193</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025906" title="DOI">10.1145/3025453.3025906</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025906&ftid=1870359&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow445" style="display:inline;"><br /><div style="display:inline">We introduce a new principled method grounded in the Kinematic Theory of Rapid Human Movements to automatically generate synthetic stroke gestures across user populations in order to support ability-based design of gesture user interfaces. Our ...</div></span>
          <span id="toHide445" style="display:none;"><br /><div style="display:inline"><p>We introduce a new principled method grounded in the Kinematic Theory of Rapid Human Movements to automatically generate synthetic stroke gestures <i>across user populations</i> in order to support ability-based design of gesture user interfaces. Our method is especially useful when the target user population is difficult to sample adequately and, consequently, when there is not enough data to train gesture recognizers to deliver high levels of accuracy. To showcase the relevance and usefulness of our method, we collected gestures from people <i>without</i> visual impairments and successfully synthesized gestures with the articulation characteristics of people <i>with</i> visual impairments. We also show that gesture recognition accuracy improves significantly when using our synthetic gesture samples for training. Our contributions will benefit researchers and practitioners that wish to design gesture user interfaces for people with various abilities by helping them prototype, evaluate, and predict gesture recognition performance without having to expressly recruit and involve people with disabilities in long, time-consuming gesture collection experiments.</p></div></span> <a id="expcoll445" href="JavaScript: expandcollapse('expcoll445',445)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Innovative Text Entry Systems</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025520&CFID=758305256&CFTOKEN=14863114">Investigating Tilt-based Gesture Keyboard Entry for Single-Handed Text Entry on Large Devices</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Hui-Shyong Yeo, Xiao-Shen Phang, Steven J. Castellucci, Per Ola Kristensson, Aaron Quigley 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4194-4202</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025520" title="DOI">10.1145/3025453.3025520</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025520&ftid=1870377&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow447" style="display:inline;"><br /><div style="display:inline">The popularity of mobile devices with large screens is making single-handed interaction difficult. We propose and evaluate a novel design point around a tilt-based text entry technique which supports single handed usage. Our technique is based on the ...</div></span>
          <span id="toHide447" style="display:none;"><br /><div style="display:inline"><p>The popularity of mobile devices with large screens is making single-handed interaction difficult. We propose and evaluate a novel design point around a tilt-based text entry technique which supports single handed usage. Our technique is based on the gesture keyboard (shape writing). However, instead of drawing gestures with a finger or stylus, users articulate a gesture by tilting the device. This can be especially useful when the user's other hand is otherwise encumbered or unavailable. We show that novice users achieve an entry rate of 15 words-per-minute (wpm) after minimal practice. A pilot longitudinal study reveals that a single participant achieved an entry rate of 32 wpm after approximate 90 minutes of practice. Our data indicate that tilt-based gesture keyboard entry enables walk-up use and provides a suitable text entry rate for occasional use and can act as a promising alternative to single-handed typing in certain situations.</p></div></span> <a id="expcoll447" href="JavaScript: expandcollapse('expcoll447',447)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/bp_award.jpg" alt="Best Paper" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025580&CFID=758305256&CFTOKEN=14863114">Modelling Learning of New Keyboard Layouts</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Jussi P. P. Jokinen, Sayan Sarcar, Antti Oulasvirta, Chaklam Silpasuwanchai, Zhenxin Wang, Xiangshi Ren 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4203-4215</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025580" title="DOI">10.1145/3025453.3025580</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025580&ftid=1870348&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow448" style="display:inline;"><br /><div style="display:inline">Predicting how users learn new or changed interfaces is a long-standing objective in HCI research. This paper contributes to understanding of visual search and learning in text entry. With a goal of explaining variance in novices' typing performance ...</div></span>
          <span id="toHide448" style="display:none;"><br /><div style="display:inline"><p>Predicting how users learn new or changed interfaces is a long-standing objective in HCI research. This paper contributes to understanding of visual search and learning in text entry. With a goal of explaining variance in novices' typing performance that is attributable to visual search, a model was designed to predict how users learn to locate keys on a keyboard: initially relying on visual short-term memory but then transitioning to recall-based search. This allows predicting search times and visual search patterns for completely and partially new layouts. The model complements models of motor performance and learning in text entry by predicting change in visual search patterns over time. Practitioners can use it for estimating how long it takes to reach the desired level of performance with a given layout.</p></div></span> <a id="expcoll448" href="JavaScript: expandcollapse('expcoll448',448)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025701&CFID=758305256&CFTOKEN=14863114">Word Clarity as a Metric in Sampling Keyboard Test Sets</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Xin Yi, Chun Yu, Weinan Shi, Xiaojun Bi, Yuanchun Shi 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4216-4228</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025701" title="DOI">10.1145/3025453.3025701</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025701&ftid=1870350&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow449" style="display:inline;"><br /><div style="display:inline">Test sets play an essential role in evaluating text entry techniques. In this paper, we argue that in addition to the widely adopted metric of bigram representativeness and memorability, word clarity should also be considered as a metric when creating ...</div></span>
          <span id="toHide449" style="display:none;"><br /><div style="display:inline"><p>Test sets play an essential role in evaluating text entry techniques. In this paper, we argue that in addition to the widely adopted metric of bigram representativeness and memorability, word clarity should also be considered as a metric when creating test sets from the target dataset. Word clarity quantifies the extent to which a word is likely to confuse with other words on a keyboard. We formally define word clarity, derive equations calculating it, and both theoretically and empirically show that word clarity has a significant effect on text entry performance: it can yield up to 26.4% difference in error rate, and 25% difference in input speed. We later propose a Pareto optimization method for sampling test sets with different sizes, which optimizes the word clarity and bigram representativeness, and memorability of the test set. The obtained test sets are published on the Internet.</p></div></span> <a id="expcoll449" href="JavaScript: expandcollapse('expcoll449',449)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025695&CFID=758305256&CFTOKEN=14863114">Quantifying Aversion to Costly Typing Errors in Expert Mobile Text Entry</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Nikola Banovic, Varun Rao, Abinaya Saravanan, Anind K. Dey, Jennifer Mankoff 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4229-4241</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025695" title="DOI">10.1145/3025453.3025695</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025695&ftid=1870378&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow450" style="display:inline;"><br /><div style="display:inline">Text entry is an increasingly important activity for mobile device users. As a result, increasing text entry speed of expert typists is an important design goal for physical and soft keyboards. Mathematical models that predict text entry speed can help ...</div></span>
          <span id="toHide450" style="display:none;"><br /><div style="display:inline"><p>Text entry is an increasingly important activity for mobile device users. As a result, increasing text entry speed of expert typists is an important design goal for physical and soft keyboards. Mathematical models that predict text entry speed can help with keyboard design and optimization. Making typing errors when entering text is inevitable. However, current models do not consider how typists themselves reduce the risk of making typing errors (and lower error frequency) by typing more slowly. We demonstrate that users respond to costly typing errors by reducing their typing speed to minimize typing errors. We present a model that estimates the effects of risk aversion to errors on typing speed. We estimate the magnitude of this speed change, and show that disregarding the adjustments to typing speed that expert typists use to reduce typing errors leads to overly optimistic estimates of maximum errorless expert typing speeds.</p></div></span> <a id="expcoll450" href="JavaScript: expandcollapse('expcoll450',450)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Models of Use and Gestures</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025509&CFID=758305256&CFTOKEN=14863114">High Costs and Small Benefits: A Field Study of How Users Experience Operating System Upgrades</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Francesco Vitale, Joanna McGrenere, Aur&#233;lien Tabard, Michel Beaudouin-Lafon, Wendy E. Mackay 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4242-4253</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025509" title="DOI">10.1145/3025453.3025509</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025509&ftid=1870354&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow452" style="display:inline;"><br /><div style="display:inline">Users must manage frequent software and operating system upgrades across multiple computing devices. While current research focuses primarily on the security aspect, we investigate the user's perspective of upgrading software. Our first study (n=65) ...</div></span>
          <span id="toHide452" style="display:none;"><br /><div style="display:inline"><p>Users must manage frequent software and operating system upgrades across multiple computing devices. While current research focuses primarily on the security aspect, we investigate the user's perspective of upgrading software. Our first study (n=65) found that users delay major upgrades by an average of 80 days. We then ran a field study (n=14), beginning with in-depth observations during an operating system upgrade, followed by a four-week diary study. Very few participants prepared for upgrades (e.g., backing up files), and over half had negative reactions to the upgrade process and other changes (e.g., bugs, lost settings, unwanted features). During the upgrade process, waiting times were too long, feedback was confusing or misleading, and few had clear mental models of what was happening. Users almost never mentioned security as a concern or reason for upgrading. By contrast, interviews (n=3) with technical staff responsible for one organization's upgrades focused only on security and licensing, not user interface changes. We conclude with recommendations to improve the user's upgrade experience.</p></div></span> <a id="expcoll452" href="JavaScript: expandcollapse('expcoll452',452)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025636&CFID=758305256&CFTOKEN=14863114">Understanding Shoulder Surfing in the Wild: Stories from Users and Observers</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Malin Eiband, Mohamed Khamis, Emanuel von Zezschwitz, Heinrich Hussmann, Florian Alt 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4254-4265</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025636" title="DOI">10.1145/3025453.3025636</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025636&ftid=1870390&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow453" style="display:inline;"><br /><div style="display:inline">Research has brought forth a variety of authentication systems to mitigate observation attacks. However, there is little work about shoulder surfing situations in the real world. We present the results of a user survey (N=174) in which we investigate ...</div></span>
          <span id="toHide453" style="display:none;"><br /><div style="display:inline"><p>Research has brought forth a variety of authentication systems to mitigate observation attacks. However, there is little work about shoulder surfing situations in the real world. We present the results of a user survey (N=174) in which we investigate actual stories about shoulder surfing on mobile devices from both users and observers. Our analysis indicates that shoulder surfing mainly occurs in an opportunistic, non-malicious way. It usually does not have serious consequences, but evokes negative feelings for both parties, resulting in a variety of coping strategies. Observed data was personal in most cases and ranged from information about interests and hobbies to login data and intimate details about third persons and relationships. Thus, our work contributes evidence for shoulder surfing in the real world and informs implications for the design of privacy protection mechanisms.</p></div></span> <a id="expcoll453" href="JavaScript: expandcollapse('expcoll453',453)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025764&CFID=758305256&CFTOKEN=14863114">Fieldward and Pathward: Dynamic Guides for Defining Your Own Gestures</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Joseph Malloch, Carla F. Griggio, Joanna McGrenere, Wendy E. Mackay 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4266-4277</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025764" title="DOI">10.1145/3025453.3025764</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025764&ftid=1870370&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow454" style="display:inline;"><br /><div style="display:inline">Although users accomplish ever more tasks on touch-enabled mobile devices, gesture-based interaction remains limited and almost never customizable by users. Our goal is to help users create gestures that are both personally memorable and reliably recognized ...</div></span>
          <span id="toHide454" style="display:none;"><br /><div style="display:inline"><p>Although users accomplish ever more tasks on touch-enabled mobile devices, gesture-based interaction remains limited and almost never customizable by users. Our goal is to help users create gestures that are both personally memorable and reliably recognized by a touch-enabled mobile device. We address these competing requirements with two dynamic guides that use progressive feedforward to interactively visualize the "negative space" of unused gestures: the Pathward technique suggests four possible completions to the current gesture, and the Fieldward technique uses color gradients to reveal optimal directions for creating recognizable gestures. We ran a two-part experiment in which 27 participants each created 42 personal gesture shortcuts on a smartphone, using Pathward, Fieldward or No Feedforward. The Fieldward technique best supported the most common user strategy, i.e. to create a memorable gesture first and then adapt it to be recognized by the system. Users preferred the Fieldward technique to Pathward or No Feedforward, and remembered gestures more easily when using the technique. Dynamic guides can help developers design novel gesture vocabularies and support users as they design custom gestures for mobile applications.</p></div></span> <a id="expcoll454" href="JavaScript: expandcollapse('expcoll454',454)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025513&CFID=758305256&CFTOKEN=14863114">Gesture Interfaces: Minor Change in Effort, Major Impact on Appeal</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Xiaoxing Liu, Geb W. Thomas 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4278-4283</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025513" title="DOI">10.1145/3025453.3025513</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025513&ftid=1870388&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow455" style="display:inline;"><br /><div style="display:inline">Making gestures easy for imaging systems to reliably recognize often comes at the expense of user effort. But what is the impact of increasing a gesture's effort, even slightly, on user preference? We investigate physical effort, system reliability, ...</div></span>
          <span id="toHide455" style="display:none;"><br /><div style="display:inline"><p>Making gestures easy for imaging systems to reliably recognize often comes at the expense of user effort. But what is the impact of increasing a gesture's effort, even slightly, on user preference? We investigate physical effort, system reliability, and user satisfaction in two experiments. The first explores eight basic command gestures. Participants preferred the less effortful gestures in two of the three easy-difficult gesture pairs when they perceived the difference in effort to be significantly different. The second experiment explores two separate three-dimensional pointing and selection conditions that differ only in the movement distance required to finish the task. In both experiments, there is a significant negative correlation between a gesture's effort and its appeal. The results show the great impact that effort has on a user's willingness to utilize the system. The findings provide evidence that the trade-off between user effort and system reliability must be carefully considered to build an effective gesture interface.</p></div></span> <a id="expcoll455" href="JavaScript: expandcollapse('expcoll455',455)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025653&CFID=758305256&CFTOKEN=14863114">MoveMeant: Anonymously Building Community Through Shared Location Histories</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Emily Sun, Ross McLachlan, Mor Naaman 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4284-4289</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025653" title="DOI">10.1145/3025453.3025653</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025653&ftid=1870356&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow456" style="display:inline;"><br /><div style="display:inline">Awareness of and connections to a local community are important for building social capital, sharing resources, and providing physical support, but have been elusive to create in dense urban environments. We describe the design and implementation of ...</div></span>
          <span id="toHide456" style="display:none;"><br /><div style="display:inline"><p>Awareness of and connections to a local community are important for building social capital, sharing resources, and providing physical support, but have been elusive to create in dense urban environments. We describe the design and implementation of MoveMeant, a system aimed to increase local community awareness through shared location traces. MoveMeant securely uses anonymized location data generated automatically by mobile devices to display aggregate, community-level location data. We report findings from interviews with residents in the Bronx, New York City who participated in a deployment of MoveMeant over a 6-week period. Our findings show that people use the anonymous information to make judgments about the people and places in their community, while opting to reveal their identity for third places where there is an opportunity to connect socially.</p></div></span> <a id="expcoll456" href="JavaScript: expandcollapse('expcoll456',456)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Sound of Music</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025505&CFID=758305256&CFTOKEN=14863114">MuEns: A Multimodal Human-Machine Music Ensemble for Live Concert Performance</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Akira Maezawa, Kazuhiko Yamamoto 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4290-4301</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025505" title="DOI">10.1145/3025453.3025505</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025505&ftid=1870392&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow458" style="display:inline;"><br /><div style="display:inline">Musical ensemble between human musicians and computers is a challenging task. We achieve this with a concert-quality synchronization using machine learning. Our system recognizes the position in a given song from the human performance using the microphone ...</div></span>
          <span id="toHide458" style="display:none;"><br /><div style="display:inline"><p>Musical ensemble between human musicians and computers is a challenging task. We achieve this with a concert-quality synchronization using machine learning. Our system recognizes the position in a given song from the human performance using the microphone and camera inputs, and responds in real-time with audio and visual feedback as a music ensemble. We address three crucial requirements in a musical ensemble system. First, our system interacts with human players through both audio and visual cues, the conventional modes of coordination for musicians. Second, our system synchronizes with human performances while retaining its intended musical expression. Third, our system prevents failures during a concert due to bad tracking, by displaying an internal confidence measure and allowing a backstage human operator to "intervene" if the system is unconfident. We show the feasibility of the system with several experiments, including a professional concert.</p></div></span> <a id="expcoll458" href="JavaScript: expandcollapse('expcoll458',458)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025900&CFID=758305256&CFTOKEN=14863114">Playing Fast and Loose with Music Recognition</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Chris Greenhalgh, Steve Benford, Adrian Hazzard, Alan Chamberlain 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4302-4313</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025900" title="DOI">10.1145/3025453.3025900</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025900&ftid=1870363&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow459" style="display:inline;"><br /><div style="display:inline">We report lessons from iteratively developing a music recognition system to enable a wide range of musicians to embed musical codes into their typical performance practice. The musician composes fragments of music that can be played back with varying ...</div></span>
          <span id="toHide459" style="display:none;"><br /><div style="display:inline"><p>We report lessons from iteratively developing a music recognition system to enable a wide range of musicians to embed musical codes into their typical performance practice. The musician composes fragments of music that can be played back with varying levels of embellishment, disguise and looseness to trigger digital interactions. We collaborated with twenty-three musicians, spanning professionals to amateurs and working with a variety of instruments. We chart the rapid evolution of the system to meet their needs as they strove to integrate music recognition technology into their performance practice, introducing multiple features to enable them to trade-off reliability with musical expression. Collectively, these support the idea of deliberately introducing "looseness" into interactive systems by addressing the three key challenges of control, feedback and attunement, and highlight the potential role for written notations in other recognition-based systems.</p></div></span> <a id="expcoll459" href="JavaScript: expandcollapse('expcoll459',459)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025989&CFID=758305256&CFTOKEN=14863114">Holographic Whisper: Rendering Audible Sound Spots in Three-dimensional Space by Focusing Ultrasonic Waves</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Yoichi Ochiai, Takayuki Hoshi, Ippei Suzuki 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4314-4325</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025989" title="DOI">10.1145/3025453.3025989</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025989&ftid=1870365&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow460" style="display:inline;"><br /><div style="display:inline">We propose a novel method of spatial audio rendering using ultrasound. An ultrasonic phased array generates one or more focal points in air, and they act as point sources of audible sound when the ultrasound waves are modulated. Our sound-point loudspeaker ...</div></span>
          <span id="toHide460" style="display:none;"><br /><div style="display:inline"><p>We propose a novel method of spatial audio rendering using ultrasound. An ultrasonic phased array generates one or more focal points in air, and they act as point sources of audible sound when the ultrasound waves are modulated. Our sound-point loudspeaker has two major advantages over conventional ultrasound-based sound-beam (superdirectional) loudspeakers. The higher audience selectivity means that our sound-point loudspeaker can deliver sound to the ears of the target person, whereas a sound-beam loudspeaker delivers sound to not only the target person but also other persons standing in the same direction. The other advantage is lower exposure to ultrasound; while an audible sound beam travels along an ultrasonic beam in a soundbeam loudspeaker, audible sound can be heard along the direction perpendicular to the ultrasonic beam in our soundpoint loudspeaker. This paper reports the principles of our sound-point loudspeaker, prototype construction, evaluation, and applications.</p></div></span> <a id="expcoll460" href="JavaScript: expandcollapse('expcoll460',460)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025583&CFID=758305256&CFTOKEN=14863114">EnseWing: Creating an Instrumental Ensemble Playing Experience for Children with Limited Music Training</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Fei Lyu, Feng Tian, Wenxin Feng, Xiang Cao, Xiaolong (Luke) Zhang, Guozhong Dai, Hongan Wang 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4326-4330</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025583" title="DOI">10.1145/3025453.3025583</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025583&ftid=1870345&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow461" style="display:inline;"><br /><div style="display:inline">While instrumental ensemble playing can benefit children's music education and collaboration skill development, it requires extensive training on music and instruments, which many school children lack. To help children with limited music training experience ...</div></span>
          <span id="toHide461" style="display:none;"><br /><div style="display:inline"><p>While instrumental ensemble playing can benefit children's music education and collaboration skill development, it requires extensive training on music and instruments, which many school children lack. To help children with limited music training experience instrumental ensemble playing, we created EnseWing, an interactive system that offers such an experience. In this paper, we report the design of the EnseWing experience and a two-month field study. Our results show that EnseWing preserves the music and ensemble skills from traditional instrumental ensemble and provides more collaboration opportunities for children.</p></div></span> <a id="expcoll461" href="JavaScript: expandcollapse('expcoll461',461)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Technology Enabled Commerce</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025515&CFID=758305256&CFTOKEN=14863114">Market Design for HCI: Successes and Failures of Peer-to-Peer Exchange Platforms</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Airi Lampinen, Barry Brown 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4331-4343</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025515" title="DOI">10.1145/3025453.3025515</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025515&ftid=1870381&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow463" style="display:inline;"><br /><div style="display:inline">This paper explores an HCI approach to designing markets, with a primary focus on peer-to peer exchange platforms. We draw on&#160;recent work in economics that has documented how markets function, how they can be evaluated, and what can be done to fix ...</div></span>
          <span id="toHide463" style="display:none;"><br /><div style="display:inline"><p>This paper explores an HCI approach to designing markets, with a primary focus on peer-to peer exchange platforms. We draw on&#160;recent work in economics that has documented how markets function, how they can be evaluated, and what can be done to fix them when they fail. We introduce five key concepts from market design: thickness, congestion, stability, safety, and repugnance. These lend HCI an analytic vocabulary for understanding why markets may succeed or struggle. Building on prior empirical work, we apply these concepts to compare two well-known network hospitality platforms, Couchsurfing and Airbnb. As a second illustrative case, we use market design to shed light on the challenges experienced by smaller-scale peer-to-peer marketplaces for lending, renting, and selling physical goods. To conclude, we discuss how this kind of analysis can make conceptual, evaluative, and generative contributions to the study and design of exchange platforms and other socio-technical systems.</p></div></span> <a id="expcoll463" href="JavaScript: expandcollapse('expcoll463',463)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025550&CFID=758305256&CFTOKEN=14863114">Community Commerce: Facilitating Trust in Mom-to-Mom Sale Groups on Facebook</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Carol Moser, Paul Resnick, Sarita Schoenebeck 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4344-4357</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025550" title="DOI">10.1145/3025453.3025550</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025550&ftid=1870380&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow464" style="display:inline;"><br /><div style="display:inline">Consumers are turning to Facebook Groups to buy and sell with strangers in their local communities. This trend is counter-intuitive given Facebook's lack of conventional e-commerce features, such as sophisticated search engines and reputation systems. ...</div></span>
          <span id="toHide464" style="display:none;"><br /><div style="display:inline"><p>Consumers are turning to Facebook Groups to buy and sell with strangers in their local communities. This trend is counter-intuitive given Facebook's lack of conventional e-commerce features, such as sophisticated search engines and reputation systems. We interviewed 18 members of two Mom-to-Mom Facebook sale groups. Despite a lack of commerce tools, members perceived sale groups as an easy-to-use way to quickly and conveniently buy and sell. Most important to members was that the groups felt safe and trustworthy. Drawing on these insights, we contribute a novel framing, <i>community commerce</i>, which explains the trust mechanisms that enable transactions between strangers in some groups. Community commerce fosters trust through (a) exclusive membership to a closed group, (b) regulation and sanctioning of behavior at the admin, member, and group level, and (c) a shared group identity or perceived similarity (though, surprisingly, not through social bonding). We discuss how community commerce affords unique and sometimes superior trust assurances and propose design implications for platforms hoping to foster trust between members who buy, sell, or share amongst themselves.</p></div></span> <a id="expcoll464" href="JavaScript: expandcollapse('expcoll464',464)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025778&CFID=758305256&CFTOKEN=14863114">No Such Thing as Too Much Chocolate: Evidence Against Choice Overload in E-Commerce</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Carol Moser, Chanda Phelan, Paul Resnick, Sarita Y. Schoenebeck, Katharina Reinecke 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4358-4369</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025778" title="DOI">10.1145/3025453.3025778</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025778&ftid=1870393&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow465" style="display:inline;"><br /><div style="display:inline">E-commerce designers must decide how many products to display at one time. Choice overload research has demonstrated the surprising finding that more choice is not necessarily better?selecting from larger choice sets can be more cognitively demanding ...</div></span>
          <span id="toHide465" style="display:none;"><br /><div style="display:inline"><p>E-commerce designers must decide how many products to display at one time. Choice overload research has demonstrated the surprising finding that more choice is not necessarily better?selecting from larger choice sets can be more cognitively demanding and can result in lower levels of choice satisfaction. This research tests the choice overload effect in an e-commerce context and explores how the choice overload effect is influenced by an individual's tendency to maximize or satisfice decisions. We conducted an online experiment with 611 participants randomly assigned to select a gourmet chocolate bar from either 12, 24, 40, 50, 60, or 72 different options. Consistent with prior work, we find that maximizers are less satisfied with their product choice than satisficers. However, using Bayesian analysis, we find that it's unlikely that choice set size affects choice satisfaction by much, if at all. We discuss why the decision-making process may be different in e-commerce contexts than the physical settings used in previous choice overload experiments.</p></div></span> <a id="expcoll465" href="JavaScript: expandcollapse('expcoll465',465)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025815&CFID=758305256&CFTOKEN=14863114">Why Users Disintermediate Peer-to-Peer Marketplaces</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Victoria Bellotti, Dan Turner, Kamila Demkova, Alexander Ambard, Amanda Waterman 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4370-4382</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025815" title="DOI">10.1145/3025453.3025815</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025815&ftid=1870349&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow466" style="display:inline;"><br /><div style="display:inline">This paper reports on a study of the prevalence of and possible reasons for peer-to-peer transaction marketplace (P2PM) users turning to out-of-market (OOM) transactions after finding transaction partners within a P2P system. We surveyed 97 P2PM users ...</div></span>
          <span id="toHide466" style="display:none;"><br /><div style="display:inline"><p>This paper reports on a study of the prevalence of and possible reasons for peer-to-peer transaction marketplace (P2PM) users turning to out-of-market (OOM) transactions after finding transaction partners within a P2P system. We surveyed 97 P2PM users and interviewed 22 of 58 who reported going OOM. We did not find any evidence of predisposing personality factors for OOM activity; instead, it seems to be a rational response to circumstances, with a variety of situationally rational motivations at play, such as liking the transaction partner and trusting that good quality repeat transactions will occur in the future.</p></div></span> <a id="expcoll466" href="JavaScript: expandcollapse('expcoll466',466)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Unusual Displays</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025608&CFID=758305256&CFTOKEN=14863114">MistForm: Adaptive Shape Changing Fog Screens</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Yutaka Tokuda, Mohd Adili Norasikin, Sriram Subramanian, Diego Martinez Plasencia 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4383-4395</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025608" title="DOI">10.1145/3025453.3025608</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025608&ftid=1870358&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow468" style="display:inline;"><br /><div style="display:inline">We present MistForm, a shape changing fog display that can support one or two users interacting with either 2D or 3D content. Mistform combines affordances from both shape changing interfaces and mid-air displays. For example, a concave display can maintain ...</div></span>
          <span id="toHide468" style="display:none;"><br /><div style="display:inline"><p>We present MistForm, a shape changing fog display that can support one or two users interacting with either 2D or 3D content. Mistform combines affordances from both shape changing interfaces and mid-air displays. For example, a concave display can maintain content in comfortable reach for a single user, while a convex shape can support several users engaged on individual tasks. MistForm also enables unique interaction possibilities by exploiting the synergies between shape changing interfaces and mid-air fog displays. For instance, moving the screen will affect the brightness and blurriness of the screen at specific locations around the display, creating spaces with similar (collaboration) or different visibility (personalized content). We describe the design of MistForm and analyse its inherent challenges, such as image distortion and uneven brightness on dynamic curved surfaces. We provide a machine learning approach to characterize the shape of the screen and a rendering algorithm to remove aberrations. We finally explore novel interactive possibilities and reflect on their potential and limitations.</p></div></span> <a id="expcoll468" href="JavaScript: expandcollapse('expcoll468',468)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025806&CFID=758305256&CFTOKEN=14863114">The Object Inside: Assessing 3D Examination with a Spherical Handheld Perspective-Corrected Display</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Francois Berard, Thibault Louis 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4396-4404</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025806" title="DOI">10.1145/3025453.3025806</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025806&ftid=1870355&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow469" style="display:inline;"><br /><div style="display:inline">Handheld Perspective Corrected Displays (HPCDs) can create the feeling of holding a virtual 3D object. They offer a direct interaction that is isomorphic to the manipulation of physical objects. This illusion depends on the ability to provide a natural ...</div></span>
          <span id="toHide469" style="display:none;"><br /><div style="display:inline"><p>Handheld Perspective Corrected Displays (HPCDs) can create the feeling of holding a virtual 3D object. They offer a direct interaction that is isomorphic to the manipulation of physical objects. This illusion depends on the ability to provide a natural visuomotor coupling. High performances systems are thus required to evaluate the fundamental merits of HPCDs. We built a spherical HPCD using external projection. The system offers a lightweight wireless seamless display with head-coupled stereo, robust tracking, and low latency. We compared users' performances with this HPCD and two other interactions that used a fixed planar display and either a touchpad or the spherical display as an indirect input. The task involved the inspection of complex virtual 3D puzzles. Physical puzzles were also tested as references. Contrary to expectations, all virtual interactions were found to be more efficient than a more "natural" physical puzzle. The HPCD yielded lower performances than the touchpad. This study indicates that the object examination task did not benefit from the accurate and precise rotations offered by the HPCD, but benefited from the high C/D gain of the touchpad.</p></div></span> <a id="expcoll469" href="JavaScript: expandcollapse('expcoll469',469)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025677&CFID=758305256&CFTOKEN=14863114">Visual Composition of Graphical Elements on Non-Rectangular Displays</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Marcos Serrano, Anne Roudaut, Pourang Irani 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4405-4416</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025677" title="DOI">10.1145/3025453.3025677</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025677&ftid=1870373&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow470" style="display:inline;"><br /><div style="display:inline">Graphical user interfaces are composed of varying elements (text, images, etc.) whose visual arrangement has been relatively well established in the context of rectangular interfaces. The advent of non-rectangular displays questions this knowledge. In ...</div></span>
          <span id="toHide470" style="display:none;"><br /><div style="display:inline"><p>Graphical user interfaces are composed of varying elements (text, images, etc.) whose visual arrangement has been relatively well established in the context of rectangular interfaces. The advent of non-rectangular displays questions this knowledge. In this paper we study how traditional content layouts can be adapted to fit different non-rectangular displays. We performed a first qualitative study where graphic designers fitted text and images into different non-rectangular displays. From the analysis of their output we generalize and adapt ten composition principles that have been proposed in the literature for rectangular displays. We evaluate the revised principles through a paired comparison questionnaire where 57 participants compared pairs of layouts. Using the Bradley-Terry-Luce model to analyze our data we show that some results contradict current conventions on visual design for rectangular displays. We then extracted the most interesting cases and conducted a follow up study with additional shapes to investigate how the principles generalize. From these results we propose a set of guidelines for designing visual content for non-rectangular displays.</p></div></span> <a id="expcoll470" href="JavaScript: expandcollapse('expcoll470',470)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025488&CFID=758305256&CFTOKEN=14863114">Effects of Tactile Feedback on the Perception of Virtual Shapes on Non-Planar DisplayObjects</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Juan Pablo Carrascal, Roel Vertegaal 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4417-4423</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025488" title="DOI">10.1145/3025453.3025488</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025488&ftid=1870357&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow471" style="display:inline;"><br /><div style="display:inline">In this paper, we report on a study investigating a novel haptic illusion for altering the perception of 3D shapes using a non-planar screen and vibrotactile friction. In our study, we presented an image of a rectangular prism on a cylindrical and a ...</div></span>
          <span id="toHide471" style="display:none;"><br /><div style="display:inline"><p>In this paper, we report on a study investigating a novel haptic illusion for altering the perception of 3D shapes using a non-planar screen and vibrotactile friction. In our study, we presented an image of a rectangular prism on a cylindrical and a flat display. Participants were asked to move their index finger horizontally along the surface of the displays towards the edge of the rectangular prism. Participants were asked whether they were experiencing a flat, cylindrical or rectangular shape. In one condition, a vibrotactile stimulus simulated increasing friction towards the visible edge of the rectangular prism, with a sudden drop-off when this edge was crossed by the finger. Results suggest that presenting an image of a rectangular prism, and applying vibrotactile friction, particularly on a cylindrical display, significantly increased participant ratings stating that they were experiencing a physical rectangular shape.</p></div></span> <a id="expcoll471" href="JavaScript: expandcollapse('expcoll471',471)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025973&CFID=758305256&CFTOKEN=14863114">BreathScreen: Design and Evaluation of an Ephemeral UI</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Ismo Alak&#228;rpp&#228;, Elisa Jaakkola, Ashley Colley, Jonna H&#228;kkil&#228; 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4424-4429</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025973" title="DOI">10.1145/3025453.3025973</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025973&ftid=1870366&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow472" style="display:inline;"><br /><div style="display:inline">We present BreathScreen, a concept where clouds created by breathing are used as a projection surface for a picoprojector, creating an ephemeral user interface. In cold weather conditions the clouds are created naturally by warm breath condensing, but ...</div></span>
          <span id="toHide472" style="display:none;"><br /><div style="display:inline"><p>We present BreathScreen, a concept where clouds created by breathing are used as a projection surface for a picoprojector, creating an ephemeral user interface. In cold weather conditions the clouds are created naturally by warm breath condensing, but in other conditions an electric vaporizer may be used. We present an initial evaluation of the concept in a user study (n = 8), utilising a vaporizer-based BreathScreen prototype. The concept was positively received by study participants as a natural, hands-free interface and considered magical and aesthetically beautiful. Additionally, we provide guidance on the quantity of content that may be displayed on a BreathScreen, which is limited both by the length of a human breath and the contrast of the system.</p></div></span> <a id="expcoll472" href="JavaScript: expandcollapse('expcoll472',472)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>User Perceptions in Sociotechnical Systems</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025575&CFID=758305256&CFTOKEN=14863114">Foreign-language Reviews: Help or Hindrance?</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Scott A. Hale, Irene Eleta 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4430-4442</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025575" title="DOI">10.1145/3025453.3025575</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025575&ftid=1870375&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow474" style="display:inline;"><br /><div style="display:inline">The number and quality of user reviews greatly affects consumer purchasing decisions. While reviews in all languages are increasing, it is still often the case (especially for non-English speakers) that there are only a few reviews in a person's first ...</div></span>
          <span id="toHide474" style="display:none;"><br /><div style="display:inline"><p>The number and quality of user reviews greatly affects consumer purchasing decisions. While reviews in all languages are increasing, it is still often the case (especially for non-English speakers) that there are only a few reviews in a person's first language. Using an online experiment, we examine the value that potential purchasers receive from interfaces showing additional reviews in a second language. The results paint a complicated picture with both positive and negative reactions to the inclusion of foreign-language reviews. Roughly 26-28% of subjects clicked to see translations of the foreign-language content when given the opportunity, and those who did so were more likely to select the product with foreign-language reviews than those who did not.</p></div></span> <a id="expcoll474" href="JavaScript: expandcollapse('expcoll474',474)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3026017&CFID=758305256&CFTOKEN=14863114">Getting Something for Nothing?: A User-Centric Perspective on Loyalty Card Schemes</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Annika Hupfeld, Chris Speed 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4443-4453</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3026017" title="DOI">10.1145/3025453.3026017</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3026017&ftid=1870384&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow475" style="display:inline;"><br /><div style="display:inline">Loyalty cards are a form of tracking and recording technology (TRT) that enables retailers to collect data about their customers' demographic and purchase behaviours. As recompense for sharing their data consumers receive 'loyalty points' which they ...</div></span>
          <span id="toHide475" style="display:none;"><br /><div style="display:inline"><p>Loyalty cards are a form of tracking and recording technology (TRT) that enables retailers to collect data about their customers' demographic and purchase behaviours. As recompense for sharing their data consumers receive 'loyalty points' which they can redeem for exclusive discounts and rewards. The design of loyalty schemes, and TRTs more generally, plays a key role in defining the economic terms of that exchange, and ultimately the economic value of personal data. In this paper we present findings from an interview study with 12 loyalty cardholders in the UK explicating the ways in which they create (and lose) value through the everyday practice of shopping with loyalty cards and the orientations associated with them. Based on our findings we suggest cardholders are less concerned with the protection of their privacy than with leveraging its value, only some of which was economic. We provide design guidelines for TRTs that may enable consumers to derive greater value from the data they produce and share.</p></div></span> <a id="expcoll475" href="JavaScript: expandcollapse('expcoll475',475)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025791&CFID=758305256&CFTOKEN=14863114">Online Feedback Exchange: A Framework for Understanding the Socio-Psychological Factors</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Eureka Foong, Steven P. Dow, Brian P. Bailey, Elizabeth M. Gerber 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4454-4467</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025791" title="DOI">10.1145/3025453.3025791</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025791&ftid=1870367&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow476" style="display:inline;"><br /><div style="display:inline">To meet the demand for authentic, timely, and affordable feedback, researchers have explored technologies to connect designers with feedback providers online. While researchers have implemented mechanisms to improve the content of feedback, most systems ...</div></span>
          <span id="toHide476" style="display:none;"><br /><div style="display:inline"><p>To meet the demand for authentic, timely, and affordable feedback, researchers have explored technologies to connect designers with feedback providers online. While researchers have implemented mechanisms to improve the content of feedback, most systems for online feedback exchange do not support an end-to-end cycle, from help-seeking to sense-making to action. Building on extant literature in learning sciences, design, organizational behavior, and online communities, we propose a conceptual framework to highlight critical processes that affect online feedback exchange. We contribute research questions for future feedback systems and argue that online feedback systems must be able to support designers through five activities that happen before, during, and after the feedback exchange. Our framework suggests that systems should address broader socio-psychological factors, such as how intent should be communicated online, how dialogue can support the interpretation of feedback, and how to balance the tradeoffs of anonymizing feedback providers.</p></div></span> <a id="expcoll476" href="JavaScript: expandcollapse('expcoll476',476)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>360 Video</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025581&CFID=758305256&CFTOKEN=14863114">The Geometry of Storytelling: Theatrical Use of Space for 360-degree Videos and Virtual Reality</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Vanessa C. Pope, Robert Dawes, Florian Schweiger, Alia Sheikh 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4468-4478</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025581" title="DOI">10.1145/3025453.3025581</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025581&ftid=1870346&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow478" style="display:inline;"><br /><div style="display:inline">360-degree filming and head-mounted displays (HMDs) give recorded media a new sense of space. Theatre practitioners' expertise in manipulating spatial interactions has much to contribute to immersive recorded content. Four theatre directors led teams ...</div></span>
          <span id="toHide478" style="display:none;"><br /><div style="display:inline"><p>360-degree filming and head-mounted displays (HMDs) give recorded media a new sense of space. Theatre practitioners' expertise in manipulating spatial interactions has much to contribute to immersive recorded content. Four theatre directors led teams of three actors to stage the same scene for both immersive theatre and for 360-degree filming. Each team was recorded performing the scene at least six times, three in each condition, to extract actors' coordinates. This study establishes how to quantify theatre practitioners' use of spatial interactions and examines the spatial adaptations made when transferring these relationships to 360-degree filming.</p> <p>Staging for a 360-degree camera compared to staging for an audience member had shorter distances from the camera and between performers, along with fewer instances of the camera being in the middle of the action. Across all groups, interpersonal distance between characters and between the audience/camera dropped at the end of the scene when the characters come together as a team, suggesting that elements of Proxemics may be applicable to narrative performance.</p></div></span> <a id="expcoll478" href="JavaScript: expandcollapse('expcoll478',478)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025964&CFID=758305256&CFTOKEN=14863114">Tap, Dwell or Gesture?: Exploring Head-Based Text Entry Techniques for HMDs</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Chun Yu, Yizheng Gu, Zhican Yang, Xin Yi, Hengliang Luo, Yuanchun Shi 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4479-4488</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025964" title="DOI">10.1145/3025453.3025964</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025964&ftid=1870394&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow479" style="display:inline;"><br /><div style="display:inline">Despite the increasing popularity of head mounted displays (HMDs), development of efficient text entry methods on these devices has remained under explored. In this paper, we investigate the feasibility of head-based text entry for HMDs, by which, the ...</div></span>
          <span id="toHide479" style="display:none;"><br /><div style="display:inline"><p>Despite the increasing popularity of head mounted displays (HMDs), development of efficient text entry methods on these devices has remained under explored. In this paper, we investigate the feasibility of head-based text entry for HMDs, by which, the user controls a pointer on a virtual keyboard using head rotation. Specifically, we investigate three techniques: TapType, DwellType, and GestureType. Users of TapType select a letter by pointing to it and tapping a button. Users of DwellType select a letter by pointing to it and dwelling over it for a period of time. Users of GestureType perform word-level input using a gesture typing style. Two lab studies were conducted. In the first study, users typed 10.59 WPM, 15.58 WPM, and 19.04 WPM with DwellType, TapType, and GestureType, respectively. Users subjectively felt that all three of the techniques were easy to learn and considered the induced fatigue to be acceptable. In the second study, we further investigated GestureType. We improved its gesture-word recognition algorithm by incorporating the head movement pattern obtained from the first study. This resulted in users reaching 24.73 WPM after 60 minutes of training. Based on these results, we argue that head-based text entry is feasible and practical on HMDs, and deserves more attention.</p></div></span> <a id="expcoll479" href="JavaScript: expandcollapse('expcoll479',479)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025748&CFID=758305256&CFTOKEN=14863114">Videos of Things: Speculating on, Anticipating and Synthesizing Technological Mediations</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Doenja Oogjes, Ron Wakkary 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4489-4500</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025748" title="DOI">10.1145/3025453.3025748</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025748&ftid=1870386&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow480" style="display:inline;"><br /><div style="display:inline">In this paper we present Videos of Things: videos that portray the mediated, lived world of computational artifacts informed by postphenomenology. In a post-phenomenological understanding, things and us are interdependent in that they mutually shape ...</div></span>
          <span id="toHide480" style="display:none;"><br /><div style="display:inline"><p>In this paper we present Videos of Things: videos that portray the mediated, lived world of computational artifacts informed by postphenomenology. In a post-phenomenological understanding, things and us are interdependent in that they mutually shape each other. And as a whole, technology or designed things mediate the relations between our world and us. This can be a challenge for designers. Through the making of design videos, we explored narrative strategies for creating stories featuring technological mediation. These include humanness, patterns in time, and non-human ensembles. We reflect on how the videos at different stages of the design process have helped to a) speculate on technological mediated relationships, b) synthesize and reflect on qualitative data on technological mediation and c) anticipate technological mediation. The paper contributes different narrative strategies for design videos and the role these videos can play within a design process aimed at elaborating the mediated qualities of technologies.</p></div></span> <a id="expcoll480" href="JavaScript: expandcollapse('expcoll480',480)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025519&CFID=758305256&CFTOKEN=14863114">Watching 360&#176; Videos Together</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Anthony Tang, Omid Fakourfar 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4501-4506</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025519" title="DOI">10.1145/3025453.3025519</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025519&ftid=1870351&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow481" style="display:inline;"><br /><div style="display:inline">360&#176; videos are made using omnidirectional cameras that capture a sphere around the camera. Viewers get an immersive experience by freely changing their field of view around the sphere. The problem is that current interfaces are designed for a single ...</div></span>
          <span id="toHide481" style="display:none;"><br /><div style="display:inline"><p>360&#176; videos are made using omnidirectional cameras that capture a sphere around the camera. Viewers get an immersive experience by freely changing their field of view around the sphere. The problem is that current interfaces are designed for a single user, and we do not know what challenges groups of people will have when viewing these videos together. We report on the findings of a study where 16 pairs of participants watched 360&#176; videos together in a "guided tour" scenario. Our findings indicate that while participants enjoyed the ability to view the scene independently, this caused challenges establishing joint references, leading to breakdowns in conversation. We conclude by discussing how gaze awareness widgets and gesturing mechanisms may support smoother collaborative interaction around collaborative viewing of 360&#176; videos.</p></div></span> <a id="expcoll481" href="JavaScript: expandcollapse('expcoll481',481)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Civic Engagement</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025543&CFID=758305256&CFTOKEN=14863114">Revisiting The American Voter on Twitter</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Huyen T. Le, G. R. Boynton, Yelena Mejova, Zubair Shafiq, Padmini Srinivasan 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4507-4519</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025543" title="DOI">10.1145/3025453.3025543</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025543&ftid=1870347&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow483" style="display:inline;"><br /><div style="display:inline">The American Voter - a seminal work in political science - uncovered the multifaceted nature of voting behavior which has been corroborated in electoral research for decades since. In this paper, we leverage The American Voter as an analysis ...</div></span>
          <span id="toHide483" style="display:none;"><br /><div style="display:inline"><p><i>The American Voter</i> - a seminal work in political science - uncovered the multifaceted nature of voting behavior which has been corroborated in electoral research for decades since. In this paper, we leverage <i>The American Voter</i> as an analysis framework in the realm of computational political science, employing the factors of <i>party, personality</i>, and <i>policy</i> to structure the analysis of public discourse on online social media during the 2016 U.S. presidential primaries. Our analysis of 50 million tweets reveals the continuing importance of these three factors; our understanding is also enriched by the application of sentiment analysis techniques. The overwhelmingly negative sentiment of conversations surrounding 10 major presidential candidates reveals more "crosstalk" from Democratic leaning users towards Republican candidates, and less vice-versa. We uncover the lack of <i>moderation</i> as the most discussed personality dimension during this campaign season, as the political field becomes more extreme - Clinton and Rubio are perceived as moderate, while Trump, Sanders, and Cruz are not. While the most discussed issues are <i>foreign policy</i> and <i>immigration</i>, Republicans tweet more about <i>abortion</i> than Democrats who tweet more about <i>gay rights</i> than Republicans. Finally, we illustrate the importance of multifaceted political discourse analysis by applying regression to quantify the impact of party, personality, and policy on national polls.</p></div></span> <a id="expcoll483" href="JavaScript: expandcollapse('expcoll483',483)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025891&CFID=758305256&CFTOKEN=14863114">Managing Uncertainty: Using Social Media for Risk Assessment during a Public Health Crisis</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Xinning Gui, Yubo Kou, Kathleen H. Pine, Yunan Chen 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4520-4533</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025891" title="DOI">10.1145/3025453.3025891</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025891&ftid=1870389&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow484" style="display:inline;"><br /><div style="display:inline">Recently, diseases like H1N1 influenza, Ebola, and Zika virus have created severe crises, requiring public resources and personal behavior adaptation. Crisis Informatics literature examines interconnections of people, organizations, and IT during crisis ...</div></span>
          <span id="toHide484" style="display:none;"><br /><div style="display:inline"><p>Recently, diseases like H1N1 influenza, Ebola, and Zika virus have created severe crises, requiring public resources and personal behavior adaptation. Crisis Informatics literature examines interconnections of people, organizations, and IT during crisis events. However, how people use technology to cope with disease crises (outbreaks, epidemics, and pandemics) remains understudied. We investigate how individuals used social media in response to the outbreak of Zika, focusing on travel-related decisions. We found that extreme uncertainty and ambiguity characterized the Zika virus crisis. To cope, people turned to social media for information gathering and social learning geared towards personal risk assessment and modifying decisions when dealing with partial and conflicting information about Zika. In particular, individuals sought local information and used socially informed logical reasoning to deduce the risk at a specific locale. We conclude with implications for designing information systems to support individual risk assessment and decision-making when faced with uncertainty and ambiguity during public health crises.</p></div></span> <a id="expcoll484" href="JavaScript: expandcollapse('expcoll484',484)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025885&CFID=758305256&CFTOKEN=14863114">Theory-Driven Collocated CMC: A Study of Collocated Mediated Interaction as a Public Sphere</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Matti Nelimarkka, Antti Salovaara, Bryan Semaan, Giulio Jacucci 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4534-4547</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025885" title="DOI">10.1145/3025453.3025885</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025885&ftid=1870372&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow485" style="display:inline;"><br /><div style="display:inline">Computer-mediated communication (CMC) tools are used to increase social interaction in collocated settings. Recent research has been primarily constructive (oriented to building of systems) or phenomenon-driven (serving attempts to understand interactions ...</div></span>
          <span id="toHide485" style="display:none;"><br /><div style="display:inline"><p>Computer-mediated communication (CMC) tools are used to increase social interaction in collocated settings. Recent research has been primarily constructive (oriented to building of systems) or phenomenon-driven (serving attempts to understand interactions in collocated CMC). The paper contributes a theory-driven approach and examines collocated CMC as a Habermasean "public sphere": a space that supports inclusive, civil, and rational discussion. An in-the-wild experimental study comparing CMC with face-to-face (F2F) communication enabled ascertaining that CMC is more inclusive than F2F communication. Respectfulness levels did not differ but were established differently: via collective construction of a common narrative in F2F and through quick reactions in CMC. Similarly, while rationality figures were on a par, F2F communication allowed participants to justify their claims better. The article discusses how a theory-based approach can strengthen phenomenon-driven research with new conceptual frames and measurement tools, and steer constructive research with a normative framework.</p></div></span> <a id="expcoll485" href="JavaScript: expandcollapse('expcoll485',485)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Cross Device Interaction</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025537&CFID=758305256&CFTOKEN=14863114">Is Two Enough?: ! Studying Benefits, Barriers, and Biases of Multi-Tablet Use for Collaborative Visualization</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Thomas Plank, Hans-Christian Jetter, Roman R&#228;dle, Clemens N. Klokmose, Thomas Luger, Harald Reiterer 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4548-4560</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025537" title="DOI">10.1145/3025453.3025537</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025537&ftid=1870383&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow487" style="display:inline;"><br /><div style="display:inline">A sizable part of HCI research on cross-device interaction is driven by the vision of users conducting complex knowledge work seamlessly across multiple mobile devices. This is based on the Weiserian assumption that people will be inclined to distribute ...</div></span>
          <span id="toHide487" style="display:none;"><br /><div style="display:inline"><p>A sizable part of HCI research on cross-device interaction is driven by the vision of users conducting complex knowledge work seamlessly across multiple mobile devices. This is based on the Weiserian assumption that people will be inclined to distribute their work across multiple ``pads' if such are available. We observed that this is not the reality today, even when devices were in abundance. We present a study with 24 participants in 12 dyads completing a collaborative visualization task with up to six tablets. They could choose between three different visualization types to answer questions about economic data. Tasks were designed to afford simultaneous use of tablets, either with linked or independent views. We found that users typically utilized only one tablet per user. A quantitative and qualitative analysis revealed a ``legacy bias' that introduced barriers for using more tablets and reduced the overall benefit of multi-device visualization.</p></div></span> <a id="expcoll487" href="JavaScript: expandcollapse('expcoll487',487)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025693&CFID=758305256&CFTOKEN=14863114">LetsPic: Supporting In-situ Collaborative Photography over a Large Physical Space</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Auk Kim, Sungjoon Kang, Uichin Lee 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4561-4573</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025693" title="DOI">10.1145/3025453.3025693</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025693&ftid=1870342&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow488" style="display:inline;"><br /><div style="display:inline">Recent advances in mobile computing technology have made it increasingly common for collocated users to perform collaborative photography over a large physical space in various group activity scenarios such as field trips, site surveys, and group tours. ...</div></span>
          <span id="toHide488" style="display:none;"><br /><div style="display:inline"><p>Recent advances in mobile computing technology have made it increasingly common for collocated users to perform collaborative photography over a large physical space in various group activity scenarios such as field trips, site surveys, and group tours. Unlike traditional collocated interactions in a shared physical space, we find that mobility and group dynamics make awareness of group activities over a large physical space very challenging. In this work, we design LetsPic, a group photoware that supports group awareness for in-situ collaborative photography over the large physical space. We have iteratively built the app and performed user studies in site survey and group tour scenarios (n = 31, n = 24). Our results confirmed that LetsPic effectively promotes group awareness, facilitates group coordination, and encourages collaboration in both scenarios. We discuss practical design implications based on our findings.</p></div></span> <a id="expcoll488" href="JavaScript: expandcollapse('expcoll488',488)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025547&CFID=758305256&CFTOKEN=14863114">XDBrowser 2.0: Semi-Automatic Generation of Cross-Device Interfaces</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Michael Nebeling 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4574-4584</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025547" title="DOI">10.1145/3025453.3025547</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025547&ftid=1870352&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow489" style="display:inline;"><br /><div style="display:inline">Several recent studies have highlighted the need to support parallel usage of multiple devices for cross-device use. Yet, most interfaces today are still designed for single-device use and require re-authoring to enable cross-device interaction. This ...</div></span>
          <span id="toHide489" style="display:none;"><br /><div style="display:inline"><p>Several recent studies have highlighted the need to support parallel usage of multiple devices for cross-device use. Yet, most interfaces today are still designed for single-device use and require re-authoring to enable cross-device interaction. This paper presents two studies to inform the design of a new web browser with support for semi-automatic generation of cross-device interfaces. Based on the results of a recent study in which users manually customized web pages for cross-device use, our first study elicits from users how they might want to trigger popular cross-device patterns to transform single-device designs with relatively little effort. Our second study then examines how the emerging design patterns could be applied to the Alexa top 50 sites from 10 different genres. Based on these studies, we design semi-automatic techniques for page segmentation and distribution between multiple devices that can work on many existing web sites and require only minimal user input to switch between different cross-device designs. Finally, we discuss possible extensions to the Chrome web browser to make the techniques available for a wide range of desktop, mobile, and wearable devices, and successfully test them on popular web sites.</p></div></span> <a id="expcoll489" href="JavaScript: expandcollapse('expcoll489',489)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Crowdwork</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025633&CFID=758305256&CFTOKEN=14863114">Low-Wage Precarious Workers' Sociotechnical Practices Working Towards Addressing Wage Theft</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Lynn Dombrowski, Adriana Alvarado Garcia, Jessica Despard 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4585-4598</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025633" title="DOI">10.1145/3025453.3025633</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025633&ftid=1870387&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow491" style="display:inline;"><br /><div style="display:inline">Nearly 40 million workers in the USA, a third of the working population, are low-wage, meaning they make less than $11.65 per hour. These workers face the pervasive and detrimental challenge of wage violations, also known as wage theft, which is any ...</div></span>
          <span id="toHide491" style="display:none;"><br /><div style="display:inline"><p>Nearly 40 million workers in the USA, a third of the working population, are low-wage, meaning they make less than $11.65 per hour. These workers face the pervasive and detrimental challenge of wage violations, also known as wage theft, which is any illegal activity by an employer that denies benefits or wages to employees. We interviewed 24 low-wage workers who experienced wage theft and sought justice about their work practices, challenges, and information technology usage. Based on these interviews, we identify three key sociotechnical practices these workers engaged in to address their wage theft: 1) <i>identifying wage and payment discrepancies</i>; 2) <i>tracking and documenting work</i>; and 3) <i>pursuing wage claims</i>. Seeking to leverage HCI research to interrupt uneven social, economic, and information relations in the low-wage workplace, we ultimately reflect on the possibility and limits of several key design recommendations.</p></div></span> <a id="expcoll491" href="JavaScript: expandcollapse('expcoll491',491)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025974&CFID=758305256&CFTOKEN=14863114">Examining Crowd Work and Gig Work Through The Historical Lens of Piecework</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Ali Alkhatib, Michael S. Bernstein, Margaret Levi 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4599-4616</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025974" title="DOI">10.1145/3025453.3025974</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025974&ftid=1870353&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow492" style="display:inline;"><br /><div style="display:inline">The internet is empowering the rise of crowd work, gig work, and other forms of on--demand labor. A large and growing body of scholarship has attempted to predict the socio--technical outcomes of this shift, especially addressing three questions: begin{inlinelist} ...</div></span>
          <span id="toHide492" style="display:none;"><br /><div style="display:inline"><p>The internet is empowering the rise of crowd work, gig work, and other forms of on--demand labor. A large and growing body of scholarship has attempted to predict the socio--technical outcomes of this shift, especially addressing three questions: begin{inlinelist} item What are the complexity limits of on-demand work?, item How far can work be decomposed into smaller microtasks?, and item What will work and the place of work look like for workers' end {inlinelist} In this paper, we look to the historical scholarship on piecework --- a similar trend of work decomposition, distribution, and payment that was popular at the turn of the nth{20} century --- to understand how these questions might play out with modern on--demand work. We identify the mechanisms that enabled and limited piecework historically, and identify whether on--demand work faces the same pitfalls or might differentiate itself. This approach introduces theoretical grounding that can help address some of the most persistent questions in crowd work, and suggests design interventions that learn from history rather than repeat it.</p></div></span> <a id="expcoll492" href="JavaScript: expandcollapse('expcoll492',492)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3026032&CFID=758305256&CFTOKEN=14863114">Leveraging Complementary Contributions of Different Workers for Efficient Crowdsourcing of Video Captions</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Yun Huang, Yifeng Huang, Na Xue, Jeffrey P. Bigham 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4617-4626</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3026032" title="DOI">10.1145/3025453.3026032</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3026032&ftid=1870360&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow493" style="display:inline;"><br /><div style="display:inline">Hearing-impaired people and non-native speakers rely on captions for access to video content, yet most videos remain uncaptioned or have machine-generated captions with high error rates. In this paper, we present the design, implementation and evaluation ...</div></span>
          <span id="toHide493" style="display:none;"><br /><div style="display:inline"><p>Hearing-impaired people and non-native speakers rely on captions for access to video content, yet most videos remain uncaptioned or have machine-generated captions with high error rates. In this paper, we present the design, implementation and evaluation of BandCaption, a system that combines automatic speech recognition with input from crowd workers to provide a cost-efficient captioning solution for accessible online videos. We consider four stakeholder groups as our source of crowd workers: (i) individuals with hearing impairments, (ii) second-language speakers with low proficiency, (iii) second-language speakers with high proficiency, and (iv) native speakers. Each group has different abilities and incentives, which our workflow leverages. Our findings show that BandCaption enables crowd workers who have different needs and strengths to accomplish micro-tasks and make complementary contributions. Based on our results, we outline opportunities for future research and provide design suggestions to deliver cost-efficient captioning solutions.</p></div></span> <a id="expcoll493" href="JavaScript: expandcollapse('expcoll493',493)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025883&CFID=758305256&CFTOKEN=14863114">Critique Style Guide: Improving Crowdsourced Design Feedback with a Natural Language Model</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Markus Krause, Tom Garncarz, JiaoJiao Song, Elizabeth M. Gerber, Brian P. Bailey, Steven P. Dow 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4627-4639</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025883" title="DOI">10.1145/3025453.3025883</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025883&ftid=1870341&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow494" style="display:inline;"><br /><div style="display:inline">Designers are increasingly leveraging online crowds; yet, online contributors may lack the expertise, context, and sensitivity to provide effective critique. Rubrics help feedback providers but require domain experts to write them and may not generalize ...</div></span>
          <span id="toHide494" style="display:none;"><br /><div style="display:inline"><p>Designers are increasingly leveraging online crowds; yet, online contributors may lack the expertise, context, and sensitivity to provide effective critique. Rubrics help feedback providers but require domain experts to write them and may not generalize across design domains. This paper introduces and tests a novel semi-automated method to support feedback providers by analyzing feedback language. In our first study, 52 students from two design courses created design solutions and received feedback from 176 online providers. Instructors, students, and crowd contributors rated the helpfulness of each feedback response. From this data, an algorithm extracted a set of natural language features (e.g., specificity, sentiment etc.) that correlated with the ratings. The features accurately predicted the ratings and remained stable across different raters and design solutions. Based on these features, we produced a critique style guide with feedback examples - automatically selected for each feature - to help providers revise their feedback through self-assessment. In a second study, we tested the validity of the guide through a between-subjects experiment (n=50). Providers wrote feedback on design solutions with or without the guide. Providers generated feedback with higher perceived helpfulness when using our style-based guidance.</p></div></span> <a id="expcoll494" href="JavaScript: expandcollapse('expcoll494',494)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Improving Touch Interfaces</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025502&CFID=758305256&CFTOKEN=14863114">ProbUI: Generalising Touch Target Representations to Enable Declarative Gesture Definition for Probabilistic GUIs</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Daniel Buschek, Florian Alt 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4640-4653</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025502" title="DOI">10.1145/3025453.3025502</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025502&ftid=1870382&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow496" style="display:inline;"><br /><div style="display:inline">We present ProbUI, a mobile touch GUI framework that merges ease of use of declarative gesture definition with the benefits of probabilistic reasoning. It helps developers to handle uncertain input and implement feedback and GUI adaptations. ProbUI ...</div></span>
          <span id="toHide496" style="display:none;"><br /><div style="display:inline"><p>We present <i>ProbUI</i>, a mobile touch GUI framework that merges ease of use of declarative gesture definition with the benefits of probabilistic reasoning. It helps developers to handle uncertain input and implement feedback and GUI adaptations. <i>ProbUI</i> replaces today's static target models (bounding boxes) with probabilistic gestures ("bounding behaviours"). It is the first touch GUI framework to unite concepts from three areas of related work: 1) Developers <i>declaratively define</i> touch behaviours for GUI targets. As a key insight, the declarations imply simple probabilistic models (HMMs with 2D Gaussian emissions). 2) <i>ProbUI</i> derives these models automatically to <i>evaluate</i> users' touch sequences. 3) It then <i>infers</i> intended behaviour and target. Developers bind callbacks to gesture progress, completion, and other conditions. We show <i>ProbUI</i>'s value by implementing existing and novel widgets, and report developer feedback from a survey and a lab study.</p></div></span> <a id="expcoll496" href="JavaScript: expandcollapse('expcoll496',496)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025565&CFID=758305256&CFTOKEN=14863114">BackXPress: Using Back-of-Device Finger Pressure to Augment Touchscreen Input on Smartphones</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Christian Corsten, Bjoern Daehlmann, Simon Voelker, Jan Borchers 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4654-4666</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025565" title="DOI">10.1145/3025453.3025565</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025565&ftid=1870361&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow497" style="display:inline;"><br /><div style="display:inline">When people hold their smartphone in landscape orientation, they use their thumbs for input on the frontal touchscreen, while their remaining fingers rest on the back of the device (BoD) to stabilize the grip. We present BackXPress, a new interaction ...</div></span>
          <span id="toHide497" style="display:none;"><br /><div style="display:inline"><p>When people hold their smartphone in landscape orientation, they use their thumbs for input on the frontal touchscreen, while their remaining fingers rest on the back of the device (BoD) to stabilize the grip. We present <i>BackXPress</i>, a new interaction technique that lets users create BoD pressure input with these remaining fingers to augment their interaction with the touchscreen on the front: Users can apply various pressure levels with each of these fingers to enter different temporary "quasi-modes" that are only active as long as that pressure is applied. Both thumbs can then interact with the frontal screen in that mode. We illustrate the practicality of BackXPress with several sample applications, and report our results from three user studies: Study 1 investigated which fingers can be used to exert BoD pressure and found index, middle, and ring finger from both hands to be practical. Study 2 revealed how pressure touches from these six fingers are distributed across the BoD. Study 3 examined user performance for applying BoD pressure (a) during single touches at the front and (b) for 20 seconds while touching multiple consecutive frontal targets. Participants achieved up to 92% pressure accuracy for three separate pressure levels above normal resting pressure, with the middle fingers providing the highest accuracy. BoD pressure did not affect frontal touch accuracy. We conclude with design guidelines for BoD pressure input.</p></div></span> <a id="expcoll497" href="JavaScript: expandcollapse('expcoll497',497)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025941&CFID=758305256&CFTOKEN=14863114">Improving Gesture Recognition Accuracy on Touch Screens for Users with Low Vision</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Radu-Daniel Vatavu 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4667-4679</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025941" title="DOI">10.1145/3025453.3025941</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025941&ftid=1870364&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow498" style="display:inline;"><br /><div style="display:inline">We contribute in this work on gesture recognition to improve the accessibility of touch screens for people with low vision. We examine the accuracy of popular recognizers for gestures produced by people with and without visual impairments, and we show ...</div></span>
          <span id="toHide498" style="display:none;"><br /><div style="display:inline"><p>We contribute in this work on gesture recognition to improve the accessibility of touch screens for people with low vision. We examine the accuracy of popular recognizers for gestures produced by people with and without visual impairments, and we show that the user-independent accuracy of $P, the best recognizer among those evaluated, is small for people with low vision (83.8%), despite $P being very effective for gestures produced by people without visual impairments (95.9%). By carefully analyzing the gesture articulations produced by people with low vision, we inform key algorithmic revisions for the P recognizer, which we call P+. We show significant accuracy improvements of $P+ for gestures produced by people with low vision, from 83.8% to 94.7% on average and up to 98.2%, and 3x faster execution times compared to P.</p></div></span> <a id="expcoll498" href="JavaScript: expandcollapse('expcoll498',498)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025835&CFID=758305256&CFTOKEN=14863114">Understanding Grip Shifts: How Form Factors Impact Hand Movements on Mobile Phones</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Rachel Eardley, Anne Roudaut, Steve Gill, Stephen J. Thompson 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4680-4691</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025835" title="DOI">10.1145/3025453.3025835</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025835&ftid=1870376&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow499" style="display:inline;"><br /><div style="display:inline">In this paper we present an investigation into how hand usage is affected by different mobile phone form factors. Our initial (qualitative) study explored how users interact with various mobile phone types (touchscreen, physical keyboard and stylus). ...</div></span>
          <span id="toHide499" style="display:none;"><br /><div style="display:inline"><p>In this paper we present an investigation into how hand usage is affected by different mobile phone form factors. Our initial (qualitative) study explored how users interact with various mobile phone types (touchscreen, physical keyboard and stylus). The analysis of the videos revealed that each type of mobile phone affords specific handgrips and that the user shifts these grips and consequently the tilt and rotation of the phone depending on the context of interaction. In order to further investigate the tilt and rotation effects we conducted a controlled quantitative study in which we varied the size of the phone and the type of grips (Symmetric bimanual, Asymmetric bimanual with finger, Asymmetric bimanual with thumb and Single handed) to better understand how they affect the tilt and rotation during a dual pointing task. The results showed that the size of the phone does have a consequence and that the distance needed to reach action items affects the phones' tilt and rotation. Additionally, we found that the amount of tilt, rotation and reach required corresponded with the participant's grip preference. We finish the paper by discussing the design lessons for mobile UI and proposing design guidelines and applications for these insights.</p></div></span> <a id="expcoll499" href="JavaScript: expandcollapse('expcoll499',499)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Innovative Input Techniques</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025468&CFID=758305256&CFTOKEN=14863114">Structured Input Improves Usability and Precision for Solving Geometry-based Algebraic Problems</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Bo Kang, Joseph J. LaViola Jr., Pamela Wisniewski 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4692-4702</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025468" title="DOI">10.1145/3025453.3025468</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025468&ftid=1870340&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow501" style="display:inline;"><br /><div style="display:inline">Previous research has shown that sketch-based input is efficient and preferable in the context of algebraic equation solving. However, research has not been conducted to evaluate whether this holds true when involving geometry input to facilitate quantitative ...</div></span>
          <span id="toHide501" style="display:none;"><br /><div style="display:inline"><p>Previous research has shown that sketch-based input is efficient and preferable in the context of algebraic equation solving. However, research has not been conducted to evaluate whether this holds true when involving geometry input to facilitate quantitative problem-solving. We developed a bimodal (graphing geometric shapes and writing algebraic expressions) user interface, in order to conduct a within-subject, controlled experiment with 24 college students and varied two types of geometry input: 1) sketch-based input and 2) structured input. The sketch-based input was significantly faster than the structured input, but there were no significant differences based on perception and cognition. However, after a post-hoc analysis, we found a significant interaction effect on perception between prior knowledge and geometry input. Novice students preferred the sketch-based input, but advanced students preferred the structured input. Our study implies that natural sketch-based input may be less preferable than structured input for geometry-based interfaces toward math problem-solving.</p></div></span> <a id="expcoll501" href="JavaScript: expandcollapse('expcoll501',501)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025506&CFID=758305256&CFTOKEN=14863114">Genie: Input Retargeting on the Web through Command Reverse Engineering</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Amanda Swearngin, Andrew J. Ko, James Fogarty 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4703-4714</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025506" title="DOI">10.1145/3025453.3025506</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025506&ftid=1870369&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow502" style="display:inline;"><br /><div style="display:inline">Most web applications are designed as one-size-fits-all, despite considerable variation in people's expertise, physical abilities, and other factors that impact interaction. For example, some web applications require the use of a mouse, precluding use ...</div></span>
          <span id="toHide502" style="display:none;"><br /><div style="display:inline"><p>Most web applications are designed as one-size-fits-all, despite considerable variation in people's expertise, physical abilities, and other factors that impact interaction. For example, some web applications require the use of a mouse, precluding use by many people with severe motor disabilities. Other applications require laborious manual input that a skilled developer could automate if the application were scriptable. This paper presents Genie, a system that automatically reverse engineers an abstract model of the underlying commands in a web application, then enables interaction with that functionality through alternative interfaces and other input modalities (e.g., speech, keyboard, or command line input). Genie comprises an abstract model of command properties, behaviors, and dependencies as well as algorithms that reverse engineer this model from an existing web application through static and dynamic program analysis. We evaluate Genie by developing several interfaces that automatically add support for speech, keyboard, and command line input to arbitrary web applications.</p></div></span> <a id="expcoll502" href="JavaScript: expandcollapse('expcoll502',502)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025595&CFID=758305256&CFTOKEN=14863114">IconHK: Using Toolbar button Icons to Communicate Keyboard Shortcuts</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Emmanouil Giannisakis, Gilles Bailly, Sylvain Malacria, Fanny Chevalier 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4715-4726</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025595" title="DOI">10.1145/3025453.3025595</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025595&ftid=1870379&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow503" style="display:inline;"><br /><div style="display:inline">We propose a novel perspective on the design of toolbar buttons that aims to increase keyboard shortcut accessibility. IconHK implements this perspective by blending visual cues that convey keyboard shortcut information into toolbar buttons without denaturing ...</div></span>
          <span id="toHide503" style="display:none;"><br /><div style="display:inline"><p>We propose a novel perspective on the design of toolbar buttons that aims to increase keyboard shortcut accessibility. IconHK implements this perspective by blending visual cues that convey keyboard shortcut information into toolbar buttons without denaturing the pictorial representation of their command. We introduce three design strategies to embed the hotkey, a visual encoding to convey the modifiers, and a magnification factor that determines the blending ratio between the pictogram of the button and the visual representation of the keyboard shortcut. Two studies examine the benefits of IconHK for end-users and provide insights from professional designers on the practicality of our approach for creating iconsets. Building on these insights, we develop a tool to assist designers in applying the IconHK design principle.</p></div></span> <a id="expcoll503" href="JavaScript: expandcollapse('expcoll503',503)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025863&CFID=758305256&CFTOKEN=14863114">Mouse, Tactile, and Tangible Input for 3D Manipulation</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Lonni Besan&#231;on, Paul Issartel, Mehdi Ammi, Tobias Isenberg 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4727-4740</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025863" title="DOI">10.1145/3025453.3025863</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025863&ftid=1870385&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow504" style="display:inline;"><br /><div style="display:inline">We evaluate the performance and usability of mouse-based, touch-based, and tangible interaction for manipulating objects in a 3D virtual environment. This comparison is a step toward a better understanding of the limitations and benefits of these existing ...</div></span>
          <span id="toHide504" style="display:none;"><br /><div style="display:inline"><p>We evaluate the performance and usability of mouse-based, touch-based, and tangible interaction for manipulating objects in a 3D virtual environment. This comparison is a step toward a better understanding of the limitations and benefits of these existing interaction techniques, with the ultimate goal of facilitating an easy transition between the different 3D data exploration environments. For this purpose we analyze participants' performance in 3D manipulation using a docking task. We measured completion times, docking accuracy, as well as subjective criteria such as fatigue, workload, and preference. Our results show that the three input modalities provide similar levels of precision but require different completion times. We also discuss our qualitative observations as well as people's preferences and put our findings into context of the application domain of 3D data analysis environments.</p></div></span> <a id="expcoll504" href="JavaScript: expandcollapse('expcoll504',504)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Markets in the Global South</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025970&CFID=758305256&CFTOKEN=14863114">Market Practices and the Bazaar: Technology Consumption in ICT Markets in the Global South</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Priyank Chandra, Syed Ishtiaque Ahmed, Joyojeet Pal 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4741-4752</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025970" title="DOI">10.1145/3025453.3025970</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025970&ftid=1870371&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow506" style="display:inline;"><br /><div style="display:inline">Local informal markets or bazaars play a central role in embedding the adoption, consumption, and reproduction of digital technologies within the economic and cultural fabric of the Global South. This paper presents ethnographic accounts of informal ...</div></span>
          <span id="toHide506" style="display:none;"><br /><div style="display:inline"><p>Local informal markets or bazaars play a central role in embedding the adoption, consumption, and reproduction of digital technologies within the economic and cultural fabric of the Global South. This paper presents ethnographic accounts of informal ICT markets in two sites, one in India and the other in Bangladesh, and assesses how technology consumption unfolds within local practices. Building on social practice theory, this paper depicts the role of materiality, relationships, and situated knowledge in the functioning of a bazaar. We discuss how this knowledge expands our understanding of the evaluation of technology and technical expertise, and the persistence of these informal spaces despite the uptake of corporatized technology marketplaces. We argue that the bazaar represents a special kind of local voice that enriches the HCI scholarship in postcolonial computing.</p></div></span> <a id="expcoll506" href="JavaScript: expandcollapse('expcoll506',506)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025481&CFID=758305256&CFTOKEN=14863114">Cinehacking Cape Town - Embracing Informality in Pursuit of High Quality Media</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          David Philip Green, Guy Schofield, Gary Pritchard, Patrick Olivier, Peter Wright 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4753-4764</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025481" title="DOI">10.1145/3025453.3025481</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025481&ftid=1870343&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow507" style="display:inline;"><br /><div style="display:inline">Although many common tools of media making such as video cameras have become more accessible in recent years, many remain inaccessible. Cinematography, lighting and sound-recording equipment for example can be prohibitively expensive to obtain, complex ...</div></span>
          <span id="toHide507" style="display:none;"><br /><div style="display:inline"><p>Although many common tools of media making such as video cameras have become more accessible in recent years, many remain inaccessible. Cinematography, lighting and sound-recording equipment for example can be prohibitively expensive to obtain, complex to configure, and/or require specialist knowledge to operate effectively. These barriers can prevent non-professionals who want to produce high-quality media from being able to. Cinehack is an ongoing project to research ways to overcome these barriers. In this paper, we specifically report on Cinehack: Cape Town, a participatory media making project. By co-producing hip hop videos within a community for whom media making is often a "means-to-an-end", we were able gain insights into the kinds of support needed to enable high quality media making by non-professionals. Specifically, we highlight ways to meet users' needs by embracing informal codes of practice via experimental making and peer-support.</p></div></span> <a id="expcoll507" href="JavaScript: expandcollapse('expcoll507',507)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025643&CFID=758305256&CFTOKEN=14863114">Informality and Invisibility: Traditional Technologies as Tools for Collaboration in an Informal Market</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Priyank Chandra 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4765-4775</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025643" title="DOI">10.1145/3025453.3025643</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025643&ftid=1870374&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow508" style="display:inline;"><br /><div style="display:inline">This paper explores how actors in local markets in the Global South adapt traditional communication technologies to successfully collaborate to sustain the markets and their business practices. Drawing on ethnographic observations at a local technology ...</div></span>
          <span id="toHide508" style="display:none;"><br /><div style="display:inline"><p>This paper explores how actors in local markets in the Global South adapt traditional communication technologies to successfully collaborate to sustain the markets and their business practices. Drawing on ethnographic observations at a local technology goods market in Bangalore, India, the study details the use of a landline telephone intercom system as the primary tool for business communication in the market. Through analyzing how the intercom system relates to informality and physical space, the paper argues that it bridges the formal with the informal, and helps facilitate informal business practices while also allowing them to remain hidden from the formal regulatory gaze of the state.</p></div></span> <a id="expcoll508" href="JavaScript: expandcollapse('expcoll508',508)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025910&CFID=758305256&CFTOKEN=14863114">From Margins to Seams: Imbrication, Inclusion, and Torque in the Aadhaar Identification Project</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Ranjit Singh, Steven J. Jackson 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4776-4824</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025910" title="DOI">10.1145/3025453.3025910</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025910&ftid=1870344&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow509" style="display:inline;"><br /><div style="display:inline">Problems of marginalization and inclusion are central to HCI scholarship and impact in the world, but are badly named in the binary models of access that currently dominate the field. Building on prior work in ICTD and infrastructure studies, this paper ...</div></span>
          <span id="toHide509" style="display:none;"><br /><div style="display:inline"><p>Problems of marginalization and inclusion are central to HCI scholarship and impact in the world, but are badly named in the binary models of access that currently dominate the field. Building on prior work in ICTD and infrastructure studies, this paper explores the problem of inclusion through historical and ethnographic study of Aadhaar, India's biometrics-based national identification project. We illustrate tensions between Aadhaar users' ability to register, authenticate and successfully deploy their registered identity to participate in the Public Distribution System (PDS), a government scheme that provides subsidized food grains to the Indian poor. We argue that rather than an all-or-nothing state, inclusion in ICTD infrastructures is an ongoing and fragile process, achieved (unevenly) at the seams of multiple interconnected systems. Finally, we show that questions of (effective) inclusion are determined not just at margins of a system (who is in and who is out) but also through the artful and often challenging negotiation of the seams that run through and connect complex distributed infrastructures.</p></div></span> <a id="expcoll509" href="JavaScript: expandcollapse('expcoll509',509)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Performative Interactions</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025751&CFID=758305256&CFTOKEN=14863114">Performing Research: Four Contributions to HCI</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Robyn Taylor, Jocelyn Spence, Brendan Walker, Bettina Nissen, Peter Wright 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4825-4837</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025751" title="DOI">10.1145/3025453.3025751</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025751&ftid=1870669&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow511" style="display:inline;"><br /><div style="display:inline">This paper identifies a body of HCI research wherein the researchers take part in digitally mediated creative experiences alongside participants. We present our definition and rationale for "self-situated performance research" based on theories in both ...</div></span>
          <span id="toHide511" style="display:none;"><br /><div style="display:inline"><p>This paper identifies a body of HCI research wherein the researchers take part in digitally mediated creative experiences alongside participants. We present our definition and rationale for "self-situated performance research" based on theories in both the HCI and performance literatures. We then analyse four case studies of this type of work, ranging from overtly "performative" staged events to locative audio and public making.</p> <p>We argue that by interrogating experience from within the context of self-situated performance, the 'performer/researcher' extends traditional practices in HCI in the following four ways: developing an intimate relationship between researchers and participants, providing new means of making sense of interactions, shaping participants' relationship to the research, and enabling researchers to refine their work as it is being conducted.</p></div></span> <a id="expcoll511" href="JavaScript: expandcollapse('expcoll511',511)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025722&CFID=758305256&CFTOKEN=14863114">MagicFace: Stepping into Character through an Augmented Reality Mirror</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Ana Javornik, Yvonne Rogers, Delia Gander, Ana Moutinho 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4838-4849</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025722" title="DOI">10.1145/3025453.3025722</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025722&ftid=1870689&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow512" style="display:inline;"><br /><div style="display:inline">Augmented Reality (AR) is coming of age and appearing in various smartphone apps. One emerging AR type uses the front-facing camera and overlays a user's face with digital features that transform the physical appearance, making the user look like someone ...</div></span>
          <span id="toHide512" style="display:none;"><br /><div style="display:inline"><p>Augmented Reality (AR) is coming of age and appearing in various smartphone apps. One emerging AR type uses the front-facing camera and overlays a user's face with digital features that transform the physical appearance, making the user look like someone else, such as a popstar or a historical character. However, little is known about how people react to such stepping into character and how convincing they perceive it to be. We developed an app with two Egyptian looks, MagicFace, which was situated both in an opera house and a museum. In the first setting, people were invited to use the app, while in the second setting they came across it on their own when visiting the exhibition. Our findings show marked differences in how people approach and experience the MagicFace in these different contexts. We discuss how realistic and compelling this kind of AR technology is, as well as its implications for educational and cultural settings.</p></div></span> <a id="expcoll512" href="JavaScript: expandcollapse('expcoll512',512)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025897&CFID=758305256&CFTOKEN=14863114">Interactive Performance as a Means of Civic Dialogue</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Chiara Rossitto, Maria Normark, Louise Barkhuus 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4850-4862</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025897" title="DOI">10.1145/3025453.3025897</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025897&ftid=1870690&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow513" style="display:inline;"><br /><div style="display:inline">This paper presents a case study of an interactive performance that was produced and designed to encourage civic engagement and reflection in relation to the social tensions in a low-income suburb, mostly inhabited by people with immigrant backgrounds. ...</div></span>
          <span id="toHide513" style="display:none;"><br /><div style="display:inline"><p>This paper presents a case study of an interactive performance that was produced and designed to encourage civic engagement and reflection in relation to the social tensions in a low-income suburb, mostly inhabited by people with immigrant backgrounds. The design of the technological setup in the performance encouraged participation by means of text entries that audience members could share with others. The analysis draws on the corpus of interview and observational data collected, as well as the related text messages that were shared during the performance. We illustrate the different levels at which citizens make sense of societal issues they are concerned about, as well as the audience-citizens' perception of participating in such an artistic experience.</p></div></span> <a id="expcoll513" href="JavaScript: expandcollapse('expcoll513',513)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025854&CFID=758305256&CFTOKEN=14863114">The Game of Performing Play: Understanding Streaming as Cultural Production</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Anthony J. Pellicone, June Ahn 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4863-4874</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025854" title="DOI">10.1145/3025453.3025854</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025854&ftid=1870670&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow514" style="display:inline;"><br /><div style="display:inline">Live streaming has become pervasive in digital game culture. Previous work has focused largely on technological considerations in streaming platforms. However, little is known about how streamers enter the practice, gain skills, and operate as content ...</div></span>
          <span id="toHide514" style="display:none;"><br /><div style="display:inline"><p>Live streaming has become pervasive in digital game culture. Previous work has focused largely on technological considerations in streaming platforms. However, little is known about how streamers enter the practice, gain skills, and operate as content producers. We present a qualitative study of an online forum dedicated to streaming. By observing the conversations between veterans and newcomers to the practice, we develop an understanding of how streamers must tie together technological, social, and gameplay-based skills to craft an appealing performance of play. We find that a key skill in streaming is the development of a unique attitude and persona as a gamer, which permeates into every element of a streamer's performance. As individual identity becomes important in streaming practice, design considerations for platform features such as community moderation and stream metrics may help improve equitable participation in this increasingly important aspect of game culture.</p></div></span> <a id="expcoll514" href="JavaScript: expandcollapse('expcoll514',514)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Serious + Educational + Exer Games</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025510&CFID=758305256&CFTOKEN=14863114">Finding the Right Fit: Understanding Health Tracking in Workplace Wellness Programs</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Chia-Fang Chung, Nanna Jensen, Irina A. Shklovski, Sean Munson 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4875-4886</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025510" title="DOI">10.1145/3025453.3025510</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025510&ftid=1870725&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow516" style="display:inline;"><br /><div style="display:inline">Workplace health and wellness programs are increasingly integrating personal health tracking technologies, such as Fitbit and Apple Watch. Many question whether these technologies truly support employees in their pursuit of better wellness levels, raising ...</div></span>
          <span id="toHide516" style="display:none;"><br /><div style="display:inline"><p>Workplace health and wellness programs are increasingly integrating personal health tracking technologies, such as Fitbit and Apple Watch. Many question whether these technologies truly support employees in their pursuit of better wellness levels, raising objections about workplace surveillance and further blurring of boundaries between work and personal life. We conducted a study to understand how tracking tools are adopted in wellness programs and employees' opinions about these programs. We find that employees are generally positive about incentivized health tracking in the workplace, as it helps raise awareness of activity levels. However, there is a gap between the intentions of the programs and individual experiences and health goals. This sometimes results in confusion and creates barriers to participation. Even if this gap can be addressed, health tracking in the workplace will not be for everyone; this has implications for the design of both workplace wellness programs and tracking technologies.</p></div></span> <a id="expcoll516" href="JavaScript: expandcollapse('expcoll516',516)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025544&CFID=758305256&CFTOKEN=14863114">Mastery Learning of Second Language through Asynchronous Modeling of Native Speakers in a Collaborative Mobile Game</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Xiangmin Fan, Wencan Luo, Jingtao Wang 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4887-4898</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025544" title="DOI">10.1145/3025453.3025544</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025544&ftid=1870686&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow517" style="display:inline;"><br /><div style="display:inline">Acquiring Chinese tones is often considered as the most difficult task in learning Chinese as a Second Language (CSL). Recently, ToneWars, a collaborative mobile learning game, demonstrated the feasibility and efficacy of connecting CSL learners with ...</div></span>
          <span id="toHide517" style="display:none;"><br /><div style="display:inline"><p>Acquiring Chinese tones is often considered as the most difficult task in learning Chinese as a Second Language (CSL). Recently, ToneWars, a collaborative mobile learning game, demonstrated the feasibility and efficacy of connecting CSL learners with native speakers for tone learning. However, the synchronous gameplay nature in ToneWars can be hard to scale due to the time constraint and limited availability of native speakers. We present principled research to make ToneWars <i>scalable</i> and <i>sustainable</i>. First, we address the scalability issue via asynchronous modeling of native speakers. Second, we quantify whether a CSL learner achieves native level mastery for a specific phrase, and explore the use of fine-grained feedback on language mastery as a sustainable motivator for language learning. The insights in this research are generalizable to designing second language learning technologies beyond Chinese. In a longitudinal study with 18 CSL learners, we found that asynchronous gameplay significantly improved learning with an average gain of 29.7 tones and 16.4 syllables, and helped participants achieve native level mastery on 58.2 out of 69 phrases.</p></div></span> <a id="expcoll517" href="JavaScript: expandcollapse('expcoll517',517)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025691&CFID=758305256&CFTOKEN=14863114">Misrepresentation of Health Research in Exertion Games Literature</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Joe Marshall, Conor Linehan 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4899-4910</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025691" title="DOI">10.1145/3025453.3025691</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025691&ftid=1870671&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow518" style="display:inline;"><br /><div style="display:inline">HCI often requires scholars to build upon research from fields outside their expertise, creating the risk that foundational work is misunderstood and misrepresented. The prevailing goal of "exergames" research towards ameliorating obesity appears to ...</div></span>
          <span id="toHide518" style="display:none;"><br /><div style="display:inline"><p>HCI often requires scholars to build upon research from fields outside their expertise, creating the risk that foundational work is misunderstood and misrepresented. The prevailing goal of "exergames" research towards ameliorating obesity appears to be built on just such a misunderstanding of health research. In this paper, we analyse all citations to a single influential study, which has been extensively cited to justify research on exergames. We categorise the 375 citations based on whether they represent the findings of that study accurately or inaccurately. Our findings suggest that 69% of exergames papers citing this study misrepresent the findings, demonstrating a systematic failure of scholarship in exergames research. We argue that exergaming research should cease focusing on games as treatment for obesity, and that HCI publications should demand more critical and scholarly engagement with research from outside HCI.</p></div></span> <a id="expcoll518" href="JavaScript: expandcollapse('expcoll518',518)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025711&CFID=758305256&CFTOKEN=14863114">Teaching Programming with Gamified Semantics</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Ian Arawjo, Cheng-Yao Wang, Andrew C. Myers, Erik Andersen, Fran&#231;ois Guimbreti&#232;re 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4911-4923</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025711" title="DOI">10.1145/3025453.3025711</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025711&ftid=1870687&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow519" style="display:inline;"><br /><div style="display:inline">Dominant approaches to programming education emphasize program construction over language comprehension. We present Reduct, an educational game embodying a new, comprehension-first approach to teaching novices core programming concepts which include ...</div></span>
          <span id="toHide519" style="display:none;"><br /><div style="display:inline"><p>Dominant approaches to programming education emphasize program construction over language comprehension. We present <i>Reduct</i>, an educational game embodying a new, comprehension-first approach to teaching novices core programming concepts which include functions, Booleans, equality, conditionals, and mapping functions over sets. In this novel teaching strategy, the player executes code using reduction-based operational semantics. During gameplay, code representations fade from concrete, block-based graphics to the actual syntax of JavaScript ES2015. We describe our design rationale and report on the results of a study evaluating the efficacy of our approach on young adults (18+) without prior coding experience. In a short timeframe, novices demonstrated promising learning of core concepts expressed in actual JavaScript. We also present results from an online deployment. Finally, we discuss ramifications for the design of future computational thinking games.</p></div></span> <a id="expcoll519" href="JavaScript: expandcollapse('expcoll519',519)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Technology in Households</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025546&CFID=758305256&CFTOKEN=14863114">Investigating the Suitability of the Asynchronous, Remote, Community-based Method for Pregnant and New Mothers</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Annu Sible Prabhakar, Lucia Guerra-Reyes, Vanessa M. Kleinschmidt, Ben Jelen, Haley MacLeod, Kay Connelly, Katie A. Siek 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4924-4934</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025546" title="DOI">10.1145/3025453.3025546</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025546&ftid=1870705&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow521" style="display:inline;"><br /><div style="display:inline">Traditional qualitative research methods, such as, interviews and focus groups, may not be feasible for certain populations- who face time, mobility, and availability constraints. We adapted the Asynchronous, Remote, Community-based (ARC) method that ...</div></span>
          <span id="toHide521" style="display:none;"><br /><div style="display:inline"><p>Traditional qualitative research methods, such as, interviews and focus groups, may not be feasible for certain populations- who face time, mobility, and availability constraints. We adapted the Asynchronous, Remote, Community-based (ARC) method that used closed Facebook groups to study people with rare diseases, to study a different population - pregnant and new mothers. During the course of eight weeks, we engaged 48 participants in 19 study activities using three closed Facebook groups. We added new activities to the original ARC method, informed by past HCI research, to triangulate participant input. We carefully analyzed participation patterns and activity engagement, to assess the suitability of the ARC method for engaging pregnant and new mothers in remote, group-based, qualitative research. We provide an in-depth analysis of the ARC method, noting participation characteristics, activity preferences, and the suitability of the ARC method as an online focus group.</p></div></span> <a id="expcoll521" href="JavaScript: expandcollapse('expcoll521',521)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025928&CFID=758305256&CFTOKEN=14863114">Has Instagram Fundamentally Altered the 'Family Snapshot'?</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Effie Le Moignan, Shaun Lawson, Duncan A. Rowland, Jamie Mahoney, Pam Briggs 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4935-4947</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025928" title="DOI">10.1145/3025453.3025928</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025928&ftid=1870663&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow522" style="display:inline;"><br /><div style="display:inline">This paper considers how parents use the social media platform Instagram to facilitate the capture, curation and sharing of 'family snapshots'. Our work draws upon established cross-disciplinary literature relating to film photography and the composition ...</div></span>
          <span id="toHide522" style="display:none;"><br /><div style="display:inline"><p>This paper considers how parents use the social media platform Instagram to facilitate the capture, curation and sharing of 'family snapshots'. Our work draws upon established cross-disciplinary literature relating to film photography and the composition of family albums in order to establish whether social media has changed the way parents visually present their families. We conducted a qualitative visual analysis of a sample of 4,000 photographs collected from Instagram using hashtags relating to children and parenting. We show that the style and composition of snapshots featuring children remains fundamentally unchanged and continues to be dominated by rather bland and idealised images of the <i>happy family</i> and the <i>cute child</i>. In addition, we find that the frequent taking and sharing of photographs via Instagram has inevitably resulted in a more mundane visual catalogue of daily life. We note a tension in the desire to use social media as a means to evidence good parenting, while trying to effectively manage the social identity of the child and finally, we note the reluctance of parents to use their own snapshots to portray family tension or disharmony, but their willingness to use externally generated content for this purpose.</p></div></span> <a id="expcoll522" href="JavaScript: expandcollapse('expcoll522',522)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025572&CFID=758305256&CFTOKEN=14863114">Internet Search Roles of Adults in their Homes</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Jinyoung Kim, Brenna McNally, Leyla Norooz, Allison Druin 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4948-4959</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025572" title="DOI">10.1145/3025453.3025572</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025572&ftid=1870696&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow523" style="display:inline;"><br /><div style="display:inline">Internet search is one of the major activities that American adults engage in online. Building on studies of youth Internet search roles, this paper investigates adults' online information seeking processes within the home. Through in-home interviews ...</div></span>
          <span id="toHide523" style="display:none;"><br /><div style="display:inline"><p>Internet search is one of the major activities that American adults engage in online. Building on studies of youth Internet search roles, this paper investigates adults' online information seeking processes within the home. Through in-home interviews and observations of search task performance with 40 adult participants, we identify and describe characteristics of 9 search roles. By comparing these roles with those of youths, we explain how previously identified roles, such as <i>Power Searcher</i> and <i>Social Searcher</i>, have evolved in adult populations, and how new roles, such as <i>Efficient Searcher</i> and <i>Interest-driven Searcher</i>, have emerged. We also review the challenges and benefits associated with search roles and their potential impacts on search performance. The findings of this study provide a better understanding of how contextual factors influence search roles in relation to ELIS, what can be learned from search roles, and opportunities to support different search roles.</p></div></span> <a id="expcoll523" href="JavaScript: expandcollapse('expcoll523',523)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3026000&CFID=758305256&CFTOKEN=14863114">Understanding the Role of Human Senses in Interactive Meditation</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Mahmoud Mohamed Hussien Ahmed, Chaklam Silpasuwanchai, Kavous Salehzadeh Niksirat, Xiangshi Ren 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4960-4965</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3026000" title="DOI">10.1145/3025453.3026000</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3026000&ftid=1870697&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow524" style="display:inline;"><br /><div style="display:inline">In our fast-paced society, stress and anxiety have become increasingly common. Meditation for relaxation has received much attention. Meditation apps exploit various senses, e.g., touch, audio and vision, but the relationship between human senses and ...</div></span>
          <span id="toHide524" style="display:none;"><br /><div style="display:inline"><p>In our fast-paced society, stress and anxiety have become increasingly common. Meditation for relaxation has received much attention. Meditation apps exploit various senses, e.g., touch, audio and vision, but the relationship between human senses and interactive meditation is not well understood. This paper empirically evaluates the effects of single and combined human senses on interactive meditation. We found that the effectiveness of human senses can be defined by their respective roles in maintaining the balance between relaxation and focus. This work is the first to attempt to understand these relationships. The findings have broad implications for the field of multi-modal interaction and interactive meditation applications.</p></div></span> <a id="expcoll524" href="JavaScript: expandcollapse('expcoll524',524)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025767&CFID=758305256&CFTOKEN=14863114">Gender Norms and Attitudes about Childcare Activities Presented on Father Blogs</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Kai Lukoff, Carol Moser, Sarita Schoenebeck 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4966-4971</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025767" title="DOI">10.1145/3025453.3025767</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025767&ftid=1870666&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow525" style="display:inline;"><br /><div style="display:inline">Father involvement is important for child well-being. However, fathers still do significantly less childcare than mothers, due in part to traditional gender norms. This research investigates whether incorporating do-it-yourself (DIY) language and imagery ...</div></span>
          <span id="toHide525" style="display:none;"><br /><div style="display:inline"><p>Father involvement is important for child well-being. However, fathers still do significantly less childcare than mothers, due in part to traditional gender norms. This research investigates whether incorporating do-it-yourself (DIY) language and imagery into parenting blogs is an effective mechanism for boosting fathers' willingness to perform childcare activities. We conducted a between-subjects experiment with 374 participants in the U.S. who responded to ten parenting blog posts. Subjects were randomized to view posts with either DIY or neutral language and either routine childcare activities (e.g., changing diapers) or interactive ones (e.g., finger painting). Results show that DIY language actually decreases a father's willingness to do a childcare activity. Further, fathers underestimate how socially appropriate it is for them to perform childcare activities and this misperception relates to their willingness to get involved. We draw on social norms literature to recommend next steps for designing interfaces to support father involvement in childrearing.</p></div></span> <a id="expcoll525" href="JavaScript: expandcollapse('expcoll525',525)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Textures and Haptics</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025741&CFID=758305256&CFTOKEN=14863114">WAVES: A Wearable Asymmetric Vibration Excitation System for Presenting Three-Dimensional Translation and Rotation Cues</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Heather Culbertson, Julie M. Walker, Michael Raitor, Allison M. Okamura 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4972-4982</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025741" title="DOI">10.1145/3025453.3025741</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025741&ftid=1870723&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow527" style="display:inline;"><br /><div style="display:inline">WAVES, a Wearable Asymmetric Vibration Excitation System, is a novel wearable haptic device for presenting three dimensions of translation and rotation guidance cues. In contrast to traditional vibration feedback, which usually requires that users learn ...</div></span>
          <span id="toHide527" style="display:none;"><br /><div style="display:inline"><p>WAVES, a Wearable Asymmetric Vibration Excitation System, is a novel wearable haptic device for presenting three dimensions of translation and rotation guidance cues. In contrast to traditional vibration feedback, which usually requires that users learn to interpret a binary cue, asymmetric vibrations have been shown to induce a pulling sensation in a desired direction. When attached to the fingers, a single voicecoil actuator presents a translation guidance cue and a pair of voicecoil actuators presents a rotation guidance cue. The directionality of mechanoreceptors in the skin led to our choice of the location and orientation of the actuators in order to elicit very strong sensations in certain directions. For example, users distinguished a "left" cue versus a "right" cue 94.5% of the time. When presented with one of six possible direction cues, users on average correctly identified the direction of translation cues 86.1% of the time and rotation cues 69.0% of the time.</p></div></span> <a id="expcoll527" href="JavaScript: expandcollapse('expcoll527',527)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025702&CFID=758305256&CFTOKEN=14863114">Magnetic Plotter: A Macrotexture Design Method Using Magnetic Rubber Sheets</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Kentaro Yasu 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4983-4993</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025702" title="DOI">10.1145/3025453.3025702</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025702&ftid=1870718&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow528" style="display:inline;"><br /><div style="display:inline">This paper presents a method for designing tactile macrotextures with magnetic rubber sheets. In the method, named "Magnetic Plotter", a desktop digital plotting machine combined with a tiny neodymium magnet writes fine magnetic patterns on the surface ...</div></span>
          <span id="toHide528" style="display:none;"><br /><div style="display:inline"><p>This paper presents a method for designing tactile macrotextures with magnetic rubber sheets. In the method, named "Magnetic Plotter", a desktop digital plotting machine combined with a tiny neodymium magnet writes fine magnetic patterns on the surface of the magnetic rubber sheets. This method enables users to design magnetic fields freely with inexpensive commercially available materials as if they are drawing pictures. Moreover, when the magnetic sheets are rubbed together, unique haptic stimuli are displayed on the fingers. The haptic stimuli can be changed by the magnetic patterns designed on the rubber sheets. We developed a prototype of the Magnetic Plotter and investigated the range of the generated haptic stimuli and the texture design possibilities.</p></div></span> <a id="expcoll528" href="JavaScript: expandcollapse('expcoll528',528)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025812&CFID=758305256&CFTOKEN=14863114">Generating Haptic Textures with a Vibrotactile Actuator</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Paul Strohmeier, Kasper Hornb&#230;k 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 4994-5005</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025812" title="DOI">10.1145/3025453.3025812</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025812&ftid=1870712&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow529" style="display:inline;"><br /><div style="display:inline">Vibrotactile actuation is mainly used to deliver buzzing sensations. But if vibrotactile actuation is tightly coupled to users' actions, it can be used to create much richer haptic experiences. It is not well understood, however, how this coupling should ...</div></span>
          <span id="toHide529" style="display:none;"><br /><div style="display:inline"><p>Vibrotactile actuation is mainly used to deliver buzzing sensations. But if vibrotactile actuation is tightly coupled to users' actions, it can be used to create much richer haptic experiences. It is not well understood, however, how this coupling should be done or which vibrotactile parameters create which experiences. To investigate how actuation parameters relate to haptic experiences, we built a physical slider with minimal native friction, a vibrotactile actuator and an integrated position sensor. By vibrating the slider as it is moved, we create an experience of texture between the sliding element and its track. We conducted a magnitude estimation experiment to map how granularity, amplitude and timbre relate to the experiences of roughness, adhesiveness, sharpness and bumpiness. We found that amplitude influences the strength of the perceived texture, while variations in granularity and timbre create distinct experiences. Our study underlines the importance of action in haptic perception and suggests strategies for deploying such tightly coupled feedback in everyday devices.</p></div></span> <a id="expcoll529" href="JavaScript: expandcollapse('expcoll529',529)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3026010&CFID=758305256&CFTOKEN=14863114">Localized Haptic Texture: A Rendering Technique based on Taxels for High Density Tactile Feedback</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Yosra Rekik, Eric Vezzoli, Laurent Grisoni, Fr&#233;d&#233;ric Giraud 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5006-5015</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3026010" title="DOI">10.1145/3025453.3026010</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3026010&ftid=1870721&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow530" style="display:inline;"><br /><div style="display:inline">We investigate the relevance of surface haptic rendering techniques for tactile devices. We focus on the two major existing techniques and show that they have complementary benefits. The first one, called textsc{S}urface textsc{H}aptic textsc{O}bject ...</div></span>
          <span id="toHide530" style="display:none;"><br /><div style="display:inline"><p>We investigate the relevance of surface haptic rendering techniques for tactile devices. We focus on the two major existing techniques and show that they have complementary benefits. The first one, called textsc{S}urface textsc{H}aptic textsc{O}bject (textsc{SHO}), which is based on finger position, is shown to be more suitable to render sparse textures; while the second one, called textsc{S}urface textsc{H}aptic textsc{T}exture (textsc{SHT}), which is based on finger velocity, is shown to be more suitable for dense textures and fast finger movements. We hence propose a new rendering technique, called textsc{L}ocalized textsc{H}aptic textsc{T}exture (textsc{LHT}), which is based on the concept of textit{taxel} considered as an elementary tactile information that is rendered on the screen. By using a grid of taxels to encode a texture, textsc{LHT} is shown to provide a consistent tactile rendering across different velocities for high density textures, and is found to reduce user textit{error rate} by up to 77.68% compared to textsc{SHO}.</p></div></span> <a id="expcoll530" href="JavaScript: expandcollapse('expcoll530',530)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Design and Games</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025494&CFID=758305256&CFTOKEN=14863114">Supporting Easy Physical-to-Virtual Creation of Mobile VR Maze Games: A New Genre</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Wei Gai, Chenglei Yang, Yulong Bian, Chia Shen, Xiangxu Meng, Lu Wang, Juan Liu, Mingda Dong, Chengjie Niu, Cheng Lin 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5016-5028</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025494" title="DOI">10.1145/3025453.3025494</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025494&ftid=1870706&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow532" style="display:inline;"><br /><div style="display:inline">With the fast development of virtual reality games, one of the key research questions is how players may express their creativity and participate in the process of game design. In this paper, we present a new game genre which combines user-controlled ...</div></span>
          <span id="toHide532" style="display:none;"><br /><div style="display:inline"><p>With the fast development of virtual reality games, one of the key research questions is how players may express their creativity and participate in the process of game design. In this paper, we present a new game genre which combines user-controlled game design in physical space with game play in virtual space on a mobile device. The new system supports authoring by anyone, creating virtual reality games that can be easily modified or developed for physical space, and be used anywhere by novice end-users without any knowledge of tracking technology. We present the design and implementation of the system, as well as a user experiment. Findings illustrate that the proposed system promotes participation and provides a richer, more interactive and engaging experience.</p></div></span> <a id="expcoll532" href="JavaScript: expandcollapse('expcoll532',532)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3026020&CFID=758305256&CFTOKEN=14863114">The UX of Avatar Customization</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Victoria McArthur 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5029-5033</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3026020" title="DOI">10.1145/3025453.3026020</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3026020&ftid=1870672&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow533" style="display:inline;"><br /><div style="display:inline">Avatar customization is a feature that is offered in many computer and video games. Customization options are presented to users via Character Creation Interfaces or CCIs. CCIs differ greatly between games, independent of genre, with regard to the quantity ...</div></span>
          <span id="toHide533" style="display:none;"><br /><div style="display:inline"><p>Avatar customization is a feature that is offered in many computer and video games. Customization options are presented to users via Character Creation Interfaces or CCIs. CCIs differ greatly between games, independent of genre, with regard to the quantity and quality of customization options available. In addition, the way in which these options are presented to users differs from game to game. Research on avatar customization is typically focused on user-avatar identity or self-representation. In general, we have found that the User Experience (UX) of avatar customization has been greatly overlooked in academic literature. As such, we look to existing research on UX in order to propose how its methodologies may be used to study the impact of CCI affordances on player experience in games.</p></div></span> <a id="expcoll533" href="JavaScript: expandcollapse('expcoll533',533)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025997&CFID=758305256&CFTOKEN=14863114">To Three or not to Three: Improving Human Computation Game Onboarding with a Three-Star System</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Jacqueline Gaston, Seth Cooper 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5034-5039</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025997" title="DOI">10.1145/3025453.3025997</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025997&ftid=1870681&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow534" style="display:inline;"><br /><div style="display:inline">While many popular casual games use three-star systems, which give players up to three stars based on their performance in a level, this technique has seen limited application in human computation games (HCGs). This gives rise to the question of what ...</div></span>
          <span id="toHide534" style="display:none;"><br /><div style="display:inline"><p>While many popular casual games use three-star systems, which give players up to three stars based on their performance in a level, this technique has seen limited application in human computation games (HCGs). This gives rise to the question of what impact, if any, a three-star system will have on the behavior of players in HCGs. In this work, we examined the impact of a three-star system implemented in the protein folding HCG Foldit. We compared the basic game's introductory levels with two versions using a three-star system, where players were rewarded with more stars for completing levels in fewer moves. In one version, players could continue playing levels for as many moves as they liked, and in the other, players were forced to reset the level if they used more moves than required to achieve at least one star on the level. We observed that the three-star system encouraged players to use fewer moves, take more time per move, and replay completed levels more often. We did not observe an impact on retention. This indicates that three-star systems may be useful for re-enforcing concepts introduced by HCG levels, or as a flexible means to encourage desired behaviors.</p></div></span> <a id="expcoll534" href="JavaScript: expandcollapse('expcoll534',534)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Design Frameworks</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
  
                  <img src="images/bp_award.jpg" alt="Best Paper" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025765&CFID=758305256&CFTOKEN=14863114">What Is Interaction?</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Kasper Hornb&#230;k, Antti Oulasvirta 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5040-5052</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025765" title="DOI">10.1145/3025453.3025765</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025765&ftid=1870719&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow536" style="display:inline;"><br /><div style="display:inline">The term interaction is field-defining, yet surprisingly confused. This essay discusses what interaction is. We first argue that only few attempts to directly define interaction exist. Nevertheless, we extract from the literature distinct and ...</div></span>
          <span id="toHide536" style="display:none;"><br /><div style="display:inline"><p>The term <i>interaction</i> is field-defining, yet surprisingly confused. This essay discusses what interaction is. We first argue that only few attempts to directly define interaction exist. Nevertheless, we extract from the literature distinct and highly developed concepts, for instance viewing interaction as dialogue, transmission, optimal behavior, embodiment, and tool use. Importantly, these concepts are associated with different scopes and ways of construing the causal relationships between the human and the computer. This affects their ability to inform empirical studies and design. Based on this discussion, we list desiderata for future work on interaction, emphasizing the need to improve scope and specificity, to better account for the effects and agency that computers have in interaction, and to generate strong propositions about interaction.</p></div></span> <a id="expcoll536" href="JavaScript: expandcollapse('expcoll536',536)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025718&CFID=758305256&CFTOKEN=14863114">Beyond Grids: Interactive Graphical Substrates to Structure Digital Layout</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Nolwenn Maudet, Ghita Jalal, Philip Tchernavskij, Michel Beaudouin-Lafon, Wendy E. Mackay 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5053-5064</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025718" title="DOI">10.1145/3025453.3025718</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025718&ftid=1870715&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow537" style="display:inline;"><br /><div style="display:inline">Traditional graphic design tools emphasize the grid for structuring layout. Interviews with professional graphic designers revealed that they use surprisingly sophisticated structures that go beyond the grid, which we call graphical substrates. ...</div></span>
          <span id="toHide537" style="display:none;"><br /><div style="display:inline"><p>Traditional graphic design tools emphasize the grid for structuring layout. Interviews with professional graphic designers revealed that they use surprisingly sophisticated structures that go beyond the grid, which we call <i>graphical substrates</i>. We present a framework to describe how designers establish graphical substrates based on properties extracted from concepts, content and context, and use them to compose layouts in both space and time. We developed two technology probes to explore how to embed graphical substrates into tools. <i>Contextify</i> lets designers tailor layouts according to each reader's intention and context; while <i>Linkify</i> lets designers create dynamic layouts based on relationships among content properties. We tested the probes with professional graphic designers, who all identified novel uses in their current projects. We incorporated their suggestions into <i>StyleBlocks</i>, a prototype that reifies CSS declarations into interactive graphical substrates. Graphical substrates offer an untapped design space for tools that can help graphic designers generate personal layout structures.</p></div></span> <a id="expcoll537" href="JavaScript: expandcollapse('expcoll537',537)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025933&CFID=758305256&CFTOKEN=14863114">Expressive Fused Deposition Modeling by Controlling Extruder Height and Extrusion Amount</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Haruki Takahashi, Homei Miyashita 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5065-5074</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025933" title="DOI">10.1145/3025453.3025933</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025933&ftid=1870711&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow538" style="display:inline;"><br /><div style="display:inline">Fused deposition modeling (FDM) 3D printers form objects by stacking layers having a linear structure. To print fine structures, an appropriate choice of parameters is necessary, or printing error occurs. On the other hand, the printing error is exploited ...</div></span>
          <span id="toHide538" style="display:none;"><br /><div style="display:inline"><p>Fused deposition modeling (FDM) 3D printers form objects by stacking layers having a linear structure. To print fine structures, an appropriate choice of parameters is necessary, or printing error occurs. On the other hand, the printing error is exploited as an expression technique. However, the relation between the printed structure and the parameters causing the printing error is unclear. In this paper, we focus on the height position of the extruder and the amount of extruded material, and explore the combination of these parameters to enhance the capability of FDM. By extending an equation that calculates the amount of material from the layer height, we investigate the behavior and structure of material extruded from various height positions. On the basis of experimental results, the printed structure is classified into six categories according to the structural feature. We describe these structural features and demonstrate examples with new inherent expressions for FDM.</p></div></span> <a id="expcoll538" href="JavaScript: expandcollapse('expcoll538',538)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025988&CFID=758305256&CFTOKEN=14863114">shiftIO: Reconfigurable Tactile Elements for Dynamic Affordances and Mobile Interaction</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Evan Strasnick, Jackie Yang, Kesler Tanner, Alex Olwal, Sean Follmer 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5075-5086</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025988" title="DOI">10.1145/3025453.3025988</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025988&ftid=1870698&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow539" style="display:inline;"><br /><div style="display:inline">Currently, virtual (i.e. touchscreen) controls are dynamic, but lack the advantageous tactile feedback of physical controls. Similarly, devices may also have dedicated physical controls, but they lack the flexibility to adapt for different contexts and ...</div></span>
          <span id="toHide539" style="display:none;"><br /><div style="display:inline"><p>Currently, virtual (i.e. touchscreen) controls are dynamic, but lack the advantageous tactile feedback of physical controls. Similarly, devices may also have dedicated physical controls, but they lack the flexibility to adapt for different contexts and applications. On mobile and wearable devices in particular, space constraints further limit our input and output capabilities. We propose utilizing reconfigurable tactile elements around the edge of a mobile device to enable dynamic physical controls and feedback. These tactile elements can be used for physical touch input and output, and can reposition according to the application both around the edge of and hidden within the device. We present shiftIO, two implementations of such a system which actuate physical controls around the edge of a mobile device using magnetic locomotion. One version utilizes PCB-manufactured electromagnetic coils, and the other uses switchable permanent magnets. We perform a technical evaluation of these prototypes and compare their advantages in various applications. Finally, we demonstrate several mobile applications which leverage shiftIO to create novel mobile interactions.</p></div></span> <a id="expcoll539" href="JavaScript: expandcollapse('expcoll539',539)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Difficulty and Challenge in Games</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3026047&CFID=758305256&CFTOKEN=14863114">A Good Reason to Die: How Avatar Death and High Challenges Enable Positive Experiences</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Serge Petralito, Florian Br&#252;hlmann, Glena Iten, Elisa D. Mekler, Klaus Opwis 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5087-5097</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3026047" title="DOI">10.1145/3025453.3026047</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3026047&ftid=1870720&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow541" style="display:inline;"><br /><div style="display:inline">Appropriate challenges and challenge-skill balance are usually key to positive player experiences. However, some games such as the successful series Dark Souls are notorious for their excessive difficulty. Yet, there has been little empirical investigation ...</div></span>
          <span id="toHide541" style="display:none;"><br /><div style="display:inline"><p>Appropriate challenges and challenge-skill balance are usually key to positive player experiences. However, some games such as the successful series Dark Souls are notorious for their excessive difficulty. Yet, there has been little empirical investigation of why players enjoy games they constantly struggle and fail with. We surveyed 95 participants right after the release of Dark Souls III about their experiences with the game, employing both open questions and different player experience measures. Players generally enjoyed challenging play sessions and mostly reported positive experiences, with achievement and learning moments strongly contributing to positive experiences. However, these factors themselves were enabled by negative events such as difficulties and avatar death. Our findings showcase that negative events bear a potential for forming positive and meaningful experiences, thus expanding previous knowledge about the role of challenge and failing in games. Moreover, the significance of hard-earned achievements extends present design conventions.</p></div></span> <a id="expcoll541" href="JavaScript: expandcollapse('expcoll541',541)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3026043&CFID=758305256&CFTOKEN=14863114">How Human Am I?: EEG-based Evaluation of Virtual Characters</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Maryam Mustafa, Stefan Guthe, Jan-Philipp Tauscher, Michael Goesele, Marcus Magnor 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5098-5108</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3026043" title="DOI">10.1145/3025453.3026043</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3026043&ftid=1870704&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow542" style="display:inline;"><br /><div style="display:inline">There is a continuous effort by animation experts to create increasingly realistic and more human-like digital characters. However, as virtual characters become more human they risk evoking a sense of unease in their audience. This sensation, called ...</div></span>
          <span id="toHide542" style="display:none;"><br /><div style="display:inline"><p>There is a continuous effort by animation experts to create increasingly realistic and more human-like digital characters. However, as virtual characters become more human they risk evoking a sense of unease in their audience. This sensation, called the Uncanny Valley effect, is widely acknowledged both in the popular media and scientific research but empirical evidence for the hypothesis has remained inconsistent. In this paper, we investigate the neural responses to computer-generated faces in a cognitive neuroscience study. We record brain activity from participants (N = 40)} using electroencephalography (EEG) while they watch videos of real humans and computer-generated virtual characters. Our results show distinct differences in neural responses for highly realistic computer-generated faces such as Digital Emily compared with real humans. These differences are unique only to agents that are highly photorealistic, i.e. the `uncanny' response. Based on these specific neural correlates we train a support vector machine~(SVM) to measure the probability of an uncanny response for any given computer-generated character from EEG data. This allows the ordering of animated characters based on their level of `uncanniness'.</p></div></span> <a id="expcoll542" href="JavaScript: expandcollapse('expcoll542',542)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025697&CFID=758305256&CFTOKEN=14863114">Testing Incremental Difficulty Design in Platformer Games</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Rina R. Wehbe, Elisa D. Mekler, Mike Schaekermann, Edward Lank, Lennart E. Nacke 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5109-5113</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025697" title="DOI">10.1145/3025453.3025697</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025697&ftid=1870688&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow543" style="display:inline;"><br /><div style="display:inline">Designing difficulty levels in platformer games is a challenge for game designers. It is important because design decisions that affect difficulty also directly affect player experience. Consequently, design strategies for balancing game difficulty are ...</div></span>
          <span id="toHide543" style="display:none;"><br /><div style="display:inline"><p>Designing difficulty levels in platformer games is a challenge for game designers. It is important because design decisions that affect difficulty also directly affect player experience. Consequently, design strategies for balancing game difficulty are discussed by both academics and game designers. In this paper, we study how manipulating the following design decisions, commonly found in platformers, moderates difficulty: Scroll Speed, Target Size, Jump Task Complexity, and Perspective. Results for Scroll Speed and Target Size indicate that errors increase as speed increases and platform size decreases. However, results for jump task complexity demonstrate a separation of errors from task complexity. Specifically, while double-jump tasks are harder than single-jump tasks, triple-jump tasks appear to be as difficult as double-jump tasks. Additionally, the study demonstrates how changes in perspective affect the errors made by players in gameplay. The study results are applicable both to automatic level generation and dynamic difficulty adjustment in platformer games.</p></div></span> <a id="expcoll543" href="JavaScript: expandcollapse('expcoll543',543)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025669&CFID=758305256&CFTOKEN=14863114">EngageMeter: A System for Implicit Audience Engagement Sensing Using Electroencephalography</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Mariam Hassib, Stefan Schneegass, Philipp Eiglsperger, Niels Henze, Albrecht Schmidt, Florian Alt 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5114-5119</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025669" title="DOI">10.1145/3025453.3025669</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025669&ftid=1870668&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow544" style="display:inline;"><br /><div style="display:inline">Obtaining information about audience engagement in presentations is a valuable asset for presenters in many domains. Prior literature mostly utilized explicit methods of collecting feedback which induce distractions, add workload on audience and do not ...</div></span>
          <span id="toHide544" style="display:none;"><br /><div style="display:inline"><p>Obtaining information about audience engagement in presentations is a valuable asset for presenters in many domains. Prior literature mostly utilized explicit methods of collecting feedback which induce distractions, add workload on audience and do not provide objective information to presenters. We present EngageMeter - a system that allows fine-grained information on audience engagement to be obtained implicitly from multiple brain-computer interfaces (BCI) and to be fed back to presenters for real time and post-hoc access. Through evaluation during an HCI conference (N<sub><i>audience</i></sub>=11, N<sub><i>presenters</i></sub>=3) we found that EngageMeter provides value to presenters (a) in real-time, since it allows reacting to current engagement scores by changing tone or adding pauses, and (b) in post-hoc, since presenters can adjust their slides and embed extra elements. We discuss how EngageMeter can be used in collocated and distributed audience sensing as well as how it can aid presenters in long term use.</p></div></span> <a id="expcoll544" href="JavaScript: expandcollapse('expcoll544',544)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3026037&CFID=758305256&CFTOKEN=14863114">Can I Think of Something Else when Using a BCI?: Cognitive Demand of an SSVEP-based BCI</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          And&#233;ol Evain, Ferran Argelaguet, Nicolas Roussel, G&#233;ry Casiez, Anatole L&#233;cuyer 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5120-5125</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3026037" title="DOI">10.1145/3025453.3026037</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3026037&ftid=1870693&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow545" style="display:inline;"><br /><div style="display:inline">BCIs are presumably supposed to require the full attention of their users and to lose accuracy if they pay attention to another task. This assertion has been verified with several BCI paradigms (e.g. P300). But the cognitive demand of the promising SSVEP ...</div></span>
          <span id="toHide545" style="display:none;"><br /><div style="display:inline"><p>BCIs are presumably supposed to require the full attention of their users and to lose accuracy if they pay attention to another task. This assertion has been verified with several BCI paradigms (e.g. P300). But the cognitive demand of the promising SSVEP paradigm had never been specifically assessed yet. We measured the accuracy of an SSVEP-based BCI used by 26 participants in various conditions of mental workload. Our analysis revealed that surprisingly, for this type of BCI, little attention is actually needed from participants to reach optimal accuracy: participants were able to successfully perform a complex secondary task (N-back) without degrading the BCI accuracy. The same observation was made whether visual or auditive attention was solicited. These results indicate that SSVEP is a low-demanding paradigm in terms of cognitive resources, and are encouraging for its use in complex interaction settings.</p></div></span> <a id="expcoll545" href="JavaScript: expandcollapse('expcoll545',545)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025721&CFID=758305256&CFTOKEN=14863114">"Not another Z piece!": Adaptive Difficulty in TETRIS</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Katharina Spiel, Sven Bertel, Fares Kayali 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5126-5131</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025721" title="DOI">10.1145/3025453.3025721</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025721&ftid=1870682&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow546" style="display:inline;"><br /><div style="display:inline">Difficulty in TETRIS is adjusted by adapting the speed with which blocks fall. In this contribution, we describe results of an exploratory study in which we investigated relationships between players' performance and their subjective assessment of difficulty ...</div></span>
          <span id="toHide546" style="display:none;"><br /><div style="display:inline"><p>Difficulty in TETRIS is adjusted by adapting the speed with which blocks fall. In this contribution, we describe results of an exploratory study in which we investigated relationships between players' performance and their subjective assessment of difficulty and fun. We tested five different algorithms that, instead of adjusting game speed, adjust difficulty by choosing blocks based on the current game state. With our results, we establish pile height and bumpiness as parameters that indicate the performance of a player during a live game, discuss the inherent difficulty of different block choosing algorithms and show how the relationship between fun and perceived difficulty varies for distinct player groups. With regard to adapting difficulty, we argue that one can still teach an old dog such a TETRIS a lot of new tricks.</p></div></span> <a id="expcoll546" href="JavaScript: expandcollapse('expcoll546',546)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Embodied Interaction</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025955&CFID=758305256&CFTOKEN=14863114">The World-as-Support: Embodied Exploration, Understanding and Meaning-Making of the Augmented World</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Laura Malinverni, Julian Maya, Marie-Monique Schaper, Narcis Pares 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5132-5144</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025955" title="DOI">10.1145/3025453.3025955</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025955&ftid=1870713&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow548" style="display:inline;"><br /><div style="display:inline">Current technical capabilities of mobile technologies are consolidating the interest in developing context-aware Augmented/Mixed Reality applications. Most of these applications are designed based on the Window-on-the-World (WoW) interaction paradigm. ...</div></span>
          <span id="toHide548" style="display:none;"><br /><div style="display:inline"><p>Current technical capabilities of mobile technologies are consolidating the interest in developing context-aware Augmented/Mixed Reality applications. Most of these applications are designed based on the Window-on-the-World (WoW) interaction paradigm. A significant decrease in cost of projection technology and advances in pico-sized projectors have spurred applications of Projective Augmented Reality. This research has focused mainly on technological development. However, there is still a need to fully understand its communicational and expressive potential. Hence, we define a conceptual paradigm that we call World-as-Support (WaS). We compare the WaS and WoW paradigms by contrasting their assumptions and cultural values, as well as through a study of an application aimed at supporting the collaborative improvisation of site-specific narratives by children. Our analysis of children's understanding of the physical and social environment and of their imaginative play allowed us to identify the affordances, strengths and weaknesses of these two paradigms.</p></div></span> <a id="expcoll548" href="JavaScript: expandcollapse('expcoll548',548)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025689&CFID=758305256&CFTOKEN=14863114">Extending the Body for Interaction with Reality</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Tiare Feuchtner, J&#246;rg M&#252;eller 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5145-5157</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025689" title="DOI">10.1145/3025453.3025689</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025689&ftid=1870707&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow549" style="display:inline;"><br /><div style="display:inline">In this paper, we explore how users can control remote devices with a virtual long arm, while preserving the perception that the artificial arm is actually part of their own body. Instead of using pointing, speech, or a remote control, the users' arm ...</div></span>
          <span id="toHide549" style="display:none;"><br /><div style="display:inline"><p>In this paper, we explore how users can control remote devices with a virtual long arm, while preserving the perception that the artificial arm is actually part of their own body. Instead of using pointing, speech, or a remote control, the users' arm is extended in augmented reality, allowing access to devices that are out of reach. Thus, we allow users to directly manipulate real-world objects from a distance using their bare hands. A core difficulty we focus on is how to maintain ownership for the unnaturally long virtual arm, which is the strong feeling that one's limbs are actually part of the own body. Fortunately, what the human brain experiences as being part of the own body is very malleable and we find that during interaction the user's virtual arm can be stretched to more than twice its real length, without breaking the user's sense of ownership for the virtual limb.</p></div></span> <a id="expcoll549" href="JavaScript: expandcollapse('expcoll549',549)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025873&CFID=758305256&CFTOKEN=14863114">Embodied Design Ideation Methods: Analysing the Power of Estrangement</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Danielle Wilde, Anna Vallg&#229;rda, Oscar Tomico 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5158-5170</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025873" title="DOI">10.1145/3025453.3025873</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025873&ftid=1870710&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow550" style="display:inline;"><br /><div style="display:inline">Embodied design ideation practices work with relationships between body, material and context to enliven design and research potential. Methods are often idiosyncratic and due to their physical nature not easily transferred. This presents challenges ...</div></span>
          <span id="toHide550" style="display:none;"><br /><div style="display:inline"><p><i>Embodied design ideation</i> practices work with relationships between body, material and context to enliven design and research potential. Methods are often idiosyncratic and due to their physical nature not easily transferred. This presents challenges for designers wishing to develop and share techniques or contribute to research. We present a framework that enables designers to understand, describe and contextualise their embodied design ideation practices in ways that can be understood by peers, as well as those new to embodied ideation. Our framework developed over two conference workshops provides a frame for discussion of embodied design actions that leverage the power of estrangement. We apply our framework to eight embodied design ideation methods. Our contribution is thus twofold: (1) a framework to understand and leverage the power of estrangement in embodied design ideation, and (2) an inspirational catalogue demonstrating the diversity of ideas that embodied design ideation methods can foster.</p></div></span> <a id="expcoll550" href="JavaScript: expandcollapse('expcoll550',550)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025714&CFID=758305256&CFTOKEN=14863114">Designing for Kinesthetic Awareness: Revealing User Experiences through Second-Person Inquiry</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Jules Fran&#231;oise, Yves Candau, Sarah Fdili Alaoui, Thecla Schiphorst 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5171-5183</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025714" title="DOI">10.1145/3025453.3025714</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025714&ftid=1870708&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow551" style="display:inline;"><br /><div style="display:inline">We consider kinesthetic awareness, the perception of our own body position and movement in space, as a critical value for embodied design within third wave HCI. We designed an interactive sound installation that supports kinesthetic awareness of a participant's ...</div></span>
          <span id="toHide551" style="display:none;"><br /><div style="display:inline"><p>We consider kinesthetic awareness, the perception of our own body position and movement in space, as a critical value for embodied design within third wave HCI. We designed an interactive sound installation that supports kinesthetic awareness of a participant's micro-movements. The installation's interaction design uses continuous auditory feedback and leverages an adaptive mapping strategy, refining its sensitivity to increase sonic resolution at lower levels of movement activity. The installation uses field recordings as rich source materials to generate a sound environment that attunes to a participant's micro-movements. Through a qualitative study using a second-person interview technique, we gained nuanced insights into the participants' subjective experiences of the installation. These reveal consistent temporal patterns, as participants build on a gradual process of integration to increase the complexity and capacity of their kinesthetic awareness during interaction.</p></div></span> <a id="expcoll551" href="JavaScript: expandcollapse('expcoll551',551)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Emerging Privacy</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025482&CFID=758305256&CFTOKEN=14863114">Chameleon Devices: Investigating More Secure and Discreet Mobile Interactions via Active Camouflaging</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Jennifer Pearson, Simon Robinson, Matt Jones, Anirudha Joshi, Shashank Ahire, Deepak Sahoo, Sriram Subramanian 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5184-5196</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025482" title="DOI">10.1145/3025453.3025482</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025482&ftid=1870717&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow553" style="display:inline;"><br /><div style="display:inline">Many users value the ability to have quick and frequent sight of their mobiles when in public settings. However, in doing so, they expose themselves to potential risks, ranging from being targets of robbery to the more subtle social losses through being ...</div></span>
          <span id="toHide553" style="display:none;"><br /><div style="display:inline"><p>Many users value the ability to have quick and frequent sight of their mobiles when in public settings. However, in doing so, they expose themselves to potential risks, ranging from being targets of robbery to the more subtle social losses through being seen to be rude or inattentive to those around them. In nature, some animals can blend into their environments to avoid being eaten or to reduce their impact on the ecosystem around them. Taking inspiration from these evolved systems we investigate the notion of chameleon approaches for mobile interaction design. Our probes were motivated, inspired and refined through extended interactions with people drawn from contexts with differing ranges of security and privacy concerns. Through deployments on users' own devices, our prototypes show the value of the concept. The encouraging results motivate further research in materials and form factors that can provide more effective automatic plain-sight hiding.</p></div></span> <a id="expcoll553" href="JavaScript: expandcollapse('expcoll553',553)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025735&CFID=758305256&CFTOKEN=14863114">Toys that Listen: A Study of Parents, Children, and Internet-Connected Toys</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Emily McReynolds, Sarah Hubbard, Timothy Lau, Aditya Saraf, Maya Cakmak, Franziska Roesner 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5197-5207</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025735" title="DOI">10.1145/3025453.3025735</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025735&ftid=1870700&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow554" style="display:inline;"><br /><div style="display:inline">Hello Barbie, CogniToys Dino, and Amazon Echo are part of a new wave of connected toys and gadgets for the home that listen. Unlike the smartphone, these devices are always on, blending into the background until needed. We conducted interviews with parent-child ...</div></span>
          <span id="toHide554" style="display:none;"><br /><div style="display:inline"><p>Hello Barbie, CogniToys Dino, and Amazon Echo are part of a new wave of connected toys and gadgets for the home that listen. Unlike the smartphone, these devices are always on, blending into the background until needed. We conducted interviews with parent-child pairs in which they interacted with Hello Barbie and CogniToys Dino, shedding light on children's expectations of the toys' "intelligence'" and parents' privacy concerns and expectations for parental controls. We find that children were often unaware that others might be able to hear what was said to the toy, and that some parents draw connections between the toys and similar tools not intended as toys (e.g., Siri, Alexa) with which their children already interact. Our findings illuminate people's mental models and experiences with these emerging technologies and will help inform the future designs of interactive, connected toys and gadgets. We conclude with recommendations for parents, designers, and policy makers.</p></div></span> <a id="expcoll554" href="JavaScript: expandcollapse('expcoll554',554)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025556&CFID=758305256&CFTOKEN=14863114">Better the Devil You Know: Exposing the Data Sharing Practices of Smartphone Apps</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Max Van Kleek, Ilaria Liccardi, Reuben Binns, Jun Zhao, Daniel J. Weitzner, Nigel Shadbolt 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5208-5220</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025556" title="DOI">10.1145/3025453.3025556</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025556&ftid=1870673&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow555" style="display:inline;"><br /><div style="display:inline">Most users of smartphone apps remain unaware of what data about them is being collected, by whom, and how these data are being used. In this mixed methods investigation, we examine the question of whether revealing key data collection practices of smartphone ...</div></span>
          <span id="toHide555" style="display:none;"><br /><div style="display:inline"><p>Most users of smartphone apps remain unaware of what data about them is being collected, by whom, and how these data are being used. In this mixed methods investigation, we examine the question of whether revealing key data collection practices of smartphone apps may help people make more informed privacy-related decisions. To investigate this question, we designed and prototyped a new class of privacy indicators, called Data Controller Indicators (DCIs), that expose previously hidden information flows out of the apps. Our lab study of DCIs suggests that such indicators do support people in making more confident and consistent choices, informed by a more diverse range of factors, including the number and nature of third-party companies that access users' data. Furthermore, personalised DCIs, which are contextualised against the other apps an individual already uses, enable them to reason effectively about the differential impacts on their overall information exposure.</p></div></span> <a id="expcoll555" href="JavaScript: expandcollapse('expcoll555',555)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025587&CFID=758305256&CFTOKEN=14863114">Parents? and Children?s Preferences about Parents Sharing about Children on Social Media</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Carol Moser, Tianying Chen, Sarita Y. Schoenebeck 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5221-5225</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025587" title="DOI">10.1145/3025453.3025587</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025587&ftid=1870674&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow556" style="display:inline;"><br /><div style="display:inline">Prior research shows that parents receive a number of benefits through sharing about their children online, but little is known about children?s perspectives about parent sharing. We conducted a survey with 331 parent-child pairs to examine parents? ...</div></span>
          <span id="toHide556" style="display:none;"><br /><div style="display:inline"><p>Prior research shows that parents receive a number of benefits through sharing about their children online, but little is known about children?s perspectives about parent sharing. We conducted a survey with 331 parent-child pairs to examine parents? and children?s preferences about what parents share about their children on social media. We find that parents and children are in agreement in their perception of how often and how much information parents share about their children on social media. However, there is disagreement about the permission-seeking process: children believe their parents should ask permission more than parents think they should, and parents believe they should ask for permission more often than they actually do, especially younger parents. We describe two categories of content that children are okay, or not okay, with their parents sharing about them. We offer design directions for managing parent sharing.</p></div></span> <a id="expcoll556" href="JavaScript: expandcollapse('expcoll556',556)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025986&CFID=758305256&CFTOKEN=14863114">Challenges of using Personal Data to Drive Personalised Electronic Programme Guides</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Neelima Sailaja, Andy Crabtree, Phil Stenton 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5226-5231</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025986" title="DOI">10.1145/3025453.3025986</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025986&ftid=1870701&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow557" style="display:inline;"><br /><div style="display:inline">Media researchers are adopting personalisation in diverse ways to deliver increasingly context-sensitive and customised media experiences. This paper explores user attitudes towards a personalised Electronic Programme Guide which tailors media recommendations ...</div></span>
          <span id="toHide557" style="display:none;"><br /><div style="display:inline"><p>Media researchers are adopting personalisation in diverse ways to deliver increasingly context-sensitive and customised media experiences. This paper explores user attitudes towards a personalised Electronic Programme Guide which tailors media recommendations based on users' personal data. We used scenario based exploration enabled by the use of probes to convey the functionalities of data-driven personalised EPGs and to facilitate user discussions around its potential use. Users preferred personalised EPGs over current popular EPGs but expressed a significant lack of trust in the personal data collection that drives personalisation. Users appreciated the functionalities afforded by personalisation of media but were apprehensive about the implications of the personal data being collected about them, particularly in the context of their homes. This calls for the need to design future personalised media experiences that help enhance trust in these socio-technical settings.</p></div></span> <a id="expcoll557" href="JavaScript: expandcollapse('expcoll557',557)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Family Health</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025651&CFID=758305256&CFTOKEN=14863114">Reflective Informatics Through Family Storytelling: Self-discovering Physical Activity Predictors</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Herman Saksono, Andrea G. Parker 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5232-5244</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025651" title="DOI">10.1145/3025453.3025651</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025651&ftid=1870714&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow559" style="display:inline;"><br /><div style="display:inline">HCI research has increasingly examined how sensing technologies can help people capture and visualize data about their health-related behaviors. Yet, few systems help people reflect more fundamentally on the factors that influence behaviors such as physical ...</div></span>
          <span id="toHide559" style="display:none;"><br /><div style="display:inline"><p>HCI research has increasingly examined how sensing technologies can help people capture and visualize data about their health-related behaviors. Yet, few systems help people reflect more fundamentally on the factors that influence behaviors such as physical activity (PA). To address this research gap, we take a novel approach, examining how such reflections can be stimulated through a medium that generations of families have used for reflection and teaching: storytelling. Through observations and interviews, we studied how 13 families interacted with a low-fidelity prototype, and their attitudes towards this tool. Our prototype used storytelling and interactive prompts to scaffold reflection on factors that impact children's PA. We contribute to HCI research by characterizing how families interacted with a story-driven reflection tool, and how such a tool can encourage critical processes for behavior change. Informed by the Transtheoretical Model, we present design implications for reflective informatics systems.</p></div></span> <a id="expcoll559" href="JavaScript: expandcollapse('expcoll559',559)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025754&CFID=758305256&CFTOKEN=14863114">Supporting Families in Reviewing and Communicating about Radiology Imaging Studies</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Matthew K. Hong, Clayton Feustel, Meeshu Agnihotri, Max Silverman, Stephen F. Simoneaux, Lauren Wilcox 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5245-5256</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025754" title="DOI">10.1145/3025453.3025754</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025754&ftid=1870716&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow560" style="display:inline;"><br /><div style="display:inline">Diagnostic radiology reports are increasingly being made available to patients and their family members. However, these reports are not typically comprehensible to lay recipients, impeding effective communication about report findings. In this paper, ...</div></span>
          <span id="toHide560" style="display:none;"><br /><div style="display:inline"><p>Diagnostic radiology reports are increasingly being made available to patients and their family members. However, these reports are not typically comprehensible to lay recipients, impeding effective communication about report findings. In this paper, we present three studies informing the design of a prototype to foster patient-clinician communication about radiology report content. First, analysis of questions posted in online health forums helped us identify patients' information needs. Findings from an elicitation study with seven radiologists provided necessary domain knowledge to guide prototype design. Finally, a clinical field study with 14 pediatric patients, their parents and clinicians, revealed positive responses of each stakeholder when using the prototype to interact with and discuss the patient's current CT or MRI report and allowed us to distill three use cases: co-located communication, preparing for the consultation, and reviewing radiology data. We draw on our findings to discuss design considerations for supporting each of these use cases.</p></div></span> <a id="expcoll560" href="JavaScript: expandcollapse('expcoll560',560)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025923&CFID=758305256&CFTOKEN=14863114">How Values Shape Collaboration Between Patients with Multiple Chronic Conditions and Spousal Caregivers</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Andrew B. L. Berry, Catherine Lim, Andrea L. Hartzler, Tad Hirsch, Edward H. Wagner, Evette Ludman, James D. Ralston 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5257-5270</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025923" title="DOI">10.1145/3025453.3025923</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025923&ftid=1870685&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow561" style="display:inline;"><br /><div style="display:inline">Individuals with multiple chronic conditions (MCC) collaborate with spousal caregivers daily to pursue what is most important to their health and well-being. Previous research in human-computer interaction has supported individuals with chronic conditions ...</div></span>
          <span id="toHide561" style="display:none;"><br /><div style="display:inline"><p>Individuals with multiple chronic conditions (MCC) collaborate with spousal caregivers daily to pursue what is most important to their health and well-being. Previous research in human-computer interaction has supported individuals with chronic conditions or their caregivers, but little has supported both as a unit. We conducted a field study with 12 patient-caregiver dyads, all married and living together, to identify partners' values and how they shape collaborative management of MCC. Partners' coinciding values motivated them to empathize with and support each other in the face of challenges related to health and well-being. When their values were asymmetric, they perceived tensions between individual autonomy and their ability to coordinate with their partner. Systems to support partners in this context could help them overcome asymmetric values, but should balance this with support for individual autonomy.</p></div></span> <a id="expcoll561" href="JavaScript: expandcollapse('expcoll561',561)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Improving Video Communication</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025548&CFID=758305256&CFTOKEN=14863114">Through the Looking Glass: The Effects of Feedback on Self-Awareness and Conversational Behaviour during Video Chat</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Matthew K. Miller, Regan L. Mandryk, Max V. Birk, Ansgar E. Depping, Tushita Patel 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5271-5283</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025548" title="DOI">10.1145/3025453.3025548</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025548&ftid=1870703&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow563" style="display:inline;"><br /><div style="display:inline">Video chat is a popular form of computer-mediated communication in a range of contexts from online job interviews to chatting with friends. Although seeing your own video feedback is the predominant interface design, self-awareness research suggests ...</div></span>
          <span id="toHide563" style="display:none;"><br /><div style="display:inline"><p>Video chat is a popular form of computer-mediated communication in a range of contexts from online job interviews to chatting with friends. Although seeing your own video feedback is the predominant interface design, self-awareness research suggests that seeing oneself could induce self-consciousness and affect interaction. We created a custom video chat application and asked pairs of strangers to engage in an online personal information exchange task with or without video feedback. Feedback increased self-awareness and the use of socially-focused words, and decreased the use of words expressing certainty. In addition, mixed-gender dyads rated themselves as more socially orientated with feedback than without, which was reflected in an increased use of inclusive pronouns and affiliation words, and fewer words expressing discrepancy. However, with feedback, same-gender dyads reported greater task orientation than mixed-gender dyads reflected in increased use of task-relevant words. We discuss design implications in contexts from remote therapy to online dating.</p></div></span> <a id="expcoll563" href="JavaScript: expandcollapse('expcoll563',563)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025641&CFID=758305256&CFTOKEN=14863114">Gestures From the Point of View of an Audience: Towards Anticipatable Interaction of Presenters With 3D Content.</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Andrey Krekhov, Katharina Emmerich, Maxim Babinski, Jens Kr&#252;ger 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5284-5294</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025641" title="DOI">10.1145/3025453.3025641</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025641&ftid=1870724&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow564" style="display:inline;"><br /><div style="display:inline">Presenting content to an audience is important in several fields, including education, marketing, and entertainment. Therefore, the main goal of the presenter is to transport messages to the audience. The paper aims to improve the process of message ...</div></span>
          <span id="toHide564" style="display:none;"><br /><div style="display:inline"><p>Presenting content to an audience is important in several fields, including education, marketing, and entertainment. Therefore, the main goal of the presenter is to transport messages to the audience.</p> <p>The paper aims to improve the process of message transportation by providing audience-friendly and anticipatable gestures for the presenter to be used for 3D interaction with the content. For this purpose, we first gathered input from a potential audience through a Wizard of Oz experiment and implemented three coherent gesture sets using the Kinect. We conducted an online survey to evaluate the hypotheses regarding the anticipation rate and perceived user experience. In particular, two of our three gesture sets show tendencies to be intuitively predictable by an untrained, uninformed audience. As the three sets differ significantly in the anticipation level, we conclude that future improvements of such gestures would enhance the audience's ability to predict the intended actions even further.</p></div></span> <a id="expcoll564" href="JavaScript: expandcollapse('expcoll564',564)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025848&CFID=758305256&CFTOKEN=14863114">Showing Objects: Holding and Manipulating Artefacts in Video-mediated Collaborative Settings</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Christian Licoppe, Paul K. Luff, Christian Heath, Hideaki Kuzuoka, Naomi Yamashita, Sylvaine Tuncer 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5295-5306</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025848" title="DOI">10.1145/3025453.3025848</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025848&ftid=1870691&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow565" style="display:inline;"><br /><div style="display:inline">In this paper we report on a pervasive practice in video-mediated communication: where participants show one another one or more objects. This is a distinct activity from others considered by researchers of video-mediated technologies that focus on a ...</div></span>
          <span id="toHide565" style="display:none;"><br /><div style="display:inline"><p>In this paper we report on a pervasive practice in video-mediated communication: where participants show one another one or more objects. This is a distinct activity from others considered by researchers of video-mediated technologies that focus on a face-to-face orientation, or just on the support necessary to help people to refer to objects. We first present examples of this pervasive phenomenon in naturally occurring Skype conversations, revealing how this conduct is configured and organized within the interaction between participants. We reveal how the subtle adjustment of the position of the body, the head and gaze with respect to the handheld objects offers crucial resources for participants to achieve joint seeing. Then we report on a quite different setting, a naturalistic experiment where participants collaborate on a collective task with remote colleagues through maneuverable, orientable devices (Kubis). Again, in these experiments participants frequently show objects, and at times the devices provide additional resources to support these activities. But at other times they also involve some difficulties. We conclude by suggesting possible technological developments, some quite simple, others more radical, that might support participants to show objects, whether they are in domestic settings or undertaking work activities.</p></div></span> <a id="expcoll565" href="JavaScript: expandcollapse('expcoll565',565)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025681&CFID=758305256&CFTOKEN=14863114">ThirdEye: Simple Add-on Display to Represent Remote Participant's Gaze Direction in Video Communication</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Mai Otsuki, Taiki Kawano, Keita Maruyama, Hideaki Kuzuoka, Yusuke Suzuki 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5307-5312</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025681" title="DOI">10.1145/3025453.3025681</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025681&ftid=1870675&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow566" style="display:inline;"><br /><div style="display:inline">A long-standing challenge in video-mediated communication systems is to represent a remote participant's gaze direction in local environments correctly. To address this issue, we developed ThirdEye, an add-on eye-display for a video communication system. ...</div></span>
          <span id="toHide566" style="display:none;"><br /><div style="display:inline"><p>A long-standing challenge in video-mediated communication systems is to represent a remote participant's gaze direction in local environments correctly. To address this issue, we developed ThirdEye, an add-on eye-display for a video communication system. This display is made from an artificial ulexite (TV rock) that is cut into a hemispherical shape, enabling light from the bottom surface to be projected onto the hemisphere surface. By drawing an appropriate ellipse on an LCD and placing ThirdEye over it, this system simulates an eyeball. Our experiment proved that an observer could perceive a remote Looker's gaze direction more precisely when the gaze was presented using ThirdEye compared to the case in which the gaze was presented using the Looker's face on a flat display.</p></div></span> <a id="expcoll566" href="JavaScript: expandcollapse('expcoll566',566)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025574&CFID=758305256&CFTOKEN=14863114">FaceShare: Mirroring with Pseudo-Smile Enriches Video Chat Communications</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Keita Suzuki, Masanori Yokoyama, Shigeo Yoshida, Takayoshi Mochizuki, Tomohiro Yamada, Takuji Narumi, Tomohiro Tanikawa, Michitaka Hirose 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5313-5317</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025574" title="DOI">10.1145/3025453.3025574</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025574&ftid=1870677&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow567" style="display:inline;"><br /><div style="display:inline">"Mirroring" refers to the unconscious mimicry of another person's behaviors, such as their facial expressions. Mirroring has many positive effects, such as enhancing closeness and improving the flow of a conversation, which enriches the quality of communication. ...</div></span>
          <span id="toHide567" style="display:none;"><br /><div style="display:inline"><p>"Mirroring" refers to the unconscious mimicry of another person's behaviors, such as their facial expressions. Mirroring has many positive effects, such as enhancing closeness and improving the flow of a conversation, which enriches the quality of communication. Our study set out to devise a means of evoking these positive effects in a video chat without any conscious effort of participants. We constructed a videophone system, called <i>FaceShare</i>, which can deform the user's face into a smile in response to their partner's smiling. That is, our system generates mirroring by producing a pseudo-smile through image processing. We conducted an experiment in which pairs of participants had brief conversations via <i>FaceShare</i>. The results implied that mirroring using the pseudo-smile lets the mimicker, whose face is deformed according to the expressions of their partner, feel a closeness, and improves the flow of the conversation for both the mimicker and the mimickee, who sees the mimicker's deformed face.</p></div></span> <a id="expcoll567" href="JavaScript: expandcollapse('expcoll567',567)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Online and On-the-go</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025526&CFID=758305256&CFTOKEN=14863114">Squeezeback: Pneumatic Compression for Notifications</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Henning Pohl, Peter Brandes, Hung Ngo Quang, Michael Rohs 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5318-5330</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025526" title="DOI">10.1145/3025453.3025526</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025526&ftid=1870664&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow569" style="display:inline;"><br /><div style="display:inline">Current mobile devices commonly use vibration feedback to signal incoming notifications. However, vibration feedback exhibits strong attention capture, limiting its use to short periods and prominent notifications. Instead, we investigate the use of ...</div></span>
          <span id="toHide569" style="display:none;"><br /><div style="display:inline"><p>Current mobile devices commonly use vibration feedback to signal incoming notifications. However, vibration feedback exhibits strong attention capture, limiting its use to short periods and prominent notifications. Instead, we investigate the use of <i>compression feedback</i> for notifications, which scales from subtle stimuli to strong ones and can provide sustained stimuli over longer periods. Compression feedback utilizes inflatable straps around a user's limbs, a form factor allowing for easy integration into many common wearables. We explore technical aspects of compression feedback and investigate its psychophysical properties with several lab and in situ studies. Furthermore, we show how compression feedback enables <i>reactive</i> feedback. Here, deflation patterns are used to reveal further information on a user's query. We also compare compression and vibrotactile feedback and find that they have similar performance.</p></div></span> <a id="expcoll569" href="JavaScript: expandcollapse('expcoll569',569)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025568&CFID=758305256&CFTOKEN=14863114">Cito: An Actuated Smartwatch for Extended Interactions</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Jun Gong, Lan Li, Daniel Vogel, Xing-Dong Yang 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5331-5345</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025568" title="DOI">10.1145/3025453.3025568</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025568&ftid=1870676&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow570" style="display:inline;"><br /><div style="display:inline">We propose and explore actuating a smartwatch face to enable extended interactions. Five face movements are defined: rotation, hinging, translation, rising, and orbiting. These movements are incorporated into interaction techniques to address limitations ...</div></span>
          <span id="toHide570" style="display:none;"><br /><div style="display:inline"><p>We propose and explore actuating a smartwatch face to enable extended interactions. Five face movements are defined: rotation, hinging, translation, rising, and orbiting. These movements are incorporated into interaction techniques to address limitations of a fixed watch face. A 20-person study uses concept videos of a passive low fidelity prototype to confirm the usefulness of the actuated interaction techniques. A second 20-person study uses 3D rendered animations to access social acceptability and perceived comfort for different actuation dynamics and usage contexts. Finally, we present Cito, a high-fidelity proof-of-concept hardware prototype that investigates technical challenges.</p></div></span> <a id="expcoll570" href="JavaScript: expandcollapse('expcoll570',570)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025946&CFID=758305256&CFTOKEN=14863114">How Busy Are You?: Predicting the Interruptibility Intensity of Mobile Users</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Fengpeng Yuan, Xianyi Gao, Janne Lindqvist 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5346-5360</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025946" title="DOI">10.1145/3025453.3025946</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025946&ftid=1870665&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow571" style="display:inline;"><br /><div style="display:inline">Smartphones frequently notify users about newly available messages or other notifications. It can be very disruptive when these notifications interrupt users while they are busy. Our work here is based on the observation that people usually exhibit different ...</div></span>
          <span id="toHide571" style="display:none;"><br /><div style="display:inline"><p>Smartphones frequently notify users about newly available messages or other notifications. It can be very disruptive when these notifications interrupt users while they are busy. Our work here is based on the observation that people usually exhibit different levels of busyness at different contexts. This means that classifying users' interruptibility as a binary status, interruptible or not interruptible, is not sufficient to accurately measure their availability towards smartphone interruptions. In this paper, we propose, implement and evaluate a two-stage hierarchical model to predict people's interruptibility intensity. Our work is the first to introduce personality traits into interruptibility prediction model, and we found that personality data improves the prediction significantly. Our model bootstraps the prediction with similar people's data, and provides a good initial prediction for users whose individual models have not been trained on their own data yet. Overall prediction accuracy of our model can reach 66.1%.</p></div></span> <a id="expcoll571" href="JavaScript: expandcollapse('expcoll571',571)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025730&CFID=758305256&CFTOKEN=14863114">Demand Around the Clock: Time Use and Data Demand of Mobile Devices in Everyday Life</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Kelly Widdicks, Oliver Bates, Mike Hazas, Adrian Friday, Alastair R. Beresford 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5361-5372</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025730" title="DOI">10.1145/3025453.3025730</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025730&ftid=1870683&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow572" style="display:inline;"><br /><div style="display:inline">Motivated by mobile devices' growing demand for connectivity, and concern in HCI with the energy intensity and sustainability of networked services, in this paper we reveal the impact of applications on smartphones and tablets in terms of network demand ...</div></span>
          <span id="toHide572" style="display:none;"><br /><div style="display:inline"><p>Motivated by mobile devices' growing demand for connectivity, and concern in HCI with the energy intensity and sustainability of networked services, in this paper we reveal the impact of applications on smartphones and tablets in terms of network demand and time use. Using a detailed mixed methods study with eight participants, we first provide an account of how data demand has meaning and utility in our participants' social practices, and the timing and relative impacts of these. We then assess the scale of this demand by drawing comparison between our fine-grained observations and a more representative dataset of 398 devices from the Device Analyzer corpus. Our results highlight the significant categories of data demanding practice, and the identification of where changes in app time and duration of use might reduce or shift demand to reduce services' impacts.</p></div></span> <a id="expcoll572" href="JavaScript: expandcollapse('expcoll572',572)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Speculation &#38; Storytelling</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3026051&CFID=758305256&CFTOKEN=14863114">Reworking the Gaps between Design and Ethnography</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Vera Khovanskaya, Phoebe Sengers, Melissa Mazmanian, Charles Darrah 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5373-5385</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3026051" title="DOI">10.1145/3025453.3026051</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3026051&ftid=1870678&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow574" style="display:inline;"><br /><div style="display:inline">Since Dourish's critique of 'implications for design' [15], researchers have asked how design and ethnography should or could relate in HCI. Here we reflect on two experiences with cross-informing ongoing ethnographic investigation with the early stages ...</div></span>
          <span id="toHide574" style="display:none;"><br /><div style="display:inline"><p>Since Dourish's critique of 'implications for design' [15], researchers have asked how design and ethnography should or could relate in HCI. Here we reflect on two experiences with cross-informing ongoing ethnographic investigation with the early stages of research through design. One uses speculative design to reflect on and inform ethnographic fieldwork on busyness in middle-class familes; the other uses speculative design to complement late-stage analysis of a historical ethnography of rural technological infrastructure. Rather than trying to do away with the gap between ethnography and design by seamlessly integrating the two processes, we reworked the relationship between ethnography and design by closing the gap in the temporal workflows while simultaneously maintaining a distinction in the performance of the two roles. We found that this new gap resulted in a series of misunderstandings; but by putting the two roles in active dialogue, we were able leverage misunderstandings into mutual benefit.</p></div></span> <a id="expcoll574" href="JavaScript: expandcollapse('expcoll574',574)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025503&CFID=758305256&CFTOKEN=14863114">On Speculative Enactments</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Chris Elsden, David Chatting, Abigail C. Durrant, Andrew Garbett, Bettina Nissen, John Vines, David S. Kirk 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5386-5399</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025503" title="DOI">10.1145/3025453.3025503</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025503&ftid=1870709&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow575" style="display:inline;"><br /><div style="display:inline">Speculative Enactments are a novel approach to speculative design research with participants. They invite the empirical analysis of participants acting amidst speculative but consequential circumstances. HCI as a broadly pragmatic, experience-centered, ...</div></span>
          <span id="toHide575" style="display:none;"><br /><div style="display:inline"><p>Speculative Enactments are a novel approach to speculative design research with participants. They invite the empirical analysis of participants acting amidst speculative but consequential circumstances. HCI as a broadly pragmatic, experience-centered, and participant-focused field is well placed to innovate methods that invite first-hand interaction and experience with speculative design projects. We discuss three case studies of this approach in practice, based on our own work: Runner Spotters, Metadating and a Quantified Wedding. In distinguishing Speculative Enactments we offer not just practical guidelines, but a set of conceptual resources for researchers and practitioners to critique the different contributions that speculative approaches make to HCI discourse.</p></div></span> <a id="expcoll575" href="JavaScript: expandcollapse('expcoll575',575)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3026023&CFID=758305256&CFTOKEN=14863114">Research Fiction: Storytelling, Plot and Design</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Mark Blythe 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5400-5411</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3026023" title="DOI">10.1145/3025453.3026023</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3026023&ftid=1870694&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow576" style="display:inline;"><br /><div style="display:inline">What kind of stories and plots do researchers of Human Computer Interaction draw on when they make fictions? This paper applies the "basic plots" identified in the study of literature to scenarios, speculative design and design fiction. Traditional HCI ...</div></span>
          <span id="toHide576" style="display:none;"><br /><div style="display:inline"><p>What kind of stories and plots do researchers of Human Computer Interaction draw on when they make fictions? This paper applies the "basic plots" identified in the study of literature to scenarios, speculative design and design fiction. Traditional HCI scenarios employ the plot of "Overcoming the Monster" where the monster is some problem to be solved. Much of the commentary on critical, speculative or adversarial design also draws on this plot as it attempts to overcome monsters like public apathy or a lack of debate. Design Fiction more frequently takes the form of a "Voyage and Return" or a "Quest". The paper argues that a better understanding of plot and storytelling could contribute to more reflective research fiction.</p></div></span> <a id="expcoll576" href="JavaScript: expandcollapse('expcoll576',576)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025766&CFID=758305256&CFTOKEN=14863114">Intersectional HCI: Engaging Identity through Gender, Race, and Class</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Ari Schlesinger, W. Keith Edwards, Rebecca E. Grinter 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5412-5427</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025766" title="DOI">10.1145/3025453.3025766</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025766&ftid=1870679&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow577" style="display:inline;"><br /><div style="display:inline">Understanding users becomes increasingly complicated when we grapple with various overlapping attributes of an individual's identity. In this paper we introduce intersectionality as a framework for engaging with the complexity of users' "and authors" ...</div></span>
          <span id="toHide577" style="display:none;"><br /><div style="display:inline"><p>Understanding users becomes increasingly complicated when we grapple with various overlapping attributes of an individual's identity. In this paper we introduce intersectionality as a framework for engaging with the complexity of users' "and authors" "identities", and situating these identities in relation to their contextual surroundings. We conducted a meta-review of identity representation in the CHI proceedings, collecting a corpus of 140 manuscripts on gender, ethnicity, race, class, and sexuality published between 1982-2016. Drawing on this corpus, we analyze how identity is constructed and represented in CHI research to examine intersectionality in a human-computer interaction (HCI) context. We find that previous identity-focused research tends to analyze one facet of identity at a time. Further, research on ethnicity and race lags behind research on gender and socio-economic class. We conclude this paper with recommendations for incorporating intersectionality in HCI research broadly, encouraging clear reporting of context and demographic information, inclusion of author disclosures, and deeper engagement with identity complexities.</p></div></span> <a id="expcoll577" href="JavaScript: expandcollapse('expcoll577',577)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Virtual Reality</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025675&CFID=758305256&CFTOKEN=14863114">Vremiere: In-Headset Virtual Reality Video Editing</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Cuong Nguyen, Stephen DiVerdi, Aaron Hertzmann, Feng Liu 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5428-5438</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025675" title="DOI">10.1145/3025453.3025675</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025675&ftid=1870684&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow579" style="display:inline;"><br /><div style="display:inline">Creative professionals are creating Virtual Reality (VR) experiences today by capturing spherical videos, but video editing is still done primarily in traditional 2D desktop GUI applications such as Premiere. These interfaces provide limited capabilities ...</div></span>
          <span id="toHide579" style="display:none;"><br /><div style="display:inline"><p>Creative professionals are creating Virtual Reality (VR) experiences today by capturing spherical videos, but video editing is still done primarily in traditional 2D desktop GUI applications such as Premiere. These interfaces provide limited capabilities for previewing content in a VR headset or for directly manipulating the spherical video in an intuitive way. As a result, editors must alternate between editing on the desktop and previewing in the headset, which is tedious and interrupts the creative process. We demonstrate an application that enables a user to directly edit spherical video while fully immersed in a VR headset. We first interviewed professional VR filmmakers to understand current practice and derived a suitable workflow for in-headset VR video editing. We then developed a prototype system implementing this new workflow. Our system is built upon a familiar timeline design, but is enhanced with custom widgets to enable intuitive editing of spherical video inside the headset. We conducted an expert review study and found that with our prototype, experts were able to edit videos entirely within the headset. Experts also found our interface and widgets useful, providing intuitive controls for their editing needs.</p></div></span> <a id="expcoll579" href="JavaScript: expandcollapse('expcoll579',579)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025762&CFID=758305256&CFTOKEN=14863114">"They're Just Tixel Pits, Man": Disputing the 'Reality' of Virtual Reality Pornography through the Story Completion Method</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Matthew Wood, Gavin Wood, Madeline Balaam 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5439-5451</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025762" title="DOI">10.1145/3025453.3025762</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025762&ftid=1870667&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow580" style="display:inline;"><br /><div style="display:inline">Pornography is a substantial part of humans' everyday interaction with computers, yet to date the topic has been underconsidered by HCI. Here, we examine some of the common cultural ideals non-experts constructed of a "new" pornographic experience - ...</div></span>
          <span id="toHide580" style="display:none;"><br /><div style="display:inline"><p>Pornography is a substantial part of humans' everyday interaction with computers, yet to date the topic has been underconsidered by HCI. Here, we examine some of the common cultural ideals non-experts constructed of a "new" pornographic experience - Virtual Reality (VR) Porn - through use of the "Story Completion Method". Forty five participants completed a story stem about a male character who was about to have his "very first virtual reality porn experience". Through our analysis, we demonstrate a narrative of a "perfect", idealised sexual experience, as well as one which emphasised the imagined "precarious" and dangerous consequences around this technology use. We indicate how the stories reproduced ideals around heteronormativity and hegemonic masculinity, suggesting an agenda of "Designing for Eroticism" as a tactic which could avoid such problematic discourses. We also suggest the opportunities and challenges presented through use of the "Story Completion Method".</p></div></span> <a id="expcoll580" href="JavaScript: expandcollapse('expcoll580',580)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025824&CFID=758305256&CFTOKEN=14863114">ThermoVR: Exploring Integrated Thermal Haptic Feedback with Head Mounted Displays</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Roshan Lalintha Peiris, Wei Peng, Zikun Chen, Liwei Chan, Kouta Minamizawa 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5452-5456</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025824" title="DOI">10.1145/3025453.3025824</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025824&ftid=1870699&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow581" style="display:inline;"><br /><div style="display:inline">Head Mounted Displays (HMDs) provide a promising opportunity for providing haptic feedback on the head for an enhanced immersive experience. In ThermoVR, we integrated five thermal feedback modules on the HMD to provide thermal feedback directly onto ...</div></span>
          <span id="toHide581" style="display:none;"><br /><div style="display:inline"><p>Head Mounted Displays (HMDs) provide a promising opportunity for providing haptic feedback on the head for an enhanced immersive experience. In ThermoVR, we integrated five thermal feedback modules on the HMD to provide thermal feedback directly onto the user's face. We conducted evaluations with 15 participants using two approaches: Firstly, we provided simultaneously actuated thermal stimulations (hot and cold) as directional cues and evaluated the accuracy of recognition; secondly, we evaluated the overall immersive thermal experience that the users experience when provided with thermal feedback on the face. Results indicated that the recognition accuracy for cold stimuli were of approx. 89.5% accuracy while the accuracy for hot stimuli were 68.6%. Also, participants reported that they felt a higher level of immersion on the face when all modules were simultaneously stimulated (hot and cold). The presented applications demonstrate the ThermoVR's directional cueing and immersive experience.</p></div></span> <a id="expcoll581" href="JavaScript: expandcollapse('expcoll581',581)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025783&CFID=758305256&CFTOKEN=14863114">Efficient Typing on a Visually Occluded Physical Keyboard</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          James Walker, Bochao Li, Keith Vertanen, Scott Kuhl 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5457-5461</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025783" title="DOI">10.1145/3025453.3025783</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025783&ftid=1870702&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow582" style="display:inline;"><br /><div style="display:inline">The rise of affordable head-mounted displays (HMDs) has raised questions about how to best design user interfaces for this technology. This paper focuses on the use of HMDs for home and office applications that require substantial text input. A physical ...</div></span>
          <span id="toHide582" style="display:none;"><br /><div style="display:inline"><p>The rise of affordable head-mounted displays (HMDs) has raised questions about how to best design user interfaces for this technology. This paper focuses on the use of HMDs for home and office applications that require substantial text input. A physical keyboard is a familiar and effective text input device in normal desktop computing. But without additional camera technology, an HMD occludes all visual feedback about a user's hand position over the keyboard. We describe a system that assists HMD users in typing on a physical keyboard. Our system has a virtual keyboard assistant that provides visual feedback inside the HMD about a user's actions on the physical keyboard. It also provides powerful automatic correction of typing errors by extending a state-of-the-art touchscreen decoder. In a study with 24 participants, we found our virtual keyboard assistant enabled users to type more accurately on a visually-occluded keyboard. We found users wearing an HMD could type at over 40 words-per-minute while obtaining an error rate of less than 5%.</p></div></span> <a id="expcoll582" href="JavaScript: expandcollapse('expcoll582',582)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Visualization for the People</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025512&CFID=758305256&CFTOKEN=14863114">Showing People Behind Data: Does Anthropomorphizing Visualizations Elicit More Empathy for Human Rights Data?</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Jeremy Boy, Anshul Vikram Pandey, John Emerson, Margaret Satterthwaite, Oded Nov, Enrico Bertini 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5462-5474</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025512" title="DOI">10.1145/3025453.3025512</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025512&ftid=1870680&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow584" style="display:inline;"><br /><div style="display:inline">We investigate the impact of using anthropomorphized data graphics over standard charts on viewers' empathy for, and prosocial behavior toward suffering populations, in the context of human rights narratives. We present a series of experiments conducted ...</div></span>
          <span id="toHide584" style="display:none;"><br /><div style="display:inline"><p>We investigate the impact of using anthropomorphized data graphics over standard charts on viewers' empathy for, and prosocial behavior toward suffering populations, in the context of human rights narratives. We present a series of experiments conducted on Amazon Mechanical Turk, in which we compare various forms of anthropomorphized data graphics-ranging from a single human figure that "fills up" to show proportional data, to separated groups of individual human beings-with a standard chart baseline. Each experiment uses two carefully crafted human rights data-driven stories to present the graphics. Contrary to our expectations, we consistently find that anthropomorphized data graphics and standard charts have very similar effects on empathy and prosocial behavior.</p></div></span> <a id="expcoll584" href="JavaScript: expandcollapse('expcoll584',584)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025870&CFID=758305256&CFTOKEN=14863114">Narratives in Crowdsourced Evaluation of Visualizations: A Double-Edged Sword?</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Evanthia Dimara, Anastasia Bezerianos, Pierre Dragicevic 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5475-5484</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025870" title="DOI">10.1145/3025453.3025870</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025870&ftid=1870692&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow585" style="display:inline;"><br /><div style="display:inline">We explore the effects of providing task context when evaluating visualization tools using crowdsourcing. We gave crowdsource workers i) abstract information visualization tasks without any context, ii) tasks where we added semantics to the dataset, ...</div></span>
          <span id="toHide585" style="display:none;"><br /><div style="display:inline"><p>We explore the effects of providing task context when evaluating visualization tools using crowdsourcing. We gave crowdsource workers i) abstract information visualization tasks without any context, ii) tasks where we added semantics to the dataset, and iii) tasks with two types of backstory narratives: an analytic narrative and a decision-making narrative. Contrary to our expectations, we did not find evidence that adding data semantics increases accuracy, and further found that our backstory narratives can even decrease accuracy. Adding dataset semantics can however increase attention and provide subjective benefits in terms of confidence, perceived easiness, task enjoyability and perceived usefulness of the visualization. Nevertheless, our backstory narratives did not appear to provide additional subjective benefits. These preliminary findings suggest that narratives may have complex and unanticipated effects, calling for more studies in this area.</p></div></span> <a id="expcoll585" href="JavaScript: expandcollapse('expcoll585',585)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025877&CFID=758305256&CFTOKEN=14863114">Visualization Literacy at Elementary School</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Basak Alper, Nathalie Henry Riche, Fanny Chevalier, Jeremy Boy, Metin Sezgin 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5485-5497</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025877" title="DOI">10.1145/3025453.3025877</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025877&ftid=1870695&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow586" style="display:inline;"><br /><div style="display:inline">This work advances our understanding of children's visualization literacy, and aims to improve it through a novel approach for teaching visualization at elementary school. We first contribute an analysis of data graphics and activities employed in grade ...</div></span>
          <span id="toHide586" style="display:none;"><br /><div style="display:inline"><p>This work advances our understanding of children's visualization literacy, and aims to improve it through a novel approach for teaching visualization at elementary school. We first contribute an analysis of data graphics and activities employed in grade K to 4 educational materials, and the results of a survey conducted with 16 elementary school teachers. We find that visualization education could benefit from integrating pedagogical strategies for teaching abstract concepts with established interactive visualization techniques. Building on these insights, we develop and study design principles for novel interactive teaching material aimed at increasing children's visualization literacy. We specifically contribute C'est La Vis, an online platform for teachers and students to respectively teach and learn about pictographs and bar charts, and report on our initial observations of its use in grades K and 2.</p></div></span> <a id="expcoll586" href="JavaScript: expandcollapse('expcoll586',586)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025777&CFID=758305256&CFTOKEN=14863114">Finding Similar People to Guide Life Choices: Challenge, Design, and Evaluation</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Fan Du, Catherine Plaisant, Neil Spring, Ben Shneiderman 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5498-5544</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025777" title="DOI">10.1145/3025453.3025777</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025777&ftid=1870722&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow587" style="display:inline;"><br /><div style="display:inline">People often seek examples of similar individuals to guide their own life choices. For example, students making academic plans refer to friends; patients refer to acquaintances with similar conditions, physicians mention past cases seen in their practice. ...</div></span>
          <span id="toHide587" style="display:none;"><br /><div style="display:inline"><p>People often seek examples of similar individuals to guide their own life choices. For example, students making academic plans refer to friends; patients refer to acquaintances with similar conditions, physicians mention past cases seen in their practice. How would they want to search for similar people in databases? We discuss the challenge of finding similar people to guide life choices and report on a need analysis based on 13 interviews. Our PeerFinder prototype enables users to find records that are similar to a seed record, using both record attributes and temporal events found in the records. A user study with 18 participants and four experts shows that users are more engaged and more confident about the value of the results to provide useful evidence to guide life choices when provided with more control over the search process and more context for the results, even at the cost of added complexity.</p></div></span> <a id="expcoll587" href="JavaScript: expandcollapse('expcoll587',587)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Classroom Tools</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025564&CFID=758305256&CFTOKEN=14863114">Better Organization or a Source of Distraction?: Introducing Digital Peer Feedback to a Paper-Based Classroom</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Amy Shannon, Alex Sciuto, Danielle Hu, Steven P. Dow, Jessica Hammer 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5545-5555</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025564" title="DOI">10.1145/3025453.3025564</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025564&ftid=1870853&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow589" style="display:inline;"><br /><div style="display:inline">Peer feedback is a central activity for project-based design education. The prevalence of devices carried by students and the emergence of novel peer feedback systems enables the possibility of collecting and sharing feedback immediately between students ...</div></span>
          <span id="toHide589" style="display:none;"><br /><div style="display:inline"><p>Peer feedback is a central activity for project-based design education. The prevalence of devices carried by students and the emergence of novel peer feedback systems enables the possibility of collecting and sharing feedback immediately between students during class. However, pen and paper is thought to be more familiar, less distracting for students, and easier for instructors to implement and manage. To evaluate the efficacy of in-class digital feedback systems, we conducted a within-subjects study with 73 students during two weeks of a game design course. After short student presentations, while instructors provided verbal feedback, peers provided feedback either on paper or through a device. The study found that both methods yielded comments of similar quality and quantity, but the digital approach provided additional ways for students to participate and required less effort from the instructors. While both methods produced similar behaviors, students held inaccurate perceptions about their behavior with each method. We discuss design implications for technologies to support in-class feedback exchange.</p></div></span> <a id="expcoll589" href="JavaScript: expandcollapse('expcoll589',589)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025679&CFID=758305256&CFTOKEN=14863114">Group Spinner: Recognizing and Visualizing Learning in the Classroom for Reflection, Communication, and Planning</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Ahmed Kharrufa, Sally Rix, Timur Osadchiy, Anne Preston, Patrick Olivier 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5556-5567</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025679" title="DOI">10.1145/3025453.3025679</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025679&ftid=1870852&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow590" style="display:inline;"><br /><div style="display:inline">Group Spinner is a digital visual tool intended to help teachers observe and reflect on children's collaborative technology-enhanced learning activities in the classroom. We describe the design of Group Spinner, which was informed by activity theory, ...</div></span>
          <span id="toHide590" style="display:none;"><br /><div style="display:inline"><p>Group Spinner is a digital visual tool intended to help teachers observe and reflect on children's collaborative technology-enhanced learning activities in the classroom. We describe the design of Group Spinner, which was informed by activity theory, previous work and teachers' focus group feedback. Based on a radar chart and a set of indicators, Group Spinner allows teachers to record in-class observations as to different aspects of group learning and learning behaviors, beyond the limited knowledge acquisition measures. Our exploratory study involved 6 teachers who used the tool for a total of 23 classes in subjects ranging from Maths and Geography to Sociology and Art. Semi-structured interviews with these teachers revealed a number of different uses of the tool. Depending on their experience and pedagogy, teachers considered Group Spinner to be a valuable tool to support awareness, reflection, communication, and/or planning.</p></div></span> <a id="expcoll590" href="JavaScript: expandcollapse('expcoll590',590)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025779&CFID=758305256&CFTOKEN=14863114">ViVo: Video-Augmented Dictionary for Vocabulary Learning</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Yeshuang Zhu, Yuntao Wang, Chun Yu, Shaoyun Shi, Yankai Zhang, Shuang He, Peijun Zhao, Xiaojuan Ma, Yuanchun Shi 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5568-5579</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025779" title="DOI">10.1145/3025453.3025779</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025779&ftid=1870866&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow591" style="display:inline;"><br /><div style="display:inline">Research on Computer-Assisted Language Learning (CALL) has shown that the use of multimedia materials such as images and videos can facilitate interpretation and memorization of new words and phrases by providing richer cues than text alone. We present ...</div></span>
          <span id="toHide591" style="display:none;"><br /><div style="display:inline"><p>Research on Computer-Assisted Language Learning (CALL) has shown that the use of multimedia materials such as images and videos can facilitate interpretation and memorization of new words and phrases by providing richer cues than text alone. We present ViVo, a novel video-augmented dictionary that provides an inexpensive, convenient, and scalable way to exploit huge online video resources for vocabulary learning. ViVo automatically generates short video clips from existing movies with the target word highlighted in the subtitles. In particular, we apply a word sense disambiguation algorithm to identify the appropriate movie scenes with adequate contextual information for learning. We analyze the challenges and feasibility of this approach and describe our interaction design. A user study showed that learners were able to retain nearly 30% more new words with ViVo than with a standard bilingual dictionary days after learning. They preferred our video-augmented dictionary for its benefits in memorization and enjoyable learning experience.</p></div></span> <a id="expcoll591" href="JavaScript: expandcollapse('expcoll591',591)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025477&CFID=758305256&CFTOKEN=14863114">From in the Class or in the Wild?: Peers Provide Better Design Feedback Than External Crowds</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Helen Wauck, Yu-Chun (Grace) Yen, Wai-Tat Fu, Elizabeth Gerber, Steven P. Dow, Brian P. Bailey 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5580-5591</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025477" title="DOI">10.1145/3025453.3025477</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025477&ftid=1870885&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow592" style="display:inline;"><br /><div style="display:inline">As demand for design education increases, instructors are struggling to provide timely, personalized feedback for student projects. Gathering feedback from classroom peers and external crowds offer scalable approaches, but there is little evidence of ...</div></span>
          <span id="toHide592" style="display:none;"><br /><div style="display:inline"><p>As demand for design education increases, instructors are struggling to provide timely, personalized feedback for student projects. Gathering feedback from classroom peers and external crowds offer scalable approaches, but there is little evidence of how they compare. We report on a study in which students (n=127) created early- and late-stage prototypes as part of nine-week projects. At each stage, students received feedback from peers and external crowds: their own social networks, online communities, and a task market. We measured the quality, quantity and valence of the feedback and the actions taken on it, and categorized its content using a taxonomy of critique discourse. The study found that peers produced feedback that was of higher perceived quality, acted upon more, and longer compared to the crowds. However, crowd feedback was found to be a viable supplement to peer feedback and students preferred it for projects targeting specialized audiences. Feedback from all sources spanned only a subset of the critique categories. Instructors may fill this gap by further scaffolding feedback generation. The study contributes insights for how to best utilize different feedback sources in project-based courses.</p></div></span> <a id="expcoll592" href="JavaScript: expandcollapse('expcoll592',592)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Finger and Pen</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025554&CFID=758305256&CFTOKEN=14863114">Collection Objects: Enabling Fluid Formation and Manipulation of Aggregate Selections</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Haijun Xia, Bruno Araujo, Daniel Wigdor 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5592-5604</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025554" title="DOI">10.1145/3025453.3025554</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025554&ftid=1870905&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow594" style="display:inline;"><br /><div style="display:inline">Despite the long development of Graphical User Interfaces, working with multiple graphical objects remains a challenge, due to the difficulties of forming complex selections, ambiguities of operations, and tediousness of repetitively unselect-reselect ...</div></span>
          <span id="toHide594" style="display:none;"><br /><div style="display:inline"><p>Despite the long development of Graphical User Interfaces, working with multiple graphical objects remains a challenge, due to the difficulties of forming complex selections, ambiguities of operations, and tediousness of repetitively unselect-reselect or ungroup-regroup objects. Instead of tackling them as individual problems, we attribute it to the lack of system support to the general selection-action cycles. We propose Collection Objects to not only support a single fast selection-action cycle but also allow multiple cycles to be chained together into a fluid workflow. Collection Objects unifies selection, grouping, and manipulation of aggregate selections into a single object, with which selection can be composed with various techniques, modified for later actions, grouped with objects inside still directly accessible, and quasi-moded for less context switching. We implemented Collection Object in the context of a vector drawing application with simultaneous pen and touch input. Results of an expert evaluation show that Collection Objects holds considerable promises for fluid interaction with multiple objects.</p></div></span> <a id="expcoll594" href="JavaScript: expandcollapse('expcoll594',594)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025525&CFID=758305256&CFTOKEN=14863114">IllumiPaper: Illuminated Interactive Paper</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Konstantin Klamka, Raimund Dachselt 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5605-5618</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025525" title="DOI">10.1145/3025453.3025525</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025525&ftid=1870876&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow595" style="display:inline;"><br /><div style="display:inline">Due to their simplicity and flexibility, digital pen-and-paper solutions have a promising potential to become a part of our daily work. Unfortunately, they lack dynamic visual feedback and thereby restrain advanced digital functionalities. In this paper, ...</div></span>
          <span id="toHide595" style="display:none;"><br /><div style="display:inline"><p>Due to their simplicity and flexibility, digital pen-and-paper solutions have a promising potential to become a part of our daily work. Unfortunately, they lack dynamic visual feedback and thereby restrain advanced digital functionalities. In this paper, we investigate new forms of paper-integrated feedback, which build on emerging paper-based electronics and novel thin-film display technologies. Our approach focuses on illuminated elements, which are seamlessly integrated into standard paper. For that, we introduce an extended design space for paper-integrated illuminations. As a major contribution, we present a systematic feedback repertoire for real-world applications including feedback components for innovative paper interaction tasks in five categories. Furthermore, we contribute a fully-functional research platform including a paper-controller, digital pen and illuminated, digitally controlled papers that demonstrate the feasibility of our techniques. Finally, we report on six interviews, where experts rated our approach as intuitive and very usable for various applications, in particular educational ones.</p></div></span> <a id="expcoll595" href="JavaScript: expandcollapse('expcoll595',595)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025585&CFID=758305256&CFTOKEN=14863114">Does Practice Make Perfect?</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Elie Cattan, Am&#233;lie Rochet-Capellan, Pascal Perrier, Fran&#231;ois B&#233;rard 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5619-5629</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025585" title="DOI">10.1145/3025453.3025585</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025585&ftid=1870908&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow596" style="display:inline;"><br /><div style="display:inline">Touch latency has been shown to deteriorate users' performances at levels as low as 25 ms, but this was tested only in short experimental sessions. Real life usage of touchscreens covers much longer periods. It provides training which could lead to reduce ...</div></span>
          <span id="toHide596" style="display:none;"><br /><div style="display:inline"><p>Touch latency has been shown to deteriorate users' performances at levels as low as 25 ms, but this was tested only in short experimental sessions. Real life usage of touchscreens covers much longer periods. It provides training which could lead to reduce the impact of latency.</p> <p>We investigate users' ability to compensate for touch latency with training. Two groups of participants were trained on a tracking task during ten different days over two weeks with either high or low latency. The gap of performances between the two groups, observed at the beginning of the experiment, was reduced by 54 % after training. Users can thus compensate for latency, at least partially. These results nuance the negative effects of touch latency reported in previous work. They suggest that long-term studies could provide better insights on users' behaviors when dealing with touch latency.</p></div></span> <a id="expcoll596" href="JavaScript: expandcollapse('expcoll596',596)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025486&CFID=758305256&CFTOKEN=14863114">MarkPad: Augmenting Touchpads for Command Selection</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Bruno Fruchard, Eric Lecolinet, Olivier Chapuis 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5630-5642</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025486" title="DOI">10.1145/3025453.3025486</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025486&ftid=1870909&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow597" style="display:inline;"><br /><div style="display:inline">We present MarkPad, a novel interaction technique taking advantage of the touchpad. MarkPad allows creating a large number of size-dependent gestural shortcuts that can be spatially organized as desired by the user. It relies on the idea of using visual ...</div></span>
          <span id="toHide597" style="display:none;"><br /><div style="display:inline"><p>We present MarkPad, a novel interaction technique taking advantage of the touchpad. MarkPad allows creating a large number of size-dependent gestural shortcuts that can be spatially organized as desired by the user. It relies on the idea of using visual or tactile marks on the touchpad or a combination of them. Gestures start from a mark on the border and end on another mark anywhere. MarkPad does not conflict with standard interactions and provides a novice mode that acts as a rehearsal of the expert mode. A first study showed that an accuracy of 95% could be achieved for a dense configuration of tactile and/or visual marks allowing many gestures. Performance was 5% lower in a second study where the marks were only on the borders. A last study showed that borders are rarely used, even when the users are unaware of the technique. Finally, we present a working prototype and briefly report on how it was used by two users for a few months.</p></div></span> <a id="expcoll597" href="JavaScript: expandcollapse('expcoll597',597)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Interactions in Virtual Reality</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025474&CFID=758305256&CFTOKEN=14863114">Experimental Evaluation of Sketching on Surfaces in VR</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Rahul Arora, Rubaiat Habib Kazi, Fraser Anderson, Tovi Grossman, Karan Singh, George Fitzmaurice 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5643-5654</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025474" title="DOI">10.1145/3025453.3025474</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025474&ftid=1870907&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow599" style="display:inline;"><br /><div style="display:inline">Sketching in immersive 3D virtual reality (VR) environments has great potential for a variety of interactive 3D design applications. Precisely sketching the intended strokes in mid-air, however, can be a challenge. In this paper, we present a set of ...</div></span>
          <span id="toHide599" style="display:none;"><br /><div style="display:inline"><p>Sketching in immersive 3D virtual reality (VR) environments has great potential for a variety of interactive 3D design applications. Precisely sketching the intended strokes in mid-air, however, can be a challenge. In this paper, we present a set of controlled studies to analyze the factors affecting human ability to sketch freely in a 3D VR environment. In our first study, we directly compare traditional sketching on a physical surface to sketching in VR, with and without a physical surface to rest the stylus on. Our results indicate that the lack of a physical drawing surface is a major cause of inaccuracies in VR drawing, and that the effect is dependent on the orientation of the drawing surface. In a second experiment, we evaluate the extent to which visual guidance can compensate for the loss of sketching precision in VR. We found that while additional visual guidance improves positional accuracy, it can be detrimental to the aesthetic quality of strokes. We conclude by distilling our experimental findings into design guidelines for sketching tools in immersive 3D environments.</p></div></span> <a id="expcoll599" href="JavaScript: expandcollapse('expcoll599',599)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3026046&CFID=758305256&CFTOKEN=14863114">I Am The Passenger: How Visual Motion Cues Can Influence Sickness For In-Car VR</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Mark McGill, Alexander Ng, Stephen Brewster 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5655-5668</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3026046" title="DOI">10.1145/3025453.3026046</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3026046&ftid=1870859&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow600" style="display:inline;"><br /><div style="display:inline">This paper explores the use of VR Head Mounted Displays (HMDs) in-car and in-motion for the first time. Immersive HMDs are becoming everyday consumer items and, as they offer new possibilities for entertainment and productivity, people will want to use ...</div></span>
          <span id="toHide600" style="display:none;"><br /><div style="display:inline"><p>This paper explores the use of VR Head Mounted Displays (HMDs) in-car and in-motion for the first time. Immersive HMDs are becoming everyday consumer items and, as they offer new possibilities for entertainment and productivity, people will want to use them during travel in, for example, autonomous cars. However, their use is confounded by motion sickness caused in-part by the restricted visual perception of motion conflicting with physically perceived vehicle motion (accelerations/rotations detected by the vestibular system). Whilst VR HMDs restrict visual perception of motion, they could also render it virtually, potentially alleviating sensory conflict. To study this problem, we conducted the first on-road and in motion study to systematically investigate the effects of various visual presentations of the real-world motion of a car on the sickness and immersion of VR HMD wearing passengers. We established new baselines for VR in-car motion sickness, and found that there is no one best presentation with respect to balancing sickness and immersion. Instead, user preferences suggest different solutions are required for differently susceptible users to provide usable VR in-car. This work provides formative insights for VR designers and an entry point for further research into enabling use of VR HMDs, and the rich experiences they offer, when travelling.</p></div></span> <a id="expcoll600" href="JavaScript: expandcollapse('expcoll600',600)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3026009&CFID=758305256&CFTOKEN=14863114">VaiR: Simulating 3D Airflows in Virtual Reality</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Michael Rietzler, Katrin Plaumann, Taras Kr&#228;nzle, Marcel Erath, Alexander Stahl, Enrico Rukzio 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5669-5677</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3026009" title="DOI">10.1145/3025453.3026009</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3026009&ftid=1870867&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow601" style="display:inline;"><br /><div style="display:inline">The integration of multi-sensory stimuli, e.g. haptic airflow, in virtual reality (VR) has become an important topic of VR research and proved to enhance the feeling of presence. VaiR focuses on an accurate and realistic airflow simulation that goes ...</div></span>
          <span id="toHide601" style="display:none;"><br /><div style="display:inline"><p>The integration of multi-sensory stimuli, e.g. haptic airflow, in virtual reality (VR) has become an important topic of VR research and proved to enhance the feeling of presence. VaiR focuses on an accurate and realistic airflow simulation that goes far beyond wind. While previous works on the topic of airflow in VR are restricted to wind, while focusing on the feeling of presence, there is to the best of our knowledge no work considering the conceptual background or on the various application areas. Our pneumatic prototype emits short and long term flows with a minimum delay and is able to animate wind sources in 3D space around the user's head. To get insights on how airflow can be used in VR and how such a device should be designed, we arranged focus groups and discussed the topic. Based on the gathered knowledge, we developed a prototype which proved to increase presence, as well as enjoyment and realism, while not disturbing the VR experience.</p></div></span> <a id="expcoll601" href="JavaScript: expandcollapse('expcoll601',601)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Mobility and Navigation in Many Forms</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025535&CFID=758305256&CFTOKEN=14863114">Collaborative Map Making: A Reflexive Method for Understanding Matters of Concern in Design Research</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Hee Rin Lee, Selma &#352;abanovi&#263;, Sonya S. Kwak 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5678-5689</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025535" title="DOI">10.1145/3025453.3025535</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025535&ftid=1870896&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow603" style="display:inline;"><br /><div style="display:inline">HCI researchers investigating the politics of technology design have recently focused on how design practice can tackle "Matters of Concern" - complex social issues perceived and experienced in multiple ways. These researchers suggest design research ...</div></span>
          <span id="toHide603" style="display:none;"><br /><div style="display:inline"><p>HCI researchers investigating the politics of technology design have recently focused on how design practice can tackle "Matters of Concern" - complex social issues perceived and experienced in multiple ways. These researchers suggest design research can generate new networks of human and non-human actors to express and act on these issues. Prior studies, however, tend to restrict their networks within traditional boundaries (e.g. existing organizations, local communities) and categories (e.g. human/nonhuman binary) without examining their significance for participants. We suggest collaborative map making as a reflexive method for understanding current Matters of Concern from the perspectives of diverse actors, not just researchers. As case studies of the method's use, we present two studies of domestic computing technologies in the US and South Korea, which show how collaborative map making allows salient networks to expand beyond the individual actors in the home to local and global power issues outside of boundaries (e.g. physical house) and categories (e.g. private/public space) commonly recognized in HCI. Our methodology provides HCI researchers with a way to understand existing Matters of Concern, so they can position themselves to address and act on these issues.</p></div></span> <a id="expcoll603" href="JavaScript: expandcollapse('expcoll603',603)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025645&CFID=758305256&CFTOKEN=14863114">Toward Principles for the Design of Navigation Affordances in Code Editors: An Empirical Investigation</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Austin Z. Henley, Scott D. Fleming, Maria V. Luong 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5690-5702</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025645" title="DOI">10.1145/3025453.3025645</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025645&ftid=1870851&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow604" style="display:inline;"><br /><div style="display:inline">Design principles are a key tool for creators of interactive systems; however, a cohesive set of principles has yet to emerge for the design of code editors. In this paper, we conducted a between-subjects empirical study comparing the navigation behaviors ...</div></span>
          <span id="toHide604" style="display:none;"><br /><div style="display:inline"><p>Design principles are a key tool for creators of interactive systems; however, a cohesive set of principles has yet to emerge for the design of code editors. In this paper, we conducted a between-subjects empirical study comparing the navigation behaviors of 32 professional LabVIEW programmers using two different code-editor interfaces: the ubiquitous tabbed editor and the experimental Patchworks editor. Our analysis focused on how the programmers arranged and navigated among open information patches (i.e., code modules and program output). Key findings of our study included that Patchworks users made significantly fewer click actions per navigation, juxtaposed patches side by side significantly more, and exhibited significantly fewer navigation mistakes than tabbed-editor users. Based on these findings and more, we propose five general principles for the design of effective navigation affordances in code editors.</p></div></span> <a id="expcoll604" href="JavaScript: expandcollapse('expcoll604',604)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025976&CFID=758305256&CFTOKEN=14863114">Follow-My-Lead: Intuitive Indoor Path Creation and Navigation Using Interactive Videos</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Quentin Roy, Simon T. Perrault, Shengdong Zhao, Richard C. Davis, Anuroop Pattena Vaniyar, Velko Vechev, Youngki Lee, Archan Misra 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5703-5715</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025976" title="DOI">10.1145/3025453.3025976</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025976&ftid=1870860&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow605" style="display:inline;"><br /><div style="display:inline">We present Follow-My-Lead, an alternative indoor navigation technique that uses visual information recorded on an actual navigation path as a navigational guide. Its design revealed a trade-off between the fidelity of information provided to users and ...</div></span>
          <span id="toHide605" style="display:none;"><br /><div style="display:inline"><p>We present Follow-My-Lead, an alternative indoor navigation technique that uses visual information recorded on an actual navigation path as a navigational guide. Its design revealed a trade-off between the fidelity of information provided to users and their effort to acquire it. Our first experiment revealed that scrolling through a continuous image stream of the navigation path is highly informative, but it becomes tedious with constant use. Discrete image checkpoints require less effort, but can be confusing. A balance may be struck by adding fast video transitions between image checkpoints, but precise control is required to handle difficult situations. Authoring still image checkpoints is also difficult, and this inspired us to invent a new technique using video checkpoints. We conducted a second experiment on authoring and navigation performance and found video checkpoints plus fast video transitions to be better than both image checkpoints plus fast video transitions and traditional written instructions.</p></div></span> <a id="expcoll605" href="JavaScript: expandcollapse('expcoll605',605)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025672&CFID=758305256&CFTOKEN=14863114">Mobility in Later Life: Appropriation of an Integrated Transportation Platform</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Martin Stein, Johanna Meurer, Alexander Boden, Volker Wulf 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5716-5729</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025672" title="DOI">10.1145/3025453.3025672</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025672&ftid=1870902&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow606" style="display:inline;"><br /><div style="display:inline">We present the results of a design case study focusing on supporting the daily transportation of elderly in Germany. We conceptualized, developed and studied the appropriation of a transportation information system intended to ease switching between ...</div></span>
          <span id="toHide606" style="display:none;"><br /><div style="display:inline"><p>We present the results of a design case study focusing on supporting the daily transportation of elderly in Germany. We conceptualized, developed and studied the appropriation of a transportation information system intended to ease switching between different transportation modes. Based on a literature review and a context study with 21 interviews we explored routinized transport mode usage and barriers when switching between modes. Iteratively, we co-designed a transport platform accessible via a website, a mobile app, and an iTV app. We further looked at the appropriation of the platform into the daily lives of 19 persons. Studying the appropriation highlighted different factors that facilitate the adoption of alternative transport options. The factors included reducing uncertainty, complementing transport information with context information (e.g. weather) and providing informational access based on the user's preferences as well as fitting in with the situational needs (activity related).</p></div></span> <a id="expcoll606" href="JavaScript: expandcollapse('expcoll606',606)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Participant Design with Children</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025622&CFID=758305256&CFTOKEN=14863114">Gains from Participatory Design Team Membership as Perceived by Child Alumni and their Parents</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Brenna McNally, Matthew Louis Mauriello, Mona Leigh Guha, Allison Druin 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5730-5741</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025622" title="DOI">10.1145/3025453.3025622</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025622&ftid=1870891&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow608" style="display:inline;"><br /><div style="display:inline">The direct gains children perceive from their membership on Participatory Design (PD) teams are seldom the focus of research studies. Yet, how HCI practitioners choose to include children in PD methods may influence the value participants see in their ...</div></span>
          <span id="toHide608" style="display:none;"><br /><div style="display:inline"><p>The direct gains children perceive from their membership on Participatory Design (PD) teams are seldom the focus of research studies. Yet, how HCI practitioners choose to include children in PD methods may influence the value participants see in their participation, and thereafter the outcomes of PD processes. To understand what gains former child members of a PD team perceive from their participation we conducted a two-part study. In Study 1 we surveyed and interviewed child alumni of a PD team to determine gains that are perceived first-hand. In Study 2 we obtained a secondary perspective by surveying and interviewing parents of alumni. We report on the perceived gains to former participants that were identified and described in these two studies-including collaboration, communication, design process knowledge, and confidence. We reflect on our findings through discussions of the continued applicability of gains, new opportunities, and implications for PD practitioners and methods.</p></div></span> <a id="expcoll608" href="JavaScript: expandcollapse('expcoll608',608)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025787&CFID=758305256&CFTOKEN=14863114">Examining Adult-Child Interactions in Intergenerational Participatory Design</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Jason C. Yip, Kiley Sobel, Caroline Pitt, Kung Jin Lee, Sijin Chen, Kari Nasu, Laura R. Pina 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5742-5754</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025787" title="DOI">10.1145/3025453.3025787</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025787&ftid=1870893&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow609" style="display:inline;"><br /><div style="display:inline">Prior studies have focused on child interactions in participatory design (PD) with adults and children, but less is known about what specific adult-child interactions constitute a partnership. In this study, we unpack what constitutes an "equal partnership" ...</div></span>
          <span id="toHide609" style="display:none;"><br /><div style="display:inline"><p>Prior studies have focused on child interactions in participatory design (PD) with adults and children, but less is known about what specific adult-child interactions constitute a partnership. In this study, we unpack what constitutes an "equal partnership" in PD between adults and children. On the basis of prior literature, we created a new framework that examines the complementary roles between children and adults. Next, we analyzed a case study of a year-long intergenerational design team of children (ages 7-11) and adults. From this analysis, we determined that design partnerships are composed of four dimensions that span from unbalanced to balanced interactions: facilitation, relationship building, design-by-doing, and elaborating together. Finally, to demonstrate its utility, we analyzed two focal co-design sessions using our framework. Our analysis suggests that equal partnership in PD is not a single static interaction but a development over time of design interactions influenced by context, experience, and participants.</p></div></span> <a id="expcoll609" href="JavaScript: expandcollapse('expcoll609',609)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025851&CFID=758305256&CFTOKEN=14863114">Participatory Evaluation with Autistic Children</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Katharina Spiel, Laura Malinverni, Judith Good, Christopher Frauenberger 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5755-5766</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025851" title="DOI">10.1145/3025453.3025851</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025851&ftid=1870889&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow610" style="display:inline;"><br /><div style="display:inline">Participatory Design (PD) has become a standard methodology in HCI, however, the evaluation of the outcomes of participatory processes is often exclusively driven by researcher defined measures of success. Through our work with autistic children, who ...</div></span>
          <span id="toHide610" style="display:none;"><br /><div style="display:inline"><p>Participatory Design (PD) has become a standard methodology in HCI, however, the evaluation of the outcomes of participatory processes is often exclusively driven by researcher defined measures of success. Through our work with autistic children, who have radically different life worlds from our own, it became evident that their criteria for the success of a project are most likely also very different. In order to address the limitations of researcher defined and led evaluations in this context, we developed an approach for <i>participatory evaluation</i> called PEACE (Participatory Evaluation with Autistic ChildrEn). Using this approach, we were able to include autistic children in dedicated evaluation phases through the co-definition of goals and methods, joint processes of data gathering and the co-interpretation of results. We discuss three case studies in which we successfully applied our approach and conclude with a reflection on the novel insights created through participatory evaluation and researchers' roles in such a process.</p></div></span> <a id="expcoll610" href="JavaScript: expandcollapse('expcoll610',610)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025588&CFID=758305256&CFTOKEN=14863114">Co-Designing with Preschoolers Using Fictional Inquiry and Comicboarding</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Alexis Hiniker, Kiley Sobel, Bongshin Lee 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5767-5772</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025588" title="DOI">10.1145/3025453.3025588</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025588&ftid=1870886&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow611" style="display:inline;"><br /><div style="display:inline">In this case study, we describe a design workshop with 7 children age 4-6 using existing co-design techniques known to elicit design insights in older individuals. We found that our 5- and 6-year-old participants successfully generated design ideas using ...</div></span>
          <span id="toHide611" style="display:none;"><br /><div style="display:inline"><p>In this case study, we describe a design workshop with 7 children age 4-6 using existing co-design techniques known to elicit design insights in older individuals. We found that our 5- and 6-year-old participants successfully generated design ideas using these methods, while 4-year-olds were unable to use create solutions in a traditional format. How-ever, these younger children enthusiastically offered opportunities where, with methodological guidance, the research-er could have followed the child's lead and shifted the design question to one that was potentially more meaningful for the participant. We propose a future work to examine the effectiveness of giving these younger participants great-er authority in defining and scoping the problem space.</p></div></span> <a id="expcoll611" href="JavaScript: expandcollapse('expcoll611',611)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Patient-generated Data in the Clinic</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025549&CFID=758305256&CFTOKEN=14863114">Making Space for the Quality Care: Opportunities for Technology in Cognitive Behavioral Therapy for Insomnia</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Haining Zhu, Yuhan Luo, Eun Kyoung Choe 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5773-5786</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025549" title="DOI">10.1145/3025453.3025549</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025549&ftid=1870879&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow613" style="display:inline;"><br /><div style="display:inline">Insomnia can drastically affect individuals' overall well-being and work performance, with substantial costs to society and industry. Cognitive behavioral therapy for insomnia (CBT-I) is a psychotherapeutic treatment, which requires patients to track ...</div></span>
          <span id="toHide613" style="display:none;"><br /><div style="display:inline"><p>Insomnia can drastically affect individuals' overall well-being and work performance, with substantial costs to society and industry. Cognitive behavioral therapy for insomnia (CBT-I) is a psychotherapeutic treatment, which requires patients to track sleep and share the data with CBT-I clinicians. However, the number of specialists who can provide CBT-I limits the number of patients who can receive it. In this paper, we aim to identify opportunities to leverage technology to assist clinicians in delivering quality and effective CBT-I services to broader populations. Toward this goal, we conducted formative studies, including 11 CBT-I clinic observations and 17 semi-structured interviews, to understand the current workflow of CBT-I and associated challenges. We discuss how technology can assist clinicians and patients throughout the various steps of CBT-I workflow while addressing some of the identified challenges, and more broadly, how technology can make space for clinicians and patients to build quality therapeutic relationships.</p></div></span> <a id="expcoll613" href="JavaScript: expandcollapse('expcoll613',613)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025570&CFID=758305256&CFTOKEN=14863114">Prescribing 10,000 Steps Like Aspirin: Designing a Novel Interface for Data-Driven Medical Consultations</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Yoojung Kim, Eunyoung Heo, Hyunjeong Lee, Sookyoung Ji, Jueun Choi, Jeong-Whun Kim, Joongseek Lee, Sooyoung Yoo 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5787-5799</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025570" title="DOI">10.1145/3025453.3025570</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025570&ftid=1870892&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow614" style="display:inline;"><br /><div style="display:inline">Due to the prevalence of personal health tracking, cases of self-logged data being utilized in the clinic are gradually increasing. However, obstacles to clinicians' ability to further adopt such data-driven medical consultations in the existing workflow ...</div></span>
          <span id="toHide614" style="display:none;"><br /><div style="display:inline"><p>Due to the prevalence of personal health tracking, cases of self-logged data being utilized in the clinic are gradually increasing. However, obstacles to clinicians' ability to further adopt such data-driven medical consultations in the existing workflow remain, such as lack of time and poor interoperability. In this paper, we conducted a workshop to design a clinician interface supporting the integration of data-driven consultation into the existing workflow and investigate the role of the interface in situ. After implementing the clinician interface designed based on the workshop results, we observed 32 cases of actual use within the clinical context. We found that our interface, <i>DataMD</i>, helped the clinician construct a new workflow, enhanced the clinician's counseling skills, and facilitated more in-depth conversation. This paper contributes to empirically identifying the role of a clinician interface through a user-centered design approach.</p></div></span> <a id="expcoll614" href="JavaScript: expandcollapse('expcoll614',614)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025589&CFID=758305256&CFTOKEN=14863114">Crafting a View of Self-Tracking Data in the Clinical Visit</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Helena M. Mentis, Anita Komlodi, Katrina Schrader, Michael Phipps, Ann Gruber-Baldini, Karen Yarbrough, Lisa Shulman 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5800-5812</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025589" title="DOI">10.1145/3025453.3025589</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025589&ftid=1870898&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow615" style="display:inline;"><br /><div style="display:inline">When self-tracking encounters clinical practices, the data is reshaped by goals and expertise that exist within a healthcare framework. To uncover these shaping practices, we provided a Fitbit Zip step-count sensor to nine patients with Parkinson's disease. ...</div></span>
          <span id="toHide615" style="display:none;"><br /><div style="display:inline"><p>When self-tracking encounters clinical practices, the data is reshaped by goals and expertise that exist within a healthcare framework. To uncover these shaping practices, we provided a Fitbit Zip step-count sensor to nine patients with Parkinson's disease. Each patient wore the sensor for four weeks and then returned for a clinical visit with their neurologist. Our analysis focuses on this first clinical visit after four weeks of data had been collected. Our use of conversation analysis of both talk and action makes visible the practices engaged in by both collaborative members to 'craft a view' of the data toward shared decision making. Our findings reveal the deliberate guiding of attention to specific interpretations of the data through both talk and actions and we explain how our systematic analysis has uncovered tools for the mutually beneficial crafting practices of the clinician and patient.</p></div></span> <a id="expcoll615" href="JavaScript: expandcollapse('expcoll615',615)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025943&CFID=758305256&CFTOKEN=14863114">What Happens to Digital Feedback?: Studying the Use of a Feedback Capture Platform by Care Organisations</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Andy Dow, John Vines, Toby Lowe, Rob Comber, Rob Wilson 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5813-5825</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025943" title="DOI">10.1145/3025453.3025943</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025943&ftid=1870869&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow616" style="display:inline;"><br /><div style="display:inline">In this paper we report on a four-month long field trial of ThoughtCloud, a feedback collection platform that allows people to leave ratings and audio or video responses to simple prompts. ThoughtCloud was trialled with four organisations providing care ...</div></span>
          <span id="toHide616" style="display:none;"><br /><div style="display:inline"><p>In this paper we report on a four-month long field trial of ThoughtCloud, a feedback collection platform that allows people to leave ratings and audio or video responses to simple prompts. ThoughtCloud was trialled with four organisations providing care services for people with disabilities. We conducted interviews with staff and volunteers that used ThoughtCloud before, during and after its deployment, and workshops with service users and staff. While the collection of feedback was high, only one organisation regularly reviewed and responded to collected opinions. Furthermore, tensions arose around data access and sharing, and the mismatch of values between "giving voice" and the capacity for staff to engage in feedback practices. We contribute insights into the challenges faced in using novel technologies in resource constrained organisations, and discuss opportunities for designs that give greater agency to service users to engage those that care for them in reflecting and responding to their opinions.</p></div></span> <a id="expcoll616" href="JavaScript: expandcollapse('expcoll616',616)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Personal Object Recognizers: Feasibility and Challenges</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025845&CFID=758305256&CFTOKEN=14863114">Facade: Auto-generating Tactile Interfaces to Appliances</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Anhong Guo, Jeeeun Kim, Xiang 'Anthony' Chen, Tom Yeh, Scott E. Hudson, Jennifer Mankoff, Jeffrey P. Bigham 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5826-5838</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025845" title="DOI">10.1145/3025453.3025845</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025845&ftid=1870899&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow618" style="display:inline;"><br /><div style="display:inline">Common appliances have shifted toward flat interface panels, making them inaccessible to blind people. Although blind people can label appliances with Braille stickers, doing so generally requires sighted assistance to identify the original functions ...</div></span>
          <span id="toHide618" style="display:none;"><br /><div style="display:inline"><p>Common appliances have shifted toward flat interface panels, making them inaccessible to blind people. Although blind people can label appliances with Braille stickers, doing so generally requires sighted assistance to identify the original functions and apply the labels. We introduce <i>Facade</i> - a crowdsourced fabrication pipeline to help blind people independently make physical interfaces accessible by adding a 3D printed augmentation of tactile buttons overlaying the original panel. Facade users capture a photo of the appliance with a readily available fiducial marker (a dollar bill) for recovering size information. This image is sent to multiple crowd workers, who work in parallel to quickly label and describe elements of the interface. Facade then generates a 3D model for a layer of tactile and pressable buttons that fits over the original controls. Finally, a home 3D printer or commercial service fabricates the layer, which is then aligned and attached to the interface by the blind person. We demonstrate the viability of Facade in a study with 11 blind participants.</p></div></span> <a id="expcoll618" href="JavaScript: expandcollapse('expcoll618',618)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025899&CFID=758305256&CFTOKEN=14863114">People with Visual Impairment Training Personal Object Recognizers: Feasibility and Challenges</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Hernisa Kacorri, Kris M. Kitani, Jeffrey P. Bigham, Chieko Asakawa 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5839-5849</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025899" title="DOI">10.1145/3025453.3025899</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025899&ftid=1870878&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow619" style="display:inline;"><br /><div style="display:inline">Blind people often need to identify objects around them, from packages of food to items of clothing. Automatic object recognition continues to provide limited assistance in such tasks because models tend to be trained on images taken by sighted people ...</div></span>
          <span id="toHide619" style="display:none;"><br /><div style="display:inline"><p>Blind people often need to identify objects around them, from packages of food to items of clothing. Automatic object recognition continues to provide limited assistance in such tasks because models tend to be trained on images taken by sighted people with different background clutter, scale, viewpoints, occlusion, and image quality than in photos taken by blind users. We explore personal object recognizers, where visually impaired people train a mobile application with a few snapshots of objects of interest and provide custom labels. We adopt transfer learning with a deep learning system for user-defined multi-label k-instance classification. Experiments with blind participants demonstrate the feasibility of our approach, which reaches accuracies over 90% for some participants. We analyze user data and feedback to explore effects of sample size, photo-quality variance, and object shape; and contrast models trained on photos by blind participants to those by sighted participants and generic recognizers.</p></div></span> <a id="expcoll619" href="JavaScript: expandcollapse('expcoll619',619)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3026002&CFID=758305256&CFTOKEN=14863114">Jackknife: A Reliable Recognizer with Few Samples and Many Modalities</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Eugene M. Taranta II, Amirreza Samiei, Mehran Maghoumi, Pooya Khaloo, Corey R. Pittman, Joseph J. LaViola Jr. 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5850-5861</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3026002" title="DOI">10.1145/3025453.3026002</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3026002&ftid=1870874&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow620" style="display:inline;"><br /><div style="display:inline">Despite decades of research, there is yet no general rapid prototyping recognizer for dynamic gestures that can be trained with few samples, work with continuous data, and achieve high accuracy that is also modality-agnostic. To begin to solve this problem, ...</div></span>
          <span id="toHide620" style="display:none;"><br /><div style="display:inline"><p>Despite decades of research, there is yet no general rapid prototyping recognizer for dynamic gestures that can be trained with few samples, work with continuous data, and achieve high accuracy that is also modality-agnostic. To begin to solve this problem, we describe a small suite of accessible techniques that we collectively refer to as the Jackknife gesture recognizer. Our dynamic time warping based approach for both segmented and continuous data is designed to be a robust, go-to method for gesture recognition across a variety of modalities using only limited training samples. We evaluate pen and touch, Wii Remote, Kinect, Leap Motion, and sound-sensed gesture datasets as well as conduct tests with continuous data. Across all scenarios we show that our approach is able to achieve high accuracy, suggesting that Jackknife is a capable recognizer and good first choice for many endeavors.</p></div></span> <a id="expcoll620" href="JavaScript: expandcollapse('expcoll620',620)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025731&CFID=758305256&CFTOKEN=14863114">Ubiquitous Accessibility for People with Visual Impairments: Are We There Yet?</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Syed Masum Billah, Vikas Ashok, Donald E. Porter, I.V. Ramakrishnan 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5862-5868</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025731" title="DOI">10.1145/3025453.3025731</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025731&ftid=1870857&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow621" style="display:inline;"><br /><div style="display:inline">Ubiquitous access is an increasingly common vision of computing, wherein users can interact with any computing device or service from anywhere, at any time. In the era of personal computing, users with visual impairments required special-purpose, assistive ...</div></span>
          <span id="toHide621" style="display:none;"><br /><div style="display:inline"><p>Ubiquitous access is an increasingly common vision of computing, wherein users can interact with any computing device or service from anywhere, at any time. In the era of personal computing, users with visual impairments required special-purpose, assistive technologies, such as screen readers, to interact with computers. This paper investigates whether technologies like screen readers have kept pace with, or have created a barrier to, the trend toward ubiquitous access, with a specific focus on desktop computing as this is still the primary way computers are used in education and employment. Towards that, the paper presents a user study with 21 visually-impaired participants, specifically involving the switching of screen readers within and across different computing platforms, and the use of screen readers in remote access scenarios. Among the findings, the study shows that, even for remote desktop access - an early forerunner of true ubiquitous access - screen readers are too limited, if not unusable. The study also identifies several accessibility needs, such as uniformity of navigational experience across devices, and recommends potential solutions. In summary, assistive technologies have not made the jump into the era of ubiquitous access, and multiple, inconsistent screen readers create new practical problems for users with visual impairments.</p></div></span> <a id="expcoll621" href="JavaScript: expandcollapse('expcoll621',621)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Spatial Manipulation and Navigation</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
  
                  <img src="images/bp_award.jpg" alt="Best Paper" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025524&CFID=758305256&CFTOKEN=14863114">BIGnav: Bayesian Information Gain for Guiding Multiscale Navigation</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Wanyu Liu, Rafael Lucas D'Oliveira, Michel Beaudouin-Lafon, Olivier Rioul 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5869-5880</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025524" title="DOI">10.1145/3025453.3025524</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025524&ftid=1870865&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow623" style="display:inline;"><br /><div style="display:inline">This paper introduces BIGnav, a new multiscale navigation technique based on Bayesian Experimental Design where the criterion is to maximize the information-theoretic concept of mutual information, also known as information gain. Rather than simply executing ...</div></span>
          <span id="toHide623" style="display:none;"><br /><div style="display:inline"><p>This paper introduces BIGnav, a new multiscale navigation technique based on Bayesian Experimental Design where the criterion is to maximize the information-theoretic concept of mutual information, also known as information gain. Rather than simply executing user navigation commands, BIGnav interprets user input to update its knowledge about the user's intended target. Then it navigates to a new view that maximizes the information gain provided by the user's expected subsequent input. We conducted a controlled experiment demonstrating that BIGnav is significantly faster than conventional pan and zoom and requires fewer commands for distant targets, especially in non-uniform information spaces. We also applied BIGnav to a realistic application and showed that users can navigate to highly probable points of interest on a map with only a few steps. We then discuss the tradeoffs of BIGnav--including efficiency vs. increased cognitive load--and its application to other interaction tasks.</p></div></span> <a id="expcoll623" href="JavaScript: expandcollapse('expcoll623',623)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025935&CFID=758305256&CFTOKEN=14863114">Design and Evaluation of a Handheld-based 3D User Interface for Collaborative Object Manipulation</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Jer&#244;nimo Gustavo Grandi, Henrique Galvan Debarba, Luciana Nedel, Anderson Maciel 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5881-5891</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025935" title="DOI">10.1145/3025453.3025935</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025935&ftid=1870890&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow624" style="display:inline;"><br /><div style="display:inline">Object manipulation in 3D virtual environments demands a combined coordination of rotations, translations and scales, as well as the camera control to change the user's viewpoint. Then, for many manipulation tasks, it would be advantageous to share the ...</div></span>
          <span id="toHide624" style="display:none;"><br /><div style="display:inline"><p>Object manipulation in 3D virtual environments demands a combined coordination of rotations, translations and scales, as well as the camera control to change the user's viewpoint. Then, for many manipulation tasks, it would be advantageous to share the interaction complexity among team members. In this paper we propose a novel 3D manipulation interface based on a collaborative action coordination approach. Our technique explores a smartphone -- the touchscreen and inertial sensors -- as input interface, enabling several users to collaboratively manipulate the same virtual object with their own devices. We first assessed our interface design on a docking and an obstacle crossing tasks with teams of two users. Then, we conducted a study with 60 users to understand the influence of group size in collaborative 3D manipulation. We evaluated teams in combinations of one, two, three and four participants. Experimental results show that teamwork increases accuracy when compared with a single user. The accuracy increase is correlated with the number of individuals in the team and their work division strategy.</p></div></span> <a id="expcoll624" href="JavaScript: expandcollapse('expcoll624',624)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025661&CFID=758305256&CFTOKEN=14863114">TDome: A Touch-Enabled 6DOF Interactive Device for Multi-Display Environments</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Houssem Saidi, Marcos Serrano, Pourang Irani, Emmanuel Dubois 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5892-5904</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025661" title="DOI">10.1145/3025453.3025661</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025661&ftid=1870900&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow625" style="display:inline;"><br /><div style="display:inline">The rapid evolution of multi-display environments (MDEs) has created a vacuum in need of novel input devices to optimize interaction in MDEs. In this paper, we propose TDome, a novel touch-enabled 6DOF input and output device to facilitate interactions ...</div></span>
          <span id="toHide625" style="display:none;"><br /><div style="display:inline"><p>The rapid evolution of multi-display environments (MDEs) has created a vacuum in need of novel input devices to optimize interaction in MDEs. In this paper, we propose TDome, a novel touch-enabled 6DOF input and output device to facilitate interactions in MDEs. TDome offers a private display as output, and multiple degrees of freedom as input by combining touch gestures on the display with physical rotation, roll and translation manipulations of the device. TDome allows versatile interactions that address major MDE tasks, which we illustrate through various proof-of-concept implementations: detect surrounding displays, select one display, transfer data across displays, reach distant displays and perform private interactions. We explore TDome's usability and suitability for MDEs through three user studies. First we explore combined <i>physical+touch</i> gestures from which we discard uncomfortable combinations. We experimentally validate their feasibility and come up with a set of 71 combined gestures that are comfortable and ensure a high success rate, i.e. that can be easily performed and efficiently detected. Finally, we collect user feedback to identify natural mappings between gestures and MDE interactions.</p></div></span> <a id="expcoll625" href="JavaScript: expandcollapse('expcoll625',625)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025905&CFID=758305256&CFTOKEN=14863114">A Field Experiment of Spatially-Stable Overviews for Document Navigation</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Carl Gutwin, Andy Cockburn, Nickolas Gough 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5905-5916</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025905" title="DOI">10.1145/3025453.3025905</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025905&ftid=1870887&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow626" style="display:inline;"><br /><div style="display:inline">Finding (and re-finding) locations in text documents is a common activity for most computer users -- but tools for document navigation are still limited in many ways. Previous research has shown that a spatially-stable overview of the entire document ...</div></span>
          <span id="toHide626" style="display:none;"><br /><div style="display:inline"><p>Finding (and re-finding) locations in text documents is a common activity for most computer users -- but tools for document navigation are still limited in many ways. Previous research has shown that a spatially-stable overview of the entire document can be substantially faster than any other navigation technique -- particularly when revisiting previous locations. However, the overview technique has only been tested in a limited laboratory study, so little is known about whether it works in more realistic contexts. To answer this question, we developed a PDF viewer that incorporates several document-navigation techniques, and carried out two studies. First, we ran a field experiment in which users carried out search tasks using an overview and other techniques -- on their own computers in a non-laboratory environment. Second, we ran a smaller field study in which people used our viewer (with choice of navigation techniques) for their own PDF tasks. In the field experiment, the overview was significantly and substantially faster than other techniques, and in the field study, the technique was frequently used for a wide variety of documents. Our work provides confirmation of the value of spatially stable overviews as a basis for document navigation.</p></div></span> <a id="expcoll626" href="JavaScript: expandcollapse('expcoll626',626)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Technology Use Around the Globe</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025545&CFID=758305256&CFTOKEN=14863114">Imagined Connectivities: Synthesized Conceptions of Public Wi-Fi in Urban India</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Nithya Sambasivan, Paul M. Aoki 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5917-5928</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025545" title="DOI">10.1145/3025453.3025545</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025545&ftid=1870882&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow628" style="display:inline;"><br /><div style="display:inline">India and other economies in the Global South are undergoing a proliferation in public Wi-Fi, with large-scale deployments from industry and government. In this paper, we report on a qualitative study on public Wi-Fi conceptions as held by urban Indians, ...</div></span>
          <span id="toHide628" style="display:none;"><br /><div style="display:inline"><p>India and other economies in the Global South are undergoing a proliferation in public Wi-Fi, with large-scale deployments from industry and government. In this paper, we report on a qualitative study on public Wi-Fi conceptions as held by urban Indians, textit{a priori} to connecting to a network. Our findings show that prior public Wi-Fi users and non-users alike raised a surprising range and depth of conceptions---ranging from suspicion of operators' intentions to monetize, to concerns about sexual image morphing, to fears of phone wipeouts, to aspiration---which were informed by popular media, BlueTooth cultures, and social learning. We found these conceptions of Wi-Fi networks to significantly influence adoption of public Wi-Fi. With enormous investments in public Wi-Fi initiatives, we call for network providers to address these deep conceptions among emerging users; by suggesting ways to build public awareness, better user experiences, and business model innovation.</p></div></span> <a id="expcoll628" href="JavaScript: expandcollapse('expcoll628',628)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025895&CFID=758305256&CFTOKEN=14863114">Agency in Assistive Technology Adoption: Visual Impairment and Smartphone Use in Bangalore</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Joyojeet Pal, Anandhi Viswanathan, Priyank Chandra, Anisha Nazareth, Vaishnav Kameswaran, Hariharan Subramonyam, Aditya Johri, Mark S. Ackerman, Sile O'Modhrain 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5929-5940</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025895" title="DOI">10.1145/3025453.3025895</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025895&ftid=1870903&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow629" style="display:inline;"><br /><div style="display:inline">Studies on technology adoption typically assume that a user's perception of usability and usefulness of technology are central to its adoption. Specifically, in the case of accessibility and assistive technology, research has traditionally focused on ...</div></span>
          <span id="toHide629" style="display:none;"><br /><div style="display:inline"><p>Studies on technology adoption typically assume that a user's perception of usability and usefulness of technology are central to its adoption. Specifically, in the case of accessibility and assistive technology, research has traditionally focused on the artifact rather than the individual, arguing that individual technologies fail or succeed based on their usability and fit for their users. Using a mixed-methods field study of smartphone adoption by 81 people with visual impairments in Bangalore, India, we argue that these positions are dated in the case of accessibility where a non-homogeneous population must adapt to technologies built for sighted people. We found that many users switch to smartphones despite their awareness of significant usability challenges with smartphones. We propose a nuanced understanding of perceived usefulness and actual usage based on need-related social and economic functions, which is an important step toward rethinking technology adoption for people with disabilities.</p></div></span> <a id="expcoll629" href="JavaScript: expandcollapse('expcoll629',629)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025960&CFID=758305256&CFTOKEN=14863114">Money, God, and SMS: Explorations in Supporting Social Action Through a Bangladeshi Mosque</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Md. Rashidujjaman Rifat, Jay Chen, Kentaro Toyama 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5941-5953</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025960" title="DOI">10.1145/3025453.3025960</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025960&ftid=1870901&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow630" style="display:inline;"><br /><div style="display:inline">Religious institutions hold a significant place in daily life for the vast majority of people in the world, especially in developing countries. Yet despite their social prominence, and despite HCI's emphasis on the social context of technology, organized ...</div></span>
          <span id="toHide630" style="display:none;"><br /><div style="display:inline"><p>Religious institutions hold a significant place in daily life for the vast majority of people in the world, especially in developing countries. Yet despite their social prominence, and despite HCI's emphasis on the social context of technology, organized religion is neglected in both the HCI and ICTD literature. This paper explores the relationship that mosques in Bangladesh have with their constituencies and with technology, with an eye toward the integration of technology with existing religious institutions as a way to achieve positive social ends. We first describe a qualitative exploration of several mosque communities in Bangladesh, where we find that skepticism and pragmatism about modern technology interact in a complex way that nevertheless leaves room for technical interventions. We then describe a randomized controlled trial to study the relative value of SMS messages infused with overtly religious or secularly altruistic frames for the purpose of mosque fundraising. We find that SMS messages increase donations overall, but that their framing is significant. Messages with secular altruistic framing increased donations by 9.5%, while those with religious sentiment increased donations by 57.3%. Our findings demonstrate how technologies like SMS amplify underlying religious forces and suggest the possibility of working with religious institutions in applying positive ICT interventions.</p></div></span> <a id="expcoll630" href="JavaScript: expandcollapse('expcoll630',630)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3026039&CFID=758305256&CFTOKEN=14863114">Negotiating Absent Practices and Dormant Features: Discourse as a Means of Shaping the Implementation of a Global Enterprise System to Meet Local Work Culture</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          George Kandathil, Erica L. Wagner 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5954-5965</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3026039" title="DOI">10.1145/3025453.3026039</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3026039&ftid=1870895&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow631" style="display:inline;"><br /><div style="display:inline">The introduction of a new enterprise system to an organization often necessitates the accommodation of standardized practices, which may be in conflict with local users' practices and their work culture. We explore such a conflict in an India-based multinational ...</div></span>
          <span id="toHide631" style="display:none;"><br /><div style="display:inline"><p>The introduction of a new enterprise system to an organization often necessitates the accommodation of standardized practices, which may be in conflict with local users' practices and their work culture. We explore such a conflict in an India-based multinational organization using an eight-month interpretive case study. Based on grounded analysis, we present a narrative account of how consultants, on contract for managing the deployment and making necessary adjustments, used discourse as a means of shaping user understanding about the features and practices embedded in the underlying system, which were not initially realized through the interface. Sustained user resistance to this shaping led to a negotiated compromise and adaptation of the system to incorporate local work culture. Our findings allow us to explore the under-theorized role of discursive power within an implementer-user-technology trio, and illustrate the feedback utility of user resistance in developing culturally-inclusive designs.</p></div></span> <a id="expcoll631" href="JavaScript: expandcollapse('expcoll631',631)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>What Things Look Like</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025478&CFID=758305256&CFTOKEN=14863114">Hybrid HFR Depth: Fusing Commodity Depth and Color Cameras to Achieve High Frame Rate, Low Latency Depth Camera Interactions</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Jiajun Lu, Hrvoje Benko, Andrew D. Wilson 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5966-5975</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025478" title="DOI">10.1145/3025453.3025478</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025478&ftid=1870863&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow633" style="display:inline;"><br /><div style="display:inline">The low frame rate and high latency of consumer depth cameras limits their use in interactive applications. We propose combining the Kinect depth camera with an ordinary color camera to synthesize a high frame rate and low latency depth image. We exploit ...</div></span>
          <span id="toHide633" style="display:none;"><br /><div style="display:inline"><p>The low frame rate and high latency of consumer depth cameras limits their use in interactive applications. We propose combining the Kinect depth camera with an ordinary color camera to synthesize a high frame rate and low latency depth image. We exploit common CMOS camera region of interest (ROI) functionality to obtain a high frame rate image over a small ROI. Motion in the ROI is computed by a fast optical flow implementation. The resulting flow field is used to extrapolate Kinect depth images to achieve high frame rate and low latency depth, and optionally predict depth to further reduce latency. Our "Hybrid HFR Depth" prototype generates useful depth images at maximum 500Hz with minimum 20ms latency. We demonstrate Hybrid HFR Depth in tracking fast moving objects, handwriting in the air, and projecting onto moving hands. Based on commonly available cameras and image processing implementations, Hybrid HFR Depth may be useful to HCI practitioners seeking to create fast, fluid depth camera-based interactions.</p></div></span> <a id="expcoll633" href="JavaScript: expandcollapse('expcoll633',633)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025607&CFID=758305256&CFTOKEN=14863114">Understanding the Aesthetic Evolution of Websites: Towards a Notion of Design Periods</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Wen Chen, David J. Crandall, Norman Makoto Su 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5976-5987</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025607" title="DOI">10.1145/3025453.3025607</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025607&ftid=1870854&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow634" style="display:inline;"><br /><div style="display:inline">In art and music, time periods like "classical" and "impressionist" are powerful means for academics and practitioners to compare and contrast artifacts that share aesthetics or philosophies. While web designs have undergone changes for 25 years, we ...</div></span>
          <span id="toHide634" style="display:none;"><br /><div style="display:inline"><p>In art and music, time periods like "classical" and "impressionist" are powerful means for academics and practitioners to compare and contrast artifacts that share aesthetics or philosophies. While web designs have undergone changes for 25 years, we lack theories to describe or explain these changes. In this paper, we take a first step towards identifying and understanding the design periods of websites. Drawing from humanistic HCI methods, we asked subject experts of web design to critically analyze a dataset of prominent websites whose lifetimes span over a decade. These informed judgments reveal a set of key <i>markers</i> that signal shifts in design periods. For instance, advances in display technologies and changes in company strategies help explain how design periods demarcated by particular layout templates and navigation models arise. We suggest that designers and marketers can draw inspiration from website designs curated into design periods. Future work should examine the utility of applying design periods to any computationally embedded artifact that is an interaction design.</p></div></span> <a id="expcoll634" href="JavaScript: expandcollapse('expcoll634',634)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025814&CFID=758305256&CFTOKEN=14863114">Understanding Blind People's Experiences with Computer-Generated Captions of Social Media Images</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Haley MacLeod, Cynthia L. Bennett, Meredith Ringel Morris, Edward Cutrell 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 5988-5999</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025814" title="DOI">10.1145/3025453.3025814</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025814&ftid=1870880&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow635" style="display:inline;"><br /><div style="display:inline">Research advancements allow computational systems to automatically caption social media images. Often, these captions are evaluated with sighted humans using the image as a reference. Here, we explore how blind and visually impaired people experience ...</div></span>
          <span id="toHide635" style="display:none;"><br /><div style="display:inline"><p>Research advancements allow computational systems to automatically caption social media images. Often, these captions are evaluated with sighted humans using the image as a reference. Here, we explore how blind and visually impaired people experience these captions in two studies about social media images. Using a contextual inquiry approach (n=6 blind/visually impaired), we found that blind people place a lot of trust in automatically generated captions, filling in details to resolve differences between an image's context and an incongruent caption. We built on this in-person study with a second, larger online experiment (n=100 blind/visually impaired) to investigate the role of phrasing in encouraging trust or skepticism in captions. We found that captions emphasizing the probability of error, rather than correctness, encouraged people to attribute incongruence to an incorrect caption, rather than missing details. Where existing research has focused on encouraging trust in intelligent systems, we conclude by challenging this assumption and consider the benefits of encouraging appropriate skepticism.</p></div></span> <a id="expcoll635" href="JavaScript: expandcollapse('expcoll635',635)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025810&CFID=758305256&CFTOKEN=14863114">Time Travel with One Click: Effects of Digital Filters on Perceptions of Photographs</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Yilang Peng 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6000-6011</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025810" title="DOI">10.1145/3025453.3025810</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025810&ftid=1870877&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow636" style="display:inline;"><br /><div style="display:inline">Today's digital photographs are being heavily "filtered." By simple clicks on mobile apps like Hipstamatic and Instagram, users can easily apply digital filters to their pictures to create effects such as faux-vintage and light leaks. To understand the ...</div></span>
          <span id="toHide636" style="display:none;"><br /><div style="display:inline"><p>Today's digital photographs are being heavily "filtered." By simple clicks on mobile apps like Hipstamatic and Instagram, users can easily apply digital filters to their pictures to create effects such as faux-vintage and light leaks. To understand the potential impacts of photo filters, we conducted an online experiment and investigated how the use of the black-and-white and film-style photo filters changed viewers' perceptions and descriptions of photographs. We found that photo filters substantially increased viewers' perceived temporal distances to photographs. Participants also tended to describe analogue-style photos more interpretively and tentatively than unfiltered ones, indicating an increase in construal levels. We suggest that the widely used photo filter is not just a tool to change aesthetics; it also adds a layer of history, meaning, and defamiliarization to photographs, allowing users to construct a mental distance in images that deviates from everyday experiences. We offer insights into the psychology of visual styles and implications for designing filter apps and photo-sharing platforms.</p></div></span> <a id="expcoll636" href="JavaScript: expandcollapse('expcoll636',636)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Accessibility</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025888&CFID=758305256&CFTOKEN=14863114">ForgetMeNot: Active Reminder Entry Support for Adults with Acquired Brain Injury</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Matthew Jamieson, Brian O'Neill, Breda Cullen, Marilyn Lennon, Stephen Brewster, Jonathan Evans 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6012-6023</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025888" title="DOI">10.1145/3025453.3025888</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025888&ftid=1870872&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow638" style="display:inline;"><br /><div style="display:inline">Smartphone reminding apps can compensate for memory impairment after acquired brain injury (ABI). In the absence of a caregiver, users must enter reminders themselves if the apps are going to help them. Poor memory and apathy associated with ABI can ...</div></span>
          <span id="toHide638" style="display:none;"><br /><div style="display:inline"><p>Smartphone reminding apps can compensate for memory impairment after acquired brain injury (ABI). In the absence of a caregiver, users must enter reminders themselves if the apps are going to help them. Poor memory and apathy associated with ABI can result in failure to initiate such configuration behaviour and the benefits of reminder apps are lost. ForgetMeNot takes a novel approach to address this problem by periodically encouraging the user to enter reminders with unsolicited prompts (UPs). An in situ case study investigated the experience of using a reminding app for people with ABI and tested UPs as a potential solution to initiating reminder entry. Three people with severe ABI living in a post-acute rehabilitation hospital used the app in their everyday lives for four weeks to collect real usage data. Field observations illustrated how difficulties with motivation, insight into memory difficulties and anxiety impact reminder app use in a rehabilitation setting. Results showed that when 6 UPs were presented throughout the day, reminder-setting increased, showing UPs are an important addition to reminder applications for people with ABI. This study demonstrates that barriers to technology use can be resolved in practice when software is developed with an understanding of the issues experienced by the user group.</p></div></span> <a id="expcoll638" href="JavaScript: expandcollapse('expcoll638',638)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025846&CFID=758305256&CFTOKEN=14863114">Interaction Proxies for Runtime Repair and Enhancement of Mobile Application Accessibility</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Xiaoyi Zhang, Anne Spencer Ross, Anat Caspi, James Fogarty, Jacob O. Wobbrock 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6024-6037</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025846" title="DOI">10.1145/3025453.3025846</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025846&ftid=1870861&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow639" style="display:inline;"><br /><div style="display:inline">We introduce interaction proxies as a strategy for runtime repair and enhancement of the accessibility of mobile applications. Conceptually, interaction proxies are inserted between an application's original interface and the manifest interface that ...</div></span>
          <span id="toHide639" style="display:none;"><br /><div style="display:inline"><p>We introduce interaction proxies as a strategy for runtime repair and enhancement of the accessibility of mobile applications. Conceptually, interaction proxies are inserted between an application's original interface and the manifest interface that a person uses to perceive and manipulate the application. This strategy allows third-party developers and researchers to modify an interaction without an application's source code, without rooting the phone, without otherwise modifying an application, while retaining all capabilities of the system (e.g., Android's full implementation of the TalkBack screen reader). This paper introduces interaction proxies, defines a design space of interaction re-mappings, identifies necessary implementation abstractions, presents details of implementing those abstractions in Android, and demonstrates a set of Android implementations of interaction proxies from throughout our design space. We then present a set of interviews with blind and low-vision people interacting with our prototype interaction proxies, using these interviews to explore the seamlessness of interaction, the perceived usefulness and potential of interaction proxies, and visions of how such enhancements could gain broad usage. By allowing third-party developers and researchers to improve an interaction, interaction proxies offer a new approach to personalizing mobile application accessibility and a new approach to catalyzing development, deployment, and evaluation of mobile accessibility enhancements.</p></div></span> <a id="expcoll639" href="JavaScript: expandcollapse('expcoll639',639)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025483&CFID=758305256&CFTOKEN=14863114">SUGILITE: Creating Multimodal Smartphone Automation by Demonstration</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Toby Jia-Jun Li, Amos Azaria, Brad A. Myers 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6038-6049</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025483" title="DOI">10.1145/3025453.3025483</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025483&ftid=1870862&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow640" style="display:inline;"><br /><div style="display:inline">SUGILITE is a new programming-by-demonstration (PBD) system that enables users to create automation on smartphones. SUGILITE uses Android's accessibility API to support automating arbitrary tasks in any Android app (or even across multiple apps). When ...</div></span>
          <span id="toHide640" style="display:none;"><br /><div style="display:inline"><p>SUGILITE is a new programming-by-demonstration (PBD) system that enables users to create automation on smartphones. SUGILITE uses Android's accessibility API to support automating arbitrary tasks in any Android app (or even across multiple apps). When the user gives verbal commands that SUGILITE does not know how to execute, the user can demonstrate by directly manipulating the regular apps' user interface. By leveraging the verbal instructions, the demonstrated procedures, and the apps? UI hierarchy structures, SUGILITE can automatically generalize the script from the recorded actions, so SUGILITE learns how to perform tasks with different variations and parameters from a single demonstration. Extensive error handling and context checking support forking the script when new situations are encountered, and provide robustness if the apps change their user interface. Our lab study suggests that users with little or no programming knowledge can successfully automate smartphone tasks using SUGILITE.</p></div></span> <a id="expcoll640" href="JavaScript: expandcollapse('expcoll640',640)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025472&CFID=758305256&CFTOKEN=14863114">Automated Detection of Facial Expressions during Computer-Assisted Instruction in Individuals on the Autism Spectrum</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Alex A. Ahmed, Matthew S. Goodwin 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6050-6055</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025472" title="DOI">10.1145/3025453.3025472</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025472&ftid=1870871&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow641" style="display:inline;"><br /><div style="display:inline">It has been suggested that computer-assisted instruction (CAI) is a promising method for educating students on the autism spectrum. We aimed to determine whether automated recognition of facial expressions aided in predicting CAI engagement and learning ...</div></span>
          <span id="toHide641" style="display:none;"><br /><div style="display:inline"><p>It has been suggested that computer-assisted instruction (CAI) is a promising method for educating students on the autism spectrum. We aimed to determine whether automated recognition of facial expressions aided in predicting CAI engagement and learning performance. Seven youth with autism (mean age = 12.7, SD = 4.2) interacted with a CAI program, TeachTown Basics, for 15 consecutive sessions. Video recordings of the participants' faces were collected during these sessions and facial expressions from these videos were analyzed using CERT, an algorithm that automatically outputs intensity values for each facial action unit (AU). Using these data, we attempted to operationally define two engagement indices: (1) behavioral engagement, the proportion of time a participant had their face oriented to the computer screen; and (2) emotional engagement, the activation of AUs previously associated with CAI. Our results suggest that both indices strongly correlated with one another, but that emotional (not behavioral) engagement predicted test performance. CAI knowledge domain, participant sex, and developmental age also contributed to the prediction.</p></div></span> <a id="expcoll641" href="JavaScript: expandcollapse('expcoll641',641)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025603&CFID=758305256&CFTOKEN=14863114">Comparing Touchscreen and Mouse Input Performance by People With and Without Upper Body Motor Impairments</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Leah Findlater, Karyn Moffatt, Jon E. Froehlich, Meethu Malu, Joan Zhang 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6056-6061</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025603" title="DOI">10.1145/3025453.3025603</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025603&ftid=1870894&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow642" style="display:inline;"><br /><div style="display:inline">Controlled studies of touchscreen input performance for users with upper body motor impairments remain relatively sparse. To address this gap, we present a controlled lab study of mouse vs. touchscreen performance with 32 participants (16 with upper ...</div></span>
          <span id="toHide642" style="display:none;"><br /><div style="display:inline"><p>Controlled studies of touchscreen input performance for users with upper body motor impairments remain relatively sparse. To address this gap, we present a controlled lab study of mouse vs. touchscreen performance with 32 participants (16 with upper body motor impairments and 16 without). Our study examines: (1) how touch input compares to an indirect pointing device (a mouse); (2) how performance compares across a range of standard interaction techniques; and (3) how these answers differ for users with and without motor impairments. While the touchscreen was faster than the mouse overall, only participants without motor impairments benefited from a lower error rate on the touchscreen. Indeed, participants <i>with</i> motor impairments had a <i>three-fold increase</i> in pointing (tapping) errors on the touchscreen compared to the mouse. Our findings also highlight the high frequency of spurious touches for users with motor impairments and update past accessibility recommendations for minimum touchscreen target sizes to at least 18mm.</p></div></span> <a id="expcoll642" href="JavaScript: expandcollapse('expcoll642',642)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Cultural Heritage</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025908&CFID=758305256&CFTOKEN=14863114">Designing Cultural Values into Interaction</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Reese Muntean, Alissa N. Antle, Brendan Matkin, Kate Hennessy, Susan Rowley, Jordan Wilson 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6062-6074</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025908" title="DOI">10.1145/3025453.3025908</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025908&ftid=1870910&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow644" style="display:inline;"><br /><div style="display:inline">In this paper, we highlight possibilities for designing intangible cultural values into interactions with technologies in heritage spaces. We do this specifically through the design of elwkw -- Belongings, an interactive tangible table installed ...</div></span>
          <span id="toHide644" style="display:none;"><br /><div style="display:inline"><p>In this paper, we highlight possibilities for designing intangible cultural values into interactions with technologies in heritage spaces. We do this specifically through the design of elwk<sup>w</sup> -- Belongings, an interactive tangible table installed in a cultural heritage museum. The tabletop was collaboratively designed to communicate complex and narrative information and values about Musqueam culture. Rather than focusing only on content and interface design, we wanted visitors to also experience Musqueam values through their interactions with the system. We describe our value-sensitive design process, present five interdependent design goals, discuss the design strategies that enabled us to meet these goals, and evaluate our approach through a user study. From our design process and evaluation we offer recommendations for designing values into interactions more generally and for tangible interactions specifically in ways that support visitors' experience and understanding of specific cultural values through technology.</p></div></span> <a id="expcoll644" href="JavaScript: expandcollapse('expcoll644',644)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/bp_award.jpg" alt="Best Paper" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025729&CFID=758305256&CFTOKEN=14863114">Kinecting with Orangutans: Zoo Visitors' Empathetic Responses to Animals? Use of Interactive Technology</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Sarah Webber, Marcus Carter, Sally Sherwen, Wally Smith, Zaher Joukhadar, Frank Vetere 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6075-6088</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025729" title="DOI">10.1145/3025453.3025729</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025729&ftid=1870897&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow645" style="display:inline;"><br /><div style="display:inline">Animal conservation organisations occasionally harness depictions of animals using digital technology to inspire interest in, and concern for animals. To better understand the forms of empathy experienced by people observing animal-computer interaction, ...</div></span>
          <span id="toHide645" style="display:none;"><br /><div style="display:inline"><p>Animal conservation organisations occasionally harness depictions of animals using digital technology to inspire interest in, and concern for animals. To better understand the forms of empathy experienced by people observing animal-computer interaction, we designed and studied an interactive installation for orangutans at a zoo. Through collaborative design we established an understanding of zoos' objectives and strategies related to empathy in the zoo context. We deployed a prototype installation, and observed and interviewed visitors who watched orangutans use the installation. Analysis of observations and interviews revealed that visitors responded with <i>cognitive, affective</i> and <i>motor</i> empathy for the animals. We propose that these empathetic responses are prompted by the visibility of orangutans' bodily movements, by the "anthropic frame" provided by digital technology, and by prompting reflection on animals' cognitive processes and affective states. This paper contributes new evidence and understanding of people's empathetic responses to observing animal-computer interaction and confirms the value of designing for empathy in its various forms</p></div></span> <a id="expcoll645" href="JavaScript: expandcollapse('expcoll645',645)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025966&CFID=758305256&CFTOKEN=14863114">Reconsidering Nature: The Dialectics of Fair Chase in the Practices of American Midwest Hunters</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Norman Makoto Su, EunJeong Cheon 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6089-6100</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025966" title="DOI">10.1145/3025453.3025966</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025966&ftid=1870883&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow646" style="display:inline;"><br /><div style="display:inline">In this paper, we describe an ethnographic study consisting of 14 interviews with hunters and participant observations in the American Midwest. We find that the ethos of "fair chase" serves to unite an eclectic group of hunters under a single moral compass. ...</div></span>
          <span id="toHide646" style="display:none;"><br /><div style="display:inline"><p>In this paper, we describe an ethnographic study consisting of 14 interviews with hunters and participant observations in the American Midwest. We find that the ethos of "fair chase" serves to unite an eclectic group of hunters under a single moral compass. Fair chase posits, for example, that hunters must not have an improper advantage over animals. The actual practices of hunters in different communities (e.g., communities revolving around different weapons or professions), however, reveals a series of opposing points of view among hunters at large on what actually constitutes fair chase. We suggest that an understanding of fair chase and its dialectics can constructively problematize nature for human-computer interaction.</p></div></span> <a id="expcoll646" href="JavaScript: expandcollapse('expcoll646',646)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025803&CFID=758305256&CFTOKEN=14863114">Exploring Seasonality in Mobile Cultural Heritage</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          David McGookin, Koray Tahiro&#259;lu, Tuomas Vaittinen, Mikko Kyt&#246;, Beatrice Monastero, Juan Carlos Vasquez 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6101-6105</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025803" title="DOI">10.1145/3025453.3025803</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025803&ftid=1870855&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow647" style="display:inline;"><br /><div style="display:inline">We present results of an investigation into the role of seasonality in mobile cultural heritage applications. 45 participants in 26 groups used one of two applications when visiting the Finnish recreational island of Seurasaari. Each provided summer ...</div></span>
          <span id="toHide647" style="display:none;"><br /><div style="display:inline"><p>We present results of an investigation into the role of seasonality in mobile cultural heritage applications. 45 participants in 26 groups used one of two applications when visiting the Finnish recreational island of Seurasaari. Each provided summer and winter content, but varied in how this was presented. We uncovered how users consider seasonality in content, seasonal preferences, as well as how different media becomes more or less interesting if shown in or out of season. We present design considerations for future researchers to consider seasonality in cultural heritage applications.</p></div></span> <a id="expcoll647" href="JavaScript: expandcollapse('expcoll647',647)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025720&CFID=758305256&CFTOKEN=14863114">Where No One Has Gone Before: A Meta-Dataset of the World's Largest Fanfiction Repository</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Kodlee Yin, Cecilia Aragon, Sarah Evans, Katie Davis 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6106-6110</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025720" title="DOI">10.1145/3025453.3025720</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025720&ftid=1870850&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow648" style="display:inline;"><br /><div style="display:inline">With its roots dating to popular television shows of the 1960s such as Star Trek, fanfiction has blossomed into an extremely widespread form of creative expression. The transition from printed zines to online fanfiction repositories has facilitated this ...</div></span>
          <span id="toHide648" style="display:none;"><br /><div style="display:inline"><p>With its roots dating to popular television shows of the 1960s such as Star Trek, fanfiction has blossomed into an extremely widespread form of creative expression. The transition from printed zines to online fanfiction repositories has facilitated this growth in popularity, with millions of fans writing stories and adding daily to sites such as Archive Of Our Own, Fanfiction.net, FIMfiction.net, and many others. Enthusiasts are sharing their writing, reading stories written by others, and helping each other to grow as writers. Yet, this domain is often undervalued by society and understudied by researchers. To facilitate the study of this large but often marginalized community, we present a fully anonymized data release (via differential privacy) of the metadata from a large fanfiction site (to protect author privacy, story, profile, and review text is excluded, and only metadata is provided). We use visual analytics techniques to draw several intriguing insights from the data and show the potential for future research. We hope other researchers can use this data to explore further questions related to online fanfiction communities.</p></div></span> <a id="expcoll648" href="JavaScript: expandcollapse('expcoll648',648)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Explorative Engineering</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
  
                  <img src="images/bp_award.jpg" alt="Best Paper" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025466&CFID=758305256&CFTOKEN=14863114">Illumination Aesthetics: Light as a Creative Material within Computational Design</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Cesar Torres, Jasper O'Leary, Molly Nicholas, Eric Paulos 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6111-6122</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025466" title="DOI">10.1145/3025453.3025466</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025466&ftid=1870868&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow650" style="display:inline;"><br /><div style="display:inline">Recent digital fabrication tools have enabled new form-giving using a wide range of physical materials. However, light as a first class creative material has been largely ignored within the design of our electronic objects. Our work expands the illumination ...</div></span>
          <span id="toHide650" style="display:none;"><br /><div style="display:inline"><p>Recent digital fabrication tools have enabled new form-giving using a wide range of physical materials. However, light as a first class creative material has been largely ignored within the design of our electronic objects. Our work expands the illumination design space by treating light as a physical material. We introduce a digital design tool that simulates and visualizes physical light interactions with a variety of materials for creating custom luminaires. We further develop a computational design and fabrication process for creating custom secondary optics elements (SOEs), which provides additional handles for users to physically shape and redirect light to compose, fill, and evenly diffuse planar and volumetric geometries. Through a workshop study with novice electronic designers, we show how incorporating physical techniques to shape light alters how users view the role and function of LEDs and electronics. We produce example pieces that showcase how our approach expands the electronics aesthetic and discuss how viewing light as material can engender novel, expressive artifacts.</p></div></span> <a id="expcoll650" href="JavaScript: expandcollapse('expcoll650',650)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3026019&CFID=758305256&CFTOKEN=14863114">Transformative Appetite: Shape-Changing Food Transforms from 2D to 3D by Water Interaction through Cooking</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Wen Wang, Lining Yao, Teng Zhang, Chin-Yi Cheng, Daniel Levine, Hiroshi Ishii 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6123-6132</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3026019" title="DOI">10.1145/3025453.3026019</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3026019&ftid=1870881&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow651" style="display:inline;"><br /><div style="display:inline">We developed a concept of transformative appetite, where edible 2D films made of common food materials (protein, cellulose or starch) can transform into 3D food during cooking. This transformation process is triggered by water adsorption, and it is strongly ...</div></span>
          <span id="toHide651" style="display:none;"><br /><div style="display:inline"><p>We developed a concept of transformative appetite, where edible 2D films made of common food materials (protein, cellulose or starch) can transform into 3D food during cooking. This transformation process is triggered by water adsorption, and it is strongly compatible with the 'flat packaging' concept for substantially reducing shipping costs and storage space. To develop these transformable foods, we performed material-based design, established a hybrid fabrication strategy, and conducted performance simulation. Users can customize food shape transformations through a pre-defined simulation platform, and then fabricate these designed patterns using additive manufacturing. Three application techniques are provided - 2D-to-3D folding, hydration-induced wrapping, and temperature-induced self-fragmentation, to present the shape, texture, and interaction with food materials. Based on this concept, several dishes were created in the kitchen, to demonstrate the futuristic dining experience through materials-based interaction design.</p></div></span> <a id="expcoll651" href="JavaScript: expandcollapse('expcoll651',651)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025953&CFID=758305256&CFTOKEN=14863114">Emotion Actuator: Embodied Emotional Feedback through Electroencephalography and Electrical Muscle Stimulation</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Mariam Hassib, Max Pfeiffer, Stefan Schneegass, Michael Rohs, Florian Alt 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6133-6146</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025953" title="DOI">10.1145/3025453.3025953</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025953&ftid=1870864&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow652" style="display:inline;"><br /><div style="display:inline">The human body reveals emotional and bodily states through measurable signals, such as body language and electroencephalography. However, such manifestations are difficult to communicate to others remotely. We propose EmotionActuator, a proof-of-concept ...</div></span>
          <span id="toHide652" style="display:none;"><br /><div style="display:inline"><p>The human body reveals emotional and bodily states through measurable signals, such as body language and electroencephalography. However, such manifestations are difficult to communicate to others remotely. We propose EmotionActuator, a proof-of-concept system to investigate the transmission of emotional states in which the recipient performs emotional gestures to understand and interpret the state of the sender.We call this kind of communication embodied emotional feedback, and present a prototype implementation. To realize our concept we chose four emotional states: amused, sad, angry, and neutral. We designed EmotionActuator through a series of studies to assess emotional classification via EEG, and create an EMS gesture set by comparing composed gestures from the literature to sign-language gestures. Through a final study with the end-to-end prototype interviews revealed that participants like implicit sharing of emotions and find the embodied output to be immersive, but want to have control over shared emotions and with whom. This work contributes a proof of concept system and set of design recommendations for designing embodied emotional feedback systems.</p></div></span> <a id="expcoll652" href="JavaScript: expandcollapse('expcoll652',652)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025493&CFID=758305256&CFTOKEN=14863114">Understanding the Role Fluidity of Stakeholders During Assistive Technology Research "In the Wild"</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          LouAnne E. Boyd, Kyle Rector, Halley Profita, Abigale J. Stangl, Annuska Zolyomi, Shaun K. Kane, Gillian R. Hayes 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6147-6158</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025493" title="DOI">10.1145/3025453.3025493</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025493&ftid=1870875&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow653" style="display:inline;"><br /><div style="display:inline">Deploying novel technologies requires the coordinated efforts of the research team, research participants, and a variety of community members and project stakeholders. To ensure that the project is completed successfully, these disparate groups of people ...</div></span>
          <span id="toHide653" style="display:none;"><br /><div style="display:inline"><p>Deploying novel technologies requires the coordinated efforts of the research team, research participants, and a variety of community members and project stakeholders. To ensure that the project is completed successfully, these disparate groups of people engage in articulation work, which is the meta-work that supports the use of collaborative systems. In this paper, we examine the articulation work surrounding the deployment of systems that have found limited long-term adoption: assistive technology. Specifically, we examine three research deployments of a collaborative game for children with autism. Analysis of the articulation work performed during these studies demonstrates how research deployments of technologies create conditions in which stakeholders must take on additional roles to make the deployment work. By understanding the articulation work surrounding deployment studies engendered in this role fluidity, we can improve both research design and the analysis of data emergent from these studies.</p></div></span> <a id="expcoll653" href="JavaScript: expandcollapse('expcoll653',653)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Health Volunteers</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025616&CFID=758305256&CFTOKEN=14863114">Video Consumption Patterns for First Time Smartphone Users: Community Health Workers in Lesotho</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Maletsabisa Molapo, Melissa Densmore, Brian DeRenzi 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6159-6170</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025616" title="DOI">10.1145/3025453.3025616</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025616&ftid=1870856&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow655" style="display:inline;"><br /><div style="display:inline">There is already strong evidence that mobile videos are a good vehicle for public health information dissemination, but there remain open questions around sustainability, appropriate target users, consumption patterns, content, and usage models. We analyse ...</div></span>
          <span id="toHide655" style="display:none;"><br /><div style="display:inline"><p>There is already strong evidence that mobile videos are a good vehicle for public health information dissemination, but there remain open questions around sustainability, appropriate target users, consumption patterns, content, and usage models. We analyse log and interview data of 42 community health workers (who were first time smartphone users) from a longitudinal 17-month deployment to better understand how the utility of mobile videos played out over time in rural Lesotho. During the study period, videos were viewed at an average of 170 times per month, for a total of 2898 views. Through this data we draw these primary findings: a) pausing is not contextually necessary, b) age is not a barrier to usage, c) the primary predictor of popularity of a given video is topical relevance and national campaigns, d) there is no apparent relationship between video length, popularity and completion rates, and e) new videos have only a short-lived novelty effect. Furthermore, we affirm that regular engagement with CHWs has an impact on continued usage, in addition to being important for reducing attrition due to technical issues.</p></div></span> <a id="expcoll655" href="JavaScript: expandcollapse('expcoll655',655)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025881&CFID=758305256&CFTOKEN=14863114">Experiences of Delivering a Public Health Data Service</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Emma Simpson, Rob Comber, Andrew Garbett, Ed Ian Jenkins, Madeline Balaam 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6171-6183</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025881" title="DOI">10.1145/3025453.3025881</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025881&ftid=1870858&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow656" style="display:inline;"><br /><div style="display:inline">The turn to in-the-wild within HCI has given rise to an increasing concern around designing technologies which are available at large scale. Uniquely, at the intersection of public health and HCI, our work has supported the deployment of a mobile application, ...</div></span>
          <span id="toHide656" style="display:none;"><br /><div style="display:inline"><p>The turn to in-the-wild within HCI has given rise to an increasing concern around designing technologies which are available at large scale. Uniquely, at the intersection of public health and HCI, our work has supported the deployment of a mobile application, FeedFinder, over the last three years. We delineate the ground-work that was required to sustain this mobile application over the long-term. Focussing in particular on efforts made to engage institutions in taking ownership over FeedFinder and the data it provides, we reflect on the tensions that arose between users and civic institutions, particularly around "what matters". We provide a reflection on key requirements when designing a health data service and provide three lessons learnt which can guide researchers toward their own successful and productive long-term research deployments.</p></div></span> <a id="expcoll656" href="JavaScript: expandcollapse('expcoll656',656)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3026045&CFID=758305256&CFTOKEN=14863114">Understanding Volunteer AT Fabricators: Opportunities and Challenges in DIY-AT for Others in e-NABLE</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Jeremiah Parry-Hill, Patrick C. Shih, Jennifer Mankoff, Daniel Ashbrook 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6184-6194</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3026045" title="DOI">10.1145/3025453.3026045</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3026045&ftid=1870884&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow657" style="display:inline;"><br /><div style="display:inline">We present the results of a study of e-NABLE, a distributed, collaborative volunteer effort to design and fabricate upper-limb assistive technology devices for limb-different users. Informed by interviews with 14 stakeholders in e-NABLE, including volunteers ...</div></span>
          <span id="toHide657" style="display:none;"><br /><div style="display:inline"><p>We present the results of a study of e-NABLE, a distributed, collaborative volunteer effort to design and fabricate upper-limb assistive technology devices for limb-different users. Informed by interviews with 14 stakeholders in e-NABLE, including volunteers and clinicians, we discuss differences and synergies among each group with respect to motivations, skills, and perceptions of risks inherent in the project. We found that both groups are motivated to be involved in e-NABLE by the ability to use their skills to help others, and that their skill sets are complementary, but that their different perceptions of risk may result in uneven outcomes or missed expectations for end users. We offer four opportunities for design and technology to enhance the stakeholders' abilities to work together.</p></div></span> <a id="expcoll657" href="JavaScript: expandcollapse('expcoll657',657)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025776&CFID=758305256&CFTOKEN=14863114">VITA: Towards Supporting Volunteer Interactions with Long-Term Care Residents with Dementia</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Pin Sym Foong, Shengdong Zhao, Kelsey Carlson, Zhe Liu 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6195-6207</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025776" title="DOI">10.1145/3025453.3025776</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025776&ftid=1870870&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow658" style="display:inline;"><br /><div style="display:inline">Volunteers are an important resource at long-term care homes because they can supply services, such as engagement activities, that over-burdened care staff struggle to provide. However, volunteers without sufficient training are often challenged in responding ...</div></span>
          <span id="toHide658" style="display:none;"><br /><div style="display:inline"><p>Volunteers are an important resource at long-term care homes because they can supply services, such as engagement activities, that over-burdened care staff struggle to provide. However, volunteers without sufficient training are often challenged in responding to dementia-linked behaviors, which can lead to frustrating difficulties during interaction. Additionally, short-staffed care homes have difficulties in training and maintaining volunteers. To better support volunteers in providing engagement activities for people with dementia without a high training burden, we created VITA, a tablet-based system that supplies carefully designed profiling and guidance using our dementia-appropriate engagement activity kit. Our evaluation indicated that the instructional guide supplied by VITA significantly improves volunteers' ability to facilitate engagement activities with people with dementia, approaching the level of engagement achievable by professional therapists.</p></div></span> <a id="expcoll658" href="JavaScript: expandcollapse('expcoll658',658)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Helping Software Developers</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025597&CFID=758305256&CFTOKEN=14863114">Micro-Versioning Tool to Support Experimentation in Exploratory Programming</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Hiroaki Mikami, Daisuke Sakamoto, Takeo Igarashi 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6208-6219</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025597" title="DOI">10.1145/3025453.3025597</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025597&ftid=1870888&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow660" style="display:inline;"><br /><div style="display:inline">Experimentation plays an essential role in exploratory programming, and programmers apply version control operations when switching the part of the source code back to the past state during experimentation. However, these operations, which we refer to ...</div></span>
          <span id="toHide660" style="display:none;"><br /><div style="display:inline"><p>Experimentation plays an essential role in exploratory programming, and programmers apply version control operations when switching the part of the source code back to the past state during experimentation. However, these operations, which we refer to as <i>micro-versioning</i>, are not well supported in current programming environments. We first examined previous studies to clarify the requirements for a micro-versioning tool. We then developed a micro-versioning tool that displays visual cues representing possible micro-versioning operations in a textual code editor. Our tool includes a history model that generates meaningful candidates by combining a regional undo model and tree-structured undo model. The history model uses code executions as a delimiter to segment text edit operations into meaning groups. A user study involving programmers indicated that our tool satisfies the above-mentioned requirements and that it is useful for exploratory programming.</p></div></span> <a id="expcoll660" href="JavaScript: expandcollapse('expcoll660',660)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025972&CFID=758305256&CFTOKEN=14863114">Codeon: On-Demand Software Development Assistance</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Yan Chen, Sang Won Lee, Yin Xie, YiWei Yang, Walter S. Lasecki, Steve Oney 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6220-6231</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025972" title="DOI">10.1145/3025453.3025972</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025972&ftid=1870904&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow661" style="display:inline;"><br /><div style="display:inline">Software developers rely on support from a variety of resources---including other developers---but the coordination cost of finding another developer with relevant experience, explaining the context of the problem, composing a specific help request, ...</div></span>
          <span id="toHide661" style="display:none;"><br /><div style="display:inline"><p>Software developers rely on support from a variety of resources---including other developers---but the coordination cost of finding another developer with relevant experience, explaining the context of the problem, composing a specific help request, and providing access to relevant code is prohibitively high for all but the largest of tasks. Existing technologies for synchronous communication (e.g. voice chat) have high scheduling costs, and asynchronous communication tools (e.g. forums) require developers to carefully describe their code context to yield useful responses. This paper introduces Codeon, a system that enables more effective task hand-off between end-user developers and remote helpers by allowing asynchronous responses to on-demand requests. With Codeon, developers can request help by speaking their requests aloud within the context of their IDE. Codeon automatically captures the relevant code context and allows remote helpers to respond with high-level descriptions, code annotations, code snippets, and natural language explanations. Developers can then immediately view and integrate these responses into their code. In this paper, we describe Codeon, the studies that guided its design, and our evaluation that its effectiveness as a support tool. In our evaluation, developers using Codeon completed nearly twice as many tasks as those who used state-of-the-art synchronous video and code sharing tools, by reducing the coordination costs of seeking assistance from other developers.</p></div></span> <a id="expcoll661" href="JavaScript: expandcollapse('expcoll661',661)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025818&CFID=758305256&CFTOKEN=14863114">PFIS-V: Modeling Foraging Behavior in the Presence of Variants</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Sruti Srinivasa Ragavan, Bhargav Pandya, David Piorkowski, Charles Hill, Sandeep Kaur Kuttal, Anita Sarma, Margaret Burnett 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6232-6244</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025818" title="DOI">10.1145/3025453.3025818</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025818&ftid=1870873&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow662" style="display:inline;"><br /><div style="display:inline">Foraging among similar variants of the same artifact is a common activity, but computational models of Information Foraging Theory (IFT) have not been developed to take such variants into account. Without being able to computationally predict people's ...</div></span>
          <span id="toHide662" style="display:none;"><br /><div style="display:inline"><p>Foraging among similar variants of the same artifact is a common activity, but computational models of Information Foraging Theory (IFT) have not been developed to take such variants into account. Without being able to computationally predict people's foraging behavior with variants, our ability to harness the theory in practical ways--such as building and systematically assessing tools for people who forage different variants of an artifact--is limited. Therefore, in this paper, we introduce a new predictive model, PFIS-V, that builds upon PFIS3, the most recent of the PFIS family of modeling IFT in programming situations. Our empirical results show that PFIS-V is up to 25% more accurate than PFIS3 in predicting where a forager will navigate in a variationed information space.</p></div></span> <a id="expcoll662" href="JavaScript: expandcollapse('expcoll662',662)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025573&CFID=758305256&CFTOKEN=14863114">Improving Communication Between Pair Programmers Using Shared Gaze Awareness</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Sarah D'Angelo, Andrew Begel 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6245-6290</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025573" title="DOI">10.1145/3025453.3025573</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025573&ftid=1870906&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow663" style="display:inline;"><br /><div style="display:inline">Remote collaboration can be more difficult than collocated collaboration for a number of reasons, including the inability to easily determine what your collaborator is looking at. This impedes a pair's ability to efficiently communicate about on-screen ...</div></span>
          <span id="toHide663" style="display:none;"><br /><div style="display:inline"><p>Remote collaboration can be more difficult than collocated collaboration for a number of reasons, including the inability to easily determine what your collaborator is looking at. This impedes a pair's ability to efficiently communicate about on-screen locations and makes synchronous coordination difficult. We designed a novel gaze visualization for remote pair programmers which shows where in the code their partner is currently looking, and changes color when they are looking at the same thing. Our design is unobtrusive, and transparently depicts the imprecision inherent in eye tracking technology. We evaluated our design with an experiment in which pair programmers worked remotely on code refactoring tasks. Our results show that with the visualization, pairs spent a greater proportion of their time concurrently looking at the same code locations. Pairs communicated using a larger ratio of implicit to explicit references, and were faster and more successful at responding to those references.</p></div></span> <a id="expcoll663" href="JavaScript: expandcollapse('expcoll663',663)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Interactive Design Methodologies</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025740&CFID=758305256&CFTOKEN=14863114">Post-userism</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Eric P. S. Baumer, Jed R. Brubaker 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6291-6303</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025740" title="DOI">10.1145/3025453.3025740</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025740&ftid=1871157&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow665" style="display:inline;"><br /><div style="display:inline">HCI is focused on improving the interactions we have with technology and innovating new types of interactions, as well as expanding the types of people for whom those interactions are designed. Central to these efforts is the simultaneously empowering ...</div></span>
          <span id="toHide665" style="display:none;"><br /><div style="display:inline"><p>HCI is focused on improving the interactions we have with technology and innovating new types of interactions, as well as expanding the types of people for whom those interactions are designed. Central to these efforts is the simultaneously empowering and contested construct of the "user." This paper examines what the construct of the user highlights, as well as what it conceals. We introduce post-userism, a perspective that simultaneously acknowledges the limits of, and proposes alternatives to, the central construct of the user as proxy for the "human" in HCI. Drawing on developments across the historical trajectory of HCI, we articulate how the user is enacted across four different levels of representation-systems, interface, design process, and the ideology and identify situations where the user breaks down. Synthesizing prior work, we offer a series of strategies for grappling with such situations. In doing so, we seek to overcome the limitations imposed by the user and develop a language that will aid in evolving the foundations of HCI by asking what, exactly, we place at the center of our scholarship and design.</p></div></span> <a id="expcoll665" href="JavaScript: expandcollapse('expcoll665',665)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3026034&CFID=758305256&CFTOKEN=14863114">Tap the: A Design-Based Inquiry into Issue Advocacy and Digital Civics</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Mariam Asad, Christopher A. Le Dantec 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6304-6316</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3026034" title="DOI">10.1145/3025453.3026034</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3026034&ftid=1871162&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow666" style="display:inline;"><br /><div style="display:inline">This paper examines the strategies of cycling advocates when deploying digital tools in their advocacy work as they support and create better cycling infrastructure and policies. Over the course of two years, we interviewed and conducted design-based ...</div></span>
          <span id="toHide666" style="display:none;"><br /><div style="display:inline"><p>This paper examines the strategies of cycling advocates when deploying digital tools in their advocacy work as they support and create better cycling infrastructure and policies. Over the course of two years, we interviewed and conducted design-based fieldwork in two large U.S. cities with individuals and advocacy organizations, learning about the goals, motivations, and constraints that inform their work in their respective urban homes. Our design-based investigation and fieldwork advance a deeper, situated understanding of the role that computing technology plays when engaging across multiple sites of advocacy work. From this, we add detail to the connections across resources, identities, and issues and continue to advance the emerging area of digital civics, which seeks to design tools that support relational civic interactions across multiple categories of civic actors.</p></div></span> <a id="expcoll666" href="JavaScript: expandcollapse('expcoll666',666)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025606&CFID=758305256&CFTOKEN=14863114">Enabling Polyvocality in Interactive Documentaries through "Structural Participation"</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          David Philip Green, Simon Bowen, Jonathan Hook, Peter Wright 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6317-6329</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025606" title="DOI">10.1145/3025453.3025606</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025606&ftid=1871139&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow667" style="display:inline;"><br /><div style="display:inline">Recent innovations in online, social and interactive media have led to the emergence of new forms of documentary, such as interactive documentaries ('i-Docs'), with qualities that lend themselves to more open and inclusive production structures. Still, ...</div></span>
          <span id="toHide667" style="display:none;"><br /><div style="display:inline"><p>Recent innovations in online, social and interactive media have led to the emergence of new forms of documentary, such as interactive documentaries ('i-Docs'), with qualities that lend themselves to more open and inclusive production structures. Still, little is known about the experience of making and/or participating-in these kinds of documentary. Our two-year <i>in-the-wild</i> study engaged a large community-of-interest in the production of an i-Doc to explore the ethically-desirable yet challenging aim of enabling multiple subjects to have agency and control over their representation in a documentary. Our study reveals insights into the experiences of participating in an i-Doc and highlights key sociotechnical challenges. We argue that new sociotechnical infrastructure is needed, that frames both "executory" and "structural" forms of participation as symbiotic elements of a co-design process.</p></div></span> <a id="expcoll667" href="JavaScript: expandcollapse('expcoll667',667)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/bp_award.jpg" alt="Best Paper" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025927&CFID=758305256&CFTOKEN=14863114">Supporting Expressive Procedural Art Creation through Direct Manipulation</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Jennifer Jacobs, Sumit Gogia, Radom&#237;r M&#277;ch, Joel R. Brandt 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6330-6341</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025927" title="DOI">10.1145/3025453.3025927</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025927&ftid=1871169&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow668" style="display:inline;"><br /><div style="display:inline">Computation is a powerful artistic medium. Artists with experience in programming have demonstrated the unique creative opportunities of using code to make art. Currently, manual artists interested in using procedural techniques must undergo the difficult ...</div></span>
          <span id="toHide668" style="display:none;"><br /><div style="display:inline"><p>Computation is a powerful artistic medium. Artists with experience in programming have demonstrated the unique creative opportunities of using code to make art. Currently, manual artists interested in using procedural techniques must undergo the difficult process of learning to program, and must adopt tools and practices far removed from those to which they are accustomed. We hypothesize that, through the right <i>direct manipulation interface</i>, we can enable <i>accessible and expressive</i> procedural art creation. To explore this, we developed Para, a digital illustration tool that supports the creation of declarative constraints in vector artwork. Para's constraints enable procedural relationships while facilitating live manual control and non-linear editing. Constraints can be combined with duplication behaviors and ordered collections of artwork to produce complex, dynamic compositions. We use the results of two open-ended studies with professional artists and designers to provide guidelines for accessible tools that integrate manual and procedural expression.</p></div></span> <a id="expcoll668" href="JavaScript: expandcollapse('expcoll668',668)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Motivation in Peer-production Communities</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025992&CFID=758305256&CFTOKEN=14863114">Crowd Diversity and Performance in Wikipedia: The Mediating Effects of Task Conflict and Communication</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Ruqin Ren, Bei Yan 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6342-6351</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025992" title="DOI">10.1145/3025453.3025992</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025992&ftid=1871140&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow670" style="display:inline;"><br /><div style="display:inline">Crowd diversity is a key attribute that impacts crowd performance in online collaboration systems. As a structural composition of a crowd, diversity is likely to influence crowd performance through communication processes during collaboration. This study ...</div></span>
          <span id="toHide670" style="display:none;"><br /><div style="display:inline"><p>Crowd diversity is a key attribute that impacts crowd performance in online collaboration systems. As a structural composition of a crowd, diversity is likely to influence crowd performance through communication processes during collaboration. This study examined how diversity influenced crowd performance under different conditions of task conflict and communication in Wikipedia article production. With a sample of 5,899 articles, we found that contribution diversity positively predicted crowd performance, whereas experience diversity was negatively related to performance. In addition, task communication and conflict partially mediated the relationship between crowd diversity and performance. Task communication positively predicted performance for both forms of diversity. Task conflict, on the other hand, was positively predicted by expertise diversity, but had negative associations with contribution diversity and performance. The findings help unpack the reasons for differential effects of diversity on crowd performance, and demonstrate the importance of including communication variables when studying online crowd collaboration.</p></div></span> <a id="expcoll670" href="JavaScript: expandcollapse('expcoll670',670)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025940&CFID=758305256&CFTOKEN=14863114">Freedom versus Standardization: Structured Data Generation in a Peer Production Community</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Andrew Hall, Sarah McRoberts, Jacob Thebault-Spieker, Yilun Lin, Shilad Sen, Brent Hecht, Loren Terveen 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6352-6362</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025940" title="DOI">10.1145/3025453.3025940</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025940&ftid=1871186&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow671" style="display:inline;"><br /><div style="display:inline">In addition to encyclopedia articles and software, peer production communities produce structured data, e.g., Wikidata and OpenStreetMap's metadata. Structured data from peer production communities has become increasingly important due to its use by ...</div></span>
          <span id="toHide671" style="display:none;"><br /><div style="display:inline"><p>In addition to encyclopedia articles and software, peer production communities produce structured data, e.g., Wikidata and OpenStreetMap's metadata. Structured data from peer production communities has become increasingly important due to its use by computational applications, such as CartoCSS, MapBox, and Wikipedia infoboxes. However, this structured data is usable by applications only if it follows standards. We did an interview study focused on OpenStreetMap's knowledge production processes to investigate how -- and how successfully -- this community creates and applies its data standards. Our study revealed a fundamental tension between the need to produce structured data in a standardized way and OpenStreetMap's tradition of contributor freedom. We extracted six themes that manifested this tension and three overarching concepts, correctness, community, and code, which help make sense of and synthesize the themes. We also offered suggestions for improving OpenStreetMap's knowledge production processes, including new data models, sociotechnical tools, and community practices (e.g. stronger leadership).</p></div></span> <a id="expcoll671" href="JavaScript: expandcollapse('expcoll671',671)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3026008&CFID=758305256&CFTOKEN=14863114">Commitment of Newcomers and Old-timers to Online Health Support Communities</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Diyi Yang, Robert Kraut, John M. Levine 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6363-6375</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3026008" title="DOI">10.1145/3025453.3026008</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3026008&ftid=1871133&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow672" style="display:inline;"><br /><div style="display:inline">For online communities to be successful, they must retain an adequate number of members who contribute to the community. The amount and type of communication members receive can play an important role in generating and sustaining members' commitment ...</div></span>
          <span id="toHide672" style="display:none;"><br /><div style="display:inline"><p>For online communities to be successful, they must retain an adequate number of members who contribute to the community. The amount and type of communication members receive can play an important role in generating and sustaining members' commitment to it. However, the communication that members find valuable may change with their tenure in the community. This paper examines how the communication members receive in an health support community influences their commitment and how this influence changes with their tenure in the community. Commitment was operationalized with three measures: self-reported attachment, continued participation in the community, and responding to others. Results show that receiving communication was generally associated with increased commitment across the three measures, with its impact increasing with members' tenure. However, the average amount of informational and emotional support members received per message was associated with decreased commitment. Results have implications for interventions to encourage members' commitment to their communities throughout their history in the community.</p></div></span> <a id="expcoll672" href="JavaScript: expandcollapse('expcoll672',672)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025639&CFID=758305256&CFTOKEN=14863114">Starting Online Communities: Motivations and Goals of Wiki Founders</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Jeremy Foote, Darren Gergle, Aaron Shaw 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6376-6380</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025639" title="DOI">10.1145/3025453.3025639</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025639&ftid=1871170&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow673" style="display:inline;"><br /><div style="display:inline">Why do people start new online communities? Previous research has studied what helps communities to grow and what motivates contributors, but the reasons that people create new communities in the first place remain unclear. We present the results of ...</div></span>
          <span id="toHide673" style="display:none;"><br /><div style="display:inline"><p>Why do people start new online communities? Previous research has studied what helps communities to grow and what motivates contributors, but the reasons that people create new communities in the first place remain unclear. We present the results of a survey of over 300 founders of new communities on the online wiki hosting site Wikia.com. We analyze the motivations and goals of wiki creators, finding that founders have diverse reasons for starting wikis and diverse ways of defining their success. Many founders see their communities as occupying narrow topics, and neither seek nor expect a large group of contributors. We also find that founders with differing goals approach community building differently. We argue that community platform designers can create interfaces that support the diverse goals of founders more effectively.</p></div></span> <a id="expcoll673" href="JavaScript: expandcollapse('expcoll673',673)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3026057&CFID=758305256&CFTOKEN=14863114">Investigating the Motivational Paths of Peer Production Newcomers</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Martina Balestra, Coye Cheshire, Ofer Arazy, Oded Nov 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6381-6385</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3026057" title="DOI">10.1145/3025453.3026057</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3026057&ftid=1871183&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow674" style="display:inline;"><br /><div style="display:inline">Maintaining participation beyond the initial period of engagement is critical for peer production systems. Theory suggests that an increase in motivation is expected with contributors' movement from the community periphery to the core. Less is known, ...</div></span>
          <span id="toHide674" style="display:none;"><br /><div style="display:inline"><p>Maintaining participation beyond the initial period of engagement is critical for peer production systems. Theory suggests that an increase in motivation is expected with contributors' movement from the community periphery to the core. Less is known, however, about how specific motivations change over time. We fill this gap by focusing on individual motivational paths in the formative periods of engagement, exploring which motivations change and how. We collected data on various instrumental and non-instrumental motivations at two points in study participants? Wikipedia career: when they started editing and again after six months. We found that non-instrumental motivations (including collective and intrinsic motives) decreased significantly over time, in contrast with socially-driven motivations such as norm-oriented motivates which did not change and social motives which increased marginally. The findings offer new insights into newcomers' evolving motivations, with implications for designing and managing peer-production systems.</p></div></span> <a id="expcoll674" href="JavaScript: expandcollapse('expcoll674',674)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Older Adults and Computers</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025618&CFID=758305256&CFTOKEN=14863114">Traversing Boundaries: Understanding the Experiences of Ageing Saudis</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Soud Nassir, Tuck Wah Leong 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6386-6397</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025618" title="DOI">10.1145/3025453.3025618</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025618&ftid=1871137&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow676" style="display:inline;"><br /><div style="display:inline">This is a methods paper that draws from our fieldwork conducted in Saudi Arabia to understand ageing people's experiences. This paper focuses on insights gained when using qualitative methods to understand the experiences of ageing Saudis. The aim is ...</div></span>
          <span id="toHide676" style="display:none;"><br /><div style="display:inline"><p>This is a methods paper that draws from our fieldwork conducted in Saudi Arabia to understand ageing people's experiences. This paper focuses on insights gained when using qualitative methods to understand the experiences of ageing Saudis. The aim is to highlight some of the cultural considerations, opportunities, challenges, and issues that influenced our approach and deployment of interviews and probes. Influences of social-cultural practices and religion led to interesting challenges for recruitment, conducting cross-gender communications, and how participants reported their experiences. This paper offers methodological considerations that include the influences of local culture, gender, religion, etc. We also discuss how we shaped our fieldwork tools based upon considerations of local cultural and religious contexts. In particular, we highlight the usefulness of probes in traversing cultural boundaries.</p></div></span> <a id="expcoll676" href="JavaScript: expandcollapse('expcoll676',676)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025913&CFID=758305256&CFTOKEN=14863114">Transitions in Digital Personhood: Online Activity in Early Retirement</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Abigail Durrant, David Kirk, Diego Trujillo Pisanty, Wendy Moncur, Kathryn Orzech, Tom Schofield, Chris Elsden, David Chatting, Andrew Monk 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6398-6411</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025913" title="DOI">10.1145/3025453.3025913</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025913&ftid=1871182&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow677" style="display:inline;"><br /><div style="display:inline">We present findings from a qualitative study about how Internet use supports self-functioning following the life transition of retirement from work. This study recruited six recent retirees and included the deployment of OnLines, a design research artifact ...</div></span>
          <span id="toHide677" style="display:none;"><br /><div style="display:inline"><p>We present findings from a qualitative study about how Internet use supports self-functioning following the life transition of retirement from work. This study recruited six recent retirees and included the deployment of OnLines, a design research artifact that logged and visualized key online services used by participants at home over four-weeks. The deployment was supported by pre- and post-deployment interviews. OnLines prompted participants' reflection on their patterns of Internet use. Position Exchange Theory was used to understand retirees' sense making from a lifespan perspective, informing the design of supportive online services. This paper delivers a three-fold contribution to the field of human-computer interaction, advancing a lifespan-oriented approach by conceptualizing the self as a dialogical phenomenon that develops over time, advancing the ageing discourse by reporting on retirees' complex identities in the context of their life histories, and advancing discourse on research through design by developing OnLines to foster participant-researcher reflection informed by Self Psychology.</p></div></span> <a id="expcoll677" href="JavaScript: expandcollapse('expcoll677',677)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025831&CFID=758305256&CFTOKEN=14863114">Dissecting Spear Phishing Emails for Older vs Young Adults: On the Interplay of Weapons of Influence and Life Domains in Predicting Susceptibility to Phishing</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Daniela Oliveira, Harold Rocha, Huizi Yang, Donovan Ellis, Sandeep Dommaraju, Melis Muradoglu, Devon Weir, Adam Soliman, Tian Lin, Natalie Ebner 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6412-6424</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025831" title="DOI">10.1145/3025453.3025831</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025831&ftid=1871194&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow678" style="display:inline;"><br /><div style="display:inline">Spear phishing emails are key in many cyber attacks. Successful emails employ psychological weapons of influence and relevant life domains. This paper investigates spear phishing susceptibility as a function of Internet user age (old vs young), weapon ...</div></span>
          <span id="toHide678" style="display:none;"><br /><div style="display:inline"><p>Spear phishing emails are key in many cyber attacks. Successful emails employ psychological weapons of influence and relevant life domains. This paper investigates spear phishing susceptibility as a function of Internet user age (old vs young), weapon of influence, and life domain. A 21-day study was conducted with 158 participants (younger and older Internet users). Data collection took place at the participants' homes to increase ecological validity. Our results show that older women were the most vulnerable group to phishing attacks. While younger adults were most susceptible to scarcity, older adults were most susceptible to reciprocation. Further, there was a discrepancy, particularly among older users, between self-reported susceptibility awareness and their behavior during the intervention. Our results show the need for demographic personalization for warnings, training and educational tools in targeting the specifics of the older adult population.</p></div></span> <a id="expcoll678" href="JavaScript: expandcollapse('expcoll678',678)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025861&CFID=758305256&CFTOKEN=14863114">Privacy Considerations when Designing Social Network Systems to Support Successful Ageing</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Andrew R. McNeill, Lynne Coventry, Jake Pywell, Pam Briggs 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6425-6437</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025861" title="DOI">10.1145/3025453.3025861</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025861&ftid=1871190&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow679" style="display:inline;"><br /><div style="display:inline">A number of interventions exist to support older adults in ageing well and these typically involve support for an active and sociable ageing process. We set out to examine the privacy implications of an intervention that would monitor mobility and share ...</div></span>
          <span id="toHide679" style="display:none;"><br /><div style="display:inline"><p>A number of interventions exist to support older adults in ageing well and these typically involve support for an active and sociable ageing process. We set out to examine the privacy implications of an intervention that would monitor mobility and share lifestyle and health data with a community of trusted others. We took a privacy-by-design approach to the system in the early stages of its development, working with older adults to firstly understand their networks of trust and secondly understand their privacy concerns should information be exchanged across that network. We used a Johari Windows framework in the thematic analysis of our data, concluding that the social sharing of information in later life carried significant risk. Our participants worried about the social signaling associated with data sharing and were cautious about a system that had the potential to disrupt established networks.</p></div></span> <a id="expcoll679" href="JavaScript: expandcollapse('expcoll679',679)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Spatial &#38; Temporal Design</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025962&CFID=758305256&CFTOKEN=14863114">Malleable Embodiment: Changing Sense of Embodiment by Spatial-Temporal Deformation of Virtual Human Body</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Shunichi Kasahara, Keina Konno, Richi Owaki, Tsubasa Nishi, Akiko Takeshita, Takayuki Ito, Shoko Kasuga, Junichi Ushiba 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6438-6448</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025962" title="DOI">10.1145/3025453.3025962</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025962&ftid=1871177&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow681" style="display:inline;"><br /><div style="display:inline">We hypothesize that replacing the visual perception of one's body with a spatial-temporal deformed state would change sensations associated with the body. We developed a system that captures full-body movement and generates estimated past and future ...</div></span>
          <span id="toHide681" style="display:none;"><br /><div style="display:inline"><p>We hypothesize that replacing the visual perception of one's body with a spatial-temporal deformed state would change sensations associated with the body. We developed a system that captures full-body movement and generates estimated past and future body movement by deformation. With a head mounted display, people could see their bodies as slightly deformed. We then investigated 1) how human movement is physically changed, and 2) how humans feel about the change in physical and emotional views of the body due to virtual body deformation. Our results show that spatial-temporal deformation of a virtual body actually changes the sense of body as well as physical movement. For instance, a body image generated at approximately 25-100 ms in the future induced a "lighter weight" sensation. On the basis of our findings, we discuss the design implication of computational control for the physical and emotional sense of body.</p></div></span> <a id="expcoll681" href="JavaScript: expandcollapse('expcoll681',681)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025756&CFID=758305256&CFTOKEN=14863114">Sensitizing Concepts for Socio-spatial Literacy in HCI</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Peter Gall Krogh, Marianne Graves Petersen, Kenton O'Hara, Jens Emil Groenbaek 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6449-6460</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025756" title="DOI">10.1145/3025453.3025756</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025756&ftid=1871141&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow682" style="display:inline;"><br /><div style="display:inline">People inherently share spaces with other people. Congenitally, interactive technologies and ubiquitous environments shape our opportunities for enacting social relations. Proxemics and Spatial Sharing have been suggested as foundations for our understanding ...</div></span>
          <span id="toHide682" style="display:none;"><br /><div style="display:inline"><p>People inherently share spaces with other people. Congenitally, interactive technologies and ubiquitous environments shape our opportunities for enacting social relations. Proxemics and Spatial Sharing have been suggested as foundations for our understanding of the socio-spatial aspects of computing. By tandeming these theoretical perspectives in a set of cases in the office domain, we develop a contribution comprised of 3 key sensitizing concepts: <i>Proxemic Malleability, Proxemic Threshold and Proxemic Gravity</i> articulating socio-spatial qualities at the interplay between interactive systems, spaces, interior elements and co-located people. The sensitizing concepts qualify interaction designers in considering proxemic consequences of technology design; they serve both as analytic lenses and as generative instruments in a design process. The proposed sensitizing concepts and the theoretical work of the paper contribute to enhanced Socio-spatial literacy in HCI.</p></div></span> <a id="expcoll682" href="JavaScript: expandcollapse('expcoll682',682)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025936&CFID=758305256&CFTOKEN=14863114">Situational When: Designing for Time Across Cultures</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Jennyfer Lawrence Taylor, Alessandro Soro, Paul Roe, Anita Lee Hong, Margot Brereton 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6461-6474</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025936" title="DOI">10.1145/3025453.3025936</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025936&ftid=1871163&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow683" style="display:inline;"><br /><div style="display:inline">We propose the concept of "Situational When", an approach to understanding time in interface design not as a point on a calendar or clock, but as a set of converging circumstances that constitute "the time" for happenings to take place. Time is encoded ...</div></span>
          <span id="toHide683" style="display:none;"><br /><div style="display:inline"><p>We propose the concept of "Situational When", an approach to understanding time in interface design not as a point on a calendar or clock, but as a set of converging circumstances that constitute "the time" for happenings to take place. Time is encoded both explicitly and implicitly in designed products. However, many technologies propagate business-centric, modernist values such as scheduling and efficiency, and marginalize broader socio-cultural aspects on which many activities are nonetheless contingent, e.g. the right people, the right weather conditions, and the right vibe. We derive our reflections from a case study of a cross-cultural digital noticeboard designed with an Australian Aboriginal community. Attention to the situational when opens up new possibilities for design that put greater emphasis on the social and relational aspects of time, the situational insights embodied in local narratives, and the tangible (e.g. people) and intangible (e.g. energy) circumstances that together make up the "right" time.</p></div></span> <a id="expcoll683" href="JavaScript: expandcollapse('expcoll683',683)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025916&CFID=758305256&CFTOKEN=14863114">Modeling Sub-Document Attention Using Viewport Time</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Max Grusky, Jeiran Jahani, Josh Schwartz, Dan Valente, Yoav Artzi, Mor Naaman 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6475-6480</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025916" title="DOI">10.1145/3025453.3025916</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025916&ftid=1871154&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow684" style="display:inline;"><br /><div style="display:inline">Website measures of engagement captured from millions of users, such as in-page scrolling and viewport position, can provide deeper understanding of attention than possible with simpler measures, such as dwell time. Using data from 1.2M news reading ...</div></span>
          <span id="toHide684" style="display:none;"><br /><div style="display:inline"><p>Website measures of engagement captured from millions of users, such as in-page scrolling and viewport position, can provide deeper understanding of attention than possible with simpler measures, such as dwell time. Using data from 1.2M news reading sessions, we examine and evaluate three increasingly sophisticated models of sub-document attention computed from <i>viewport time</i>, the time a page component is visible on the user display. Our modeling incorporates prior eye-tracking knowledge about onscreen reading, and we validate it by showing how, when used to estimate user reading rate, it aligns with known empirical measures. We then show how our models reveal an interaction between article topic and attention to page elements. Our approach supports refined large-scale measurement of user engagement at a level previously available only from lab-based eye-tracking studies.</p></div></span> <a id="expcoll684" href="JavaScript: expandcollapse('expcoll684',684)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025717&CFID=758305256&CFTOKEN=14863114">Remote Collaboration With Mixed Reality Displays: How Shared Virtual Landmarks Facilitate Spatial Referencing</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Jens M&#252;ller, Roman R&#228;dle, Harald Reiterer 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6481-6486</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025717" title="DOI">10.1145/3025453.3025717</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025717&ftid=1871142&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow685" style="display:inline;"><br /><div style="display:inline">HCI research has demonstrated Mixed Reality (MR) as being beneficial for co-located collaborative work. For remote collaboration, however, the collaborators' visual contexts do not coincide due to their individual physical environments. The problem becomes ...</div></span>
          <span id="toHide685" style="display:none;"><br /><div style="display:inline"><p>HCI research has demonstrated Mixed Reality (MR) as being beneficial for co-located collaborative work. For remote collaboration, however, the collaborators' visual contexts do not coincide due to their individual physical environments. The problem becomes apparent when collaborators refer to physical landmarks in their individual environments to guide each other's attention. In an experimental study with 16 dyads, we investigated how the provisioning of shared virtual landmarks (SVLs) influences communication behavior and user experience. A quantitative analysis revealed that participants used significantly less ambiguous spatial expressions and reported an improved user experience when SVLs were provided. Based on these findings and a qualitative video analysis we provide implications for the design of MRs to facilitate remote collaboration.</p></div></span> <a id="expcoll685" href="JavaScript: expandcollapse('expcoll685',685)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>The Infrastructure of Trust</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025959&CFID=758305256&CFTOKEN=14863114">Growing the Blockchain Information Infrastructure</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Karim Jabbar, Pernille Bj&#248;rn 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6487-6498</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025959" title="DOI">10.1145/3025453.3025959</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025959&ftid=1871165&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow687" style="display:inline;"><br /><div style="display:inline">In this paper, we present ethnographic data that unpacks the everyday work of some of the many infrastructuring agents who contribute to creating, sustaining and growing the Blockchain information infrastructure. We argue that this infrastructuring work ...</div></span>
          <span id="toHide687" style="display:none;"><br /><div style="display:inline"><p>In this paper, we present ethnographic data that unpacks the everyday work of some of the many infrastructuring agents who contribute to creating, sustaining and growing the Blockchain information infrastructure. We argue that this infrastructuring work takes the form of entrepreneurial actions, which are self-initiated and primarily directed at sustaining or increasing the initiator's stake in the emerging information infrastructure. These entrepreneurial actions wrestle against the affordances of the installed base of the Blockchain infrastructure, and take the shape of engaging or circumventing activities. These activities purposefully aim at either influencing or working around the enablers and constraints afforded by the Blockchain information infrastructure, as its installed base is gaining inertia. This study contributes to our understanding of the purpose of infrastructuring, seen from the perspective of heterogeneous entrepreneurial agents. It supplements existing accounts of the "when" and "how" of infrastructure, with a lens for examining the "why" of infrastructure.</p></div></span> <a id="expcoll687" href="JavaScript: expandcollapse('expcoll687',687)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025886&CFID=758305256&CFTOKEN=14863114">Design for Trust: An Exploration of the Challenges and Opportunities of Bitcoin Users</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Corina Sas, Irni Eliana Khairuddin 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6499-6510</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025886" title="DOI">10.1145/3025453.3025886</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025886&ftid=1871195&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow688" style="display:inline;"><br /><div style="display:inline">Bitcoin is a cryptocurrency which has received increasing interest over the last five years. Built upon a decentralized peer to peer system, it supports transparent, fast, cost effective, and irreversible transactions, without the need for trusting third ...</div></span>
          <span id="toHide688" style="display:none;"><br /><div style="display:inline"><p>Bitcoin is a cryptocurrency which has received increasing interest over the last five years. Built upon a decentralized peer to peer system, it supports transparent, fast, cost effective, and irreversible transactions, without the need for trusting third party financial institutions. We know however little about people's motivation and experience with bitcoin currency. This paper reports on interviews with 20 bitcoin users in Malaysia about their experience and trust challenges. Findings show that bitcoins are used more as store of value for speculative investment or savings' protection. The paper advances the HCI theories on trust by identifying main bitcoin characteristics and their impact on trust, such as decentralization, unregulation, embedded expertise, and reputation, as well as transactions' transparency, low cost, and easiness to complete. We discuss insecure transactions, the risk of dishonest traders and its mitigating strategies. The paper concludes with design implications including support for the transparency of two-way transactions, tools for materializing trust, and tools for supporting reversible transactions.</p></div></span> <a id="expcoll688" href="JavaScript: expandcollapse('expcoll688',688)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025889&CFID=758305256&CFTOKEN=14863114">Infrastructure as Creative Action: Online Buying, Selling, and Delivery in Phnom Penh</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Margaret Jack, Jay Chen, Steven J. Jackson 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6511-6522</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025889" title="DOI">10.1145/3025453.3025889</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025889&ftid=1871158&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow689" style="display:inline;"><br /><div style="display:inline">This paper describes a complex global sales and logistics network based in Phnom Penh, Cambodia, which utilizes Internet tools (particularly Facebook) as well as a suite of offline tools such as feature phones, paper receipts, and motorcycles to facilitate ...</div></span>
          <span id="toHide689" style="display:none;"><br /><div style="display:inline"><p>This paper describes a complex global sales and logistics network based in Phnom Penh, Cambodia, which utilizes Internet tools (particularly Facebook) as well as a suite of offline tools such as feature phones, paper receipts, and motorcycles to facilitate the buying and selling of clothes and other commodities. Against the gap or import models that sometimes limit HCI understandings of computational change in non-Western environments, we argue that the consumers, business owners, delivery drivers, and call center staff play active and formative roles in producing this infrastructure, integrating new tools into older cultural practices and determining how they work within the limits and conventions of the environment. We argue that resourceful and imaginative activities such as these constitute a form of creative infrastructural action and are central to the ways that new tools circulate in the world, though they often go unrecognized by HCI as innovation.</p></div></span> <a id="expcoll689" href="JavaScript: expandcollapse('expcoll689',689)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025975&CFID=758305256&CFTOKEN=14863114">Supporting Cultures of Making: Technology, Policy, Visions, and Myths</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Shaowen Bardzell, Jeffrey Bardzell, Sarah Ng 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6523-6535</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025975" title="DOI">10.1145/3025453.3025975</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025975&ftid=1871185&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow690" style="display:inline;"><br /><div style="display:inline">Recent HCI research has linked social policy to design, e.g., in issues such as public safety, privacy, and social justice. One area where policy, technology, and design intersect is in the vision of the creative economy. In that vision, creativity, ...</div></span>
          <span id="toHide690" style="display:none;"><br /><div style="display:inline"><p>Recent HCI research has linked social policy to design, e.g., in issues such as public safety, privacy, and social justice. One area where policy, technology, and design intersect is in the vision of the creative economy. In that vision, creativity, distinct local/regional cultural practices, technology, and entrepreneurship synergistically produce social innovation on a scale sufficient to drive economies. Culture and creative industries (CCI) policy specifies how governments intervene to support such clusters. Maker cultures are seen as central to this vision, but comparatively little is known about how makers produce culture. We offer a critical analysis of several encounters between CCI policy in Taiwan and its maker scene. These encounters reveal misalignments that undercut efforts intended to support making. We propose that supporting any creative culture, including making, entails a serious commitment to understanding its culture, including its cultural contents and their means of production. We further argue that scholarly rigor in cultivating cultural appreciation is just as fundamental as scholarly rigor in empirically representing cultural practices when it comes to pursuing such a cultural understanding.</p></div></span> <a id="expcoll690" href="JavaScript: expandcollapse('expcoll690',690)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Video "Smart" Viewers</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025821&CFID=758305256&CFTOKEN=14863114">EgoScanning: Quickly Scanning First-Person Videos with Egocentric Elastic Timelines</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Keita Higuchi, Ryo Yonetani, Yoichi Sato 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6536-6546</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025821" title="DOI">10.1145/3025453.3025821</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025821&ftid=1871148&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow692" style="display:inline;"><br /><div style="display:inline">This work presents EgoScanning, a novel video fast-forwarding interface that helps users to find important events from lengthy first-person videos recorded with wearable cameras continuously. This interface is featured by an elastic timeline that adaptively ...</div></span>
          <span id="toHide692" style="display:none;"><br /><div style="display:inline"><p>This work presents EgoScanning, a novel video fast-forwarding interface that helps users to find important events from lengthy first-person videos recorded with wearable cameras continuously. This interface is featured by an elastic timeline that adaptively changes playback speeds and emphasizes egocentric cues specific to first-person videos, such as hand manipulations, moving, and conversations with people, based on computer-vision techniques. The interface also allows users to input which of such cues are relevant to events of their interests. Through our user study, we confirm that users can find events of interests quickly from first-person videos thanks to the following benefits of using the EgoScanning interface: 1) adaptive changes of playback speeds allow users to watch fast-forwarded videos more easily; 2) Emphasized parts of videos can act as candidates of events actually significant to users; 3) Users are able to select relevant egocentric cues depending on events of their interests.</p></div></span> <a id="expcoll692" href="JavaScript: expandcollapse('expcoll692',692)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025688&CFID=758305256&CFTOKEN=14863114">Retargeting Video Tutorials Showing Tools With Surface Contact to Augmented Reality</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Peter Mohr, David Mandl, Markus Tatzgern, Eduardo Veas, Dieter Schmalstieg, Denis Kalkofen 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6547-6558</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025688" title="DOI">10.1145/3025453.3025688</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025688&ftid=1871152&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow693" style="display:inline;"><br /><div style="display:inline">A video tutorial effectively conveys complex motions, but may be hard to follow precisely because of its restriction to a predetermined viewpoint. Augmented reality (AR) tutorials have been demonstrated to be more effective. We bring the advantages of ...</div></span>
          <span id="toHide693" style="display:none;"><br /><div style="display:inline"><p>A video tutorial effectively conveys complex motions, but may be hard to follow precisely because of its restriction to a predetermined viewpoint. Augmented reality (AR) tutorials have been demonstrated to be more effective. We bring the advantages of both together by interactively retargeting conventional, two-dimensional videos into three-dimensional AR tutorials. Unlike previous work, we do not simply overlay video, but synthesize 3D-registered motion from the video. Since the information in the resulting AR tutorial is registered to 3D objects, the user can freely change the viewpoint without degrading the experience. This approach applies to many styles of video tutorials. In this work, we concentrate on a class of tutorials which alter the surface of an object.</p></div></span> <a id="expcoll693" href="JavaScript: expandcollapse('expcoll693',693)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025772&CFID=758305256&CFTOKEN=14863114">Close to the Action: Eye-Tracking Evaluation of Speaker-Following Subtitles</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Kuno Kurzhals, Emine Cetinkaya, Yongtao Hu, Wenping Wang, Daniel Weiskopf 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6559-6568</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025772" title="DOI">10.1145/3025453.3025772</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025772&ftid=1871143&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow694" style="display:inline;"><br /><div style="display:inline">The incorporation of subtitles in multimedia content plays an important role in communicating spoken content. For example, subtitles in the respective language are often preferred to expensive audio translation of foreign movies. The traditional representation ...</div></span>
          <span id="toHide694" style="display:none;"><br /><div style="display:inline"><p>The incorporation of subtitles in multimedia content plays an important role in communicating spoken content. For example, subtitles in the respective language are often preferred to expensive audio translation of foreign movies. The traditional representation of subtitles displays text centered at the bottom of the screen. This layout can lead to large distances between text and relevant image content, causing eye strain and even that we miss visual content. As a recent alternative, the technique of speaker-following subtitles places subtitle text in speech bubbles close to the current speaker. We conducted a controlled eye-tracking laboratory study (<i>n</i> = 40) to compare the regular approach (center-bottom subtitles) with content-sensitive, speaker-following subtitles. We compared different dialog-heavy video clips with the two layouts. Our results show that speaker-following subtitles lead to higher fixation counts on relevant image regions and reduce saccade length, which is an important factor for eye strain.</p></div></span> <a id="expcoll694" href="JavaScript: expandcollapse('expcoll694',694)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025880&CFID=758305256&CFTOKEN=14863114">Responsive Action-based Video Synthesis</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Corneliu Ilisescu, Halil Aytac Kanaci, Matteo Romagnoli, Neill D. F. Campbell, Gabriel J. Brostow 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6569-6580</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025880" title="DOI">10.1145/3025453.3025880</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025880&ftid=1871144&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow695" style="display:inline;"><br /><div style="display:inline">We propose technology to enable a new medium of expression, where video elements can be looped, merged, and triggered, interactively. Like audio, video is easy to sample from the real world, but hard to segment into clean reusable elements. Reusing a ...</div></span>
          <span id="toHide695" style="display:none;"><br /><div style="display:inline"><p>We propose technology to enable a new medium of expression, where video elements can be looped, merged, and triggered, interactively. Like audio, video is easy to sample from the real world, but hard to segment into clean reusable elements. Reusing a video clip means non-linear editing, and compositing with novel footage. The new context dictates how carefully a clip must be prepared, so our end-to-end approach enables previewing and easy iteration. We convert static-camera videos into loopable sequences, synthesizing them in response to simple end-user requests. This is hard because a) users want essentially semantic-level control over the synthesized video content, and b) automatic loop-finding is brittle and leaves users limited opportunity to work through problems. We propose a human-in-the-loop system where adding effort gives the user progressively more creative control. Artists help us evaluate how our trigger interfaces can be used for authoring of videos and video-performances.</p></div></span> <a id="expcoll695" href="JavaScript: expandcollapse('expcoll695',695)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>3D Tangibles</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025825&CFID=758305256&CFTOKEN=14863114">Co-3Deator: A Team-First Collaborative 3D Design Ideation Tool</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Cecil Piya, Vinayak -, Senthil Chandrasegaran, Niklas Elmqvist, Karthik Ramani 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6581-6592</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025825" title="DOI">10.1145/3025453.3025825</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025825&ftid=1871145&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow697" style="display:inline;"><br /><div style="display:inline">We present Co-3Deator, a sketch-based collaborative 3D modeling system based on the notion of "team-first" ideation tools, where the needs and processes of the entire design team come before that of an individual designer. Co-3Deator includes two specific ...</div></span>
          <span id="toHide697" style="display:none;"><br /><div style="display:inline"><p>We present Co-3Deator, a sketch-based collaborative 3D modeling system based on the notion of "team-first" ideation tools, where the needs and processes of the entire design team come before that of an individual designer. Co-3Deator includes two specific team-first features: a <i>concept component hierarchy</i> which provides a design representation suitable for multi-level sharing and reusing of design information, and a <i>collaborative design explorer</i> for storing, viewing, and accessing hierarchical design data during collaborative design activities. We conduct two controlled user studies, one with individual designers to elicit the form and functionality of the collaborative design explorer, and the other with design teams to evaluate the utility of the concept component hierarchy and design explorer towards collaborative design ideation. Our results support our rationale for both of the proposed team-first collaboration mechanisms and suggest further ways to streamline collaborative design.</p></div></span> <a id="expcoll697" href="JavaScript: expandcollapse('expcoll697',697)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025980&CFID=758305256&CFTOKEN=14863114"><i>EdiPulse</i>: Investigating a Playful Approach to Self-monitoring through 3D Printed Chocolate Treats</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Rohit Ashok Khot, Deepti Aggarwal, Ryan Pennings, Larissa Hjorth, Florian 'Floyd' Mueller 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6593-6607</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025980" title="DOI">10.1145/3025453.3025980</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025980&ftid=1871187&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow698" style="display:inline;"><br /><div style="display:inline">Self-monitoring offers benefits in facilitating awareness about physical exercise, but such data-centric activity may not always lead to an enjoyable experience. We introduce EdiPulse a novel system that creates activity treats to offer playful reflections ...</div></span>
          <span id="toHide698" style="display:none;"><br /><div style="display:inline"><p>Self-monitoring offers benefits in facilitating awareness about physical exercise, but such data-centric activity may not always lead to an enjoyable experience. We introduce EdiPulse a novel system that creates activity treats to offer playful reflections on everyday physical activity through the appealing medium of chocolate. EdiPulse translates self-monitored data from physical activity into small 3D printed chocolate treats. These treats (< 20 grams of chocolate in total) embody four forms: Graph, Flower, Slogan and Emoji. We deployed our system across 7 households and studied its use with 13 participants for 2 weeks per household. The field study revealed positive aspects of our approach along with some open challenges, which we disseminate across five themes: Reflection, Positivity, Determination, Affection, and Co-experience. We conclude by highlighting key implications of our work for future playful food-based technology design in supporting the experience of being physically active</p></div></span> <a id="expcoll698" href="JavaScript: expandcollapse('expcoll698',698)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025724&CFID=758305256&CFTOKEN=14863114">Investigating Cross-Device Interaction between a Handheld Device and a Large Display</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Jeni Paay, Dimitrios Raptis, Jesper Kjeldskov, Mikael B. Skov, Eric V. Ruder, Bjarke M. Lauridsen 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6608-6619</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025724" title="DOI">10.1145/3025453.3025724</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025724&ftid=1871178&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow699" style="display:inline;"><br /><div style="display:inline">There is a growing interest in HCI research to explore cross-device interaction, giving rise to an interest in different approaches facilitating interaction between handheld devices and large displays. Contributing to this, we have investigated the use ...</div></span>
          <span id="toHide699" style="display:none;"><br /><div style="display:inline"><p>There is a growing interest in HCI research to explore cross-device interaction, giving rise to an interest in different approaches facilitating interaction between handheld devices and large displays. Contributing to this, we have investigated the use of four existing approaches combining touch and mid-air gestures, <i>pinching, swiping, swinging</i> and <i>flicking</i>. We look specifically at their relative efficiency, effectiveness and accuracy in bi-directional interaction between a smartphone and large display in a point-click context. We report findings from two user studies, which show that swiping is both most effective, fastest and most accurate, closely followed by swinging. What these two approaches have in common is the ability to keep the pointer steady on the large display, unaffected by concurrent gestures or body movements used to complete the interaction, suggesting that this is an important factor for designing effective cross-device interaction with large displays.</p></div></span> <a id="expcoll699" href="JavaScript: expandcollapse('expcoll699',699)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Appropriation and Individuation</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025727&CFID=758305256&CFTOKEN=14863114">Competent Men and Warm Women: Gender Stereotypes and Backlash in Image Search Results</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Jahna Otterbacher, Jo Bates, Paul Clough 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6620-6631</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025727" title="DOI">10.1145/3025453.3025727</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025727&ftid=1871167&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow701" style="display:inline;"><br /><div style="display:inline">There is much concern about algorithms that underlie information services and the view of the world they present. We develop a novel method for examining the content and strength of gender stereotypes in image search, inspired by the trait adjective ...</div></span>
          <span id="toHide701" style="display:none;"><br /><div style="display:inline"><p>There is much concern about algorithms that underlie information services and the view of the world they present. We develop a novel method for examining the content and strength of gender stereotypes in image search, inspired by the trait adjective checklist method. We compare the gender distribution in photos retrieved by Bing for the query "person" and for queries based on 68 character traits (e.g., "intelligent person") in four regional markets. Photos of men are more often retrieved for "person," as compared to women. As predicted, photos of women are more often retrieved for <i>warm</i> traits (e.g., "emotional") whereas <i>agentic</i> traits (e.g., "rational") are represented by photos of men. A backlash effect, where stereotype-incongruent individuals are penalized, is observed. However, backlash is more prevalent for "competent women" than "warm men." Results underline the need to understand how and why biases enter search algorithms and at which stages of the engineering process.</p></div></span> <a id="expcoll701" href="JavaScript: expandcollapse('expcoll701',701)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025770&CFID=758305256&CFTOKEN=14863114">Technology Individuation: The Foibles of Augmented Everyday Objects</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Aloha Hufana Ambe, Margot Brereton, Alessandro Soro, Paul Roe 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6632-6644</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025770" title="DOI">10.1145/3025453.3025770</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025770&ftid=1871149&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow702" style="display:inline;"><br /><div style="display:inline">This paper presents the concept of technology individuation and explores its role in design. Individuation expresses how, over time, a technology becomes personal and intimate, unique in purpose, orchestrated in place, and how people eventually come ...</div></span>
          <span id="toHide702" style="display:none;"><br /><div style="display:inline"><p>This paper presents the concept of technology individuation and explores its role in design. Individuation expresses how, over time, a technology becomes personal and intimate, unique in purpose, orchestrated in place, and how people eventually come to rely on it to sustain connection with others. We articulate this concept as a critical vantage point for designing augmented everyday objects and the Internet of Things. Individuation foregrounds aspects of habituation, routines and arrangements that through everyday practices reveal unique meaning, reflect self-identity and support agency.</p> <p>The concept is illustrated through three long term case studies of technology in use, involving tangible and embodied interaction with devices that afford communication, monitoring, and awareness in the home setting. The cases are analysed using Hornecker and Buur's Tangible Interaction Framework. We further extend upon this framework to better reveal the role played by personal values, history of use, and arrangements, as they develop over time in the home setting, in shaping tangible and embodied interaction with individuated technologies.</p></div></span> <a id="expcoll702" href="JavaScript: expandcollapse('expcoll702',702)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025775&CFID=758305256&CFTOKEN=14863114">Social Consequences of Grindr Use: Extending the Internet-Enhanced Self-Disclosure Hypothesis</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Samuel Hardman Taylor, Jevan Alexander Hutson, Tyler Richard Alicea 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6645-6657</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025775" title="DOI">10.1145/3025453.3025775</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025775&ftid=1871131&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow703" style="display:inline;"><br /><div style="display:inline">Grindr, a location-based real-time dating application, provides sexual-minority men (SMM) a space through which they can identify, access, and communicate with one another. Although previous research has examined user motivations and public self-disclosure ...</div></span>
          <span id="toHide703" style="display:none;"><br /><div style="display:inline"><p>Grindr, a location-based real-time dating application, provides sexual-minority men (SMM) a space through which they can identify, access, and communicate with one another. Although previous research has examined user motivations and public self-disclosure patterns on Grindr, we investigate the effects intimate self-disclosure and sexting via the application's private messaging on internalized homophobia and loneliness. Using the Internet-enhanced self-disclosure hypothesis (ISDH) as a framework, we conducted an online survey of 274 Grindr users. Serial mediation analysis showed support for the ISDH, suggesting that Grindr use was negatively associated with loneliness. Intimate self-disclosure and internalized homophobia mediated the relationship between Grindr use and loneliness, but sexting had no relationship with internalized homophobia or loneliness. We discuss implications for the ISDH, Grindr, self-disclosure, and sexting.</p></div></span> <a id="expcoll703" href="JavaScript: expandcollapse('expcoll703',703)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025609&CFID=758305256&CFTOKEN=14863114">Gender-Inclusiveness Personas vs. Stereotyping: Can We Have it Both Ways?</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Charles G. Hill, Maren Haag, Alannah Oleson, Chris Mendez, Nicola Marsden, Anita Sarma, Margaret Burnett 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6658-6671</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025609" title="DOI">10.1145/3025453.3025609</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025609&ftid=1871191&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow704" style="display:inline;"><br /><div style="display:inline">Personas often aim to improve product designers' ability to "see through the eyes of" target users through the empathy personas can inspire - but personas are also known to promote stereotyping. This tension can be particularly problematic when personas ...</div></span>
          <span id="toHide704" style="display:none;"><br /><div style="display:inline"><p>Personas often aim to improve product designers' ability to "see through the eyes of" target users through the empathy personas can inspire - but personas are also known to promote stereotyping. This tension can be particularly problematic when personas (who, of course as "people" have genders) are used to promote gender inclusiveness - because reinforcing stereotypical perceptions can run counter to gender inclusiveness. In this paper we explicitly investigate this tension through a new approach to personas: one that includes multiple photos (of males and females) for a single persona. We compared this approach to an identical persona with only one photo using a controlled laboratory study and an eye-tracking study. Our goal was to answer the following question: is it possible for personas to encourage product designers to engage with personas while at the same avoiding promoting gender stereotyping? Our results are encouraging about the use of personas with multiple pictures as a way to expand participants' consideration of multiple genders without reducing their engagement with the persona.</p></div></span> <a id="expcoll704" href="JavaScript: expandcollapse('expcoll704',704)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Data Extraction</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025540&CFID=758305256&CFTOKEN=14863114">SEER: Auto-Generating Information Extraction Rules from User-Specified Examples</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Maeda F. Hanafi, Azza Abouzied, Laura Chiticariu, Yunyao Li 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6672-6682</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025540" title="DOI">10.1145/3025453.3025540</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025540&ftid=1871150&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow706" style="display:inline;"><br /><div style="display:inline">Time-consuming and complicated best describe the current state of the Information Extraction (IE) field. Machine learning approaches to IE require large collections of labeled datasets that are difficult to create and use obscure mathematical models, ...</div></span>
          <span id="toHide706" style="display:none;"><br /><div style="display:inline"><p>Time-consuming and complicated best describe the current state of the Information Extraction (IE) field. Machine learning approaches to IE require large collections of labeled datasets that are difficult to create and use obscure mathematical models, occasionally returning unwanted results that are unexplainable. Rule-based approaches, while resulting in easy-to-understand IE rules, are still time-consuming and labor-intensive. SEER combines the best of these two approaches: a learning model for IE rules based on a small number of user-specified examples. In this paper, we explain the design behind SEER and present a user study comparing our system against a commercially available tool in which users create IE rules manually. Our results show that SEER helps users complete text extraction tasks more quickly, as well as more accurately.</p></div></span> <a id="expcoll706" href="JavaScript: expandcollapse('expcoll706',706)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025571&CFID=758305256&CFTOKEN=14863114">Leveraging Human Routine Models to Detect and Generate Human Behaviors</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Nikola Banovic, Anqi Wang, Yanfeng Jin, Christie Chang, Julian Ramos, Anind Dey, Jennifer Mankoff 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6683-6694</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025571" title="DOI">10.1145/3025453.3025571</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025571&ftid=1871184&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow707" style="display:inline;"><br /><div style="display:inline">An ability to detect behaviors that negatively impact people's wellbeing and show people how they can correct those behaviors could enable technology that improves people's lives. Existing supervised machine learning approaches to detect and generate ...</div></span>
          <span id="toHide707" style="display:none;"><br /><div style="display:inline"><p>An ability to detect behaviors that negatively impact people's wellbeing and show people how they can correct those behaviors could enable technology that improves people's lives. Existing supervised machine learning approaches to detect and generate such behaviors require lengthy and expensive data labeling by domain experts. In this work, we focus on the domain of routine behaviors, where we model routines as a series of frequent actions that people perform in specific situations. We present an approach that bypasses labeling each behavior instance that a person exhibits. Instead, we weakly label instances using people's demonstrated routine. We classify and generate new instances based on the probability that they belong to the routine model. We illustrate our approach on an example system that helps drivers become aware of and understand their aggressive driving behaviors. Our work enables technology that can trigger interventions and help people reflect on their behaviors when those behaviors are likely to negatively impact them.</p></div></span> <a id="expcoll707" href="JavaScript: expandcollapse('expcoll707',707)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025872&CFID=758305256&CFTOKEN=14863114">Interactive Vectorization</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Jun Xie, Holger Winnem&#246;ller, Wilmot Li, Stephen Schiller 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6695-6705</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025872" title="DOI">10.1145/3025453.3025872</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025872&ftid=1871155&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow708" style="display:inline;"><br /><div style="display:inline">Vectorization turns photographs into vector art. Manual vectorization, where the artist traces over the image by hand, requires skill and time. On the other hand, automatic approaches allow users to generate a result by setting a few global parameters. ...</div></span>
          <span id="toHide708" style="display:none;"><br /><div style="display:inline"><p>Vectorization turns photographs into vector art. Manual vectorization, where the artist traces over the image by hand, requires skill and time. On the other hand, automatic approaches allow users to generate a result by setting a few global parameters. However, global settings often leave too much detail/complexity in some parts of the image while missing important details in others. We propose interactive vectorization tools that offer more local control than automatic systems, but are more powerful and high-level than simple curve editing. Our system enables novices to vectorize images significantly faster than even experts with state-of-the-art tools.</p></div></span> <a id="expcoll708" href="JavaScript: expandcollapse('expcoll708',708)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025957&CFID=758305256&CFTOKEN=14863114">ChartSense: Interactive Data Extraction from Chart Images</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Daekyoung Jung, Wonjae Kim, Hyunjoo Song, Jeong-in Hwang, Bongshin Lee, Bohyoung Kim, Jinwook Seo 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6706-6717</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025957" title="DOI">10.1145/3025453.3025957</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025957&ftid=1871164&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow709" style="display:inline;"><br /><div style="display:inline">Charts are commonly used to present data in digital documents such as web pages, research papers, or presentation slides. When the underlying data is not available, it is necessary to extract the data from a chart image to utilize the data for further ...</div></span>
          <span id="toHide709" style="display:none;"><br /><div style="display:inline"><p>Charts are commonly used to present data in digital documents such as web pages, research papers, or presentation slides. When the underlying data is not available, it is necessary to extract the data from a chart image to utilize the data for further analysis or improve the chart for more accurate perception. In this paper, we present ChartSense, an interactive chart data extraction system. ChartSense first determines the chart type of a given chart image using a deep learning based classifier, and then extracts underlying data from the chart image using semi-automatic, interactive extraction algorithms optimized for each chart type. To evaluate chart type classification accuracy, we compared ChartSense with ReVision, a system with the state-of-the-art chart type classifier. We found that ChartSense was more accurate than ReVision. In addition, to evaluate data extraction performance, we conducted a user study, comparing ChartSense with WebPlotDigitizer, one of the most effective chart data extraction tools among publicly accessible ones. Our results showed that ChartSense was better than WebPlotDigitizer in terms of task completion time, error rate, and subjective preference.</p></div></span> <a id="expcoll709" href="JavaScript: expandcollapse('expcoll709',709)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Displays and Collaboration</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025604&CFID=758305256&CFTOKEN=14863114">CamRay: Camera Arrays Support Remote Collaboration on Wall-Sized Displays</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Ignacio Avellino, C&#233;dric Fleury, Wendy E. Mackay, Michel Beaudouin-Lafon 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6718-6729</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025604" title="DOI">10.1145/3025453.3025604</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025604&ftid=1871160&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow711" style="display:inline;"><br /><div style="display:inline">Remote collaboration across wall-sized displays creates a key challenge: how to support audio-video communication among users as they move in front of the display. We present CamRay, a platform that uses camera arrays embedded in wall-sized displays ...</div></span>
          <span id="toHide711" style="display:none;"><br /><div style="display:inline"><p>Remote collaboration across wall-sized displays creates a key challenge: how to support audio-video communication among users as they move in front of the display. We present CamRay, a platform that uses camera arrays embedded in wall-sized displays to capture video of users and present it on remote displays according to the users' positions. We investigate two settings: in Follow-Remote, the position of the video window follows the position of the remote user; in Follow-Local, the video window always appears in front of the local user. We report the results of a controlled experiment showing that with Follow-Remote, participants are faster, use more deictic instructions, interpret them more accurately, and use fewer words. However, some participants preferred the virtual face-to-face created by Follow-Local when checking for their partners' understanding. We conclude with design recommendations to support remote collaboration across wall-sized displays.</p></div></span> <a id="expcoll711" href="JavaScript: expandcollapse('expcoll711',711)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025594&CFID=758305256&CFTOKEN=14863114">CoReach: Cooperative Gestures for Data Manipulation on Wall-sized Displays</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Can Liu, Olivier Chapuis, Michel Beaudouin-Lafon, Eric Lecolinet 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6730-6741</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025594" title="DOI">10.1145/3025453.3025594</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025594&ftid=1871173&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow712" style="display:inline;"><br /><div style="display:inline">Multi-touch wall-sized displays afford collaborative exploration of large datasets and re-organization of digital content. However, standard touch interactions, such as dragging to move content, do not scale well to large surfaces and were not designed ...</div></span>
          <span id="toHide712" style="display:none;"><br /><div style="display:inline"><p>Multi-touch wall-sized displays afford collaborative exploration of large datasets and re-organization of digital content. However, standard touch interactions, such as dragging to move content, do not scale well to large surfaces and were not designed to support collaboration, such as passing an object around. This paper introduces <i>CoReach</i>, a set of collaborative gestures that combine input from multiple users in order to manipulate content, facilitate data exchange and support communication. We conducted an observational study to inform the design of <i>CoReach</i>, and a controlled study showing that it reduced physical fatigue and facilitated collaboration when compared with traditional multi-touch gestures. A final study assessed the value of also allowing input through a handheld tablet to manipulate content from a distance.</p></div></span> <a id="expcoll712" href="JavaScript: expandcollapse('expcoll712',712)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025584&CFID=758305256&CFTOKEN=14863114">Turbulent Touch: Touchscreen Input for Cockpit Flight Displays</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Andy Cockburn, Carl Gutwin, Philippe Palanque, Yannick Deleris, Catherine Trask, Ashley Coveney, Marcus Yung, Karon MacLean 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6742-6753</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025584" title="DOI">10.1145/3025453.3025584</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025584&ftid=1871134&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow713" style="display:inline;"><br /><div style="display:inline">Touchscreen input in commercial aircraft cockpits offers potential advantages, including ease of use, modifiability, and reduced weight. However, tolerance to turbulence is a challenge for their deployment. To better understand the impact of turbulence ...</div></span>
          <span id="toHide713" style="display:none;"><br /><div style="display:inline"><p>Touchscreen input in commercial aircraft cockpits offers potential advantages, including ease of use, modifiability, and reduced weight. However, tolerance to turbulence is a challenge for their deployment. To better understand the impact of turbulence on cockpit input methods we conducted a comparative study of user performance with three input methods -- touch, trackball (as currently used in commercial aircraft), and a touchscreen stencil overlay designed to assist finger stabilization. These input methods were compared across a variety of interactive tasks and at three levels of simulated turbulence (none, low, and high). Results showed that performance degrades and subjective workload increases as vibration increases. Touch-based interaction was faster than the trackball when precision requirements were low (at all vibrations), but it was slower and less accurate for more precise pointing, particularly at high vibrations. The stencil did not improve touch selection times, although it did reduce errors on small targets at high vibrations, but only when finger lift-off errors had been eliminated by a timeout. Our work provides new information on the types of tasks affected by turbulence and the input mechanisms that perform best under different levels of vibration.</p></div></span> <a id="expcoll713" href="JavaScript: expandcollapse('expcoll713',713)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025924&CFID=758305256&CFTOKEN=14863114">AlterNail: Ambient, Batteryless, Stateful, Dynamic Displays at your Fingertips</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Christine Dierk, Tom&#225;s Vega G&#225;lvez, Eric Paulos 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6754-6759</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025924" title="DOI">10.1145/3025453.3025924</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025924&ftid=1871198&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow714" style="display:inline;"><br /><div style="display:inline">Beyond phones, watches, and activity tracking devices, a new ecosystem of functional and fashionable wearable technologies can easily, safely, and economically be designed, prototyped, and integrated directly on the body. In this paper, we present AlterNail, ...</div></span>
          <span id="toHide714" style="display:none;"><br /><div style="display:inline"><p>Beyond phones, watches, and activity tracking devices, a new ecosystem of functional and fashionable wearable technologies can easily, safely, and economically be designed, prototyped, and integrated directly on the body. In this paper, we present AlterNail, a fingernail form factor, ambient, low-power, stateful, wireless, dynamic display with onboard vibrational sensing. AlterNail integrates a batteryless design using inductive coupling with e-ink technology to enable both quick dynamic and long-term static fingernail based visual designs without the need for power. We also detail the use of simple vibrational signals to uniquely identify everyday objects as they are handled using AlterNails. The intentionally limited interactional functionality of AlterNails, coupled with the rich personal and dynamic expressive potential, combine to present a compelling range of opportunities for designers of new interactive wearable technologies. We detail a range of practical and playful applications using this technology.</p></div></span> <a id="expcoll714" href="JavaScript: expandcollapse('expcoll714',714)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025500&CFID=758305256&CFTOKEN=14863114">Subtle and Personal Workspace Requirements for Visual Search Tasks on Public Displays</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          James R. Wallace, Ariel Weingarten, Edward Lank 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6760-6764</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025500" title="DOI">10.1145/3025453.3025500</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025500&ftid=1871135&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow715" style="display:inline;"><br /><div style="display:inline">We explore how users approach and define personal space on large, public displays. Our results show that users of public displays use one of two strategies for visual search tasks: minimizers create a small window and work up close to the display, and ...</div></span>
          <span id="toHide715" style="display:none;"><br /><div style="display:inline"><p>We explore how users approach and define personal space on large, public displays. Our results show that users of public displays use one of two strategies for visual search tasks: minimizers create a small window and work up close to the display, and maximizers expand content to its full resolution and work at a distance. We show that these interaction styles match predicted 'personal' and 'subtle' interaction zones, characterize typical width and height requirements for these interactions, and show that these requirements are independent of the on-screen content's dimensions. Finally, we suggest practical guidelines for defining workspaces during personal and subtle interaction on large, public displays.</p></div></span> <a id="expcoll715" href="JavaScript: expandcollapse('expcoll715',715)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Drones</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025632&CFID=758305256&CFTOKEN=14863114">Spiders in the Sky: User Perceptions of Drones, Privacy, and Security</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Victoria Chang, Pramod Chundury, Marshini Chetty 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6765-6776</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025632" title="DOI">10.1145/3025453.3025632</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025632&ftid=1871192&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow717" style="display:inline;"><br /><div style="display:inline">Drones are increasingly being used for various purposes from recording footage in inaccessible areas to delivering packages. A rise in drone usage introduces privacy and security concerns about flying boundaries, what data drones collect in public and ...</div></span>
          <span id="toHide717" style="display:none;"><br /><div style="display:inline"><p>Drones are increasingly being used for various purposes from recording footage in inaccessible areas to delivering packages. A rise in drone usage introduces privacy and security concerns about flying boundaries, what data drones collect in public and private spaces, and how that data is stored and disseminated. However, commercial and personal drone regulations focusing on privacy and security have been fairly minimal in the USA. To inform privacy and security guidelines for drone design and regulation, we need to understand users' perceptions about drones, privacy and security. In this paper, we describe a laboratory study with 20 participants who interacted with a real or model drone to elicit user perceptions of privacy and security issues around drones. We present our results, discuss the implications of our work and make recommendations to improve drone design and regulations that enhance individual privacy and security.</p></div></span> <a id="expcoll717" href="JavaScript: expandcollapse('expcoll717',717)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025907&CFID=758305256&CFTOKEN=14863114">Privacy Mechanisms for Drones: Perceptions of Drone Controllers and Bystanders</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Yaxing Yao, Huichuan Xia, Yun Huang, Yang Wang 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6777-6788</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025907" title="DOI">10.1145/3025453.3025907</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025907&ftid=1871172&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow718" style="display:inline;"><br /><div style="display:inline">Drones pose privacy concerns such as surveillance and stalking. Many technology-based or policy-based mechanisms have been proposed to mitigate these concerns. However, it is unclear how drone controllers and bystanders perceive these mechanisms and ...</div></span>
          <span id="toHide718" style="display:none;"><br /><div style="display:inline"><p>Drones pose privacy concerns such as surveillance and stalking. Many technology-based or policy-based mechanisms have been proposed to mitigate these concerns. However, it is unclear how drone controllers and bystanders perceive these mechanisms and whether people intend to adopt them. In this paper, we report results from two rounds of online survey with 169 drone controllers and 717 bystanders in the U.S. We identified respondents' perceived pros and cons of eight privacy mechanisms. We found that <i>owner registration</i> and <i>automatic face blurring</i> individually received most support from both controllers and bystanders. Our respondents also suggested using varied combinations of mechanisms under different drone usage scenarios, highlighting their context-dependent preferences. We outline a set of important questions for future privacy designs and public policies of drones.</p></div></span> <a id="expcoll718" href="JavaScript: expandcollapse('expcoll718',718)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3026049&CFID=758305256&CFTOKEN=14863114">Free to Fly in Public Spaces: Drone Controllers' Privacy Perceptions and Practices</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Yaxing Yao, Huichuan Xia, Yun Huang, Yang Wang 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6789-6793</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3026049" title="DOI">10.1145/3025453.3026049</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3026049&ftid=1871181&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow719" style="display:inline;"><br /><div style="display:inline">Prior research has discovered various privacy concerns that bystanders have about drones. However, little is known about drone controllers' privacy perceptions and practices of drones. Understanding controllers' perspective is important because it will ...</div></span>
          <span id="toHide719" style="display:none;"><br /><div style="display:inline"><p>Prior research has discovered various privacy concerns that bystanders have about drones. However, little is known about drone controllers' privacy perceptions and practices of drones. Understanding controllers' perspective is important because it will inform whether controllers' current practices protect or infringe on bystanders' privacy and what mechanisms could be designed to better address the potential privacy issues of drones. In this paper, we report results from interviews of 12 drone controllers in the US. Our interviewees treated safety as their top priority but considered privacy issues of drones exaggerated. Our results also highlight many significant differences in how controllers and bystanders think about drone privacy, for instance, how they determine public vs. private spaces and whether notice and consent of bystanders are needed.</p></div></span> <a id="expcoll719" href="JavaScript: expandcollapse('expcoll719',719)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025755&CFID=758305256&CFTOKEN=14863114">Drone &#38; Wo: Cultural Influences on Human-Drone Interaction Techniques</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Jane L. E, Ilene L. E, James A. Landay, Jessica R. Cauchard 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6794-6799</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025755" title="DOI">10.1145/3025453.3025755</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025755&ftid=1871161&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow720" style="display:inline;"><br /><div style="display:inline">As drones become ubiquitous, it is important to understand how cultural differences impact human-drone interaction. A previous elicitation study performed in the USA illustrated how users would intuitively interact with drones. We replicated this study ...</div></span>
          <span id="toHide720" style="display:none;"><br /><div style="display:inline"><p>As drones become ubiquitous, it is important to understand how cultural differences impact human-drone interaction. A previous elicitation study performed in the USA illustrated how users would intuitively interact with drones. We replicated this study in China to gain insight into how these user-defined interactions vary across the two cultures. We found that as per the US study, Chinese participants chose to interact primarily using gesture. However, Chinese participants used multi-modal interactions more than their US counterparts. Agreement for many proposed interactions was high within each culture. Across cultures, there were notable differences despite similarities in interaction modality preferences. For instance, culturally-specific gestures emerged in China, such as a T-shape gesture for stopping the drone. Participants from both cultures anthropomorphized the drone, and welcomed it into their personal space. We describe the implications of these findings on designing culturally-aware and intuitive human-drone interaction.</p></div></span> <a id="expcoll720" href="JavaScript: expandcollapse('expcoll720',720)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Online Experiments</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025473&CFID=758305256&CFTOKEN=14863114">Citizen Science Opportunities in Volunteer-Based Online Experiments</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Nigini Oliveira, Eunice Jun, Katharina Reinecke 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6800-6812</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025473" title="DOI">10.1145/3025453.3025473</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025473&ftid=1871156&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow722" style="display:inline;"><br /><div style="display:inline">Online experimentation with volunteers could be described as a form of citizen science in which participants take part in behavioral studies without financial compensation. However, while citizen science projects aim to improve scientific understanding, ...</div></span>
          <span id="toHide722" style="display:none;"><br /><div style="display:inline"><p>Online experimentation with volunteers could be described as a form of citizen science in which participants take part in behavioral studies without financial compensation. However, while citizen science projects aim to improve scientific understanding, volunteer-based online experiment platforms currently provide minimal possibilities for research involvement and learning. The goal of this paper is to uncover opportunities for expanding participant involvement and learning in the research process. Analyzing comments from 8,288 volunteers who took part in four online experiments on LabintheWild, we identified six themes that reveal needs and opportunities for closer interaction between researchers and participants. Our findings demonstrate opportunities for research involvement, such as engaging participants in refining experiment implementations, and learning opportunities, such as providing participants with possibilities to learn about research aims. We translate these findings into ideas for the design of future volunteer-based online experiment platforms that are more mutually beneficial to citizen scientists and researchers.</p></div></span> <a id="expcoll722" href="JavaScript: expandcollapse('expcoll722',722)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025820&CFID=758305256&CFTOKEN=14863114">Differences in Crowdsourced vs. Lab-based Mobile and Desktop Input Performance Data</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Leah Findlater, Joan Zhang, Jon E. Froehlich, Karyn Moffatt 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6813-6824</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025820" title="DOI">10.1145/3025453.3025820</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025820&ftid=1871146&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow723" style="display:inline;"><br /><div style="display:inline">Research on the viability of using crowdsourcing for HCI performance experiments has concluded that online results are similar to those achieved in the lab---at least for desktop interactions. However, mobile devices, the most popular form of online ...</div></span>
          <span id="toHide723" style="display:none;"><br /><div style="display:inline"><p>Research on the viability of using crowdsourcing for HCI performance experiments has concluded that online results are similar to those achieved in the lab---at least for desktop interactions. However, mobile devices, the most popular form of online access today, may be more problematic due to variability in the user's posture and in movement of the device. To assess this possibility, we conducted two experiments with 30 lab-based and 303 crowdsourced participants using basic mouse and touchscreen tasks. Our findings show that: (1) separately analyzing the crowd and lab data yields different study conclusions-touchscreen input was significantly less error prone than mouse input in the lab but <i>more</i> error prone online; (2) age-matched crowdsourced participants were significantly faster and less accurate than their lab-based counterparts, contrasting past work; (3) variability in mobile device movement and orientation increased as experimenter control decreased--a potential factor affecting the touchscreen error differences. This study cautions against assuming that crowdsourced data for performance experiments will directly reflect lab-based data, particularly for mobile devices.</p></div></span> <a id="expcoll723" href="JavaScript: expandcollapse('expcoll723',723)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025769&CFID=758305256&CFTOKEN=14863114">Gut Instinct: Creating Scientific Theories with Online Learners</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Vineet Pandey, Amnon Amir, Justine Debelius, Embriette R. Hyde, Tomasz Kosciolek, Rob Knight, Scott Klemmer 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6825-6836</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025769" title="DOI">10.1145/3025453.3025769</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025769&ftid=1871174&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow724" style="display:inline;"><br /><div style="display:inline">Learners worldwide collectively spend millions of hours per week testing their skills on assignments with known answers. Might some of this time fruitfully be spent posing and exploring novel questions? This paper investigates an approach for learners ...</div></span>
          <span id="toHide724" style="display:none;"><br /><div style="display:inline"><p>Learners worldwide collectively spend millions of hours per week testing their skills on assignments with known answers. Might some of this time fruitfully be spent posing and exploring novel questions? This paper investigates an approach for learners to contribute scientific ideas. The Gut Instinct system embodies this approach, hosting online learning materials and invites learners to collaboratively brainstorm potential influences on people's microbiome. A between-subjects experiment compared the performance of participants who engaged in just learning, just contributing, or a combination. Participants in the learning condition scored highest on a summative test. Participants in both the contribution and combined conditions generated novel, useful questions; there was not a significant difference between the two. Though participants in the combined condition both learned and contributed, this setting did not exhibit an additive benefit, such as better learning in the combined condition. These results highlight the promise and difficulty of double-bottom-line learning experiences.</p></div></span> <a id="expcoll724" href="JavaScript: expandcollapse('expcoll724',724)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3026038&CFID=758305256&CFTOKEN=14863114">Self-Experimentation for Behavior Change: Design and Formative Evaluation of Two Approaches</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Jisoo Lee, Erin Walker, Winslow Burleson, Matthew Kay, Matthew Buman, Eric B. Hekler 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6837-6849</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3026038" title="DOI">10.1145/3025453.3026038</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3026038&ftid=1871168&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow725" style="display:inline;"><br /><div style="display:inline">Desirable outcomes such as health are tightly linked to behaviors, thus inspiring research on technologies that support people in changing those behaviors. Many behavior-change technologies are designed by HCI experts but this approach can make it difficult ...</div></span>
          <span id="toHide725" style="display:none;"><br /><div style="display:inline"><p>Desirable outcomes such as health are tightly linked to behaviors, thus inspiring research on technologies that support people in changing those behaviors. Many behavior-change technologies are designed by HCI experts but this approach can make it difficult to personalize support to each user's unique goals and needs. This paper reports on the iterative design of two complementary support strategies for helping users create their own personalized behavior-change plans via self-experimentation: One emphasized the use of interactive instructional materials, and the other additionally introduced context-aware computing to enable user creation of "just in time" home-based interventions. In a formative trial with 27 users, we compared these two approaches to an unstructured sleep education control. Results suggest great promise in both strategies and provide insights on how to develop personalized behavior-change technologies.</p></div></span> <a id="expcoll725" href="JavaScript: expandcollapse('expcoll725',725)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Personal Informatics &#38; Self-Tracking</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025480&CFID=758305256&CFTOKEN=14863114">TummyTrials: A Feasibility Study of Using Self-Experimentation to Detect Individualized Food Triggers</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Ravi Karkar, Jessica Schroeder, Daniel A. Epstein, Laura R. Pina, Jeffrey Scofield, James Fogarty, Julie A. Kientz, Sean A. Munson, Roger Vilardaga, Jasmine Zia 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6850-6863</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025480" title="DOI">10.1145/3025453.3025480</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025480&ftid=1871147&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow727" style="display:inline;"><br /><div style="display:inline">Diagnostic self-tracking, the recording of personal information to diagnose or manage a health condition, is a common practice, especially for people with chronic conditions. Unfortunately, many who attempt diagnostic self tracking have trouble accomplishing ...</div></span>
          <span id="toHide727" style="display:none;"><br /><div style="display:inline"><p>Diagnostic self-tracking, the recording of personal information to diagnose or manage a health condition, is a common practice, especially for people with chronic conditions. Unfortunately, many who attempt diagnostic self tracking have trouble accomplishing their goals. People often lack knowledge and skills needed to design and conduct scientifically rigorous experiments, and current tools provide little support. To address these shortcomings and explore opportunities for diagnostic self tracking, we designed, developed, and evaluated a mobile app that applies a self experimentation framework to support patients suffering from irritable bowel syndrome (IBS) in identifying their personal food triggers. TummyTrials aids a person in designing, executing, and analyzing self experiments to evaluate whether a specific food triggers their symptoms. We examined the feasibility of this approach in a field study with 15 IBS patients, finding that participants could use the tool to reliably undergo a self-experiment. However, we also discovered an underlying tension between scientific validity and the lived experience of self experimentation. We discuss challenges of applying clinical research methods in everyday life, motivating a need for the design of self experimentation systems to balance rigor with the uncertainties of everyday life.</p></div></span> <a id="expcoll727" href="JavaScript: expandcollapse('expcoll727',727)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025557&CFID=758305256&CFTOKEN=14863114">Making Sense of Sleep Sensors: How Sleep Sensing Technologies Support and Undermine Sleep Health</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Ruth Ravichandran, Sang-Wha Sien, Shwetak N. Patel, Julie A. Kientz, Laura R. Pina 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6864-6875</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025557" title="DOI">10.1145/3025453.3025557</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025557&ftid=1871179&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow728" style="display:inline;"><br /><div style="display:inline">Sleep is an important aspect of our health, but it is difficult for people to track manually because it is an unconscious activity. The ability to sense sleep has aimed to lower the barriers of tracking sleep. Although sleep sensors are widely ...</div></span>
          <span id="toHide728" style="display:none;"><br /><div style="display:inline"><p>Sleep is an important aspect of our health, but it is difficult for people to track manually because it is an unconscious activity. The ability to <i>sense</i> sleep has aimed to lower the barriers of tracking sleep. Although sleep sensors are widely available, their usefulness and potential to promote healthy sleep behaviors has not been fully realized. To understand people's perspectives on sleep sensing devices and their potential for promoting sleep health, we surveyed 87 and interviewed 12 people who currently use or have previously used sleep sensors, interviewed 5 sleep medical experts, and conducted an in-depth qualitative analysis of 6986 reviews of the most popular commercial sleep sensing technologies. We found that the feedback provided by current sleep sensing technologies affects users' perceptions of their sleep and encourages goals that are in tension with evidence-based methods for promoting good sleep health. Our research provides design recommendations for improving the feedback of sleep sensing technologies by bridging the gap between expert and user goals.</p></div></span> <a id="expcoll728" href="JavaScript: expandcollapse('expcoll728',728)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/bp_award.jpg" alt="Best Paper" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025635&CFID=758305256&CFTOKEN=14863114">Examining Menstrual Tracking to Inform the Design of Personal Informatics Tools</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Daniel A. Epstein, Nicole B. Lee, Jennifer H. Kang, Elena Agapie, Jessica Schroeder, Laura R. Pina, James Fogarty, Julie A. Kientz, Sean Munson 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6876-6888</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025635" title="DOI">10.1145/3025453.3025635</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025635&ftid=1871151&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow729" style="display:inline;"><br /><div style="display:inline">We consider why and how women track their menstrual cycles, examining their experiences to uncover design opportunities and extend the field's understanding of personal informatics tools. To understand menstrual cycle tracking practices, we collected ...</div></span>
          <span id="toHide729" style="display:none;"><br /><div style="display:inline"><p>We consider why and how women track their menstrual cycles, examining their experiences to uncover design opportunities and extend the field's understanding of personal informatics tools. To understand menstrual cycle tracking practices, we collected and analyzed data from three sources: 2,000 reviews of popular menstrual tracking apps, a survey of 687 people, and follow-up interviews with 12 survey respondents. We find that women track their menstrual cycle for varied reasons that include remembering and predicting their period as well as informing conversations with healthcare providers. Participants described six methods of tracking their menstrual cycles, including use of technology, awareness of their premenstrual physiological states, and simply remembering. Although women find apps and calendars helpful, these methods are ineffective when predictions of future menstrual cycles are inaccurate. Designs can create feelings of exclusion for gender and sexual minorities. Existing apps also generally fail to consider life stages that women experience, including young adulthood, pregnancy, and menopause. Our findings encourage expanding the field's conceptions of personal informatics.</p></div></span> <a id="expcoll729" href="JavaScript: expandcollapse('expcoll729',729)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025869&CFID=758305256&CFTOKEN=14863114">Quantifying the Body and Caring for the Mind: Self-Tracking in Multiple Sclerosis</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Amid Ayobi, Paul Marshall, Anna L. Cox, Yunan Chen 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6889-6901</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025869" title="DOI">10.1145/3025453.3025869</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025869&ftid=1871153&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow730" style="display:inline;"><br /><div style="display:inline">Consumer health technologies have an enormous potential to transform the self-management of chronic conditions. However, it is unclear how individuals use self-tracking technologies to manage them. This in-depth interview study explores self-tracking ...</div></span>
          <span id="toHide730" style="display:none;"><br /><div style="display:inline"><p>Consumer health technologies have an enormous potential to transform the self-management of chronic conditions. However, it is unclear how individuals use self-tracking technologies to manage them. This in-depth interview study explores self-tracking practices in multiple sclerosis (MS), a complex neurological disease that causes physical, cognitive, and psychological symptoms. Our findings illustrate that when faced the unpredictable and degenerative nature of MS, individuals regained a sense of control by intertwining self-care practices with different self-tracking technologies. They engaged in disease monitoring, fitness tracking, and life journaling to quantify the body and care for the mind. We focus attention on the role of emotional wellbeing and the experience of control in self-tracking and managing MS. Finally, we discuss in which ways self-tracking technologies could support the experiential nature of control and foster mindful experiences rather than focusing only on tracking primary disease indicators.</p></div></span> <a id="expcoll730" href="JavaScript: expandcollapse('expcoll730',730)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Presentation in Online Communities</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025771&CFID=758305256&CFTOKEN=14863114">Share First, Save Later: Performance of Self through Snapchat Stories</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Sarah McRoberts, Haiwei Ma, Andrew Hall, Svetlana Yarosh 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6902-6911</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025771" title="DOI">10.1145/3025453.3025771</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025771&ftid=1871188&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow732" style="display:inline;"><br /><div style="display:inline">As the third most popular social network among millennials, Snapchat is well known for its picture and video messaging system that deletes content after it is viewed. However, the Stories feature of Snapchat offers a different perspective of ephemeral ...</div></span>
          <span id="toHide732" style="display:none;"><br /><div style="display:inline"><p>As the third most popular social network among millennials, Snapchat is well known for its picture and video messaging system that deletes content after it is viewed. However, the Stories feature of Snapchat offers a different perspective of ephemeral content sharing, with pictures and videos that are available for friends to watch an unlimited number of times for 24 hours. We conduct-ed an in-depth qualitative investigation by interviewing 18 participants and reviewing 14 days of their Stories posts. We identify five themes focused on how participants perceive and use the Stories feature, and apply a Goffmanesque metaphor to our analysis. We relate the Stories medium to other research on self-presentation and identity curation in social media.</p></div></span> <a id="expcoll732" href="JavaScript: expandcollapse('expcoll732',732)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025682&CFID=758305256&CFTOKEN=14863114">Situated Anonymity: Impacts of Anonymity, Ephemerality, and Hyper-Locality on Social Media</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Ari Schlesinger, Eshwar Chandrasekharan, Christina A. Masden, Amy S. Bruckman, W. Keith Edwards, Rebecca E. Grinter 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6912-6924</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025682" title="DOI">10.1145/3025453.3025682</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025682&ftid=1871129&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow733" style="display:inline;"><br /><div style="display:inline">Anonymity, ephemerality, and hyper-locality are an uncommon set of features in the design of online communities. However, these features were key to Yik Yak's initial success and popularity. In an interview-based study, we found that these three features ...</div></span>
          <span id="toHide733" style="display:none;"><br /><div style="display:inline"><p>Anonymity, ephemerality, and hyper-locality are an uncommon set of features in the design of online communities. However, these features were key to Yik Yak's initial success and popularity. In an interview-based study, we found that these three features deeply affected the identity of the community as a whole, the patterns of use, and the ways users committed to this community. We conducted interviews with 18 Yik Yak users on an urban American university campus and found that these three focal design features contributed to casual commitment, transitory use, and emergent community identity. We describe <i>situated anonymity</i>, which is the result of anonymity, ephemerality, and hyper-locality coexisting as focal design features of an online community. This work extends our understanding of use and identity-versus-bond based commitment, which has implications for the design and study of other atypical online communities.</p></div></span> <a id="expcoll733" href="JavaScript: expandcollapse('expcoll733',733)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3026026&CFID=758305256&CFTOKEN=14863114">Relational Distancing and Termination between Online Friends: An Application of the Investment Model</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Christopher J. Carpenter, Stephanie Tom Tong 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6925-6935</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3026026" title="DOI">10.1145/3025453.3026026</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3026026&ftid=1871130&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow734" style="display:inline;"><br /><div style="display:inline">This research examined the relational maintenance versus termination of online friendships in Facebook. Guided by Rusbult's [33] investment model (IM), the study constructed a model to examine 55 matched pairs of Facebook friends consisting of one "primary ...</div></span>
          <span id="toHide734" style="display:none;"><br /><div style="display:inline"><p>This research examined the relational maintenance versus termination of online friendships in Facebook. Guided by Rusbult's [33] investment model (IM), the study constructed a model to examine 55 matched pairs of Facebook friends consisting of one "primary user" and one "annoyer." Results indicated that primary users' judgments of relational satisfaction with annoyers were influenced by annoyers' narcissistic personality and their overall propensity for posting overly self-focused content. Commitment affected primary users' use of both passive "unfollowing" and active "unfriending" in response to annoyers' behavior. Decisions to maintain or terminate online friendships are related to judgments and actions of both partners. Overall, these results emphasize the dyadic nature of relational maintenance and termination processes in online environments, and the importance of studying them as such.</p></div></span> <a id="expcoll734" href="JavaScript: expandcollapse('expcoll734',734)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025804&CFID=758305256&CFTOKEN=14863114">Enhancing Personal Informatics Through Social Sensemaking</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Aare Puussaar, Adrian K. Clear, Peter Wright 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6936-6942</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025804" title="DOI">10.1145/3025453.3025804</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025804&ftid=1871132&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow735" style="display:inline;"><br /><div style="display:inline">Personal informatics practices are increasingly common, with a range of consumer technologies available to support, largely individual, interactions with data (e.g., performance measurement and activity/health monitoring). In this paper, we explore the ...</div></span>
          <span id="toHide735" style="display:none;"><br /><div style="display:inline"><p>Personal informatics practices are increasingly common, with a range of consumer technologies available to support, largely individual, interactions with data (e.g., performance measurement and activity/health monitoring). In this paper, we explore the concept of <i>social sensemaking</i>. In contrast to high-level statistics, we posit that social networking and reciprocal sharing of <i>fine-grained</i> self-tracker data can provide valuable context for individuals in making sense of their data. We present the design of an online platform called Citizense Makers (CM), which facilitates group sharing, annotating and discussion of self-tracker data. In a field trial of CM, we explore design issues around willingness to share data reciprocally; the importance of familiarity between individuals; and understandings of common activities in contextualising one's own data.</p></div></span> <a id="expcoll735" href="JavaScript: expandcollapse('expcoll735',735)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3026007&CFID=758305256&CFTOKEN=14863114">Sizing Up the Troll: A Quantitative Characterization of Moderator-Identified Trolling in an Online Forum</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Mattia Samory, Enoch Peserico 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6943-6947</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3026007" title="DOI">10.1145/3025453.3026007</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3026007&ftid=1871175&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow736" style="display:inline;"><br /><div style="display:inline">A few troublemakers often spoil online environments for everyone else. An extremely disruptive type of abuser is the troll, whose malicious activities are relatively non-obvious, and thus difficult to detect and contain -- particularly by automated systems. ...</div></span>
          <span id="toHide736" style="display:none;"><br /><div style="display:inline"><p>A few troublemakers often spoil online environments for everyone else. An extremely disruptive type of abuser is the troll, whose malicious activities are relatively non-obvious, and thus difficult to detect and contain -- particularly by automated systems. A growing corpus of qualitative research focuses on trolling, and differentiates it from other forms of abuse; however, its findings are not directly actionable into automated systems. On the other hand, quantitative research uses definitions of "troll" that mostly fail to capture what moderators and users consider trolling. We address this gap by giving a quantitative analysis of posts, conversations, and users, specifically sanctioned for trolling in an online forum. Although trolls (unlike most other abusers) hardly stand out in a conversation e.g. in terms of vocabulary, textit{how} they interact, rather than textit{what} they contribute, provides cues of their malicious intent.</p></div></span> <a id="expcoll736" href="JavaScript: expandcollapse('expcoll736',736)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Sharing, People and Communities</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3026056&CFID=758305256&CFTOKEN=14863114">Building a Maker Community Around an Open Hardware Platform</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Fabio Morreale, Giulio Moro, Alan Chamberlain, Steve Benford, Andrew P. McPherson 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6948-6959</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3026056" title="DOI">10.1145/3025453.3026056</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3026056&ftid=1871138&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow738" style="display:inline;"><br /><div style="display:inline">This paper reflects on the dynamics and practices of building a maker community around a new hardware platform. We examine the factors promoting the successful uptake of a maker platform from two perspectives: first, we investigate the technical and ...</div></span>
          <span id="toHide738" style="display:none;"><br /><div style="display:inline"><p>This paper reflects on the dynamics and practices of building a maker community around a new hardware platform. We examine the factors promoting the successful uptake of a maker platform from two perspectives: first, we investigate the technical and user experience considerations that users identify as the most important. Second, we explore the specific activities that help attract a community and encourage sustained participation. We present an inductive approach based on the case study of Bela, an embedded platform for creating interactive audio systems. The technical design and community building processes are detailed, culminating in a successful crowdfunding campaign. To further understand the community dynamics, the paper also presents an intensive three-day workshop with eight digital musical instrument designers. From observations and interviews, we reflect on the relationship between the platform and the community and offer suggestions for HCI researchers and practitioners interested in establishing their own maker communities.</p></div></span> <a id="expcoll738" href="JavaScript: expandcollapse('expcoll738',738)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025492&CFID=758305256&CFTOKEN=14863114">Celebratory Technology to Orchestrate the Sharing of Devices and Stories during Family Mealtimes</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Hasan Shahid Ferdous, Frank Vetere, Hilary Davis, Bernd Ploderer, Kenton O'Hara, Rob Comber, Geremy Farr-Wharton 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6960-6972</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025492" title="DOI">10.1145/3025453.3025492</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025492&ftid=1871193&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow739" style="display:inline;"><br /><div style="display:inline">While the idea of "celebratory technologies" during family mealtimes to support positive interactions at the dinner table is promising, there are few studies that investigate how these technologies can be meaningfully integrated into family practices. ...</div></span>
          <span id="toHide739" style="display:none;"><br /><div style="display:inline"><p>While the idea of "celebratory technologies" during family mealtimes to support positive interactions at the dinner table is promising, there are few studies that investigate how these technologies can be meaningfully integrated into family practices. This paper presents the deployment of Chorus - a mealtime technology that orchestrates the sharing of personal devices and stories during family mealtimes, explores related content from all participants' devices, and supports revisiting previously shared content. A three-week field deployment with seven families shows that Chorus augments family interactions through sharing contents of personal and familial significance, supports togetherness and in-depth discussion by combining resources from multiple devices, helps to broach sensitive topics into familial conversation, and encourages participation from all family members including children. We discuss implications of this research and reflect on design choices and opportunities that can further enhance the family mealtime experience.</p></div></span> <a id="expcoll739" href="JavaScript: expandcollapse('expcoll739',739)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025840&CFID=758305256&CFTOKEN=14863114">Exploring Topic-Based Sharing Mechanisms</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Manya Sleeper, Lorrie Faith Cranor, Sarah K. Pearman 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6973-6985</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025840" title="DOI">10.1145/3025453.3025840</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025840&ftid=1871196&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow740" style="display:inline;"><br /><div style="display:inline">General-purpose content-sharing platforms make it difficult for users to limit sharing to people interested in particular topics. Additional topic-based controls may allow users to better reach desired audiences. Designing such tools requires understanding ...</div></span>
          <span id="toHide740" style="display:none;"><br /><div style="display:inline"><p>General-purpose content-sharing platforms make it difficult for users to limit sharing to people interested in particular topics. Additional topic-based controls may allow users to better reach desired audiences. Designing such tools requires understanding current interest-based targeting techniques and the potential impact of additional mechanisms. We present an exploratory, interview-based study (n = 16) that addresses these dynamics for Facebook. We use diary-driven probes to explore general topic-based sharing across applications. We then use Facebook-based mockups to probe use cases and design tensions around adding topic-based sharing mechanisms to Facebook. We find that participants currently draw on various audience-limiting and reaching strategies to target interest-based audiences. Participants felt additional topic-based sharing mechanisms on Facebook might allow them to avoid oversharing or offending others and allow them to target improved audiences or share improved content. Usable topic-based sharing tools would also need to account, however, for participants' varied desired engagement strategies.</p></div></span> <a id="expcoll740" href="JavaScript: expandcollapse('expcoll740',740)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025579&CFID=758305256&CFTOKEN=14863114">HCI and Environmental Public Policy: Opportunities for Engagement</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Vanessa Thomas, Christian Remy, Mike Hazas, Oliver Bates 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6986-6992</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025579" title="DOI">10.1145/3025453.3025579</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025579&ftid=1871159&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow741" style="display:inline;"><br /><div style="display:inline">This note discusses opportunities for the HCI community to engage with environmental public policy. It draws on insights and observations made during the primary author's recent work for a policy unit at Global Affairs Canada, which is a federal ministry ...</div></span>
          <span id="toHide741" style="display:none;"><br /><div style="display:inline"><p>This note discusses opportunities for the HCI community to engage with environmental public policy. It draws on insights and observations made during the primary author's recent work for a policy unit at Global Affairs Canada, which is a federal ministry of the Government of Canada. During that work, the primary author identified several domains of environmental public policy that are of direct relevance to the HCI community. This note contributes a preliminary discussion of how, why, with whom, and in what capacity HCI researchers and practitioners might engage with three types of environmental public policy: climate change, waste electrical and electronic equipment, and green ICT procurement policies. This builds on existing public policy and environmental knowledge within the HCI community and responds directly to calls from some members to engage with environmental public policy.</p></div></span> <a id="expcoll741" href="JavaScript: expandcollapse('expcoll741',741)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Technology in the Workplace</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025620&CFID=758305256&CFTOKEN=14863114">Utilizing Experience Goals in Design of Industrial Systems</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Virpi Roto, Eija Kaasinen, Tomi Heimonen, Hannu Karvonen, Jussi P. P. Jokinen, Petri Mannonen, Hannu Nousu, Jaakko Hakulinen, Yichen Lu, Pertti O. Saariluoma, Tiina Kym&#228;l&#228;inen, Tuuli Keskinen, Markku Turunen, Hanna Maria Kaarina Koskinen 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 6993-7004</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025620" title="DOI">10.1145/3025453.3025620</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025620&ftid=1871136&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow743" style="display:inline;"><br /><div style="display:inline">The core idea of experience-driven design is to define the intended experience before functionality and technology. This is a radical idea for companies that have built their competences around specific technologies. Although many technology companies ...</div></span>
          <span id="toHide743" style="display:none;"><br /><div style="display:inline"><p>The core idea of experience-driven design is to define the intended experience before functionality and technology. This is a radical idea for companies that have built their competences around specific technologies. Although many technology companies are willing to shift their focus towards experience-driven design, reports on real-life cases about the utilization of this design approach are rare. As part of an industry-led research program, we introduced experience-driven design to metal industry companies with experience goals as the key technique. Four design cases in three companies showed that the goals are useful in keeping the focus on user experience, but several challenges are still left for future research to tackle. This exploratory research lays ground for future research by providing initial criteria for assessing experience design tools. The results shed light on utilizing experience goals in industrial design projects and help practitioners in planning and managing the product design process with user experience in mind.</p></div></span> <a id="expcoll743" href="JavaScript: expandcollapse('expcoll743',743)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025712&CFID=758305256&CFTOKEN=14863114">Evaluating Digital Creativity Support To Improve Health-and-Safety in a Manufacturing Plant</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Neil Maiden, Konstantinos Zachos, James Lockerbie, Sergio Levis, Kasia Camargo, Shaun Hoddy, Gianluca Allemandi 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 7005-7014</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025712" title="DOI">10.1145/3025453.3025712</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025712&ftid=1871197&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow744" style="display:inline;"><br /><div style="display:inline">This paper reports an evaluation of digital support for human creativity to improve health-and-safety in one manufacturing plant. It reports the use of this support as part of the plant's risk management process over 66 working days. Results revealed ...</div></span>
          <span id="toHide744" style="display:none;"><br /><div style="display:inline"><p>This paper reports an evaluation of digital support for human creativity to improve health-and-safety in one manufacturing plant. It reports the use of this support as part of the plant's risk management process over 66 working days. Results revealed that this use led to more complete, more useful and more novel risk resolutions, compared with the original paper process, and informed how digital creativity support can be rolled out across manufacturing plants, as well as to other domains not recognized as creative.</p></div></span> <a id="expcoll744" href="JavaScript: expandcollapse('expcoll744',744)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025650&CFID=758305256&CFTOKEN=14863114">The Design Fictions of Philanthropic IT: Stuck Between an Imperfect Present and an Impossible Future</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Ellie Harmon, Chris Bopp, Amy Voida 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 7015-7028</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025650" title="DOI">10.1145/3025453.3025650</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025650&ftid=1871171&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow745" style="display:inline;"><br /><div style="display:inline">In this paper, we examine the stories about philanthropic IT that circulate via product websites, marketing materials, and third-party news articles. Through a series of product-centered case studies, we surface these texts' implicit and explicit visions ...</div></span>
          <span id="toHide745" style="display:none;"><br /><div style="display:inline"><p>In this paper, we examine the stories about philanthropic IT that circulate via product websites, marketing materials, and third-party news articles. Through a series of product-centered case studies, we surface these texts' implicit and explicit visions about the (near) future of philanthropy. We detail their prescriptions about how, why, and in service of what ends nonprofit organizations could, should, and ought to leverage IT. We also examine their underlying assumptions about philanthropy: how social good is accomplished, how philanthropic organizations are - and might be more - effective, to whom organizations and beneficiaries should be accountable, and the terms of that accountability. Analyzing these visions as design fictions, we argue that they help cultivate unrealistic anticipatory relationships to the present and entail concomitantly unrealistic imperatives for the philanthropic sector. We conclude by arguing for the crucial role of HCI scholars in disrupting these impossible futures, and by highlighting areas needing further, re-imagined, research.</p></div></span> <a id="expcoll745" href="JavaScript: expandcollapse('expcoll745',745)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025487&CFID=758305256&CFTOKEN=14863114">Proxemic Transitions: Designing Shape-Changing Furniture for Informal Meetings</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Jens Emil Gr&#248;nb&#230;k, Henrik Korsgaard, Marianne Graves Petersen, Morten Henriksen Birk, Peter Gall Krogh 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 7029-7041</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025487" title="DOI">10.1145/3025453.3025487</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025487&ftid=1871166&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow746" style="display:inline;"><br /><div style="display:inline">The field of Shape-Changing Interfaces explores the qualities of physically dynamic artifacts. At furniture-scale, such artifacts have the potential of changing the ways we collaborate and engage with interiors and physical spaces. Informed by theories ...</div></span>
          <span id="toHide746" style="display:none;"><br /><div style="display:inline"><p>The field of Shape-Changing Interfaces explores the qualities of physically dynamic artifacts. At furniture-scale, such artifacts have the potential of changing the ways we collaborate and engage with interiors and physical spaces. Informed by theories of proxemics, empirical studies of informal meetings and design work with shape-changing furniture, we develop the notion of proxemic transitions. We present three design aspects of proxemic transitions: transition speed, stepwise reconfiguration, and radical shifts. The design aspects focus on how to balance between physical and digital transformations in designing for proxemic transitions. Our contribution is three-fold: 1) the notion of proxemic transitions, 2) three design aspects to consider in designing for proxemic transitions, and 3) initial exploration of how these design aspects might generate designs of dynamic furniture. These contributions outline important aspects to consider when designing shape-changing furniture for informal workplace meetings.</p></div></span> <a id="expcoll746" href="JavaScript: expandcollapse('expcoll746',746)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="2">SESSION: <strong>Technology Use Challenges for Older Adults</strong></td>
  </tr>
  
          <tr>
          <td></td>
          <td style="padding-bottom:5px;">
          
          </td>
          </tr>

          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025802&CFID=758305256&CFTOKEN=14863114">Successful Leisure in Independent Living Communities: Understanding Older Adults' Motivations to Engage in Leisure Activities</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Amanda Lazar, David H. Nguyen 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 7042-7056</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025802" title="DOI">10.1145/3025453.3025802</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025802&ftid=1871180&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow748" style="display:inline;"><br /><div style="display:inline">Leisure activities are a source of meaning and enjoyment for individuals across the lifespan. In this study, we conducted interviews with twenty-four older adults living in four different independent living communities. We present societal and ecological ...</div></span>
          <span id="toHide748" style="display:none;"><br /><div style="display:inline"><p>Leisure activities are a source of meaning and enjoyment for individuals across the lifespan. In this study, we conducted interviews with twenty-four older adults living in four different independent living communities. We present societal and ecological factors and motivations that influenced the way people participated in and decided what constitutes leisure activities. The goal of maintaining physical and cognitive health was often intertwined with motivations to engage in leisure activities. We discuss how this fits into the broader framework of successful aging and implications for technology design. We also provide an example of how findings from this study can be applied to a specific leisure activity: watching television.</p></div></span> <a id="expcoll748" href="JavaScript: expandcollapse('expcoll748',748)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
            
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025859&CFID=758305256&CFTOKEN=14863114">Navigating Relationships and Boundaries: Concerns around ICT-uptake for Elderly People</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Dominik Hornung, Claudia M&#252;ller, Irina Shklovski, Timo Jakobi, Volker Wulf 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 7057-7069</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025859" title="DOI">10.1145/3025453.3025859</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025859&ftid=1871189&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow749" style="display:inline;"><br /><div style="display:inline">Despite a proliferation of research in the use of ICTs to support active and healthy ageing, few have considered the privacy and security concerns particular to the elderly. We investigated the appropriation of tablet devices and a neighborhood portal ...</div></span>
          <span id="toHide749" style="display:none;"><br /><div style="display:inline"><p>Despite a proliferation of research in the use of ICTs to support active and healthy ageing, few have considered the privacy and security concerns particular to the elderly. We investigated the appropriation of tablet devices and a neighborhood portal as well as emerging privacy and security issues through ethnographic and action research in a long-term participatory design (PD) project with elderly participants. We discuss two major themes: a) the tensions related to perceived digital threats and the social pressures of online disclosure to the social environment; and b) the relation of these issues to the ICT appropriation process and the referring challenges we encountered. We argue that there is a need to understand the interleaving of physical and virtual habitats, the various ways resulting in discomfort and the senior citizens' actions -- which at first glance appear contradictory. We consider the implications of the issues observed for examining privacy and security concerns more broadly as well as discussing implications for the design of the portal and the shaping of social measures for appropriation support.</p></div></span> <a id="expcoll749" href="JavaScript: expandcollapse('expcoll749',749)">expand</a>
          </div>
		  </td>
          </tr>          
          
  <tr>
 
  
  <td>
  
                  <img src="images/hm_award.jpg" alt="Honorable Mention" style="vertical-align: middle">
                        
  </td>
  <td colspan="1"><span style="padding-left:20"><a href="citation.cfm?id=3025945&CFID=758305256&CFTOKEN=14863114">Older Adults Learning Computer Programming: Motivations, Frustrations, and Design Opportunities</a></span></td>
  </tr>
  
          <tr>
          <td> </td>
          <td>
          <span style="padding-left:20">
          Philip J. Guo 
          </span>    
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td> <span style="padding-left:20">Pages: 7070-7083</span></td>
          </tr>
          
          <tr>
          <td></td>

          <td> <span style="padding-left:20">doi&gt;<a href="https://doi.org/10.1145/3025453.3025945" title="DOI">10.1145/3025453.3025945</a></span></td>          
          </tr>
          
          <tr>
          <td></td>
          <td>
           <span style="padding-left:20">
          Full text: <a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3025945&ftid=1871176&dwn=1&CFID=758305256&CFTOKEN=14863114" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
           </span>
          </td>
          </tr>
          
          <tr>
          <td></td>
          <td style="padding-bottom:15px;">
          <div style="padding-left:20">
          <span id="toShow750" style="display:inline;"><br /><div style="display:inline">Computer programming is a highly in-demand skill, but most learn-to-code initiatives and research target some of the youngest members of society: children and college students. We present the first known study of older adults learning computer programming. ...</div></span>
          <span id="toHide750" style="display:none;"><br /><div style="display:inline"><p>Computer programming is a highly in-demand skill, but most learn-to-code initiatives and research target some of the youngest members of society: children and college students. We present the first known study of older adults learning computer programming. Using an online survey with 504 respondents aged 60 to 85 who are from 52 different countries, we discovered that older adults were motivated to learn to keep their brains challenged as they aged, to make up for missed opportunities during youth, to connect with younger family members, and to improve job prospects. They reported frustrations including a perceived decline in cognitive abilities, lack of opportunities to interact with tutors and peers, and trouble dealing with constantly-changing software technologies. Based on these findings, we propose a learner-centered design of techniques and tools for motivating older adults to learn programming and discuss broader societal implications of a future where more older adults have access to computer programming -- not merely computer literacy -- as a skill set.</p></div></span> <a id="expcoll750" href="JavaScript: expandcollapse('expcoll750',750)">expand</a>
          </div>
		  </td>
          </tr>          
          
</table>




</div> 